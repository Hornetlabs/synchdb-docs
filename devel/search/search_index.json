{"config":{"lang":["en","es","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"About","text":""},{"location":"#about-synchdb","title":"About SynchDB","text":"<p>SynchDB is a PostgreSQL extension that enables fast and reliable replication from heterogeneous databases \u2014 such as MySQL, SQL Server, and Oracle \u2014 directly into PostgreSQL. Unlike traditional data pipelines, SynchDB handles the entire synchronization and data conversion process natively within PostgreSQL, without requiring any middleware or external orchestration tools. It mainly manages the following end-to-end tasks:</p> <ul> <li>Establishes and maintains connections to external databases</li> <li>Captures change events from source systems</li> <li>Transforms these events into PostgreSQL-compatible formats</li> <li>Applies them to PostgreSQL</li> </ul> <p>At its core, SynchDB integrates the Debezium Embedded Engine, a powerful Java-based change data capture (CDC) library that supports multiple database connectors. SynchDB bridges PostgreSQL's C-based runtime and Debezium's Java environment using the Java Native Interface (JNI), enabling seamless cooperation between both worlds.</p> <p>This architecture allows PostgreSQL to leverage the rich ecosystem of Debezium connectors while keeping the extension lightweight, flexible, and easy to deploy.</p> <p>\ud83d\udd17 Learn more about Debezium here.</p>"},{"location":"#notable-features","title":"Notable Features","text":"<ul> <li>Efficient data synchronization</li> <li>Support replication from MySQL, SQL Server and Oracle databases</li> <li>Flexible data transformation rules, including table names, column names, data types and custom data transform expression</li> <li>Easy integration with existing PostgreSQL databases</li> <li>Initial snapshot and Change Data Capture (CDC) modes</li> <li>Support DDL and DML logical replication</li> <li>Global connector state, error and statistic provisioning</li> </ul>"},{"location":"#supported-postgresql-versions","title":"Supported PostgreSQL Versions","text":"<ul> <li>PostgreSQL: 16, 17, 18</li> <li>IvorySQL: 4, 5</li> </ul>"},{"location":"#supported-source-databasess","title":"Supported Source Databasess","text":"<ul> <li>MySQL: 8.0.x, 8.2</li> <li>SQL Server: 2017, 2019, 2022</li> <li>Oracle: 12c, 19c, 21c, 23ai</li> <li>Openlog Replicator: 1.3.0 ~ 1.8.5</li> </ul>"},{"location":"#required-third-party-libraries-and-extensions","title":"Required Third Party Libraries and extensions","text":"<ul> <li>Java Runtime Environment\uff08JRE) 17 or above</li> <li>pgcrypto extension - for encrypt and decrypt credentials</li> </ul>"},{"location":"#optional-third-party-libraries-and-extensions","title":"Optional Third Party Libraries and extensions","text":"<ul> <li>libprotobuf-c v1.5.2 (tested version) (optional for Openlog Replicator support)</li> <li>oracle_fdw extension v2.8.0 (tested version) (needed if you choose to use fdw based initial snapshot for OLR or Oracle connector)</li> <li>mysql_fdw extensions v2.9.3 (tested version) (needed if you choose to use fdw based initial snapshot for MySQL connector)</li> <li>postgres_fdw extension - (needed if you need initial snapshot for PostgreSQL connector)</li> </ul>"},{"location":"#version-history","title":"Version History","text":"<ul> <li>SynchDB v1.3</li> <li>SynchDB v1.2</li> <li>SynchDB v1.1</li> <li>SynchDB v1.0</li> <li>SynchDB v1.0 Beta1</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>The quickest way to get started with SynchDB is to use the pre-compiled Docker images together with the companion images for source database systems (MySQL, SQL Server, Oracle, etc.), all driven by the <code>ezdeploy.sh</code> tool in the source repository. This interactive tool can spin up SynchDB, one or more source databases, and optional Prometheus + Grafana for monitoring, perfect for a fast end-to-end smoke test. For step-by-step instructions, refer to the Quick Start Guide.</p> <p>Other useful links:</p> <ul> <li>SynchDB Architecture Decisions</li> <li>Installation Guide</li> <li>Source Database Setups</li> </ul>"},{"location":"changelog/","title":"Change Log","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#synchdb-13-2025-11-25","title":"SynchDB 1.3 - 2025-11-25","text":"<p>SynchDB 1.3 delivers a major performance enhancement with the new FDW-based snapshot engine, offering significantly faster initial snapshot performance over Debezium. This advancement makes OpenLog Replicator (OLR) connector a fully native snapshot + CDC pipeline (no Debezium is used) with significantly reduced latency and overhead for large Oracle datasets. Platform support has been broadened as well. SynchDB now runs on PostgreSQL 18 and IvorySQL 5, accompanied by a series of performance optimizations and I/O improvements across the system.</p>"},{"location":"changelog/#added","title":"Added","text":""},{"location":"changelog/#fdw-based-snapshot-engine","title":"FDW-based Snapshot Engine","text":"<ul> <li>FDW-based snapshot provides a much faster alternative to Debezium's initial snapshot process</li> <li>Added a new GUC parameter \"synchdb.snapshot_engine\" to select snapshot engine, can be \"debezium\" or \"fdw\"</li> <li>Added a new GUC parameter \"synchdb.cdc_start_delay_ms\" to add a millisecond delay that needs to be waited after initial snapshot is completed and before CDC is started.</li> <li>Added a new GUC parameter \"synchdb.fdw_migrate_with_subtx\" to use sub-transactions to migrate each table or not during FDW-based snapshot process.</li> <li>Applicable only to Openlog Replicator and Oracle connector types via oracle_fdw 2.8.0. Other connector types may be supported in future releases.</li> <li>Supported a retry mechanism: If some tables fail to snapshot, the error messages will be saved to synchdb_fdw_snapshot_errors_xxx table and can be retried by resuming the connector. Tables that succeeded will remain.</li> <li>If 'schemasync' or 'nodata' snapshot mode is used, FDW-engine will synchronize table schemas only.</li> <li>Tables and data created via FDW-engine are subject to name and expression transformation rules as defined in \"synchdb_objmap\" </li> <li>Added a new function synchdb_translate_datatype() that returns SynchDB's data type translation results based on selected connector type.</li> </ul>"},{"location":"changelog/#revamped-statistics-views","title":"Revamped Statistics Views","text":"<ul> <li>Revamped statistics view to group different statistics to proper categories.</li> <li>synchdb_stats_view() has been removed</li> <li>Added a new view called synchdb_genstats that records statistics about batches of events processed</li> <li>Added a new view called synchdb_snapstats that records statistics about initial snapshot process</li> <li>Added a new view called synchdb_cdcstats that records statistics about CDC process</li> </ul>"},{"location":"changelog/#postgresql-18-and-ivorysql-5-compatibility","title":"PostgreSQL 18 and IvorySQL 5 Compatibility","text":"<ul> <li>SynchDB is compatible with PostgreSQL 18 and IvorySQL 5.</li> <li>When running FDW-based snapshot under IvorySQL 5 in 'oracle' compatible mode, this mode will be switched back to 'pg' mode for the duration of the snapshot because the PL/pgSQL functions are written in PostgreSQL standard.</li> <li>Synchdb will set \"ivorysql.identifier_case_switch\" settings to 'normal' in SynchDB workers to prevent letter casing being reversed undesirably.</li> <li>Renamed liboracle_parser.so and oracle_raw_parser() symbol inside to libsynchdb_oracle_parser.so and synchdb_oracle_raw_parser() to prevent symbol name conflicts with IvorySQL.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Openlog Replicator Connector: Enhanced Oracle parser to support more contraint operators: enable, disable, novalidate, validate</li> <li>Openlog Replicator Connector: Enhanced Oracle parser to support MODIFY clauses with and without paraenthesis</li> <li>Openlog Replicator Connector: Enhanced Oracle parser to support DEFAULT ON NULL clauses.</li> <li>Openlog Replicator Connector: Improve processing performance by removing one pre-scan loop.</li> <li>Openlog Replicator Connector: Optimized non-null terminated event processing as PostgreSQL text type to save one copy operation. (PG17+)</li> <li>Openlog Replicator Connector: default read buffer size changed to 128MB</li> <li>Openlog Replicator Connector: added a new GUC parameter \"synchdb.olr_read_timeout_ms\" to configure read timeout.</li> <li>Openlog Replicator Connector: added a new GUC parameter \"synchdb.olr_connect_timeout_ms\" to configure connect timeout.</li> <li>Openlog Replicator Connector: will ignore \"log_mining_flush\" table created by Debezium.</li> <li>Updated default data type mappings for all connector types</li> <li>More robust JSON processing: no longer crashes when a JSON element fails to look up </li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Openlog Replicator Connector: fixed an issue where Oracle parser fails to parse when running under PostgreSQL 16</li> <li>Openlog Replicator Connector: fixed an issue where unexpected DDL statement with system owner get passed to SynchDB by mistake</li> <li>Openlog Replicator Connector: Adjusted the SCN and C_SCN values to resume CDC as stored in the offset file rather than adding 1 to them, which could potentially skip a previously failed change event upon resume.</li> <li>Synchdb now allows source table or schema names to contain spaces.</li> <li>Fixed the incorrect processing of negative decimal values.</li> <li>Fixed the incorrect processing of large decimal overflow values. </li> <li>Fixed an issue in Oracle's default data type mappings for NUMBER that omits the length and scale by mistake.</li> <li>Fixed the missing default data type mappings with auto_increment attributes for mysql connector</li> </ul>"},{"location":"changelog/#known-issues-and-additional-info","title":"Known Issues and Additional Info","text":"<ul> <li>SynchDB always normalize incoming table, schema and column names to lowercase letters before applying them to PostgreSQL, this is a problem if source table supports objects with the same name but in different cases. For example, 'mytable' and 'MYTABLE' are considered different in MySQL and Oracle. Link to the issue here</li> <li>FDW-based snapshot for MySQL and SQL server are not supported yet and we may add support for them in future releases. More info here</li> </ul>"},{"location":"changelog/#synchdb-12-2025-09-04","title":"SynchDB 1.2 - 2025-09-04","text":"<p>SynchDB 1.2 introduces introduces a native Openlog Replicator connector (BETA), enhanced monitoring with JMX and Grafana, and a new ezdeploy.sh tool for quick deployments and testing. It also adds snapshot table selection, performance improvements, and key fixes, while addressing connector isolation and stability issues.</p>"},{"location":"changelog/#added_1","title":"Added","text":""},{"location":"changelog/#native-openlog-replicator-connector-beta","title":"Native Openlog Replicator Connector - BETA","text":"<ul> <li>Added <code>synchdb_add_olr_conninfo</code> and <code>synchdb_del_olr_conninfo</code> to enable or disable openlog replicator based streaming.</li> <li>Added a new connector type <code>olr</code>, which is a native (no Debezium) openlog replicator client that stream Oracle database changes from an external Openlog Replicator service. </li> <li>Supported DMLs: insert, update delete</li> <li>Supported DDLs: CREATE TABLE, DROP TABLE, ALTER TABLE MODIFY, ALTER TABLE ADD/DROP COLUMN, ALTER TABLE ADD/DROP CONSTRAINT, TRUNCATE</li> <li>Based on libprotobuf-c to communiate with Openlog Replicator and IvorySQL's Oracle parser to process incoming DDL query events,</li> <li>Supported snapshot modes: initial, initial_only, no_data, always, never</li> <li>Supported batching, schema history, and offset management just like other Debezium based connectors.</li> <li>Supported Debezium-based Openlog Replicator connector in addition to native.</li> </ul>"},{"location":"changelog/#monitoring","title":"Monitoring","text":"<ul> <li>Added <code>synchdb_add_jmx_conninfo</code> and <code>synchdb_del_jmx_conninfo</code> to enable or disable JMX based monitoring.</li> <li>Added <code>synchdb_add_jmx_exporter_conninfo</code> and <code>synchdb_del_jmx_exporter_conninfo</code> to enable and disable monitoring support with Prometheus and Grafana.</li> <li>Added Grafana based dashboard templates for supported Debezium based connectors (MySQL, SQL Server and Oracle).</li> </ul>"},{"location":"changelog/#ezdeploysh","title":"ezdeploy.sh","text":"<ul> <li>Added <code>ezdeploy.sh</code> tool that can quickly deploy a pre-build SynchDB and selected source database types to do quick connector testing.</li> <li>supported deployment: MySQL, SQL Server, Oracle23ai, Oracle19c, Openlog Replicator 1.3.0</li> <li>supported Prometheus and Grafana deployment with preloaded dashboards.</li> <li>Supported pre-compiled SynchDB v1.2 for quick deployment + tests</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Added a new argument called <code>snapshot table</code> in <code>synchdb_add_conninfo</code> to allow users to select which tables to redo initial snapshot when started in <code>always</code> snapshot mode.</li> <li>Updated pytest framework to support hammerdb based TPC tests for Oracle.</li> <li>Enhanced the performance of event polling between Debezium engine and SynchDB by using direct buffer instead of frequent JNI calls. </li> <li>When a connector is resumed via <code>synchdb_resume_engine</code>, it will always resume in <code>initial</code> snapshot mode rather than the mode it was first started with.</li> <li><code>synchdb_state_view</code> and <code>synchdb_stats_view</code> will now only display connector information created by the current SynchDB extension. Connectors created by other SynchDB extensions in different databases will not be shown.</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Fixed a crash in <code>spi_execute_select_one()</code> where it would return a reference that has been destroyed by SPI memory context at the end of a successful SPI execution.</li> <li>Resolved compilation issues with SynchDB when PostgreSQL is built with cassert.</li> <li>Fixed an issue where multiple connectors created with the same name by multiple SynchDB extensions (created in different databases) overwrite each other's shared memory data.</li> </ul>"},{"location":"changelog/#known-issues-and-additional-info_1","title":"Known Issues and Additional Info","text":"<ul> <li>Native Openlog Replicator Connector currently stream all tables under specified database. Table Filtering is to be configured in Openlog Replicator rather than SynchDB.</li> <li>Prometheus and Grafana based monitoring require JMX Exporter which can be downloaded here</li> </ul>"},{"location":"changelog/#synchdb-11-2025-04-17","title":"SynchDB 1.1 - 2025-04-17","text":"<p>SynchDB 1.1 introduces Oracle connector support, enhanced data type transformation capabilities, and significantly improved core data processing engine. This update enhances performance through intelligent caching and optimized JSON parsing, while extending compatibility with PostgreSQL 16, 17, and IvorySQL 4.4.</p>"},{"location":"changelog/#added_2","title":"Added","text":""},{"location":"changelog/#connector-support","title":"Connector Support","text":"<ul> <li>added Oracle connector support.</li> <li>added support for PostgreSQL 16, 17 and IvorySQL 4.4</li> <li>added support for Oracle's variable size/scale data type <code>NUMBER</code> processing. </li> </ul>"},{"location":"changelog/#object-mapping-data-transformation","title":"Object Mapping &amp; Data Transformation","text":"<ul> <li>Added new <code>synchdb_objmap</code> table to store object mapping entries</li> <li>Added new <code>synchdb_add_objamp()</code> function to add object mappings for table names, column names, data types, and transform expressions</li> <li>Added new <code>synchdb_reload_objmap()</code> function to force connectors to reload object mappings</li> <li>Added new <code>synchdb_del_objmap()</code> function to disable and remove object mapping entries</li> <li>Normalized all data type mapping entries to use lowercase letters</li> </ul>"},{"location":"changelog/#metadata-monitoring","title":"Metadata &amp; Monitoring","text":"<ul> <li>Added new <code>synchdb_attribute</code> table that stores remote table attribute information</li> <li>Added new <code>synchdb_att_view</code> view showing side-by-side comparison of data type, table and column name mappings</li> <li>Added source timestamp, DBZ timestamp and PG timestamp information in <code>synchdb_get_stats</code></li> </ul>"},{"location":"changelog/#connection-management","title":"Connection Management","text":"<ul> <li>Added <code>synchdb_add_extra_conninfo()</code> function to configure extra SSL connection parameters</li> <li>Added <code>synchdb_del_extra_conninfo()</code> function to remove all extra parameters created by <code>synchdb_add_extra_conninfo()</code></li> <li>Added <code>synchdb_del_conninfo()</code> function to remove existing connector information</li> </ul>"},{"location":"changelog/#configuration-control","title":"Configuration &amp; Control","text":"<ul> <li>Added new GUC <code>synchdb.error_handling_strategy</code> to control error handling strategy (skip, exit, or retry)</li> <li>Added new GUC <code>synchdb.dbz_log_level</code> to control the log level of Debezium runner engine</li> <li>Added new <code>schemasync</code> snapshot mode</li> </ul>"},{"location":"changelog/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Optimized DML parser to use cached hash table rather than accessing the catalog and rebuilding the hash at every change event</li> <li>DML parser now uses more efficient JSONB API calls for increased performance</li> <li>Optimized JNI calls to use cached JNI handle rather than recreating at every change event</li> <li>Enhanced batch completion marking by only marking the first and last change events within a batch</li> <li>Revamped data processing engine with more modular design to handle complex data type mappings</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>When processing ALTER TABLE change events, SynchDB now only adds a primary key when the table itself has no primary key</li> <li>Removed the ability to configure connectors to connect to PostgreSQL databases other than where SynchDB is installed</li> <li>SynchDB now updates the new <code>synchdb_attribute</code> table at the end of every DDL change event processing</li> <li>Connectors now correct table names, column names, and data types when configured object mappings differ from current values</li> <li>Rule files have been replaced by <code>synchdb_add_objmap()</code> utilities</li> <li>All ID-based SQL function column definitions have changed data types from TEXT to NAME</li> <li>Removed the rulefile parameter from <code>synchdb_add_conninfo()</code></li> <li>Non-native data types are now processed based on their category rather than all being treated as text</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Fixed an issue where SPI update or delete could fail when only including primary key fields in WHERE clause</li> <li>Fixed an issue with ALTER TABLE errors when attempting to add duplicate primary keys</li> <li>Fixed an issue where SynchDB occasionally incorrectly looks up column schema values from JSON change events</li> <li>Fixed an issue in 'skip on error' mode causing panics due to error stack overflow</li> <li>Fixed an issue in ALTER TABLE ADD and DROP column operations not recognizing column name mappings in PostgreSQL</li> </ul>"},{"location":"changelog/#synchdb-10-2024-12-24","title":"SynchDB 1.0 - 2024-12-24","text":"<p>This release focuses on bug fixes and performance enhancements following the v1.0 Beta1 release that generally makes it more usable under moderate to high data loads. A lot more Debezium tuning related parameters have also been exposed as PostgreSQL GUCs, allowing user to test with different parameters.</p>"},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>added a data cache in DML parsing stage to prevent frequent access to PostgreSQL's catalog to obtain a table's tuple descriptor structure.</li> <li>added a variant of <code>synchdb_start_engine_bgw(name, mode)</code> that takes a second argument to indicate a custom snapshot mode to start the connector with.</li> <li>added several new GUCs that can be adjusted to tune the performance of Debezium Runner. Refer to here for complete list.</li> <li>added a debug SQL function <code>synchdb_log_jvm_meminfo(name)</code> that causes specified connector to output current JVM heap memory usage summary in PostgreSQL log file.</li> <li>added a new VIEW <code>synchdb_stats_view</code> that prints statistic information for all connectors.</li> <li>added a new SQL function <code>synchdb_reset_stats(name)</code> to clear statistic information of specified connector.</li> <li>added a mess creation script to quickly generate test tables and data on MySQL database type.</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>synchdb_state_view(): added a new field called <code>stage</code> that indicates the current stage of a connector (value can either be <code>Initial Snapshot</code> or <code>Change Data Capture</code>).</li> <li>synchdb_state_view(): will only show state of valid connectors.</li> <li>removed sending \"partial batch completion\" notification to Debezium Runner in case of error, because a batch is now handled by one PostgreSQL transaction, and partial completion is not allowed.</li> <li>SSL related parameters per connector can now be specified in the rule file.</li> <li>the maximum heap memory to allocate to JVM that runs the Debezium Runner can now be configured via GUC.</li> <li>max number of connector background worker is now configurable instead of hardcoded 30.</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>fixed rapid memory buildups in Debezium runner in JVM by adding a throttle control in the receiving of change events.</li> <li>resolved majority of memory leak in both SynchDB and Debezium runner components.</li> <li>corrected the use of memory context in SynchDB such that heap memory can be correctly freed at the end of each change event processing.</li> <li>significantly increased the processing speed of SynchDB by processing a batch within a single PostgreSQL transaction rather than multiple.</li> <li>corrected SQLServer's default data type size mapping for <code>char</code> type from 0 to -1.</li> <li>resolved high memory usage during DML processing using SPI.</li> </ul>"},{"location":"changelog/#synchdb-10-beta1-2024-10-23","title":"SynchDB 1.0 Beta1 - 2024-10-23","text":"<p>The first SynchDB beta software release that lays a robust foundation for seamless replication from heterogeneous databases to PostgreSQL.</p>"},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>logical replication from heterogeneous databases: (MySQL and SQLServer).</li> <li>DDL replication (CREATE TABLE, DROP TABLE, ALTER TABLE ADD COLUMN, ALTER TABLE DROP COLUMN, ALTER TABLE ALTER COLUMN).</li> <li>DML replication (INSERT, UPDATE, DELETE).</li> <li>max 30 concurrent connector workers.</li> <li>automatic connector launcher at PostgreSQL startup.</li> <li>global connector state and last error message views.</li> <li>selective databases and tables replication.</li> <li>change events in batches.</li> <li>connector restarts in different snapshot modes.</li> <li>offset management interfaces to select custom replication resume point.</li> <li>default data type and object name transform rules for supported heterogeneous databases.</li> <li>JSON rule file to define custom: (data type, column name, table name and data expression transform rules).</li> <li>2 data apply modes (SPI, HeapAM API).</li> <li>several utility functions to perform connector operations: (start, stop, pause, resume).</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":""},{"location":"changelog/#fixed_4","title":"Fixed","text":""},{"location":"architecture/architecture/","title":"Architecture Overview","text":""},{"location":"architecture/architecture/#overall-archtecture-diagram","title":"Overall Archtecture Diagram","text":"<p>SynchDB extension consists of 2 code spaces (Java and C) with JNI sitting in between them as facilitator.</p> <p>Debezium Runner - Java</p> <ul> <li>Debezium Runner Driver</li> <li>Embedded Debezium Engine</li> </ul> <p>SynchDB Extension - C</p> <ul> <li>SynchDB Launcher</li> <li>SynchDB Worker</li> <li>Format Converter</li> <li>Replication Agent</li> </ul> <p>The 2 code spaces are interconnected via Java Native Interface (JNI), which is a framework that allows Java applications to interact with native code written in languages like C or C++ and vice versa. It enables Java programs to call and be called by native applications and libraries, providing a bridge between Java\u2019s platform independence and the performance advantages of native code. JNI is commonly used to integrate platform-specific features, optimize performance-critical sections of an application, or access legacy libraries that are not available in Java. It requires careful management of resources, as it involves switching between the Java Virtual Machine (JVM) and native environments, which can introduce complexity.</p> <p>For this reason, SynchDB requires JNI to exchange resources between Debezium runner engine and SynchDB PostgreSQL extension. JNI is available with Java Installation (ex. openjdk).</p>"},{"location":"architecture/architecture/#debezium-runner-java","title":"Debezium Runner - Java","text":"<p>This is the driver program in Java that utilizes the Debezium Embedded Engine with various <code>connectors</code> to different database sources. This is the key underlying components that make logical replication from multiple database vendors possible. Its main responsibility is to connect to the specified remote database and periodically fetch its changes and convert them to a common JSON structure. This JSON structure is then passed down to <code>SynchDB Extension in C</code> to process and eventually apply the changes to PostgreSQL.</p> <p>Debezium Runner Component Architecture</p>"},{"location":"architecture/architecture/#synchdb-extension-c","title":"SynchDB Extension - C","text":"<p>This is the main entrypoint that initializes a Java Virtual Machine (JVM) and run Debezium Runner on it. It periodically fetches a batch of JSON change events from Debezium Runner, process the data and apply them to PostgreSQL. It is also responsible for notifying Debezium that it has successfully completed a batch of JSON change events so that both components are synchronized in terms of replication progress. </p> <ul> <li>Debezium Event Processor Architecture</li> <li>Openlog Replicator Event Processor Architecture</li> </ul>"},{"location":"architecture/batch_change_handling/","title":"Batch Change Handling","text":""},{"location":"architecture/batch_change_handling/#overview","title":"Overview","text":"<p>SynchDB periodically fetches a batch of change request from Debezium runner engine at a period of <code>synchdb.naptime</code> milliseconds (default 100). This batch of change request is then processed by SynchDB. If all the change requests within the batch have been processed successfully (parsed, transformed and applied to PostgreSQL), SynchDB will notify the Debezium runner engine that this batch has been completed. This signals Debezium runner to commit the offset up until the last successfully completed change record. With this mechanism in place, SynchDB is able to track each change record and instruct Debezium runner not to fetch an old change that has been processed before, or not to send a duplcate change record.</p>"},{"location":"architecture/batch_change_handling/#batch-handling","title":"Batch Handling","text":"<p>SynchDB processes a batch within one transaction. This means the change events inside a batch are either all or none processed. When all the changes have been successfully processed, SynchDB simply sends a message to Debezium runner engine to mark the batch as processed and completed. This action causes offsets to be committed and eventually flush to disk. An offset represents a logical location during a replication similar to the LSN (Log Seqeuence Number) in PostgreSQL.</p> <p></p> <p>If a batch of changes are partially successful on PostgreSQL, it would cause the transaction to rollback and SynchDB will not notify Debezium runner about batch completion. When the connector is restarted, the same batch will resume processing again.</p>"},{"location":"architecture/batch_change_handling/#batch-handling-for-openlog-replicator-connector","title":"Batch Handling for Openlog Replicator Connector","text":"<p>Since Openlog Replicator Connector does not rely on Debezium to orchestrate batches of change events, its batch processing is determined purely on the OLR client's raw read buffer size (configured by GUC <code>synchdb.olr_read_buffer_size</code>). The client tries to read as much data as possible from the socket, which could compose of multiple change events. However many \"complete\" change events appear in the read buffer are considered in the same batch and will be executed in the same PostgreSQL transaction. If the read buffer contains incomplete change event, it will not be considered in the current batch. It is expected that in the next read, the remaining data of this incomplete change event will arrive and will be part of the next batch of change events.</p> <p>So, increasing the value of <code>synchdb.olr_read_buffer_size</code> increases the batch size.</p>"},{"location":"architecture/ddl_replication/","title":"DDL Replication","text":""},{"location":"architecture/ddl_replication/#overview","title":"Overview","text":"<p>SynchDB provides comprehensive support for Data Definition Language (DDL) operations, allowing real-time schema synchronization across different database systems.</p>"},{"location":"architecture/ddl_replication/#supported-ddl-commands","title":"Supported DDL Commands","text":"<p>SynchDB supports the following general DDL operations for Debezium based connectors (MySQL, SQL Server, Oracle):</p> <p>\u2705 CREATE [table] \u2705 ALTER [table] ADD COLUMN \u2705 ALTER [table] DROP COLUMN \u2705 ALTER [table] ALTER COLUMN \u2705 DROP [table]</p> <p>For Openlog Replicator based connector these Oracle DDL syntax is supported: </p> <p>\u2705 CREATE [table] \u2705 DROP [table] \u2705 ALTER [table] MODIFY \u2705 ALTER [table] ADD COLUMN \u2705 ALTER [table] DROP COLUMN \u2705 ALTER [table] ADD CONSTRAINT \u2705 ALTER [table] DROP CONSTRAINT</p>"},{"location":"architecture/ddl_replication/#detailed-command-support","title":"Detailed Command Support","text":""},{"location":"architecture/ddl_replication/#create-table","title":"CREATE TABLE","text":"<p>SynchDB captures these properties during CREATE TABLE events:</p> Property Description Table Name Fully Qualified Name (FQN) format Column Names Individual column identifiers Data Types Column data type specifications Data Length Length/precision specifications (if applicable) Unsigned Flag Unsigned constraints for numeric types Nullability NULL/NOT NULL constraints Default Values Default value expressions Primary Keys Primary key column definitions <p>Note: Additional CREATE TABLE properties are not currently supported</p>"},{"location":"architecture/ddl_replication/#drop-table","title":"DROP TABLE","text":"<p>Captured properties: - Table name (in FQN format) to be dropped</p>"},{"location":"architecture/ddl_replication/#alter-table-add-column","title":"ALTER TABLE ADD COLUMN","text":"<p>Captures the following properties:</p> Property Description Column Names Names of newly added columns Data Types Data types for new columns Data Length Length specifications (if applicable) Unsigned Flag Unsigned constraints Nullability NULL/NOT NULL specifications Default Values Default value expressions Primary Keys Updated primary key definitions <p>Other properties that can be specified during ALTER TABLE ADD COLUMN  are not supported at the moment.</p>"},{"location":"architecture/ddl_replication/#alter-table-drop-column","title":"ALTER TABLE DROP COLUMN","text":"<p>Captures: - List of column names to be dropped</p>"},{"location":"architecture/ddl_replication/#alter-table-alter-column","title":"ALTER TABLE ALTER COLUMN","text":"<p>Supported modifications:</p> Modification Description Data Type Change column data type Type Length Modify type length/precision Default Value Alter/drop default values NOT NULL Modify/drop NOT NULL constraint <p>Other properties that can be specified during ALTER TABLE ALTER COLUMN  are not supported at the moment.</p> <p>Please note that SynchDB only supports basic data type change on an existing column. For example, <code>INT</code> \u2192 <code>BIGINT</code> or <code>VARCHAR</code> \u2192 <code>TEXT</code>. Complex data type changes such as  <code>TEXT</code> \u2192 <code>INT</code> or <code>INT</code> \u2192 <code>TIMESTAMP</code> are not currently supported. This is because PostgreSQL requires the user to additioanlly supply a type casting function to perform the type casting as the result of complex data type change. SynchDB currently has to knowledge what type casting functions to use for specific type conversion. In the future, We may allow user to supply his or her own casting functions to use for specific type conversions via the rule file, but for now, it is not supported.</p>"},{"location":"architecture/ddl_replication/#database-specific-behavior","title":"Database-Specific Behavior","text":""},{"location":"architecture/ddl_replication/#mysql-and-oracle-ddl-change-events","title":"MySQL and Oracle DDL Change Events","text":"<p>Since MySQL logs both DDL and DML operations in the binlog and Oracles logs the same to logminer, SynchDB is able to replicate both DDLs and DMLs as they happen. No special actions are needed on MySQL or Oracle side to enable DDLs replication.</p>"},{"location":"architecture/ddl_replication/#sqlserver-ddl-change-events","title":"**SQLServer DDL Change Events **","text":"<p>SQLServer does not natively supports DDL replication in streaming mode. The table schema is constructed by SynchDB during initial snapshot construction phase when the connector is started for the very first time. After this phase, SynchDB will try to detect any schema changes but they need to be explicitly added to SQL server's CDC table list.</p>"},{"location":"architecture/ddl_replication/#trigger-create-table-event-on-sqlserver","title":"Trigger CREATE TABLE event on SQLServer","text":"<p>To create a new table on SQL Server and added to its CDC table list: <pre><code>CREATE TABLE dbo.altertest (\n    a INT,\n    b TEXT\n    );\nGO\n\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @role_name = NULL,\n    @supports_net_changes = 0,\n    @capture_instance = 'dbo_altertest_1'\nGO\n</code></pre></p> <p>The command adds the table <code>dbo.altertest</code> to the CDC table list and would cause SynchDB to receive a CREATE TABLE DDL change event.</p>"},{"location":"architecture/ddl_replication/#trigger-alter-table-events","title":"Trigger ALTER TABLE Events","text":"<p>If an existing table is altered (add, drop or alter column), it needs to be explicitly updated to SQLServer's CDC table list, so that SynchDB will be able to receive the ALTER TABLE events.</p> <p>For example:</p> <p>Alter a table in SQLServer: <pre><code>ALTER TABLE altertest ADD c NVARCHAR(MAX),\n    d INT DEFAULT 0 NOT NULL,\n    e NVARCHAR(255) NOT NULL,\n    f INT DEFAULT 5 NOT NULL,\n    CONSTRAINT PK_altertest PRIMARY KEY (\n    d,\n    f\n    );\nGO\n</code></pre></p> <p>Disable the old capture instance: <pre><code>EXEC sys.sp_cdc_disable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @capture_instance = 'dbo_altertest_1';\nGO\n</code></pre></p> <p>Enable as a new capture intance: <pre><code>EXEC sys.sp_cdc_enable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @role_name = NULL,\n    @supports_net_changes = 0,\n    @capture_instance = 'dbo_altertest_2';\nGO\n</code></pre></p> <p>Add new record: <pre><code>INSERT INTO altertest VALUES(1, 's', 'c', 1, 'v', 5);\nGO\n</code></pre></p> <p>The above example should allow SynchDB to receive an ALTER TABLE ADD COLUMN and an INSERT events. There is no need to restart both SQL Server or SynchDB to capture such events. The same apply to ALTER TABLE DROP COLUMN and ALTER TABLE ALTER COLUMN events as well.</p>"},{"location":"architecture/debezium_event_processor/","title":"Debezium Event Processor - C","text":""},{"location":"architecture/debezium_event_processor/#debezium-event-processor-component-diagram","title":"Debezium Event Processor Component Diagram","text":"<p>Debezium Event Processor is a PostgreSQL background worker initiated and started by the SynchDB extension. It is responsible for initializing Java Virtual Machine (JVM), run Debezium runner, which is the Java part of SynchDB that utilizes the embedded Debezium engine to obtain change events from heterogeneous database sources. Each SynchDB worker consists of components and modules as shown in the component diagram and listed below:</p> <ol> <li>Event Fetcher</li> <li>JVM + DBZ Initializer</li> <li>Request Handler</li> <li>JSON Parser</li> <li>Object Mapping Engine</li> <li>Stats Collector</li> <li>DDL Converter</li> <li>DML Converter</li> <li>Error Handler</li> <li>SPI Client</li> <li>Executor API</li> </ol>"},{"location":"architecture/debezium_event_processor/#1-event-fetcher","title":"1) Event Fetcher","text":"<p>The Event Fetcher is primarily responsible for fetching a batch of JSON change events from embedded Debezium Runner running inside JVM. This is done via Java Native Interface (JNI) library by periodically calling a JAVA method that returns a JAVA <code>List</code> of <code>String</code>, which represents each change request in JSON. This <code>List</code> represents a <code>Batch</code> of JSON change events. JNI library is invoked again to iterate over this <code>List</code>, cast the contents from JAVA <code>String</code> to C string and send it to <code>4) JSON Parser</code> for further processing. The frequency of fetch is configurable via <code>synchdb.naptime</code>, and the maximum size of the batch can be configured via <code>synchdb.dbz_batch_size</code>.</p> <p>When a batch is completed, meaning all the change events inside have been processed, it will invoke <code>markBatchComplete()</code> JAVA method via JNI to indicate that this batch has been completed successfully. This would cause the Debezium Runner to commit and advance the offset. More about batch management can he found here.</p>"},{"location":"architecture/debezium_event_processor/#2-jvm-debezium-dbz-initializer","title":"2) JVM + Debezium (DBZ) Initializer","text":"<p>The JVM + DBZ Initializer is primarily responsible for instanitiate a new JVM environment and run Debezium Runner (<code>dbz-engine-x.x.x.jar</code>) in it. This .jar file is by default installed in $LIBDIR as returned by <code>pg_config</code>. You can specify an alternative path for Debezium Runner .jar file by setting the environment variable <code>DBZ_ENGINE_DIR</code>. SynchDB currently uses <code>JNI_VERSION_10</code> as the JNI version, which is compatible between JAVA v10 to v18. In the future, however, we may up the JNI version to get the latest improvements and benefits for JNI. The maximum heap memory allocated to JVM can be configured via <code>synchdb.jvm_max_heap_size</code>. If set to zero, JVM will automatically allocate the ideal heap size. </p> <p>Please note that each SynchDB worker will initialize and run a JVM instance, so the more workers you run, the more heap memory will be required. You can dump the current heap and non-heap memory usage of JVM of a SynchDB worker by invoking <code>synchdb_log_jvm_meminfo('$connector_name')</code> function, a memory summary will be logged in the PostgreSQL log file.</p>"},{"location":"architecture/debezium_event_processor/#3-request-handler","title":"3) Request Handler","text":"<p>The Request Handler is primarily responsible for checking and handling any incoming state change request from the SynchDB user. Examples of such state change requests include going from \"SYNCING\" to \"PAUSED\", from \"PAUSED\" to \"UPDATE OFFSET\" ...etc. Below is the state diagram of synchdb. More information can be found here.</p> <p></p>"},{"location":"architecture/debezium_event_processor/#4-json-parser","title":"4) JSON Parser","text":"<p>The JSON Parser is responsible for parsing the incoming JSON change event into C structures that SynchDB can work with. SynchDB relies on PostgreSQL's native JSONB parser for all the parsing and iteration needs. For a DML JSON event, it first parses the \"schema\" section (also referred as metadata in this documentation) of the JSON change evnet to learn about how Debezium represents the user data. This include each field's data type representation, scale of the value...etc. Then it parses the \"payload\" to obtain the \"before\" and \"after\" values. Lastly, it parses the \"source\" section to obtain the table name, the database name and the connector type in which the data comes from.</p> <p>For DML JSON event, the same sections will be parsed but with different attributes expected under \"payload\". It parses \"tableChanges\" under \"payload\" to learn about the designated table's column names, types and other properties.</p> <p>Based on the nature of operation, the produced C structure data is then sent to <code>DDL Converter</code> for DDL requests or <code>DML Converter</code> for DML requests for next stage of processing. Below are examples of DDL and DML \"payload\" from a JSON event:</p> <p>DML payload: <pre><code>{\n  \"payload\": {\n    \"before\": null,\n    \"after\": {\n      \"id\": 3,\n      \"g\": {\n        \"wkb\": \"AQMAAAABAAAABQAAAAAAAAAAAAAAAAAAAAAAFEAAAAAAAAAAQAAAAAAAABRAAAAAAAAAAEAAAAAAAAAcQAAAAAAAAAAAAAAAAAAAHEAAAAAAAAAAAAAAAAAAABRA\",\n        \"srid\": null\n      },\n      \"h\": null\n    },\n    \"source\": {\n      \"version\": \"2.6.2.Final\",\n      \"connector\": \"mysql\",\n      \"name\": \"synchdb-connector\",\n      \"ts_ms\": 1743631156000,\n      \"snapshot\": \"last\",\n      \"db\": \"inventory\",\n      \"sequence\": null,\n      \"ts_us\": 1743631156000000,\n      \"ts_ns\": 1743631156000000000,\n      \"table\": \"geom\",\n      \"server_id\": 0,\n      \"gtid\": null,\n      \"file\": \"mysql-bin.000009\",\n      \"pos\": 1026620577,\n      \"row\": 0,\n      \"thread\": null,\n      \"query\": null\n    },\n    \"op\": \"r\",\n    \"ts_ms\": 1743631156410,\n    \"ts_us\": 1743631156410423,\n    \"ts_ns\": 1743631156410423395,\n    \"transaction\": null\n  }\n}\n</code></pre></p> <p>DDL payload: <pre><code>  \"payload\": {\n    \"source\": {\n      \"version\": \"2.6.2.Final\",\n      \"connector\": \"sqlserver\",\n      \"name\": \"synchdb-connector\",\n      \"ts_ms\": 1728337635149,\n      \"snapshot\": \"true\",\n      \"db\": \"testDB\",\n      \"sequence\": null,\n      \"ts_us\": 1728337635149000,\n      \"ts_ns\": 1728337635149000000,\n      \"schema\": \"dbo\",\n      \"table\": \"customers\",\n      \"change_lsn\": null,\n      \"commit_lsn\": \"00000195:000010a0:0003\",\n      \"event_serial_no\": null\n    },\n    \"ts_ms\": 1728337635150,\n    \"databaseName\": \"testDB\",\n    \"schemaName\": \"dbo\",\n    \"ddl\": null,\n    \"tableChanges\": [\n      {\n        \"type\": \"CREATE\",\n        \"id\": \"\\\"testDB\\\".\\\"dbo\\\".\\\"customers\\\"\",\n        \"table\": {\n          \"defaultCharsetName\": null,\n          \"primaryKeyColumnNames\": [\n            \"id\"\n          ],\n          \"columns\": [\n            {\n              \"name\": \"id\",\n              \"jdbcType\": 4,\n              \"nativeType\": null,\n              \"typeName\": \"int identity\",\n              \"typeExpression\": \"int identity\",\n              \"charsetName\": null,\n              \"length\": 10,\n              \"scale\": 0,\n              \"position\": 1,\n              \"optional\": false,\n              \"autoIncremented\": true,\n              \"generated\": false,\n              \"comment\": null,\n              \"defaultValueExpression\": null,\n              \"enumValues\": null\n            },\n            {\n              \"name\": \"first_name\",\n              \"jdbcType\": 12,\n              \"nativeType\": null,\n              \"typeName\": \"varchar\",\n              \"typeExpression\": \"varchar\",\n              \"charsetName\": null,\n              \"length\": 255,\n              \"scale\": null,\n              \"position\": 2,\n              \"optional\": false,\n              \"autoIncremented\": false,\n              \"generated\": false,\n              \"comment\": null,\n              \"defaultValueExpression\": null,\n              \"enumValues\": null\n            },\n            {\n              \"name\": \"last_name\",\n              \"jdbcType\": 12,\n              \"nativeType\": null,\n              \"typeName\": \"varchar\",\n              \"typeExpression\": \"varchar\",\n              \"charsetName\": null,\n              \"length\": 255,\n              \"scale\": null,\n              \"position\": 3,\n              \"optional\": false,\n              \"autoIncremented\": false,\n              \"generated\": false,\n              \"comment\": null,\n              \"defaultValueExpression\": null,\n              \"enumValues\": null\n            },\n            {\n              \"name\": \"email\",\n              \"jdbcType\": 12,\n              \"nativeType\": null,\n              \"typeName\": \"varchar\",\n              \"typeExpression\": \"varchar\",\n              \"charsetName\": null,\n              \"length\": 255,\n              \"scale\": null,\n              \"position\": 4,\n              \"optional\": false,\n              \"autoIncremented\": false,\n              \"generated\": false,\n              \"comment\": null,\n              \"defaultValueExpression\": null,\n              \"enumValues\": null\n            }\n          ],\n          \"comment\": null\n        }\n      }\n    ]\n  }\n</code></pre></p>"},{"location":"architecture/debezium_event_processor/#5-object-mapping-engine","title":"5) Object Mapping Engine","text":"<p>The Object Mapping Engine is responsible for loading and maintaining object mapping information under each active connector. These mapping information tells SynchDB how to map a source object to a destination object during DDL and DML processing. By default, Synchdb has no object mapping rules, it will use the default mapping rules to process the data.</p> <p>An object could refer to a: * table name. * column name. * data type. * transform expression.</p> <p>It is possible to map a source table name, column name and data type to a different destination table name, column name an a data type before mapping rules can be created using<code>synchdb_add_objmap()</code> function and all rules can be viewed by quering the <code>synchdb_objmap</code> table. More on object mapping here. A summary of what gets mapped to what can be viewed under <code>synchdb_att_view()</code> VIEW.</p> <p>The <code>transform expression</code> is a SQL expression that will be run (if specified) after the data conversion is finished and before data is applied. This expression can be any expressions runnable in PostgreSQL, such as invoking another SQL function, or using operators. More information on object mapping rule can be found here.</p>"},{"location":"architecture/debezium_event_processor/#6-stats-collector","title":"6) Stats Collector","text":"<p>The Stats Collector is responsible for collecting statistic information about SynchDB's data processing since the beginning of the operation. This includes the number of DDLs and DMLs, how many CREATE, INSERT, UPDATE, DELETE operations have been processed, average batch size processed and several timestamps that describe the time when the data is first generated in the source, the time when the data is processed by Debezium and the time when the data is applied in PostgreSQL. These metrics can help user understand the processing behavior of SynchDB to tune and optimize settings to increase the processing performance. More on stats can be found here.</p>"},{"location":"architecture/debezium_event_processor/#7-ddl-converter","title":"7) DDL Converter","text":"<p>The DDL Converter is responsible for converting the DDL data produced by the \"JSON Parser\" to a format that can be understood by PostgreSQL. For DDLs, SynchDB relies on PostgreSQL SPI engine to process, so the output of the conversion is a normal SQL query string. DDL Converter examines the DDL data and has to work with \"Object Mapping Engine\" to correctly transform the table, column name or data type mappings between the source and destination. </p> <p>If a remote table named \"employee\" is to be mapped as \"staff\" in the destination according to \"Object Mapping Engine\", DDL Converter is responsible for resolving these name mappings and create the SQL query for SPI accordingly.</p> <p>The converter currently can handle these DDL operations:</p> <ul> <li>CREATE TABLE</li> <li>DROP TABLE</li> <li>ALTER TABLE ALTER COLUMN</li> <li>ALTER TABLE ADD COLUMN</li> <li>ALTER TABLE DROP COLUMN</li> </ul> <p>For CREATE and DROP, the converter is able to create a corresponding query string for SPI from the input DDL data. For ALTER, ADD and DROP COLUMN, the convert requires a visit to PostgreSQL catalog to learn about the existing table properties and will determine if there is a column to be added, dropped or altered. Debezium's JSON change event always contains the entire table's information and does not explicitly indicate what has been dropped or added. Therefore, the DDL Converter component is required to figure this information out and produce a correct query string. More on DDL replication can be found here</p>"},{"location":"architecture/debezium_event_processor/#8-dml-converter","title":"8) DML Converter","text":"<p>The DML Converter is responsible for converting the DML data produced by the \"JSON Parser\" to a format that can be understood by PostgreSQL. For DMLs, SynchDB relies on PostgreSQL's executor APIs to directly apply the data to PostgreSQL, so the output of the conversion is in TupleTableSlot (TTS) format in which PostgreSQL executor understands. To produce the correct TTS for PostgreSQL, DML Converter relies on:</p> <ul> <li>DBZ metadata that describes how the payload data is represented</li> <li>PostgreSQL catalog (pg_class and pg_type) to learn about the table's information, each column's data type and properties. </li> <li>Object Mapping Rules to determine if it needs to run additional transform expression on the processed data</li> <li>The payload data itself to process</li> </ul> <p>DML Converter consists of several routines that can handle a particular input data type and produce a particular output type. Selecting the right routine for a particular conversion scenario could be a challenge because some data types may be user-defined or created by another extensions that SynchDB does not know much about. SynchDB has to be designed to handle both native and non-native data type that could exist in PostgreSQL.</p> <p>The routine selection starts by looking at the data type created at the PostgreSQL, which can be divided into 2 types, each with slightly different handling techniques:</p> <ul> <li>native data types.</li> <li>non-native data types.</li> </ul>"},{"location":"architecture/debezium_event_processor/#data-transformation","title":"Data Transformation","text":"<p>After the input data has been processed by the logics as described above, the converter will then check if the user has configured a <code>transform expression</code> that shall be applied to the processed data before applying to PostgreSQL. A transform expression could be any PostgreSQL expressions, commands, or SQL functions that could be run on a psql prompt. It uses the <code>%d</code> as a placeholder character that will be replaced with the processed data during the transformation. For example, a transform expression \"'&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\" will prepend and append additional characters to the processed string data. </p> <p>So, if a non-native data type has category TYPCATEGORY_USER, DML Converter does not have a suitable routine to process this data and will leave it as is, we can define a transform expression to call a custom SQL function from where it knows how to properly handle the data and produce a suitable output. For example, the expression, \"to_my_composite_type('%d')\" will call a user-defined SQL function <code>to_my_composite_type</code> with the data as input. The expression must have a return value as it will be fed into PostgreSQL during apply.</p>"},{"location":"architecture/debezium_event_processor/#9-error-handler","title":"9) Error Handler","text":"<p>The Error Handler is primarily responsible for handling any error that could arise from each stage of data synchronization. Format Converter supports several error handling strategies that can be configured via \"synchdb.error_handling_strategy\" parameters. Details can be found here.</p>"},{"location":"architecture/debezium_event_processor/#10-spi-client","title":"10) SPI Client","text":"<p>the SPI Client component exists under the Replication Agent, which serves as a bridge between PostgreSQL core and SynchDB. It is responsible for establishing a connection to SPI server, start a transaction, obtain a snapshot and execute a given SQL query created by the <code>DDL Converter</code> and destroy the connection. For each query to process, the SPI connection is created and destroyed, which may seem inefficient. Since the SPI is only used during DDL, which is normally not very frequent, it should be fine in terms of performance.</p>"},{"location":"architecture/debezium_event_processor/#11-executor-apis","title":"11) Executor APIs","text":"<p>Also residing in the Replication Agent. This component is responsible for initialize a executor context, open the table, acquire proper locks, create TupleTableSlot (TTS) from the output of DML Converter, call the executor API to execute INSERT, UPDATE, DELETE operations and do resource cleanup. This is generally a much faster approach to do data operations than SPI because it does not need to parse an input query string likst SPI does.</p>"},{"location":"architecture/debezium_runner_components/","title":"Debezium Runner Component Architecture - Java","text":""},{"location":"architecture/debezium_runner_components/#debezium-runner-component-diagram","title":"Debezium Runner Component Diagram","text":"<p>Debezium Runner resides on Java side of the deployment. It is the main faciliator between embedded Debezium engine (Java) and SynchDB Worker (C). It provides several Java methods that SynchDB worker can interact via JNI library. These interactions include initializing a Debezium engine, start or stop the engine, obtain a batch of change events and mark a batch as done. These operations are essential for ensuring replication consistency. Main components are:</p> <ol> <li>Parameter Class</li> <li>Controller</li> <li>Emitter</li> <li>Batch Manager</li> </ol>"},{"location":"architecture/debezium_runner_components/#1-parameter-class","title":"1) Parameter Class","text":"<p>The parameter class represents a JAVA class that include a list of exposed parameters and methods that allow SynchDB Worker to set/get the parameter values. These parameters affect how Debezium Runner and the embedded Debezium perform. These parameters have also been exposed to PostgreSQL GUCs so that SynchDB worker could invoke the respective methods to set the parameter values. This is currently the only way to pass configuration from C based SynchDB Worker to JAVA based Debezium Runner.</p>"},{"location":"architecture/debezium_runner_components/#2-controller","title":"2) Controller","text":"<p>The controller allows SynchDB to start or stop the Embedded Debezium Engine. This is done via several JAVA methods that SynchDB Worker can invoke to control Debezium Engine.</p>"},{"location":"architecture/debezium_runner_components/#3-emitter","title":"3) Emitter","text":"<p>The emitter represents a JAVA method that is periodically invoked by the \"Event Fetcher\" component in SynchDB Worker. It is mainly responsible to pop a batch from \"4) Batch Manager\", formulate it into a List of JSON events as String and return it to \"Event Fetcher\" via JNI. If Batch Manager has no batch available, it will return NULL and no processing will happen on the \"Event Fetcher\" side.</p>"},{"location":"architecture/debezium_runner_components/#4-batch-manager","title":"4) Batch Manager","text":"<p>The Batch Manager is mainly responsible for receiving new batches originated from Embedded Debezium Engine and stores it in its internal queue. This queue is much smaller and is different from the Batch Queue inside Embedded Debezium Engine in the component diagram. When Batch Manager's internal queue is full, a throttle control will activate to temporarily halt the event generation from Debezium side until this small batch queue has free space. A batch is taken away from the queue only when the \"Emitter\" receives a fetch request from \"Event Fetcher\" and pops a batch from batch manager.</p> <p>Batch manager also assigns a batch ID to each batch popped, sent to emitter and eventually to the SynchDB worker to process. This unique ID is stored in its interal hash table along with a \"committer\" object associated with it. These pieces of information is important to keep track. When SynchDB worker finishes a batch, it will invoke a Mark Batch Completion method within the Batch Manager, the same batch ID is also included, which helps the Batch Manager to look up the corresponding \"committer\" object. The committer object is then used to notify the Embedded Debezium Engine that a batch is completed, forcing it to commit and move its internal offset forward. This ensures that the same batch will not be processed again (no duplication) in case of engine restarts.</p>"},{"location":"architecture/fdw_based_snapshot/","title":"FDW Based Snapshot","text":""},{"location":"architecture/fdw_based_snapshot/#overview","title":"Overview","text":"<p>All the connectors support Debezium based initial snapshot (except for Postgres connector), which migrates remote table schemas to PostgreSQL with or without the initial data (depending on the snapshot mode used). This works mostly, but may suffer from performance issues when there is a large number of tables to migrate and extra overhead is introduced via JNI calls. It is possible to achieve the same initial snapshot using a Foreign Data Wrapper (FDW) as long as we have a way to gurantee consistency and identify a \"cut-off\" point to allow CDC to resume.</p> <p>FDW based snapshot is supported for:</p> <ul> <li>MySQL Connector</li> <li>Postgres Connector</li> <li>Oracle and Openlog Replicator Connectors</li> </ul>"},{"location":"architecture/fdw_based_snapshot/#how-synchdb-guarentees-consistency-and-obtains-cut-off-point","title":"How Synchdb Guarentees Consistency and Obtains Cut-Off Point","text":""},{"location":"architecture/fdw_based_snapshot/#mysql-connector","title":"MySQL Connector","text":"<ul> <li>Begin a transaction in repeatable read isolation level.</li> <li>Temporarily put a table read lock on all desired tables.</li> <li>Read <code>binlog_log_file</code>, <code>binlog_pos</code> and <code>server_id</code> from global configuration. These are served as \"cut-off\" point for the snapshot.</li> <li>Release the table locks.</li> <li>In the same repeatable read transaction, migrate all desired tables schema and data with proper type translations</li> <li>Once done, the CDC can resume from the cut-off point, which will handle the data changes that happened during the snapshot.</li> </ul> <p>WARNING: BACKUP_ADMIN permission is required to obtain the \"cut-point\" parameters.</p>"},{"location":"architecture/fdw_based_snapshot/#postgres-connector","title":"Postgres Connector","text":"<ul> <li>Begin a transaction in repeatable read isolation level.</li> <li>Temporarily put a table read lock on all desired tables.</li> <li>Read current LSN, which serves as a \"cut-off\" point for the snapshot.</li> <li>Release the table locks.</li> <li>In the same repeatable read transaction, migrate all desired tables schema and data with proper type translations</li> <li>Once done, the CDC can resume from the cut-off point, which will handle the data changes that happened during the snapshot.</li> </ul>"},{"location":"architecture/fdw_based_snapshot/#oracle-and-openlog-replicator-connectors","title":"Oracle and Openlog Replicator Connectors","text":"<ul> <li>Before snapshot begins, read the current SCN value, which serves as a \"cut-off\" point for the snapshot</li> <li>During foreign table schema migration, extra attribute \"AS OF SCN xxx\" will be associated with each desired foreign table,causing all the foreign reads to use Oracle's FLASHBACK query</li> <li>FLASHBACK query returns the table results as of the SCN specified so consistency is automatically guarenteed. No extra locking needed.</li> <li>Migrate all desired tables schema and data with proper type translations with FLASHBACK query.</li> <li>Once done, the CDC can resume from the cut-off point, which will handle the data changes that happened during the snapshot.</li> </ul> <p>WARNING: FLASHBACK permission is required to obtain the \"cut-point\" parameters.</p>"},{"location":"architecture/fdw_based_snapshot/#how-does-fdw-based-snapshot-work","title":"How does FDW Based Snapshot Work","text":"<p>FDW based snapshot consists of about 10 steps:</p>"},{"location":"architecture/fdw_based_snapshot/#1-preparation","title":"1. Preparation","text":"<p>This steps checks if <code>oracle_fdw</code> is installed and available, creates a <code>server</code> and <code>user mapping</code> based on the connector information created by <code>synchdb_add_conninfo</code> </p>"},{"location":"architecture/fdw_based_snapshot/#2-create-oracle-object-views","title":"2. Create Oracle Object Views","text":"<p>This steps create numerous foreign tables in a separate schema (ex. <code>ora_obj</code>) in PostgreSQL. These foreign tables (when queried) connects to Oracle via oracle_fdw and obtains most (if not all) of the objects available on Oracle. Objects such as:</p> <ul> <li>tables</li> <li>columns</li> <li>keys</li> <li>indexes</li> <li>functions</li> <li>sequences</li> <li>views</li> <li>triggers</li> <li>...etc</li> </ul> <p>SynchDB does not need to account for every single object to complete an initial snapshot; It only accounts for <code>tables</code>, <code>columns</code> and <code>keys</code> objects to construct the tables in PostgreSQL. </p>"},{"location":"architecture/fdw_based_snapshot/#3-create-a-foreign-table-to-fetch-cut-off-value","title":"3. Create a Foreign Table to Fetch Cut-Off value","text":"<p>Foreign tables will be created to read the cut-off value from difference source databases:</p> <p>MySQL Connector</p> <ul> <li>Read <code>binglog_file</code> and <code>binlog_pos</code> from performance_schema.log_status</li> <li>Read <code>server_id</code> from performance_schema.global_variables</li> </ul> <p>Postgres Connector</p> <ul> <li>Read current <code>LSN</code> from a custom view called public.synchdb_wal_lsn. This must be pre-created as a requirement</li> </ul> <p>Oracle and Openlog Replicator Connector</p> <ul> <li>Read current <code>SCN</code> from current_scn table</li> </ul>"},{"location":"architecture/fdw_based_snapshot/#4-create-a-list-of-desired-foreign-tables","title":"4. Create a List of Desired Foreign Tables","text":"<p>The goal for this step is to create a new staging schema (ex. ora_stage), and create desired foreign tables for the snapshot based on:</p> <ul> <li>object views created from step 2</li> <li>SynchDB's <code>data-&gt;'snapshottable'</code> parameter in <code>synchdb_conninfo</code> -&gt; this is a filter of tables that SynchDB needs to do a snapshot. All tables will be considered in snapshot if set to <code>null</code>.</li> <li>Extra data type mapping as described in <code>synchdb_objmap</code> </li> <li>the cut-off SCN obtained from step 3 (Oracle and Openlog Replicator Connectors only)</li> </ul> <p>At the end of this step, the staging schema will contain foreign tables with their data types mapped according to SycnhDB's data type mapping rules. For Oracle and Openlog Replicator Connectors, the foreign tables will have <code>AS OF SCN xxx</code> attribute, causing each foreign read to return data only up to specified SCN. For other connector types, the foreign reads return all data at the moment when repeatable transaction starts</p>"},{"location":"architecture/fdw_based_snapshot/#5-materialize-the-schema","title":"5. Materialize the Schema","text":"<p>The goal for this step is to materialize (turn foreign tables into real PostgreSQL tables) only the table schemas created from step 4 and put them in a new destination schema (ex. dst_stage). So, at the end of the step, the destination schema will contain real tables with the same structure as those in staging schema.</p>"},{"location":"architecture/fdw_based_snapshot/#6-migrate-primary-key","title":"6. Migrate Primary Key","text":"<p>Based on oracle object views created from step 2, do <code>ALTER TABLE ADD PRIMARY KEY</code> commands on the materialized tables created from step 5 to add primary keys as needed. </p>"},{"location":"architecture/fdw_based_snapshot/#7-apply-column-name-mappings","title":"7. Apply Column Name Mappings","text":"<p>Based on column name mappings as described in <code>synchdb_objmap</code> , do <code>ALTER TABLE RENAME COLUMN</code> commands on the materialized tables created from step 5 to change column names as needed. </p>"},{"location":"architecture/fdw_based_snapshot/#8-migrate-data-with-transforms","title":"8. Migrate Data With Transforms","text":"<p>The goal for This step is to migrate the table data from staging to destination schemas and perform any value transforms as described in <code>synchdb_objmap</code>, basically doing something like:</p> <ul> <li>remote query</li> <li>apply data transform</li> <li>local insert</li> </ul>"},{"location":"architecture/fdw_based_snapshot/#9-apply-table-name-mappings","title":"9. Apply Table Name Mappings","text":"<p>Once the data is migrated, SynchDB will apply table name mapping as described in <code>synchdb_objmap</code>. The reason it is done last is that table name mapping could potentially move the table to some other schema in which we do not wish to happen during materialization. </p>"},{"location":"architecture/fdw_based_snapshot/#10-finalize-initial-snapshot","title":"10. Finalize Initial Snapshot","text":"<p>The initial snapshot is considered done at this point. This step will do a cleanup as follows:</p> <ul> <li>drop server and user mapping created from step 1</li> <li>drop Oracle object view created from step 2</li> <li>drop staging schema created from step 4</li> </ul> <p>The tables that reside in the destination schema created from step 5 is the final result of initial snapshot.</p>"},{"location":"architecture/metadata_files/","title":"Metadata Files","text":"<p>During Operation, Debezium Runner engine produces metadata files under $PGDATA/pg_synchdb. Currently 2 types of metadata files are generated and persisted: * offset file: contains the offset to resume the replication operation at start up * schema history file: contains the schema information to build all the tables for a replication. This is created during the initial data snapshot sync and can be updated during operation.</p> <p>These metadata filenames consist of:</p> <ul> <li> <p>(connector type)(connector name)(destination database)_offsets.dat</p> </li> <li> <p>(connector type)(connector name)(destination_database)_schemahistory.dat</p> </li> </ul> <pre><code>ls $PGDATA/pg_synchdb\nmysql_mysqlconn_postgres_offsets.dat        sqlserver_sqlserverconn_postgres_offsets.dat\nmysql_mysqlconn_postgres_schemahistory.dat  sqlserver_sqlserverconn_postgres_schemahistory.dat\n</code></pre> <p>These binary files' contents can be viewed with hexdump command: <pre><code>hexdump -C $PGDATA/pg_synchdb/mysql_mysqlconn_postgres_offsets.dat\nhexdump -C $PGDATA/pg_synchdb/mysql_mysqlconn_postgres_schemahistory.dat\n</code></pre></p>"},{"location":"architecture/metadata_files/#reset-connector","title":"Reset Connector","text":"<p>A connector can be reset (re-copy and re-synchronize) specified tables, simply by\uff1a</p> <ul> <li>stop the connector </li> <li>Remove both the offsets and schemahistory file</li> <li>start the connector</li> </ul>"},{"location":"architecture/native_datatype_handling/","title":"Native Data Type Handling","text":""},{"location":"architecture/native_datatype_handling/#handling-native-data-types","title":"Handling Native Data Types","text":"<p>The image below shows the list of supported native data types and how SynchDB groups them together based on their nature (or category). For example, the numeric group contains all integer or float data types that are numeric in nature. An error is raised if a numeric data contains non-numeric characters. Likewise, different groups of data types requires a sepcific format of data in order to apply.</p> <p></p> <p>Now that DML Converter knows how to produce the data for these supported native data types on the PostgreSQL side, it then looks at the DBZ metadata to learn how the source data is represented. This is needed because Debezium engine may encode the payload data to pack more information that requires decoding prior to processing the data, or use a structure to represent complex data types like Geometry. Without knowing how Debezium represents the data, the data processing is likely to produce undesired results, causing PostgreSQL to error during apply. Below is the list of formatting types that Debezium could represent a payload data with:</p> <p></p> <p>With these 2 pieces of information, DML Converter knows what the input looks like and what the output should look like. It will select the best handler from its function matrix to process the data. For example, if destination type is <code>FLOAT4</code>, and source data type is formatted as <code>DBZTYPE_BYTES</code>, the function <code>handle_base64_to_numeric()</code> will be selected to process the data. The selected function is responsible for decode the binary input and compute it as a numeric. </p>"},{"location":"architecture/non_native_datatype_handling/","title":"None-native Data Type Handling","text":""},{"location":"architecture/non_native_datatype_handling/#handling-non-native-data-types","title":"Handling Non-Native Data Types","text":"<p>It is possible that a table contains a column data type that is custom created by the user or created by another installed extension. In this case, it cannot be processed using tradition native data type handling becasue the type is most likely not supported natively. Instead, the DML Converter accesses the catalog, obtains the OID of the non-native data type, and looks up its \"category\" as defined in PostgreSQL. Below is a list of category supported by PostgreSQL as of version 17:</p> <pre><code>#define  TYPCATEGORY_INVALID    '\\0'\n#define  TYPCATEGORY_ARRAY      'A'\n#define  TYPCATEGORY_BOOLEAN    'B'\n#define  TYPCATEGORY_COMPOSITE  'C'\n#define  TYPCATEGORY_DATETIME   'D'\n#define  TYPCATEGORY_ENUM       'E'\n#define  TYPCATEGORY_GEOMETRIC  'G'\n#define  TYPCATEGORY_NETWORK    'I'\n#define  TYPCATEGORY_NUMERIC    'N'\n#define  TYPCATEGORY_PSEUDOTYPE 'P'\n#define  TYPCATEGORY_RANGE      'R'\n#define  TYPCATEGORY_STRING     'S'\n#define  TYPCATEGORY_TIMESPAN   'T'\n#define  TYPCATEGORY_USER       'U'\n#define  TYPCATEGORY_BITSTRING  'V'\n#define  TYPCATEGORY_UNKNOWN    'X'\n</code></pre> <p>The category tells DML Converter about the nature of the data type (numeric? string? datetime? ...etc) to help the converter select the right routine to process. For most cases, using type category paired with the DBZ metadata that describes how the input data payload is formatted is sufficient to select the right routine to process the data. However, in some cases, it may not be sufficient. For example, custom DATE, TIME, TIMESTAMP date types could all be categorized under <code>TYPCATEGORY_DATETIME</code>, so the converter does not know if it is working with a DATE, TIME or TIMESTAMP as each would produce different time formats. Currently, the covnerter looks for certain keywords from the data type name to identify. In the future, we may expose this part to let the user tell the converter exactly which routine to use should there be an ambiguity. Another example would be <code>TYPCATEGORY_USER</code> and <code>TYPCATEGORY_GEOMETRIC</code> which does not clearly indicate the data format. For these categories, the converter currently does not perform any further processing as it simply leaves the data payload as is. PostgreSQL may or may not reject such unprocessed data. This is why the transform feature next is important to give the DML converter a final chance to correct its data payload.</p>"},{"location":"architecture/openlog_replicator_event_processor/","title":"Openlog Replicator Event Processor","text":""},{"location":"architecture/openlog_replicator_event_processor/#openlog-replicator-event-processor-component-diagram","title":"Openlog Replicator Event Processor Component Diagram","text":"<p>Openlog Replicator Event Processor is a PostgreSQL background worker initiated and started by the SynchDB extension. It is responsible for connecting to Openlog Replicator, initiate replication, and fetch change events in JSON format. The internal components of this module are listed below:</p> <ol> <li>OLR Client</li> <li>Oracle Parser</li> <li>JSON Parser</li> <li>Object Mapping Engine</li> <li>Stats Collector</li> <li>DDL Converter</li> <li>DML Converter</li> <li>Error Handler</li> <li>SPI Client</li> <li>Executor API</li> </ol>"},{"location":"architecture/openlog_replicator_event_processor/#1-olr-client","title":"1) OLR Client","text":"<p>OLR Client establishes a TCP/IP session with an OpenLog Replicator (OLR) server, negotiates a replication stream via a protocol handshake (e.g., protocol version and starting offset/SCN), and then continuously consumes change events emitted as JSON. Wire-level frames (handshake, acknowledgements, heartbeats) are encoded/decoded with libprotobuf-c, using the .proto definitions sourced directly from the official OpenLog Replicator repository to ensure strict protocol compatibility. After decoding, events are normalized to JSON and handed off to <code>3) JSON parser</code> for downstream processing.</p>"},{"location":"architecture/openlog_replicator_event_processor/#2-oracle-parser","title":"2) Oracle Parser","text":"<p>The Oracle Parser is responsible for parsing a Oracle query (DDL only) and producing a PostgreSQL raw parse tree, in which SynchDB can understand the intended actions. SynchDb's Oracle Parser is based on IvorySQL 4's Oracle parser for PostgreSQL but modified to fit the needs of SynchDB. The source code of this modified Oracle parser is located in <code>src/backend/olr/oracle_parser</code> and it does not support all Oracle syntax. It is sufficient to support all the DDL commands we intended to support (See below).</p>"},{"location":"architecture/openlog_replicator_event_processor/#3-json-parser","title":"3) JSON Parser","text":"<p>The JSON Parser is responsible for parsing the incoming JSON change event into C structures that SynchDB can work with. SynchDB relies on PostgreSQL's native JSONB utility for all the parsing and iteration needs. Each DML event contains the <code>scn</code> and <code>commit scn</code> values, tells how each column value is represented based on data types, and the before / after values. </p> <p>Unlink a DDL event from Debezium, Openlog Replicator's DDL Event contains the raw Oracle DDL query instead of a broken-down structure. This means that a <code>2) Oracle parser</code> is required to parse this DDL query further to learn about its intended actions.</p> <p>DML payload: <pre><code>{\n  \"scn\": 3531590,\n  \"tm\": 1752686342000000000,\n  \"c_scn\": 3531691,\n  \"c_idx\": 2,\n  \"xid\": \"0x0007.01a.000004a1\",\n  \"db\": \"FREE\",\n  \"payload\": [\n    {\n      \"op\": \"c\",\n      \"schema\": {\n        \"owner\": \"DBZUSER\",\n        \"table\": \"ORDERS\",\n        \"obj\": 73406,\n        \"columns\": [\n          {\n            \"name\": \"ORDER_NUMBER\",\n            \"type\": \"number\",\n            \"precision\": -1,\n            \"scale\": -1,\n            \"nullable\": false\n          },\n          {\n            \"name\": \"ORDER_DATE\",\n            \"type\": \"date\",\n            \"nullable\": true\n          },\n          {\n            \"name\": \"PURCHASER\",\n            \"type\": \"number\",\n            \"precision\": -1,\n            \"scale\": -1,\n            \"nullable\": true\n          },\n          {\n            \"name\": \"QUANTITY\",\n            \"type\": \"number\",\n            \"precision\": -1,\n            \"scale\": -1,\n            \"nullable\": true\n          },\n          {\n            \"name\": \"PRODUCT_ID\",\n            \"type\": \"number\",\n            \"precision\": -1,\n            \"scale\": -1,\n            \"nullable\": true\n          }\n        ]\n      },\n      \"num\": 0,\n      \"rid\": \"AAAR6+AAFAAAACGAAA\",\n      \"after\": {\n        \"ORDER_NUMBER\": 10013,\n        \"ORDER_DATE\": 1704067200000000000,\n        \"PURCHASER\": 1003,\n        \"QUANTITY\": 2,\n        \"PRODUCT_ID\": 107\n      }\n    }\n  ]\n}\n</code></pre></p> <p>DDL payload: <pre><code>{\n  \"scn\": 2930816,\n  \"tm\": 1753384727000000000,\n  \"c_scn\": 2930820,\n  \"c_idx\": 3,\n  \"xid\": \"0x0008.011.000004c7\",\n  \"db\": \"FREE\",\n  \"payload\": [\n    {\n      \"op\": \"ddl\",\n      \"schema\": {\n        \"owner\": \"DBZUSER\",\n        \"table\": \"TEST_TABLE\",\n        \"obj\": 74234\n      },\n      \"sql\": \"CREATE TABLE test_table (\\n    id NUMBER PRIMARY KEY,\\n    binary_double_col BINARY_DOUBLE,\\n    binary_float_col BINARY_FLOAT,\\n    float_col FLOAT(10),\\n    number_col NUMBER(10,2),\\n    long_col LONG,\\n    date_col DATE,\\n    interval_ds_col INTERVAL DAY TO SECOND,\\n    interval_ym_col INTERVAL YEAR TO MONTH,\\n    timestamp_col TIMESTAMP,\\n    timestamp_tz_col TIMESTAMP WITH TIME ZONE,\\n    timestamp_ltz_col TIMESTAMP WITH LOCAL TIME ZONE,\\n    char_col CHAR(10),\\n    nchar_col NCHAR(10),\\n    nvarchar2_col NVARCHAR2(50),\\n    varchar_col VARCHAR(50),\\n    varchar2_col VARCHAR2(50),\\n    raw_col RAW(100),\\n    bfile_col BFILE,\\n    blob_col BLOB,\\n    clob_col CLOB,\\n    nclob_col NCLOB,\\n    rowid_col ROWID,\\n    urowid_col UROWID\\n)\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"architecture/openlog_replicator_event_processor/#4-object-mapping-engine","title":"4) Object Mapping Engine","text":"<p>The Object Mapping Engine is responsible for loading and maintaining object mapping information under each active connector. These mapping information tells SynchDB how to map a source object to a destination object during DDL and DML processing. By default, Synchdb has no object mapping rules, it will use the default mapping rules to process the data.</p> <p>An object could refer to a: * table name. * column name. * data type. * transform expression.</p> <p>It is possible to map a source table name, column name and data type to a different destination table name, column name an a data type before mapping rules can be created using<code>synchdb_add_objmap()</code> function and all rules can be viewed by quering the <code>synchdb_objmap</code> table. More on object mapping here. A summary of what gets mapped to what can be viewed under <code>synchdb_att_view()</code> VIEW.</p> <p>The <code>transform expression</code> is a SQL expression that will be run (if specified) after the data conversion is finished and before data is applied. This expression can be any expressions runnable in PostgreSQL, such as invoking another SQL function, or using operators. More information on object mapping rule can be found here.</p>"},{"location":"architecture/openlog_replicator_event_processor/#5-stats-collector","title":"5) Stats Collector","text":"<p>The Stats Collector is responsible for collecting statistic information about SynchDB's data processing since the beginning of the operation. This includes the number of DDLs and DMLs, how many CREATE, INSERT, UPDATE, DELETE operations have been processed, average batch size processed and several timestamps that describe the time when the data is first generated in the source, the time when the data is processed by Debezium and the time when the data is applied in PostgreSQL. These metrics can help user understand the processing behavior of SynchDB to tune and optimize settings to increase the processing performance. More on stats can be found here.</p>"},{"location":"architecture/openlog_replicator_event_processor/#6-ddl-converter","title":"6) DDL Converter","text":"<p>The DDL Converter is responsible for converting the DDL data produced by the \"JSON Parser\" to a format that can be understood by PostgreSQL. For DDLs, SynchDB relies on PostgreSQL SPI engine to process, so the output of the conversion is a normal SQL query string. DDL Converter examines the DDL data and has to work with \"Object Mapping Engine\" to correctly transform the table, column name or data type mappings between the source and destination. </p> <p>If a remote table named \"employee\" is to be mapped as \"staff\" in the destination according to \"Object Mapping Engine\", DDL Converter is responsible for resolving these name mappings and create the SQL query for SPI accordingly.</p> <p>The converter currently can handle these Oracle DDL operations:</p> <ul> <li>CREATE TABLE</li> <li>DROP TABLE</li> <li>ALTER TABLE MODIFY</li> <li>ALTER TABLE ADD COLUMN</li> <li>ALTER TABLE DROP COLUMN</li> <li>ALTER TABLE ADD CONSTRAINT</li> <li>ALTER TABLE DROP CONSTRAINT</li> </ul>"},{"location":"architecture/openlog_replicator_event_processor/#limitations","title":"Limitations","text":"<p>The following Oracle features declared in DDL commands are not supported by Openlog Replicator connector:</p> <ul> <li>virtual columns</li> <li>quoted table or column names with space</li> <li>Index organized tables (IOT)</li> <li><code>CREATE TABLE AS</code> clauses</li> <li><code>CREATE TYPE</code> clauses</li> <li><code>CREATE TABLE OF</code> caluses</li> <li><code>ALTER TABLE MODIFY name DEFAULT</code></li> <li><code>ALTER TABLE MODIFY name NOT NULL</code></li> <li><code>ALTER TABLE MODIFY name NULL</code></li> <li><code>ALTER TABLE MODIFY name SET UNUSED</code></li> <li><code>ALTER TABLE MODIFY name DROP UNUSED COLUMNS</code></li> <li><code>ALTER TABLE RENAME</code></li> </ul> <p>The following constraints clauses are accpeted but ignored by Openlog Replicator connector:</p> <ul> <li>ENABLE VALIDATE</li> <li>ENABLE NOVALIDATE</li> <li>DISABLE VALIDATE</li> <li>DISABLE NOVALIDATE</li> </ul> <p>The following is treated as DEFAULT NULL:</p> <ul> <li>DEFAULT ON NULL 'expr'</li> <li>DEFAULT 'expr'</li> </ul> <p>The following can only take one set of column definition rather than multiple</p> <ul> <li><code>ALTER TABLE MODIFY ADD ...</code> </li> <li><code>ALTER TABLE MODIFY (ADD ...)</code> </li> <li><code>ALTER TABLE MODIFY DROP ...</code> </li> <li><code>ALTER TABLE MODIFY (DROP ...)</code> </li> </ul> <p>&lt;NOTE&gt; More limitations may be updated here as we discover them.</p>"},{"location":"architecture/openlog_replicator_event_processor/#7-dml-converter","title":"7) DML Converter","text":"<p>The DML Converter is responsible for converting the DML data produced by the \"JSON Parser\" to a format that can be understood by PostgreSQL. For DMLs, SynchDB relies on PostgreSQL's executor APIs to directly apply the data to PostgreSQL, so the output of the conversion is in TupleTableSlot (TTS) format in which PostgreSQL executor understands. To produce the correct TTS for PostgreSQL, DML Converter relies on:</p> <ul> <li>The schema metadata that describes how the payload data is represented</li> <li>PostgreSQL catalog (pg_class and pg_type) to learn about the table's information, each column's data type and properties. </li> <li>Object Mapping Rules to determine if it needs to run additional transform expression on the processed data</li> <li>The payload data itself to process</li> </ul> <p>DML Converter consists of several routines that can handle a particular input data type and produce a particular output type. Selecting the right routine for a particular conversion scenario could be a challenge because some data types may be user-defined or created by another extensions that SynchDB does not know much about. SynchDB has to be designed to handle both native and non-native data type that could exist in PostgreSQL.</p> <p>The routine selection starts by looking at the data type created at the PostgreSQL, which can be divided into 2 types, each with slightly different handling techniques:</p> <ul> <li>native data types.</li> <li>non-native data types.</li> </ul>"},{"location":"architecture/openlog_replicator_event_processor/#data-transformation","title":"Data Transformation","text":"<p>After the input data has been processed by the logics as described above, the converter will then check if the user has configured a <code>transform expression</code> that shall be applied to the processed data before applying to PostgreSQL. A transform expression could be any PostgreSQL expressions, commands, or SQL functions that could be run on a psql prompt. It uses the <code>%d</code> as a placeholder character that will be replaced with the processed data during the transformation. For example, a transform expression \"'&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\" will prepend and append additional characters to the processed string data. </p> <p>So, if a non-native data type has category TYPCATEGORY_USER, DML Converter does not have a suitable routine to process this data and will leave it as is, we can define a transform expression to call a custom SQL function from where it knows how to properly handle the data and produce a suitable output. For example, the expression, \"to_my_composite_type('%d')\" will call a user-defined SQL function <code>to_my_composite_type</code> with the data as input. The expression must have a return value as it will be fed into PostgreSQL during apply.</p>"},{"location":"architecture/openlog_replicator_event_processor/#8-error-handler","title":"8) Error Handler","text":"<p>The Error Handler is primarily responsible for handling any error that could arise from each stage of data synchronization. Format Converter supports several error handling strategies that can be configured via \"synchdb.error_handling_strategy\" parameters. Details can be found here.</p>"},{"location":"architecture/openlog_replicator_event_processor/#9-spi-client","title":"9) SPI Client","text":"<p>the SPI Client component exists under the Replication Agent, which serves as a bridge between PostgreSQL core and SynchDB. It is responsible for establishing a connection to SPI server, start a transaction, obtain a snapshot and execute a given SQL query created by the <code>DDL Converter</code> and destroy the connection. For each query to process, the SPI connection is created and destroyed, which may seem inefficient. Since the SPI is only used during DDL, which is normally not very frequent, it should be fine in terms of performance.</p>"},{"location":"architecture/openlog_replicator_event_processor/#10-executor-apis","title":"10) Executor APIs","text":"<p>Also residing in the Replication Agent. This component is responsible for initialize a executor context, open the table, acquire proper locks, create TupleTableSlot (TTS) from the output of DML Converter, call the executor API to execute INSERT, UPDATE, DELETE operations and do resource cleanup. This is generally a much faster approach to do data operations than SPI because it does not need to parse an input query string likst SPI does.</p>"},{"location":"architecture/test_framework/","title":"Test Framework","text":""},{"location":"getting-started/configuration/","title":"SynchDB Configuration","text":"<p>SynchDB supports the following GUC variables in postgresql.conf. These are common parameters that apply the all connectors managed by SynchDB:</p> GUC Variable Type Default Value Description synchdb.naptime integer 100 The delay in milliseconds between each data polling from Debezium runner engine synchdb.dml_use_spi boolean false Option to use SPI to handle DML operations synchdb.synchdb_auto_launcher boolean true Option to automatically launch active SynchDB connector workers. This option only works when SynchDB is included in <code>shared_preload_library</code> GUC option synchdb.dbz_batch_size integer 2048 The maximum number of change events produced by Debezium embedded engine for SynchDB to process. This batch of changes is processed within a single transaction by SynchDB synchdb.dbz_queue_size integer 8192 The maximum size (measured in number of change events) of Debezium embedded engine's change event queue. It should be set at least twice of <code>synchdb.dbz_batch_size</code> synchdb.dbz_connect_timeout_ms integer 30000 The timeout value in milliseconds for Debezium embedded engine to established an initial connection to a remote database synchdb.dbz_query_timeout_ms integer 600000 The timeout value in milliseconds for Debezium embedded engine to execute a query on a remote database synchdb.dbz_skipped_oeprations string \"t\" A comma-separated list of operations Debezium shall skip when processing change events. \"c\" is for inserts, \"u\" is for updates, \"d\" is for deletes, \"t\" is for truncates synchdb.jvm_max_heap_size integer 1024 The maximum heap size in MB to be allocated to Java Virtual Machine (JVM) when starting a connector. synchdb.dbz_snapshot_thread_num integer 2 The number of threads Debezium embedded connector should spawn during initial snapshot. Please note that according to Debezium, multi-threaded snapshot is an <code>incubating feature</code> synchdb.dbz_snapshot_fetch_size integer 0 The number of rows Debezium embedded connector should fetch at a time during initial snapshot. Set it to 0 to let the engine choose automatically synchdb.dbz_snapshot_min_row_to_stream_results integer 0 The minimum number of rows a remote table should contain before Debezium embedded engine will switch to streaming mode during initial snapshot. Set it to 0 to always switching to stream mode synchdb.dbz_incremental_snapshot_chunk_size integer 2048 The maximum number of change events produced by Debezium embedded engine for SynchDB to process during incremental snapshot synchdb.dbz_incremental_snapshot_watermarking_strategy string \"insert-insert The watermarking strategy used by Debezium embedded engine to resolve potential conflicts during incremental snapshot. Possible values are \"insert-insert\" and \"insert-delete\" synchdb.dbz_offset_flush_interval_ms integer 60000 The interval in milliseconds that Debezium embedded engine flushes offset data to disk synchdb.dbz_capture_only_selected_table_ddl boolean true whether or not Debezium embedded engine should capture the schema of all tables (false) or selected tables(true) during initial snapshot synchdb.max_connector_workers integer 30 the maximum number of connector workers that can be running at a time synchdb.error_handling_strategy enum \"exit\" configures the error handling strategy of a connector worker. Possible values are \"exit\" for exiting on error, \"skip\" for continuing on error, \"retry\" for retrying on error synchdb.dbz_log_level enum \"warn\" the log level setting for Debezium Runner. Possible values are \"debug\", \"info\", \"warn\", \"error\", \"all\", \"fatal\", \"off\", \"trace\" synchdb.log_change_on_error boolean true whether the connector should log the original JSON change event in case of error synchdb.jvm_max_direct_buffer_size integer 1024 The maximum direct buffer size in MB to be allocated to hold JSON change events synchdb.dbz_logminer_stream_mode enum \"uncommitted\" The streaming mode for Debezium based Oracle connector. The default is uncommitted, which means all the changes streamed from Oracle via Debezium is uncommitted. This indicates Debezium has to do some work to ensure the integrity of transactions and all associated changes. Setting to \"committed\" shifts this work on Oralce side synchdb.olr_connect_timeout_ms integer 5000 (affects OLR connector only) the connect timeout in milliseconds when connecting to openlog replicator service synchdb.olr_read_timeout_m integer 5000 (affects OLR connector only) the read timeout in milliseconds when reading from a socket synchdb.olr_snapshot_engine enum \"debezium\" the underlining engine to complete the initial snapshot process. Could be \"debezium\" or \"fdw\". If \"fdw\" is selected, you need to ensure the corresponding FDW is installed prior. For example, for Oracle connector, ensure \"oracle_fdw\" is preinstalled. synchdb.cdc_start_delay_ms integer 0 a delay waited after initial snapshot completes and before CDC streaming begins. synchdb.fdw_migrate_with_subtx boolean true option to use sub transactions to migrate a table during FDW based snapshot synchdb.letter_casing_strategy enum \"lowercase\" how should synchdb deal with potentially different object letter casings from different database source. Possible values are: \"lower\" for normalizing the lower case, \"upper\" to normalize to upper case, or \"asis\" to preserve whatever letter casing it receives"},{"location":"getting-started/configuration/#technical-notes","title":"Technical Notes","text":"<ul> <li>GUC (Grand Unified Configuration) variables are global configuration parameters in PostgreSQL</li> <li>Values are set in the <code>postgresql.conf</code> file</li> <li>Changes require a server restart to take effect</li> <li><code>shared_preload_library</code> is a critical system configuration that determines which libraries are loaded at startup, synchdb must be put here to enable connector auto launcher</li> </ul>"},{"location":"getting-started/configuration/#configuration-examples","title":"Configuration Examples","text":"<pre><code># Example configuration in postgresql.conf\nsynchdb.naptime = 1000                                                  # Increase wait time to 1 second\nsynchdb.dml_use_spi = true                                              # Enable SPI usage for DML operations\nsynchdb.synchdb_auto_launcher = true                                    # Enable automatic connector startup\nsynchdb.dbz_batch_size=4096                                             # Each batch can have at most 4096 change events\nsynchdb.dbz_queue_size=8192                                             # Debezium will use 8192 change event queue size\nsynchdb.jvm_max_heap_size=2048                                          # 2GB heap memory to be allocated to a connector\nsynchdb.dbz_snapshot_fetch_size=0                                       # Let Debezium figure out the optimal number of rows to fetch during initial snapshot\nsynchdb.dbz_min_row_to_stream_results=0                                 # Always stream the results during initial snapshot\nsynchdb.dbz_snapshot_thread_num=1                                       # Single thread during Debezium's initial snapshot\nsynchdb.dbz_incremental_snapshot_chunk_size=4096                        # Incremental snapshot produces change events in batches of 4096 max\nsynchdb.dbz_incremental_snapshot_watermarking_strategy='insert_insert'  # Use insert_insert watermarking strategy\nsynchdb.dbz_offset_flush_interval_ms=60000                              # Flush offset data to disk every minute if needed    \nsynchdb.dbz_capture_only_selected_table_ddl=false                       # Debezium will only capture the schema of selected tables rather than all tables\nsynchdb.max_connector_workers=10                                        # 10 connector workers can be run at a time\nsynchdb.error_handling_strategy='retry'                                 # connector should retry on error\nsynchdb.dbz_log_leve='error'                                            # Debezium Runner should log error messages only\nsynchdb.log_change_on_error=true                                        # log JSON change event on error\nsynchdb.cdc_start_delay_ms=30000                                        # wait 30s after snapshot completes and before CDC begins\nsynchdb.olr_snapshot_engine=\"fdw\"                                       # use FDW based snapshot engine to complete the snapshot process\nsynchdb.letter_casing_strategy=\"asis\"                                   # preserve all object letter casings as they appear in the sources\n</code></pre>"},{"location":"getting-started/configuration/#usage-recommendations","title":"Usage Recommendations","text":"<ol> <li> <p>synchdb.naptime</p> <ul> <li>Lower values: Higher update frequency but more system load</li> <li>Higher values: Lower system load but less frequent updates</li> <li>Adjust based on data latency requirements</li> </ul> </li> <li> <p>synchdb.dml_use_spi</p> <ul> <li>Enable if specific SPI integration is needed</li> <li>Keep <code>false</code> for standard DML operations</li> </ul> </li> <li> <p>synchdb.synchdb_auto_launcher</p> <ul> <li>Recommended to keep <code>true</code> for automatic connector resume upon PostgreSQL restarts</li> <li>Change to <code>false</code> only if manual connector control is required</li> </ul> </li> <li> <p>synchdb.dbz_batch_size</p> <ul> <li>Lower values: Slower processing of change events at lower JVM memory usage</li> <li>Higher values: Faster processing of change events at higher JVM memory usage</li> <li>Adjust based on resource requirements</li> </ul> </li> <li> <p>synchdb.dbz_queue_size</p> <ul> <li>Lower values: Smaller Debezium queue to hold change events</li> <li>Higher values: Larger Debezium queue to hold change events</li> <li>Need to be set at least twice of <code>synchdb.dbz_batch_size</code></li> </ul> </li> <li> <p>synchdb.jvm_max_heap_size</p> <ul> <li>Lower values: Smaller heap memory allocated to JVM</li> <li>Higher values: Larger heap memory allocated to JVM</li> <li>Adjust based on system resource and workload requirements</li> <li>Needs increase when working with large number of tables</li> </ul> </li> <li> <p>synchdb.dbz_snapshot_fetch_size</p> <ul> <li>Lower values: Less rows to be fetched from a table during snapshot</li> <li>Higher values: More rows to be fetched from a table during snapshot</li> <li>Recommended to keep it 0 to let Debezium figure out an optimal value</li> </ul> </li> <li> <p>synchdb.dbz_min_row_to_stream_results</p> <ul> <li>Lower values: Less JVM memory requirement, slower processing of change events</li> <li>Higher values: More JVM memory requirement, faster processing of change events</li> <li>Recommended to keep it 0 to let Debezium use streaming mode always to reduce memory usage</li> </ul> </li> <li> <p>synchdb.dbz_snapshot_thread_num</p> <ul> <li>Lower values: Slower data export to SynchDB for processing </li> <li>Higher values: Faster data export to SyncDB for processing</li> <li>Recommended to set it to the same number of CPU cores</li> </ul> </li> <li> <p>synchdb.dbz_incremental_snapshot_chunk_size</p> <ul> <li>Lower values: Slower processing of change events at lower JVM memory usage during incremental snapshot</li> <li>Higher values: Faster processing of change events at higher JVM memory usage during incremental snapshot</li> <li>Recommended to set it the same as <code>synchdb.dbz_batch_size</code> and adjust Adjust based on resource requirements</li> </ul> </li> <li> <p>synchdb.dbz_offset_flush_interval_ms</p> <ul> <li>Lower values: More frequent update to offset file, more IO, less old batches to re-preocess after fault restored</li> <li>Higher values: Less frequent update to offset file, less IO, more old batches to re-preocess after fault restored</li> <li>Recommended to set it to 60000 as Debezium's recommendation</li> </ul> </li> <li> <p>synchdb.max_connector_workers</p> <ul> <li>Lower values: less connector workers can be run at a time, less shared memory requirement</li> <li>Higher values: more connector workers can be run at a time, more shared memory requirement</li> </ul> </li> </ol>"},{"location":"getting-started/configuration/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Adjust <code>synchdb.naptime</code> based on system load and latency requirements</li> <li>Adjust <code>synchdb.dbz_batch_size</code> and <code>synchdb.dbz_queue_size</code> higher to increase processing throughput</li> <li>Adjust <code>synchdb.jvm_max_heap_size</code> based on workload<ul> <li>Smaller number of tables (10k or less) + large amount of data per table: 512MB ~ 1024MB should suffice</li> <li>Larger number of tables (100k or more) + moderate amount of data per table: consider increasing to 2048MB or above</li> </ul> </li> <li>Set <code>synchdb.dbz_snapshot_fetch_size</code> to 0 to let Debezium pick optimal fetch value</li> <li>Set <code>synchdb.dbz_snapshot_thread_num</code> to match number of CPU cores</li> <li>Set <code>synchdb.dbz_min_row_to_stream_results</code> to 0 to always use stream mode to reduce memory usage</li> </ul>"},{"location":"getting-started/configuration/#common-use-cases","title":"Common Use Cases","text":""},{"location":"getting-started/configuration/#high-throughput-systems","title":"High-Throughput Systems","text":"<pre><code>synchdb.naptime = 10            # Faster polling for real-time updates\nsynchdb.dml_use_spi = false     # Standard DML for better performance\nsynchdb.dbz_batch_size = 16384\nsynchdb.dbz_queue_size = 32768\nsynchdb.jvm_max_heap_size = 2048\nsynchdb.dbz_snapshot_thread_num = 4\nsynchdb.dbz_snapshot_fetch_size = 0\nsynchdb.dbz_min_row_to_stream_results = 0\n</code></pre>"},{"location":"getting-started/configuration/#resource-constrained-systems","title":"Resource-Constrained Systems","text":"<pre><code>synchdb.naptime = 1000          # Reduced polling frequency\nsynchdb.dml_use_spi = false     # Minimize additional overhead\nsynchdb.dbz_batch_size = 1024\nsynchdb.dbz_queue_size = 2048\nsynchdb.jvm_max_heap_size = 512\nsynchdb.dbz_snapshot_thread_num = 1\nsynchdb.dbz_snapshot_fetch_size = 0\nsynchdb.dbz_min_row_to_stream_results = 0\n</code></pre>"},{"location":"getting-started/configuration/#developmenttesting","title":"Development/Testing","text":"<pre><code>synchdb.naptime = 500           # Default polling\nsynchdb.dml_use_spi = true      # Enable advanced features for testing\nsynchdb.dbz_batch_size = 2048\nsynchdb.dbz_queue_size = 4096\nsynchdb.jvm_max_heap_size = 1024\nsynchdb.dbz_snapshot_thread_num = 2\nsynchdb.dbz_snapshot_fetch_size = 0\nsynchdb.dbz_min_row_to_stream_results = 0\n</code></pre>"},{"location":"getting-started/configuration/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>High CPU Usage</p> <ul> <li>Increase <code>synchdb.naptime</code></li> <li>Review DML operation patterns</li> <li>Reduce <code>synchdb.dbz_batch_size</code> and <code>synchdb.dbz_queue_size</code></li> <li>Increase <code>synchdb.dbz_snapshot_thread_num</code></li> </ul> </li> <li> <p>Data Latency Issues</p> <ul> <li>Decrease <code>synchdb.naptime</code></li> <li>Increase <code>synchdb.dbz_batch_size</code> and <code>synchdb.dbz_queue_size</code></li> <li>Check network connectivity</li> <li>Increase <code>shared_buffers</code></li> <li>Split workload to more connectors rather than just one</li> <li>Start the connector with <code>no_data</code> mode to obtain schema only and begin CDC rather than <code>initial</code> mode which capture both schema and initial data before CDC begins.</li> </ul> </li> <li> <p>Startup Problems</p> <ul> <li>Verify <code>shared_preload_library</code> configuration</li> <li>Check error messages from <code>synchdb_get_state()</code></li> <li>Check connector worker status</li> </ul> </li> <li> <p>Out of Memory Problems</p> <ul> <li>Increase <code>synchdb.jvm_max_heap_size</code></li> <li>Increase <code>shared_buffers</code></li> </ul> </li> </ol>"},{"location":"getting-started/configuration/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Initial Setup</p> <ul> <li>Start with default values</li> <li>Monitor system performance</li> <li>Adjust gradually based on requirements</li> </ul> </li> <li> <p>Production Environment</p> <ul> <li>Document all configuration changes</li> <li>Test changes in staging first</li> <li>Maintain backup of working configurations</li> </ul> </li> <li> <p>Monitoring</p> <ul> <li>Track system resource usage</li> <li>Monitor data synchronization latency</li> <li>Log configuration changes</li> </ul> </li> </ol>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#install-from-packages","title":"Install from Packages","text":"<p>visit our release page here to download a synchdb packages on supported platforms.</p>"},{"location":"getting-started/installation/#deb-packages","title":".deb Packages","text":"<ol> <li> <p>Install PostgreSQL from official apt repository (version 16 as example): <pre><code>sudo apt install -y postgresql-common\nsudo /usr/share/postgresql-common/pgdg/apt.postgresql.org.sh\nsudo apt install postgresql-16\n</code></pre></p> </li> <li> <p>Install Java Runtime Environment: <pre><code>sudo apt install openjdk-17-jre-headless\n</code></pre></p> </li> <li> <p>Update shared library path: <pre><code>JAVA_PATH=$(which java)\nJRE_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJRE_LIB_PATH=${JRE_HOME_PATH}/lib\necho \"$JRE_LIB_PATH\" | sudo tee /etc/ld.so.conf.d/java.conf\nsudo ldconfig\n</code></pre></p> </li> <li> <p>Install SynchDB: <pre><code>dpkg -i synchdb-1.1-1.ub22.pg16_x86_64.deb\n</code></pre></p> </li> <li>SynchDB should be ready to go. Refer to quick start page to get started</li> </ol>"},{"location":"getting-started/installation/#rpm-packages","title":".rpm Packages","text":"<ol> <li>Install PostgreSQL from official rpm repository (version 16 as example): Refer to official PostgreSQL rpm download instructions for other PostgreSQL versions here <pre><code>sudo dnf install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-9-x86_64/pgdg-redhat-repo-latest.noarch.rpm\nsudo dnf -qy module disable postgresql\nsudo dnf install -y postgresql16-server postgresql16-contrib\n</code></pre></li> <li> <p>Install Java Runtime Environment: <pre><code>sudo dnf install -y java-17-openjdk\n</code></pre></p> </li> <li> <p>Update shared library path: <pre><code>JAVA_PATH=$(which java)\nJRE_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJRE_LIB_PATH=${JRE_HOME_PATH}/lib\necho \"$JRE_LIB_PATH\" | sudo tee /etc/ld.so.conf.d/java.conf\nsudo ldconfig\n</code></pre></p> </li> <li> <p>Install SynchDB: <pre><code>sudo dnf install -y synchdb-1.1-1.el9.pg16.x86_64.rpm\n</code></pre></p> </li> <li>SynchDB should be ready to go. Refer to quick start page to get started</li> </ol>"},{"location":"getting-started/installation/#install-from-pre-compiled-binaries","title":"Install from Pre-compiled Binaries","text":"<p>visit our release page here to download a pre-compiled binaries on supported platforms. We currently support pre-compiled binaries on Debian-based Linux systems such as Ubuntu. Other platforms will be supported in the near future. SynchDB pre-compiled binaries requires existing PostgreSQL to be installed first. The version of PostgreSQL it requires is described in the package name. For example, <code>synchdb-1.1-1.ub22.pg16_x86_64.tar.gz</code> is tar.gz package built on Ubuntu 22.04 against PostgreSQL 16. </p>"},{"location":"getting-started/installation/#pre-compiled-binaries","title":"Pre-compiled Binaries","text":"<ol> <li> <p>Extract the tar.gz package that contains the pre-compiled binaries: <pre><code>tar xzvf synchdb-1.1-1.ub22.pg16_x86_64.tar.gz -C /tmp\n</code></pre></p> </li> <li> <p>Find out the lib and share directories of your current PostgreSQL installation <pre><code>LIBDIR=$(pg_config | grep -w LIBDIR | awk -F ' = ' '/LIBDIR/ {print $2}')\nSHAREDIR=$(pg_config | grep -w SHAREDIR | awk -F ' = ' '/SHAREDIR/ {print $2}')\n</code></pre></p> </li> <li> <p>Copy pre-compiled binaries to the respective directories: <pre><code>cp /tmp/synchdb-1.1-1.ub22.pg16_x86_64/usr/lib/postgresql/16/lib/* $LIBDIR\ncp /tmp/synchdb-1.1-1.ub22.pg16_x86_64.tar.gz/usr/share/postgresql/16/extension/* $SHAREDIR\n</code></pre></p> </li> <li> <p>Install Java Runtime Environment: <pre><code>sudo apt install openjdk-17-jre-headless\n</code></pre></p> </li> <li> <p>Update shared library path: <pre><code>JAVA_PATH=$(which java)\nJRE_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJRE_LIB_PATH=${JRE_HOME_PATH}/lib\necho \"$JRE_LIB_PATH\" | sudo tee /etc/ld.so.conf.d/java.conf\nsudo ldconfig\n</code></pre></p> </li> <li> <p>SynchDB should be ready to go. Refer to quick start page to get started</p> </li> </ol>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<p>This option requires you to build both PostgreSQL and SynchDB from source code.</p>"},{"location":"getting-started/installation/#build-requirements","title":"Build Requirements","text":"<p>The following software is required to build and run SynchDB. The versions listed are the versions tested during development. Older versions may still work.</p> <ul> <li>Java Development Kit 17 or later. Download here</li> <li>Apache Maven 3.6.3 or later. Download here</li> <li>PostgreSQL Source. Git clone here. Refer to this wiki for PostgreSQL build requirements</li> <li>Docker compose 2.28.1 (for testing). Refer to here</li> </ul> <p>Additional Requirement for Openlog Replicator Connector Support (if enabled in build)</p> <ul> <li>libprotobuf-c v1.5.2. Refer to here to build from source.</li> </ul> <p>The following is required if you would like to use FDW based snapshot</p> <ul> <li>OCI v23.9.0. Refer to here for more information</li> <li>oracle_fdw v2.8.0. Refer to here to build from source</li> </ul>"},{"location":"getting-started/installation/#default-synchdb-build-support-mysql-sqlserver-and-oracle-connectors","title":"Default SynchDB Build - Support MySQL, SQLServer and Oracle Connectors","text":"<p>If you already have PostgreSQL installed, you can build and install Default SynchDB with PGXS. Please note that your PostgreSQL installation must have pgcrypto extension as required by SynchDB.</p> <pre><code>USE_PGXS=1 make PG_CONFIG=$(which pg_config)\nUSE_PGXS=1 make build_dbz PG_CONFIG=$(which pg_config)\n\nsudo USE_PGXS=1 make PG_CONFIG=$(which pg_config) install\nsudo USE_PGXS=1 make install_dbz PG_CONFIG=$(which pg_config)\n</code></pre>"},{"location":"getting-started/installation/#build-synchdb-with-openlog-replicator-connector-support","title":"Build SynchDB with Openlog Replicator Connector Support","text":"<p>To build Synchdb with Openlog Replicator Connector support, an additional Synchdb Oracle Parser component must be built as well. This component is based on IvorySQL's Oracle Parser, modified to suit SynchDB and it requires PostgreSQL backend source codes to build successfully. Here's the procedure:</p>"},{"location":"getting-started/installation/#prepare-source-using-163-as-example","title":"Prepare Source (Using 16.3 as example)","text":"<p>Clone the PostgreSQL source and switch to 16.3 release tag <pre><code>git clone https://github.com/postgres/postgres.git\ncd postgres\ngit checkout REL_16_3\n</code></pre></p> <p>Clone the SynchDB source from within the extension folder Note: Branch (synchdb-devel)[https://github.com/Hornetlabs/synchdb/tree/synchdb-devel] is used for development so far. <pre><code>cd contrib/\ngit clone https://github.com/Hornetlabs/synchdb.git\n</code></pre></p>"},{"location":"getting-started/installation/#build-and-install-postgresql","title":"Build and Install PostgreSQL","text":"<p>This can be done by following the standard build and install procedure as described here </p> <p>Warning: SynchDB depends on pgcrypto to encrypt and decrypt sensitive access information. Please ensure PostgreSQL is built with SSL support.</p> <pre><code>cd /home/$USER/postgres\n./configure --with-ssl=openssl --enable-cassert\nmake\nsudo make install\n</code></pre> <p>Build the required pgcrypto extension <pre><code>cd /home/$USER/postgres/contrib/pgcrypto\nmake\nsudo make install\n</code></pre></p>"},{"location":"getting-started/installation/#build-synchdb-with-additional-openlog-replicator-connector-support","title":"Build SynchDB with Additional Openlog Replicator Connector Support","text":"<pre><code># build and install debezium runner\ncd /home/$USER/postgres/contrib/synchdb\nmake build_dbz\nsudo make install_dbz\n\n# build and install oracle parser\nmake oracle_parser\nsudo make install_oracle_parser\n\n# build and install synchdb\nmake WITH_OLR=1\nsudo make WITH_OLR=1 install\n</code></pre>"},{"location":"getting-started/installation/#configure-your-linker-to-find-java-ubuntu","title":"Configure your Linker to find Java (Ubuntu)","text":"<p>Lastly, we also need to tell your system's linker where the newly added Java library (libjvm.so) is located in your system.</p> <p><pre><code># Dynamically set JDK paths\nJAVA_PATH=$(which java)\nJDK_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJDK_LIB_PATH=${JDK_HOME_PATH}/lib\n\necho $JDK_LIB_PATH\necho $JDK_LIB_PATH/server\n\nsudo echo \"$JDK_LIB_PATH\" \uff5c sudo tee -a /etc/ld.so.conf.d/x86_64-linux-gnu.conf\nsudo echo \"$JDK_LIB_PATH/server\" | sudo tee -a /etc/ld.so.conf.d/x86_64-linux-gnu.conf\n</code></pre> Note, for mac with M1/M2 chips, the linker file is located in /etc/ld.so.conf.d/aarch64-linux-gnu.conf</p> <p>Run ldconfig to reload: <pre><code>sudo ldconfig\n</code></pre></p> <p>Ensure synchdo.so extension can link to libjvm Java library on your system: <pre><code>ldd synchdb.so\n        linux-vdso.so.1 (0x00007ffeae35a000)\n        libjvm.so =&gt; /usr/lib/jdk-22.0.1/lib/server/libjvm.so (0x00007fc1276c1000)\n        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fc127498000)\n        libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fc127493000)\n        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fc12748e000)\n        librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007fc127489000)\n        libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007fc1273a0000)\n        /lib64/ld-linux-x86-64.so.2 (0x00007fc128b81000)\n</code></pre></p> <p>If SynchDB is built with openlog replicator support, ensure it can link to libprotobuf-c library on your system: <pre><code>ldd synchdb.so\n        linux-vdso.so.1 (0x00007ffde6ba5000)\n        libjvm.so =&gt; /home/ubuntu/java/jdk-22.0.1/lib/server/libjvm.so (0x00007f3c8e191000)\n        libprotobuf-c.so.1 =&gt; /usr/local/lib/libprotobuf-c.so.1 (0x00007f3c8e186000)\n        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3c8df5d000)\n        libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f3c8df58000)\n        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f3c8df53000)\n        librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f3c8df4c000)\n        libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f3c8de65000)\n        /lib64/ld-linux-x86-64.so.2 (0x00007f3c8f69e000)\n</code></pre></p>"},{"location":"getting-started/prepare_tests_env/","title":"Quick Test Environment","text":"<p>The procedures mentioned here are meant to quickly spin up a external database for verification and feature demostration of Synchdb. The necessary files and scripts for starting sample heterogeneous databases can be found at SynchDB repository here</p>"},{"location":"getting-started/prepare_tests_env/#prepare-a-sample-mysql-database","title":"Prepare a Sample MySQL Database","text":"<p>We can start a sample MySQL database for testing using docker compose. The user credentials are described in the <code>synchdb-mysql-test.yaml</code> file <pre><code>docker compose -f synchdb-mysql-test.yaml up -d\n</code></pre></p> <p>Login to MySQL as <code>root</code> and grant permissions to user <code>mysqluser</code> to perform real-time CDC <pre><code>mysql -h 127.0.0.1 -u root -p\n\nGRANT replication client on *.* to mysqluser;\nGRANT replication slave  on *.* to mysqluser;\nGRANT RELOAD ON *.* TO 'mysqluser'@'%';\nFLUSH PRIVILEGES;\n</code></pre></p> <p>Exit mysql client tool: <pre><code>\\q\n</code></pre></p>"},{"location":"getting-started/prepare_tests_env/#prepare-a-sample-sql-server-database","title":"Prepare a Sample SQL Server Database","text":"<p>We can start a sample SQL Server database for testing using docker compose. The user credentials are described in the <code>synchdb-sqlserver-test.yaml</code> file <pre><code>docker compose -f synchdb-sqlserver-test.yaml up -d\n</code></pre> use synchdb-sqlserver-withssl-test.yaml file for the SQL Server with SSL certificate enabled.</p> <p>You may not have SQL Server client tool installed, you could login to SQL Server container to access its client tool.</p> <p>Find out the container ID for SQL server: <pre><code>id=$(docker ps | grep sqlserver | awk '{print $1}')\n</code></pre></p> <p>Copy the database schema into SQL Server container: <pre><code>docker cp inventory.sql $id:/\n</code></pre></p> <p>Log in to SQL Server container: <pre><code>docker exec -it $id bash\n</code></pre></p> <p>Build the database according to the schema: <pre><code>/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -i /inventory.sql\n</code></pre></p> <p>Run some simple queries (add -N -C if you are using SSL enabled SQL Server): <pre><code>/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -d testDB -Q \"insert into orders(order_date, purchaser, quantity, product_id) values( '2024-01-01', 1003, 2, 107)\"\n\n/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -d testDB -Q \"select * from orders\"\n</code></pre></p>"},{"location":"getting-started/prepare_tests_env/#prepare-a-sample-oracle-database","title":"Prepare a Sample Oracle Database","text":"<p>We can use the free Oracle database docker image provided by Oracle for testing and evaluation of SynchDB. It comes with a free container database <code>FREE</code> and a pluggable database <code>FREEPDB1</code> <pre><code>docker run -d -p 1521:1521 container-registry.oracle.com/database/free:latest\n</code></pre></p> <p>Find out the container ID and login to it: <pre><code>id=$(docker ps | grep oracle | awk '{print $1}')\ndocker exec -it $id bash\n</code></pre></p> <p>Follow the procedure described here to set up logminer and logminer user</p>"},{"location":"getting-started/prepare_tests_env/#use-ci-script-to-prepare-test-databases","title":"Use CI Script to Prepare Test Databases","text":"<p>Example MySQL, SQL Server and Oracle databases can also be prepared using a script, located in <code>ci/</code> folder under the source repository. The script requires docker and docker-compose to run and basically follow the same procedures as described above.</p> <p>Prepare MySQL database for test: <pre><code>DBTYPE=mysql ci/setup-remotedbs.sh\n</code></pre></p> <p>Prepare SQL Server database for test: <pre><code>DBTYPE=sqlserver ci/setup-remotedbs.sh\n</code></pre></p> <p>Prepare Oracle23ai database for test: <pre><code>DBTYPE=oracle ci/setup-remotedbs.sh\n</code></pre></p> <p>Prepare Oracle19c database for test: <pre><code>DBTYPE=ora19c ci/setup-remotedbs.sh\n</code></pre></p> <p>Prepare Oracle19c database with Openlog Replicator for test: <pre><code>DBTYPE=olr OLRVER=1.3.0 ci/setup-remotedbs.sh\n</code></pre></p>"},{"location":"getting-started/quick_start/","title":"Quick Start Guide","text":"<p>The fastest way to try SynchDB is with the pre-built Docker images for SynchDB and companion sources (MySQL, SQL Server, Oracle, etc.). Use the repo\u2019s <code>ezdeploy.sh</code> (Linux only) to guide you with simple interactive prompts to spin up your chosen sources plus optional Prometheus/Grafana, so you can validate capture and replication in minutes. </p>"},{"location":"getting-started/quick_start/#ezdeploysh","title":"ezdeploy.sh","text":"<p>This tool can be downloaded from SynchDB source repository here. It requires <code>docker</code>, and <code>docker-compose</code> (or <code>docker compose</code>) and must be run on Linux. It prints a list of deployment options when run:</p> <pre><code>./ezdeploy.sh\n----------------------------------\n-----&gt; Welcome to ezdeploy! &lt;-----\n----------------------------------\n\nplease select a quick deploy option:\n         1) synchdb only\n         2) synchdb + mysql\n         3) synchdb + sqlserver\n         4) synchdb + oracle23ai\n         5) synchdb + oracle19c\n         6) synchdb + olr(oracle19c)\n         7) synchdb + all source databases\n         8) custom deployment\n         9) deploy monitoring\n        10) teardown deployment\nenter your selection:\n</code></pre> <ul> <li>For synchdb deployment only, use option <code>1)</code>.</li> <li>For synchdb + 1 source database, use option <code>2)</code> to <code>6)</code>.</li> <li>For synchdb + all source databases, use option <code>7)</code>.</li> <li>For synchdb + custom source databases, use option <code>8)</code>.</li> <li>For prometheus and grafana monitoring deployment, use option <code>9)</code>.</li> <li>to teardown all deployment, use option <code>10)</code>.</li> </ul>"},{"location":"getting-started/quick_start/#access-details-of-source-databases-for-testing","title":"Access Details of Source Databases for Testing","text":"<p>MySQL:</p> <ul> <li>database: inventory</li> <li>schema: N/A</li> <li>user: mysqluser</li> <li>password: mysqlpwd</li> </ul> <p>Sqlserver:</p> <ul> <li>database: testDB</li> <li>schema: dbo</li> <li>user: sa</li> <li>password: Password!</li> </ul> <p>Oracle23ai:</p> <ul> <li>database: FREE</li> <li>schema: c##dbzuser</li> <li>user: c##dbzuser</li> <li>password: dbz</li> </ul> <p>Oracle19c:</p> <ul> <li>database: FREE</li> <li>schema: DBZUSER</li> <li>user: DBZUSER</li> <li>password: dbz</li> </ul> <p>Openlog Replicator (OLR):</p> <ul> <li>service name: ORACLE</li> </ul>"},{"location":"getting-started/quick_start/#access-synchdb-with-psql","title":"Access Synchdb with psql","text":"<p>Once deployed, synchdb can be accessed by:</p> <pre><code>docker exec -it synchdb bash -c \"psql -d postgres\"\n</code></pre> <p>Once connected, create the <code>synchdb</code> extension:</p> <pre><code>CREATE EXTENSION synchdb CASCADE;\n</code></pre>"},{"location":"getting-started/quick_start/#create-a-connector","title":"Create a Connector","text":"<p>Here are some examples to create a basic connector for each supported source database type.</p> <p>MySQL: <pre><code>SELECT synchdb_add_conninfo('mysqlconn',\n                            'mysql',\n                            3306,\n                            'mysqluser',\n                            'mysqlpwd',\n                            'inventory',\n                            'postgres',\n                            'null',\n                            'null',\n                            'mysql');\n</code></pre></p> <p>Sqlserver: <pre><code>SELECT synchdb_add_conninfo('sqlserverconn',\n                            'sqlserver', \n                            1433,\n                            'sa',\n                            'Password!',\n                            'testDB',\n                            'postgres',\n                            'null',\n                            'null',\n                            'sqlserver');\n</code></pre></p> <p>Oracle23ai: <pre><code>SELECT synchdb_add_conninfo('oracleconn',\n                            'oracle',\n                            1521,\n                            'c##dbzuser',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'oracle');\n</code></pre></p> <p>Oracle19c: <pre><code>SELECT synchdb_add_conninfo('ora19cconn',\n                            'ora19c',\n                            1521,\n                            'DBZUSER',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'oracle');\n</code></pre></p> <p>OLR(Oracle19c): <pre><code>SELECT synchdb_add_conninfo('olrconn',\n                            'ora19c',\n                            1521,\n                            'DBZUSER',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'olr');\n\nSELECT synchdb_add_olr_conninfo('olrconn',\n                                'OpenLogReplicator',\n                                7070,\n                                'ORACLE');\n</code></pre></p> <p>View Created Connectors:</p> <pre><code>SELECT * FROM synchdb_conninfo;\n</code></pre> <p>More details on creating a connector can be found here</p>"},{"location":"getting-started/quick_start/#create-object-mappings","title":"Create Object Mappings","text":"<p>By default, source database names will be mapped to a schema name in destination. Object mappings can be used to change this schema name. Let's change the destination schema for <code>orders</code> table from oracle based connectors and leave the rest as default.</p> <pre><code>SELECT synchdb_add_objmap('oracleconn','table','free.c##dbzuser.orders','oracle23ai.orders');\nSELECT synchdb_add_objmap('ora19cconn','table','free.dbzuser.orders','oracle19c.orders');\nSELECT synchdb_add_objmap('olrconn','table','free.dbzuser.orders','olr.orders');\n</code></pre> <p>More details on creating a object mappings can be found here</p>"},{"location":"getting-started/quick_start/#create-jmx-exporter-optional","title":"Create JMX Exporter - Optional","text":"<p>Here are some examples to enable JMX exporter for monitoring (If Prometheus + Grafana have been pre-deployed by <code>ezdeploy.sh</code>):</p> <p>MySQL: <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n                            'mysqlconn',\n                            '/home/ubuntu/jmx_prometheus_javaagent-1.3.0.jar',\n                            9404,\n                            '/home/ubuntu/jmxexport.conf');\n</code></pre></p> <p>Sqlserver: <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n                            'sqlserverconn',\n                            '/home/ubuntu/jmx_prometheus_javaagent-1.3.0.jar',\n                            9405,\n                            '/home/ubuntu/jmxexport.conf');\n</code></pre></p> <p>Oracle23ai: <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n                            'oracleconn',\n                            '/home/ubuntu/jmx_prometheus_javaagent-1.3.0.jar',\n                            9406,\n                            '/home/ubuntu/jmxexport.conf');\n</code></pre></p> <p>Oracle19c: <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n                            'ora19cconn',\n                            '/home/ubuntu/jmx_prometheus_javaagent-1.3.0.jar',\n                            9407,\n                            '/home/ubuntu/jmxexport.conf');\n</code></pre></p> <p>More details on creating a JMX Exporter can be found here</p>"},{"location":"getting-started/quick_start/#start-a-connector","title":"Start a Connector","text":"<p>MySQL: <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre></p> <p>Sqlserver: <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn');\n</code></pre></p> <p>Oracle23ai: <pre><code>SELECT synchdb_start_engine_bgw('oracleconn');\n</code></pre></p> <p>Oracle19c: <pre><code>SELECT synchdb_start_engine_bgw('ora19cconn');\n</code></pre></p> <p>OLR(Oracle19c): <pre><code>SELECT synchdb_start_engine_bgw('olrconn');\n</code></pre></p> <p>More details on connector start can be found here</p>"},{"location":"getting-started/quick_start/#check-connector-running-state","title":"Check Connector Running State","text":"<p>Use <code>synchdb_state_view()</code> to examine all connectors' running states. </p> <pre><code>SELECT * FROM synchdb_state_view;\n</code></pre> <p>Example outputs: <pre><code>postgres=# SELECT * FROM synchdb_state_view;\n     name      | connector_type |  pid   |       stage      |  state  |   err    |                                           last_dbz_offset\n---------------+----------------+--------+------------------+---------+----------+------------------------------------------------------------------------------------------------------\n sqlserverconn | sqlserver      | 579820 | initial snapshot | polling | no error | {\"commit_lsn\":\"0000006a:00006608:0003\",\"snapshot\":true,\"snapshot_completed\":false}\n mysqlconn     | mysql          | 579845 | initial snapshot | polling | no error | {\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}\n oracleconn    | oracle         | 580053 | initial snapshot | polling | no error | offset file not flushed yet\n ora19cconn    | oracle         | 593421 | initial snapshot | polling | no error | offset file not flushed yet\n olrconn       | oracle         | 601235 | initial snapshot | polling | no error | offset file not flushed yet\n(5 rows)\n</code></pre></p> <p>More on running states here, and also running statistics here.</p>"},{"location":"getting-started/quick_start/#check-the-tables-and-data-from-initial-snapshot","title":"Check the Tables and Data from Initial Snapshot","text":"<p>By default, the connector will perform a <code>initial</code> snapshot to capture both the table schema and initial data, convert and apply them to PostgreSQL under different <code>schema</code>. You should see something similar to the following:</p> <p>MySQL: <pre><code>\\dt inventory.*\n</code></pre></p> <pre><code>\\dt inventory.*\n               List of relations\n  Schema   |       Name       | Type  | Owner\n-----------+------------------+-------+--------\n inventory | addresses        | table | ubuntu\n inventory | customers        | table | ubuntu\n inventory | geom             | table | ubuntu\n inventory | orders           | table | ubuntu\n inventory | products         | table | ubuntu\n inventory | products_on_hand | table | ubuntu\n(6 rows)\n</code></pre> <p>Sqlserver: <pre><code>\\dt testdb.*\n</code></pre></p> <pre><code>\\dt testdb.*\n             List of relations\n Schema |       Name       | Type  | Owner\n--------+------------------+-------+--------\n testdb | customers        | table | ubuntu\n testdb | orders           | table | ubuntu\n testdb | products         | table | ubuntu\n testdb | products_on_hand | table | ubuntu\n(4 rows)\n</code></pre> <p>Oracle23ai <pre><code>\\dt oracle23ai.*\n</code></pre></p> <pre><code>\\dt oracle23ai.*\n          List of relations\n   Schema   |  Name  | Type  | Owner\n------------+--------+-------+--------\n oracle23ai | orders | table | ubuntu\n(1 row)\n</code></pre> <p>Oracle19c <pre><code>\\dt oracle19c.*\n</code></pre></p> <pre><code>\\dt oracle19c.*\n          List of relations\n  Schema   |  Name  | Type  | Owner\n-----------+--------+-------+--------\n oracle19c | orders | table | ubuntu\n(1 row)\n</code></pre> <p>OLR <pre><code>\\dt olr.*\n</code></pre></p> <pre><code>\\dt olr.*\n        List of relations\n Schema |  Name  | Type  | Owner\n--------+--------+-------+--------\n olr    | orders | table | ubuntu\n(1 row)\n</code></pre>"},{"location":"getting-started/quick_start/#similate-an-insert-event-and-observe-cdc","title":"Similate an INSERT Event and Observe CDC","text":"<p>We can use <code>docker exec</code> to similate an INSERT for each connector type and observe the Change Data Capture (CDC).</p> <p>MySQL: <pre><code>docker exec -i mysql mysql -D inventory -umysqluser -pmysqlpwd -e \"INSERT INTO orders(order_date, purchaser, quantity, product_id) VALUES ('2025-12-12', 1002, 10000, 102)\"\n</code></pre></p> <pre><code>postgres=# SELECT * from inventory.orders;\n order_number | order_date | purchaser | quantity | product_id\n--------------+------------+-----------+----------+------------\n        10001 | 2016-01-16 |      1001 |        1 |        102\n        10002 | 2016-01-17 |      1002 |        2 |        105\n        10003 | 2016-02-19 |      1002 |        2 |        106\n        10004 | 2016-02-21 |      1003 |        1 |        107\n        10005 | 2025-12-12 |      1002 |    10000 |        102\n(5 rows)\n</code></pre> <p>Sqlserver: <pre><code>docker exec -i sqlserver /opt/mssql-tools18/bin/sqlcmd -U sa -P 'Password!' -d testDB -C -Q \"INSERT INTO orders(order_date, purchaser, quantity, product_id) VALUES ('2025-12-12', 1002, 10000, 102)\"\n</code></pre></p> <pre><code>postgres=# SELECT * from testdb.orders;\n order_number | order_date | purchaser | quantity | product_id\n--------------+------------+-----------+----------+------------\n        10001 | 2016-01-16 |      1001 |        1 |        102\n        10002 | 2016-01-17 |      1002 |        2 |        105\n        10003 | 2016-02-19 |      1002 |        2 |        106\n        10004 | 2016-02-21 |      1003 |        1 |        107\n        10005 | 2025-12-12 |      1002 |    10000 |        102\n(5 rows)\n</code></pre> <p>Oracle23ai: <pre><code>echo -ne \"INSERT INTO orders(order_number, order_date, purchaser, quantity, product_id) VALUES (10005, TO_DATE('2025-12-12', 'YYYY-MM-DD'), 1002, 10000, 102);\\n\" | docker exec -i oracle sqlplus c##dbzuser/dbz@//localhost:1521/FREE\n</code></pre></p> <pre><code>postgres=# SELECT * FROM oracle23ai.orders;\n order_number |     order_date      | purchaser | quantity | product_id\n--------------+---------------------+-----------+----------+------------\n        10001 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10002 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10003 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10004 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10005 | 2025-12-12 00:00:00 |      1002 |    10000 |        102\n(5 rows)\n</code></pre> <p>Oracle19c: <pre><code>echo -ne \"INSERT INTO orders(order_number, order_date, purchaser, quantity, product_id) VALUES (10005, TO_DATE('2025-12-12', 'YYYY-MM-DD'), 1002, 10000, 102);\\n\" | docker exec -i ora19c sqlplus DBZUSER/dbz@//localhost:1521/FREE\n</code></pre></p> <pre><code>postgres=# SELECT * FROM oracle19c.orders;\n order_number |     order_date      | purchaser | quantity | product_id\n--------------+---------------------+-----------+----------+------------\n        10001 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10002 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10003 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10004 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10005 | 2025-12-12 00:00:00 |      1002 |    10000 |        102\n(5 rows)\n</code></pre> <p>OLR: <pre><code>echo -ne \"INSERT INTO orders(order_number, order_date, purchaser, quantity, product_id) VALUES (10005, TO_DATE('2025-12-12', 'YYYY-MM-DD'), 1002, 10000, 102);\\n\" | docker exec -i ora19c sqlplus DBZUSER/dbz@//localhost:1521/FREE\n</code></pre></p> <pre><code>postgres=# SELECT * FROM olr.orders;\n order_number |     order_date      | purchaser | quantity | product_id\n--------------+---------------------+-----------+----------+------------\n        10001 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10002 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10003 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10004 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10005 | 2025-12-12 00:00:00 |      1002 |    10000 |        102\n(5 rows)\n</code></pre>"},{"location":"getting-started/quick_start/#connector-metrics-on-grafana-optional","title":"Connector Metrics on Grafana - Optional","text":"<p>Connector metrics will be available on Grafana if you choose to deploy monitoring using <code>ezdeploy.sh</code> and have called the optional <code>synchdb_add_jmx_exporter_conninfo()</code> before starting the connector. </p> <ul> <li>Access Grafana: http://localhost:3000/</li> <li>Default Login: admin/admin (You will be required to change password on first time login)</li> </ul> <p>Nativate to the dashboards menu: </p> <p>Select desired templates: * Java Virtual Machine - resource information about JVM * SynchDB MySQL Dashboard - information about MySQL connector * SynchDB SQLServer Dashboard - information about SQLServer connector * SynchDB Oracle Dashboard - information about Oracle connector</p> <p>Select desired Instance: Each connector with JMX exporter enabled is bound to a dedicated port number so that prometheus can fetch the data from. Use the instance drop-down menu to select a connector by port number.</p> <p></p> <p>Java Virtual Machine Dashboard: </p> <p>MySQL Dashboard: </p> <p>SQLServer Dashboard: </p> <p>Oracle Dashboard: </p>"},{"location":"getting-started/quick_start/#stop-and-remove-a-connector","title":"Stop and Remove a Connector","text":"<p>MySQL: <pre><code>SELECT synchdb_stop_engine_bgw('mysqlconn');\nSELECT synchdb_del_conninfo('mysqlconn');\n</code></pre></p> <p>Sqlserver: <pre><code>SELECT synchdb_stop_engine_bgw('sqlserverconn');\nSELECT synchdb_del_conninfo('sqlserverconn');\n</code></pre></p> <p>Oracle23ai: <pre><code>SELECT synchdb_stop_engine_bgw('oracleconn');\nSELECT synchdb_del_conninfo('oracleconn');\n</code></pre></p> <p>Oracle19c: <pre><code>SELECT synchdb_stop_engine_bgw('ora19cconn');\nSELECT synchdb_del_conninfo('ora19cconn');\n</code></pre></p> <p>OLR(Oracle19c): <pre><code>SELECT synchdb_stop_engine_bgw('olrconn');\nSELECT synchdb_del_conninfo('olrconn');\n</code></pre></p>"},{"location":"getting-started/remote_database_setups/","title":"Source Database Setups","text":"<p>Before Synchdb can interact with an external, heterogeneous database and start the replication, it needs to be configured according to the procedure below.</p>"},{"location":"getting-started/remote_database_setups/#set-up-mysql-for-synchdb","title":"Set up MySQL for SynchDB","text":""},{"location":"getting-started/remote_database_setups/#create-a-user","title":"Create a User","text":"<p>create a user <pre><code>mysql&gt; CREATE USER 'user'@'localhost' IDENTIFIED BY 'password';\n</code></pre></p> <p>grant required permissions <pre><code>mysql&gt; GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'user' IDENTIFIED BY 'password';\n</code></pre></p> <p>finalize the user's permission <pre><code>mysql&gt; FLUSH PRIVILEGES;\n</code></pre></p>"},{"location":"getting-started/remote_database_setups/#enable-binlog","title":"Enable binlog","text":"<p>check if binlog is enabled <pre><code>// for MySQL 5.x\nmysql&gt; SELECT variable_value as \"BINARY LOGGING STATUS (log-bin) ::\"\nFROM information_schema.global_variables WHERE variable_name='log_bin';\n\n// for MySQL 8.x\nmysql&gt; SELECT variable_value as \"BINARY LOGGING STATUS (log-bin) ::\"\nFROM performance_schema.global_variables WHERE variable_name='log_bin';\n</code></pre></p> <p>add the properties below to configuration file if binlog is <code>OFF</code> <pre><code>server-id                   = 223344\nlog_bin                     = mysql-bin\nbinlog_format               = ROW\nbinlog_row_image            = FULL\nbinlog_expire_logs_seconds  = 864000\n</code></pre></p> <p>check binlog status again <pre><code>// for MySQL 5.x\nmysql&gt; SELECT variable_value as \"BINARY LOGGING STATUS (log-bin) ::\"\nFROM information_schema.global_variables WHERE variable_name='log_bin';\n\n// for MySQL 8.x\nmysql&gt; SELECT variable_value as \"BINARY LOGGING STATUS (log-bin) ::\"\nFROM performance_schema.global_variables WHERE variable_name='log_bin';\n</code></pre></p>"},{"location":"getting-started/remote_database_setups/#enable-gtids-optional","title":"Enable GTIDs (Optional)","text":"<p>Global transaction identifiers (GTIDs) uniquely identify transactions that occur on a server within a cluster. Though not required for SynchDB connector, using GTIDs simplifies replication and enables you to more easily confirm if primary and replica servers are consistent.</p> <p>enable <code>gtid_mode</code> <pre><code>mysql&gt; gtid_mode=ON\n</code></pre></p> <p>enable <code>enforce_gtid_consistency</code> <pre><code>mysql&gt; enforce_gtid_consistency=ON\n</code></pre></p> <p>confirm changes <pre><code>mysql&gt; show global variables like '%GTID%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| enforce_gtid_consistency | ON    |\n| gtid_mode                | ON    |\n+--------------------------+-------+\n</code></pre></p>"},{"location":"getting-started/remote_database_setups/#configure-session-timeout","title":"Configure Session Timeout","text":"<p>When an initial consistent snapshot is made for large databases, your established connection could timeout while the tables are being read. You can prevent this behavior by configuring <code>interactive_timeout</code> and <code>wait_timeout</code> in your MySQL configuration file.</p> <p>configure <code>interactive_timeout:</code> <pre><code>mysql&gt; interactive_timeout=&lt;duration in seconds&gt;\n</code></pre></p> <p>configure <code>wait_timeout</code> <pre><code>mysql&gt; wait_timeout=&lt;duration in seconds&gt;\n</code></pre></p>"},{"location":"getting-started/remote_database_setups/#enable-query-log-events","title":"Enable Query Log Events","text":"<p>You might want to see the original SQL statement for each binlog event. Enabling the <code>binlog_rows_query_log_events</code> option in the MySQL configuration file allows you to do this. Currently SynchDB does not process or parse the original SQL statement in anyway even if they are included. These are for reference / debug only.</p> <p>enable <code>binlog_rows_query_log_events</code> <pre><code>mysql&gt; binlog_rows_query_log_events=ON\n</code></pre></p>"},{"location":"getting-started/remote_database_setups/#validate-binlog-row-value-options","title":"Validate Binlog Row Value Options","text":"<p>Verify the setting of the <code>binlog_row_value_options</code> variable in the database. To enable the connector to consume UPDATE events, this variable must be set to a value other than <code>PARTIAL_JSON</code>.</p> <p>check current variable value <pre><code>mysql&gt; show global variables where variable_name = 'binlog_row_value_options';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| binlog_row_value_options |       |\n+--------------------------+-------+\n</code></pre></p> <p>if the value of the variable is <code>PARTIAL_JSON</code>, run the following to unset it <pre><code>mysql&gt; set @@global.binlog_row_value_options=\"\" ;\n</code></pre></p>"},{"location":"getting-started/remote_database_setups/#set-up-sqlserver-for-synchdb","title":"Set up SQLServer for SynchDB","text":""},{"location":"getting-started/remote_database_setups/#enable-cdc-on-the-sqlserver-database","title":"Enable CDC on the SQLServer Database","text":"<p>Before you can enable CDC for a table, you must enable it for the SQL Server database. A SQLServer admin enables CDC by running a system stored procedure. System stored procedures can be run by using SQL Server Management Studio, or by using Transact-SQL.</p> <pre><code>USE MyDB\nGO\nEXEC sys.sp_cdc_enable_db\nGO\n</code></pre>"},{"location":"getting-started/remote_database_setups/#enable-cdc-on-a-sqlserver-table","title":"Enable CDC on a SQLServer Table","text":"<p>SQLServer admin must enable change data capture on the source tables that you want SynchDB to capture. The database must already be enabled for CDC. To enable CDC on a table, a SQLServer administrator runs the stored procedure <code>sys.sp_cdc_enable_table</code> for the table. SQL Server CDC must be enabled for every table that you want to capture.</p> <p>enable 3 tables <code>customer</code>, <code>district</code>, and <code>history</code> for SynchDB to capture:</p> <pre><code>USE MyDB\nGO\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'customer', @role_name = NULL, @supports_net_changes = 0;\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'district', @role_name = NULL, @supports_net_changes = 0;\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'history', @role_name = NULL, @supports_net_changes = 0;\nGO\n</code></pre>"},{"location":"getting-started/remote_database_setups/#verify-user-permission-for-cdc-tables","title":"Verify User Permission for CDC Tables","text":"<p>A SQLServer administrator can run a system stored procedure to query a database or table to retrieve its CDC configuration information. </p> <p>The query below returns configuration information for each table in the database that is enabled for CDC and that contains change data that the caller is authorized to access. If the result is empty, verify that the user has privileges to access both the capture instance and the CDC tables.</p> <pre><code>USE MyDB;\nGO\nEXEC sys.sp_cdc_help_change_data_capture\nGO\n</code></pre>"},{"location":"getting-started/remote_database_setups/#when-table-schema-changed-while-cdc-is-enabled","title":"When Table Schema Changed While CDC is Enabled","text":"<p>If a table has already been added to the CDC capture list and being captured by SynchDB already, any schema change that has happened to this table on SQLServer needs to be re-added back to the CDC capture list to generate a proper DDL ALTER TABLE event to SynchDB. Refer to DDL Replication page for more information.</p>"},{"location":"getting-started/remote_database_setups/#set-up-oracle-for-synchdb","title":"Set up Oracle for SynchDB","text":"<p>The following examples are based on container database <code>FREE</code> and pluggable database <code>FREEPDB1</code></p>"},{"location":"getting-started/remote_database_setups/#set-a-password-for-sys-user","title":"Set a Password for Sys User","text":"<pre><code>sqlplus / as sysdba\n    Alter user sys identified by oracle;\nExit\n</code></pre>"},{"location":"getting-started/remote_database_setups/#configure-logminer","title":"Configure logminer","text":"<pre><code>sqlplus /nolog\n\n    CONNECT sys/oracle as sysdba;\n    alter system set db_recovery_file_dest_size = 10G;\n    alter system set db_recovery_file_dest = '/opt/oracle/oradata/recovery_area' scope=spfile;\n    shutdown immediate;\n    startup mount;\n    alter database archivelog;\n    alter database open;\n    archive log list;\nexit\n</code></pre>"},{"location":"getting-started/remote_database_setups/#create-a-logminer-user","title":"Create a logminer User","text":"<pre><code>sqlplus sys/oracle@//localhost:1521/FREE as sysdba\n\n    ALTER DATABASE ADD SUPPLEMENTAL LOG DATA;\n    ALTER PROFILE DEFAULT LIMIT FAILED_LOGIN_ATTEMPTS UNLIMITED;\n    exit;\n\nsqlplus sys/oracle@//localhost:1521/FREE as sysdba\n\n    CREATE TABLESPACE LOGMINER_TBS DATAFILE '/opt/oracle/oradata/FREE/logminer_tbs.dbf' SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;\n    exit;\n\nsqlplus sys/oracle@//localhost:1521/FREEPDB1 as sysdba\n\n    CREATE TABLESPACE LOGMINER_TBS DATAFILE '/opt/oracle/oradata/FREE/FREEPDB1/logminer_tbs.dbf' SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;\n    exit;\n\nsqlplus sys/oracle@//localhost:1521/FREE as sysdba\n\n    CREATE USER c##dbzuser IDENTIFIED BY dbz DEFAULT TABLESPACE LOGMINER_TBS QUOTA UNLIMITED ON LOGMINER_TBS CONTAINER=ALL;\n\n    GRANT CREATE SESSION TO c##dbzuser CONTAINER=ALL;\n    GRANT SET CONTAINER TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$DATABASE TO c##dbzuser CONTAINER=ALL;\n    GRANT FLASHBACK ANY TABLE TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ANY TABLE TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT_CATALOG_ROLE TO c##dbzuser CONTAINER=ALL;\n    GRANT EXECUTE_CATALOG_ROLE TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ANY TRANSACTION TO c##dbzuser CONTAINER=ALL;\n    GRANT LOGMINING TO c##dbzuser CONTAINER=ALL;\n\n    GRANT SELECT ANY DICTIONARY TO c##dbzuser CONTAINER=ALL;\n\n    GRANT CREATE TABLE TO c##dbzuser CONTAINER=ALL;\n    GRANT LOCK ANY TABLE TO c##dbzuser CONTAINER=ALL;\n    GRANT CREATE SEQUENCE TO c##dbzuser CONTAINER=ALL;\n\n    GRANT EXECUTE ON DBMS_LOGMNR TO c##dbzuser CONTAINER=ALL;\n    GRANT EXECUTE ON DBMS_LOGMNR_D TO c##dbzuser CONTAINER=ALL;\n\n    GRANT SELECT ON V_$LOG TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$LOG_HISTORY TO c##dbzuser CONTAINER=ALL;\n\n    GRANT SELECT ON V_$LOGMNR_LOGS TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$LOGMNR_CONTENTS TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$LOGMNR_PARAMETERS TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$LOGFILE TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$ARCHIVED_LOG TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$ARCHIVE_DEST_STATUS TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$TRANSACTION TO c##dbzuser CONTAINER=ALL; \n    GRANT SELECT ON V_$MYSTAT TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$STATNAME TO c##dbzuser CONTAINER=ALL; \n\n    GRANT EXECUTE ON DBMS_WORKLOAD_REPOSITORY TO C##DBZUSER;\n    GRANT SELECT ON DBA_HIST_SNAPSHOT TO C##DBZUSER;\n    GRANT EXECUTE ON DBMS_WORKLOAD_REPOSITORY TO PUBLIC;\n\n\n    Exit\n</code></pre>"},{"location":"getting-started/remote_database_setups/#enable-supplemental-log-data-for-tables-designated-for-capture","title":"Enable Supplemental Log Data for Tables Designated for Capture","text":"<p>This configuration needs to be run on each table designzted for catpure in order to correctly handle the UPDATE and DELETE operations.</p> <pre><code>ALTER TABLE customer ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;\nALTER TABLE products ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;\n... etc\n</code></pre>"},{"location":"getting-started/remote_database_setups/#additional-oracle-setups-for-openlog-replicator-support","title":"Additional Oracle Setups for Openlog Replicator Support","text":"<p>Openlog Replicator requires additional permissions to stream Oracle changes:</p> <pre><code>GRANT SELECT, FLASHBACK ON SYS.CCOL$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.CDEF$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.COL$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.DEFERRED_STG$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.ECOL$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.LOB$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.LOBCOMPPART$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.LOBFRAG$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.OBJ$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TAB$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TABCOMPART$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TABPART$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TABSUBPART$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TS$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.USER$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON XDB.XDB$TTSET TO DBZUSER;\nGRANT FLASHBACK ANY TABLE TO DBZUSER;\nGRANT SELECT ON SYS.V_$ARCHIVED_LOG TO DBZUSER;\nGRANT SELECT ON SYS.V_$DATABASE TO DBZUSER;\nGRANT SELECT ON SYS.V_$DATABASE_INCARNATION TO DBZUSER;\nGRANT SELECT ON SYS.V_$LOG TO DBZUSER;\nGRANT SELECT ON SYS.V_$LOGFILE TO DBZUSER;\nGRANT SELECT ON SYS.V_$PARAMETER TO DBZUSER;\nGRANT SELECT ON SYS.V_$STANDBY_LOG TO DBZUSER;\nGRANT SELECT ON SYS.V_$TRANSPORTABLE_PLATFORM TO DBZUSER;\nDECLARE\n    CURSOR C1 IS SELECT TOKSUF FROM XDB.XDB$TTSET;\n    CMD VARCHAR2(2000);\nBEGIN\n    FOR C IN C1 LOOP\n        CMD := 'GRANT SELECT, FLASHBACK ON XDB.X$NM' || C.TOKSUF || ' TO DBZUSER';\n        EXECUTE IMMEDIATE CMD;\n        CMD := 'GRANT SELECT, FLASHBACK ON XDB.X$QN' || C.TOKSUF || ' TO DBZUSER';\n        EXECUTE IMMEDIATE CMD;\n        CMD := 'GRANT SELECT, FLASHBACK ON XDB.X$PT' || C.TOKSUF || ' TO DBZUSER';\n        EXECUTE IMMEDIATE CMD;\n    END LOOP;\nEND;\n</code></pre>"},{"location":"getting-started/remote_database_setups/#set-up-postgres-connector-for-synchdb","title":"Set up Postgres Connector for SynchDB","text":"<p>PostgreSQL server needs to be configured to be used as a database source to SynchDB</p>"},{"location":"getting-started/remote_database_setups/#guc-settings","title":"GUC Settings","text":"<pre><code>wal_level = logical\nmax_wal_senders = &lt;&lt; may need to be adjusted based on your requirement - default is 10 &gt;&gt;\nmax_replication_slots = &lt;&lt; may need to be adjusted based on your requirement - default is 10 &gt;&gt;\nwal_writer_delay = &lt;&lt; recommend to set to 10ms if `synchronous_commit` has a value other than \"on\". Default is 200ms &gt;&gt;\n</code></pre>"},{"location":"getting-started/remote_database_setups/#permission-settings","title":"Permission Settings","text":"<p>Create a new user with replication privileges:</p> <pre><code>CREATE ROLE &lt;name&gt; REPLICATION LOGIN;\n</code></pre> <p>SynchDB streams change events for PostgreSQL source tables from publications that are created for the tables. Publications contain a filtered set of change events that are generated from one or more tables. The data in each publication is filtered based on the publication specification. The specification can be created by the PostgreSQL database administrator or by the Debezium connector. To permit the SynchDB Postgres connector to create publications and specify the data to replicate to them, the connector must operate with specific privileges in the database.</p> <p>There are several options for determining how publications are created. In general, it is best to manually create publications for the tables that you want to capture, before you set up the connector. However, you can configure your environment in a way that permits SynchDB to create publications automatically, and to specify the data that is added to them.</p> <p>SynchDB uses include list properties (when a connector is created with <code>synchdb_add_conninfo</code>) to specify how data is inserted in the publication. </p> <p>For SynchDB to create a PostgreSQL publication, it must run as a user that has the following privileges:</p> <ul> <li>Replication privileges in the database to add the table to a publication.</li> <li>CREATE privileges on the database to add publications.</li> <li>SELECT privileges on the tables to copy the initial table data. Table owners automatically have SELECT permission for the table.</li> </ul> <p>To add tables to a publication, the user must be an owner of the table. But because the source table already exists, you need a mechanism to share ownership with the original owner. To enable shared ownership, you create a PostgreSQL replication group, and then add the existing table owner and the replication user to the group.</p> <p>Procedure:</p> <ul> <li>Create a replication group.</li> </ul> <pre><code>CREATE ROLE &lt;replication_group&gt;;\n</code></pre> <ul> <li>Add the original owner of the table to the group.</li> </ul> <pre><code>GRANT REPLICATION_GROUP TO &lt;original_owner&gt;;\n</code></pre> <ul> <li>Add the Debezium replication user to the group.</li> </ul> <pre><code>GRANT REPLICATION_GROUP TO &lt;replication_user&gt;;\n</code></pre> <ul> <li>Transfer ownership of the table to . <pre><code>ALTER TABLE &lt;table_name&gt; OWNER TO REPLICATION_GROUP;\n</code></pre>"},{"location":"getting-started/remote_database_setups/#pg_hba-settings","title":"pg_hba Settings","text":"<p>To enable Debezium to replicate PostgreSQL data, you must configure the database to permit replication with the host that runs the PostgreSQL connector. To specify the clients that are permitted to replicate with the database, add entries to the PostgreSQL host-based authentication file, <code>pg_hba.conf</code>. For more information about the pg_hba.conf file, see the PostgreSQL documentation.</p> <pre><code>local   replication     &lt;youruser&gt;                          trust   \nhost    replication     &lt;youruser&gt;  127.0.0.1/32            trust   \nhost    replication     &lt;youruser&gt;  ::1/128                 trust \n</code></pre>"},{"location":"getting-started/remote_database_setups/#install-ddl-trigger-and-custom-lsn-view","title":"Install DDL Trigger and Custom LSN View","text":"<p>To allow logical replication of user table DDLs to SynchDB, you must install a DDL trigger at source PostgreSQL database. Also, you need to create a custom view that returns the current LSN at the source database so that SycnhDB can retrieve it via FDW during snapshot process. </p> <p>SynchDB source repo contains a SQL script to set up and a script to tear down. Make sure to run them at the source PostgreSQL database:</p> <p>Install DDL trigger function and current LSN view via a psql session:</p> <pre><code>psql -U &lt;user&gt; -d &lt;database&gt; &lt; postgres-connector-src-ddl-setup.sql\n</code></pre> <p>Tear down DDL trigger function via a psql session:</p> <pre><code>psql -U &lt;user&gt; -d &lt;database&gt; &lt; postgres-connector-src-ddl-teardown.sql\n</code></pre> <p>If you do not need DDL replication, then you do not need to install this DDL trigger function at the source. The current LSN view, however, is needed if you would like to take a current snapshot of the source database (current table + data). You can add it to the source database like this without loading the SQL script above. Please ensure this VIEW is created under <code>public</code> schema.</p> <pre><code>CREATE VIEW synchdb_wal_lsn AS SELECT pg_current_wal_lsn()::pg_lsn AS wal_lsn;\n</code></pre>"},{"location":"monitoring/attr_view/","title":"Attribute View","text":""},{"location":"monitoring/attr_view/#review-attributes-managed-by-a-connector","title":"Review Attributes Managed by a Connector","text":"<p>As a connector completes initial table snapshot, the source tables, columns and data types would have been translated, transformed and created on PostgreSQL side according to the object mapping rules. SynchDB provides a view that displays a side-by-side view of a connector's data type, name mapping and transform rule relationships between source and destination tables.</p> <p>This view is informational and it intends to show the user the list of tables a connector currently is tracking and the mapping/transform rules it uses per table/column.</p> <pre><code>SELECT * FROM synchdb_att_view();\n</code></pre> <p>Return Fields:</p> Field Description Type <code>name</code> Connector identifier Text <code>attnum</code> Attribute number Integer <code>ext_tbname</code> table name as appeared remotely Text <code>pg_tbname</code> mapped table name in PostgreSQL Text <code>ext_attname</code> column name as appeared remotely Text <code>pg_attname</code> mapped column name in PostgreSQL Text <code>ext_atttypename</code> data type as appeared remotely Text <code>pg_atttypename</code> mapped data type in PostgreSQL Text <code>transform</code> transform expression Text <p>Example Output</p> <pre><code>SELECT * from synchdb_att_view;\n   name    | type  | attnum |         ext_tbname         |         pg_tbname          | ext_attname | pg_attname  | ext_atttypename | pg_atttypename |         transform\n-----------+-------+--------+----------------------------+----------------------------+-------------+-------------+-----------------+----------------+----------------------------\n mysqlconn | mysql |      1 | inventory.addresses        | inventory.addresses        | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.addresses        | inventory.addresses        | customer_id | customer_id | INT             | int4           |\n mysqlconn | mysql |      3 | inventory.addresses        | inventory.addresses        | street      | street      | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.addresses        | inventory.addresses        | city        | city        | VARCHAR         | varchar        |\n mysqlconn | mysql |      5 | inventory.addresses        | inventory.addresses        | state       | state       | VARCHAR         | varchar        |\n mysqlconn | mysql |      6 | inventory.addresses        | inventory.addresses        | zip         | zip         | VARCHAR         | varchar        |\n mysqlconn | mysql |      7 | inventory.addresses        | inventory.addresses        | type        | type        | ENUM            | text           |\n mysqlconn | mysql |      1 | inventory.customers        | schema1.people             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.customers        | schema1.people             | first_name  | first_name  | VARCHAR         | varchar        |\n mysqlconn | mysql |      3 | inventory.customers        | schema1.people             | last_name   | family_name | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.customers        | schema1.people             | email       | contact     | VARCHAR         | varchar        |\n mysqlconn | mysql |      1 | inventory.geom             | inventory.geom             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.geom             | inventory.geom             | g           | g           | GEOMETRY        | geometry       |\n mysqlconn | mysql |      3 | inventory.geom             | inventory.geom             | h           | h           | GEOMETRY        | text           |\n mysqlconn | mysql |      1 | inventory.products         | public.stuff               | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products         | public.stuff               | name        | name        | VARCHAR         | varchar        | '&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\n mysqlconn | mysql |      3 | inventory.products         | public.stuff               | description | description | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.products         | public.stuff               | weight      | weight      | FLOAT           | float4         |\n mysqlconn | mysql |      1 | inventory.products_on_hand | inventory.products_on_hand | product_id  | product_id  | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products_on_hand | inventory.products_on_hand | quantity    | quantity    | INT             | int8           |\n</code></pre>"},{"location":"monitoring/jmx_exporter/","title":"JMX Exporter","text":""},{"location":"monitoring/jmx_exporter/#what-is-jmx-exporter","title":"What is JMX Exporter","text":"<p>JMX Exporter (also known as the JMX Prometheus Java Agent) is a Java agent that exposes JMX metrics of a Java application in a format Prometheus can scrape and monitor. It is a tool created by the Prometheus community that allows:</p> <ul> <li>Access JVM internal metrics (like memory usage, thread count, GC stats, etc.)</li> <li>Expose custom application metrics exposed via MBeans</li> <li>Export these metrics via an HTTP endpoint (e.g., http://localhost:9404/metrics)</li> <li>Integrate Java applications (like Kafka, Cassandra, or your own apps) into a Prometheus monitoring setupx</li> </ul> <p>This tool unlocks Prometheus + Graphana based monitoring for a SynchDB Connector</p> <p></p>"},{"location":"monitoring/jmx_exporter/#obtain-jmx-exporter","title":"Obtain JMX Exporter","text":"<p>Pre-compiled JMX Exporter (.jar) are available on official JMX Exporter release page. We are interested in the \"jmx_prometheus_javaagent\" tool such as:</p> <pre><code>jmx_prometheus_javaagent-1.3.0.jar\n</code></pre> <p>Please download it to the same machine where SynchDB connector is running.</p>"},{"location":"monitoring/jmx_exporter/#write-a-jmx-exporter-conf-file","title":"Write a JMX Exporter Conf File","text":"<p>JMX exporter requires a config file to define the behavior of exposing metrics. Below is a basic configuration template to get started.</p> <pre><code>startDelaySeconds: 0\nssl: false\nlowercaseOutputName: true\nlowercaseOutputLabelNames: true\n\nrules:\n  - pattern: \".*\"\n</code></pre> <p>Refer to the official prometheus documentation for more advanced configuration parameters and their usage.</p>"},{"location":"monitoring/jmx_exporter/#configure-jmx-exporter-to-a-synchdb-connector","title":"Configure JMX Exporter to a SynchDB Connector","text":"<p>The synchdb_add_jmx_exporter_conninfo() and synchdb_del_jmx_exporter_conninfo() functions adds or deletes JMX exporter configuration to or from an existing connector. This enables runtime monitoring and diagnostics via tools like Prometheus and Graphana.</p> <p>Function Signature</p> <pre><code>synchdb_add_jmx_exporter_conninfo(\n    name TEXT,\n    exporter_jar_path TEXT,\n    exporter_port INTEGER,\n    config_file_path TEXT\n);\n\nsynchdb_del_jmx_exporter_conninfo(\n    name text\n)\n</code></pre> Parameter Type Description <code>connector_name</code> <code>TEXT</code> Name of the existing connector you want to attach the JMX Exporter to. <code>exporter_jar_path</code> <code>TEXT</code> Absolute path to the <code>jmx_prometheus_javaagent.jar</code> file. <code>exporter_port</code> <code>INT</code> Port on which the JMX Exporter HTTP server will expose metrics (e.g. 9404). <code>config_file_path</code> <code>TEXT</code> Path to the JMX Exporter's YAML configuration file we defined above. <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n    'mysqlconn',    -- existing connector name\n    '/path/to/jmx_exporter/jar',        -- path to JMX exporter java agent jar\n    9404,           -- JMX exporter running port\n    '/path/to/jmx/conf');       -- path to JMX exporter conf file\n</code></pre>"},{"location":"monitoring/jmx_exporter/#obtain-metrics-via-http","title":"Obtain Metrics via HTTP","text":"<p>when the connector starts with JMX exporter settings, it will expose metrics at:</p> <pre><code>http://&lt;host&gt;:9404/metrics\n</code></pre> <p>we can test it by:</p> <pre><code>curl http://&lt;host&gt;:9404/metrics\n\n# HELP debezium_mysql_connector_metrics_binlogposition debezium.mysql:name=null,type=connector-metrics,attribute=BinlogPosition\n# TYPE debezium_mysql_connector_metrics_binlogposition untyped\ndebezium_mysql_connector_metrics_binlogposition{context=\"streaming\",server=\"synchdb-connector\"} 1500.0\n# HELP debezium_mysql_connector_metrics_changesapplied debezium.mysql:name=null,type=connector-metrics,attribute=ChangesApplied\n# TYPE debezium_mysql_connector_metrics_changesapplied untyped\ndebezium_mysql_connector_metrics_changesapplied{context=\"schema-history\",server=\"synchdb-connector\"} 39.0\n# HELP debezium_mysql_connector_metrics_changesrecovered debezium.mysql:name=null,type=connector-metrics,attribute=ChangesRecovered\n# TYPE debezium_mysql_connector_metrics_changesrecovered untyped\ndebezium_mysql_connector_metrics_changesrecovered{context=\"schema-history\",server=\"synchdb-connector\"} 26.0\n# HELP debezium_mysql_connector_metrics_connected debezium.mysql:name=null,type=connector-metrics,attribute=Connected\n# TYPE debezium_mysql_connector_metrics_connected untyped\ndebezium_mysql_connector_metrics_connected{context=\"streaming\",server=\"synchdb-connector\"} 1.0\n\n...\n...\n...\n</code></pre>"},{"location":"monitoring/jmx_exporter/#prometheus-and-graphana","title":"Prometheus and Graphana","text":"<p>Once we have confirmed the metrics can be obtained via HTTP, then we can configure this endpoint to prometheus system and have it to <code>scrape</code> them all. Then we can create a prometheus data source in graphana and create a dashboard out of it. Please refer to prometheus and graphana tutorial on how to do so.</p> <p>For quick test, you could also use the <code>ezdeploy</code> tool to quickly deploy prometheus and grafana with built-in dashboard templates for Synchdb. Refer to the Quick Start Guide for mode details. </p>"},{"location":"monitoring/jmx_monitor/","title":"JMX MBEAN Monitoring","text":""},{"location":"monitoring/jmx_monitor/#jmx-java-management-extensions","title":"JMX (Java Management Extensions)","text":"<p>JMX, or Java Management Extensions, is a Java technology that provides tools for managing and monitoring applications, system objects, devices, and service-oriented networks. It allows developers to expose application information and enables external tools to access and interact with this information for monitoring and management purposes.</p>"},{"location":"monitoring/jmx_monitor/#jmx-mbean-for-debezium","title":"JMX MBean for Debezium","text":"<p>Debezium connectors expose metrics via the MBean name for the connector with MBean tag equals to the connector name. These metrics, which are specific to each connector instance, provide data about the behavior of the connector\u2019s snapshot, streaming, and schema history processes. </p>"},{"location":"monitoring/jmx_monitor/#enable-jmx-on-a-connector-with-synchdb_add_jmx_conninfo-or-disable-with-synchdb_del_jmx_conninfo","title":"Enable JMX on a Connector with synchdb_add_jmx_conninfo() or disable with synchdb_del_jmx_conninfo()","text":"<p>The synchdb_add_jmx_conninfo() and synchdb_del_jmx_conninfo() functions adds or deletes JMX monitoring configuration to or from an existing connector. This enables runtime monitoring and diagnostics via tools like JConsole. </p> <p>Function Signature</p> <pre><code>synchdb_add_jmx_conninfo(\n    name text,\n    jmx_listenaddr text,\n    jmx_port integer,\n    jmx_rmiserveraddr text,\n    jmx_rmiport integer,\n    jmx_auth boolean,\n    jmx_auth_passwdfile text,\n    jmx_auth_accessfile text,\n    jmx_ssl boolean,\n    jmx_ssl_keystore text,\n    jmx_ssl_keystore_pass text,\n    jmx_ssl_truststore text,\n    jmx_ssl_truststore_pass text\n)\n\nsynchdb_del_jmx_conninfo(\n    name text\n)\n</code></pre> Parameter Description <code>name</code> (text)The name of the existing connector to which JMX configuration should be added. Must already exist in <code>synchdb_conninfo</code>. <code>jmx_listenaddr</code> (text)The IP address on which the JVM will listen for JMX connections. Use <code>'0.0.0.0'</code> to listen on all network interfaces, or specify a specific IP. <code>jmx_port</code> (integer)The local port for JMX communication (used for client discovery). Must be open and not in use. <code>jmx_rmiserveraddr</code> (text)The public/external IP address used by remote JMX clients (e.g., JConsole) to connect to the JVM. Usually set to the host machine\u2019s external IP. <code>jmx_rmiport</code> (integer)The RMI server port used for actual JMX object communication. This must also be open in firewall and network settings. Usually the same as <code>jmx_port</code>. <code>jmx_auth</code> (boolean)Enable authentication for JMX? If <code>true</code>, clients must provide a username/password stored in the files below. <code>jmx_auth_passwdfile</code> (text)Path to the password file used for JMX authentication. If not using authentication, pass <code>'null'</code>. <code>jmx_auth_accessfile</code> (text)Path to the access control file defining roles (e.g., <code>monitor</code>, <code>control</code>). Required only if authentication is enabled. If not using authentication, pass <code>'null'</code> <code>jmx_ssl</code> (boolean)Enable SSL encryption for JMX connections? Set to <code>true</code> to secure communication. <code>jmx_ssl_keystore</code> (text)Path to the keystore file (in JKS format) containing the server\u2019s private key and certificate. Required if <code>jmx_ssl = true</code>. <code>jmx_ssl_keystore_pass</code> (text)Password for the keystore file. <code>jmx_ssl_truststore</code> (text)Path to the truststore (JKS) that holds trusted CA certificates. Used to verify client identities if mutual TLS is configured. <code>jmx_ssl_truststore_pass</code> (text)Password for the truststore file."},{"location":"monitoring/jmx_monitor/#password-and-access-files-for-jmx-authentication","title":"Password and Access Files for JMX Authentication","text":"<p>When enabling JMX authentication in your JVM configuration (i.e., setting jmx_auth = true), you must provide two files:</p>"},{"location":"monitoring/jmx_monitor/#password-file","title":"Password File:","text":"<p>This file stores valid JMX usernames and their corresponding passwords.</p> <p>Format: <pre><code># Format: username password\n&lt;username&gt; &lt;password&gt;\n</code></pre></p> <p>Example:</p> <pre><code>monitorRole mySecretPassword\ncontrolRole anotherSecretPassword\n</code></pre> <p>monitorRole and controlRole are example usernames. Replace mySecretPassword and anotherSecretPassword with strong passwords of your choice. You can define multiple users.</p>"},{"location":"monitoring/jmx_monitor/#access-file","title":"Access File:","text":"<p>This file defines what each user is allowed to do via JMX. Possible access levels:</p> <ul> <li>readonly \u2013 can view MBeans but not modify them.</li> <li>readwrite \u2013 can both view and modify MBeans.</li> </ul> <p>Format: <pre><code># Format: username access_level\n&lt;username&gt; &lt;access&gt;\n</code></pre></p> <p>Example: <pre><code>monitorRole readonly\ncontrolRole readwrite\n</code></pre></p>"},{"location":"monitoring/jmx_monitor/#file-permissions","title":"File Permissions:","text":"<p>Make sure both files are owned by the user running the JVM, and have restricted permissions:</p> <pre><code>chmod 600 jmxpwd.file jmxacc.file\nchown youruser:youruser jmxpwd.file jmxacc.file\n</code></pre>"},{"location":"monitoring/jmx_monitor/#synchdb_add_jmx_conninfo-examples","title":"synchdb_add_jmx_conninfo Examples","text":"<p>Enable JMX MBean with no authentication and no SSL:</p> <pre><code>SELECT synchdb_add_jmx_conninfo(\n    'mysqlconn',    -- existing connector name\n    '0.0.0.0',      -- JMX listen address\n    9010,           -- JMX listen port\n    '10.55.13.17',  -- JMX RMI server address - for remote client connect\n    9010,           -- JMX RMI server port - for remoet client connect\n    false,          -- use authentication?\n    'null',         -- password file for authentication\n    'null',         -- access file for authentication\n    false,          -- use SSL?\n    'null',         -- SSL keystore path\n    'null',         -- SSL keystore password\n    'null',         -- SSL trust store\n    'null');        -- SSL trust store password\n</code></pre> <p>Enable JMX MBean with authentication</p> <pre><code>SELECT synchdb_add_jmx_conninfo(\n    'mysqlconn',    -- existing connector name\n    '0.0.0.0',      -- JMX listen address\n    9010,           -- JMX listen port\n    '10.55.13.17',  -- JMX RMI server address - for remote client connect\n    9010,           -- JMX RMI server port - for remoet client connect\n    true,           -- use authentication?\n    '/path/to/passwd.file',         -- password file for authentication\n    '/path/to/access.file',         -- access file for authentication\n    false,          -- use SSL?\n    'null',         -- SSL keystore path\n    'null',         -- SSL keystore password\n    'null',         -- SSL trust store\n    'null');        -- SSL trust store password\n</code></pre> <p>Enable JMX MBean with authentication and SSL without SSL client verify</p> <pre><code>SELECT synchdb_add_jmx_conninfo(\n    'mysqlconn',    -- existing connector name\n    '0.0.0.0',      -- JMX listen address\n    9010,           -- JMX listen port\n    '10.55.13.17',  -- JMX RMI server address - for remote client connect\n    9010,           -- JMX RMI server port - for remoet client connect\n    true,           -- use authentication?\n    '/path/to/passwd.file',         -- password file for authentication\n    '/path/to/access.file',         -- access file for authentication\n    true,           -- use SSL?\n    '/path/to/keystore',            -- SSL keystore path\n    'keystorepass',         -- SSL keystore password\n    'null',         -- SSL trust store\n    'null');        -- SSL trust store password\n</code></pre> <p>Enable JMX MBean with authentication and SSL + SSL client verify</p> <pre><code>SELECT synchdb_add_jmx_conninfo(\n    'mysqlconn',    -- existing connector name\n    '0.0.0.0',      -- JMX listen address\n    9010,           -- JMX listen port\n    '10.55.13.17',  -- JMX RMI server address - for remote client connect\n    9010,           -- JMX RMI server port - for remoet client connect\n    true,           -- use authentication?\n    '/path/to/passwd.file',         -- password file for authentication\n    '/path/to/access.file',         -- access file for authentication\n    true,           -- use SSL?\n    '/path/to/keystore',            -- SSL keystore path\n    'keystorepass',         -- SSL keystore password\n    '/path/to/truststore',          -- SSL trust store\n    'truststorepass');      -- SSL trust store password\n</code></pre>"},{"location":"monitoring/jmx_monitor/#visualize-jmx-metrics-with-jconsole","title":"Visualize JMX metrics with jconsole","text":"<p>When a connector with JMX configuration is started, the JMX service will be running on the designated port number. We can use <code>jconsole</code> that comes with Java distribution to connect to JMX server. It is possible to connect locally via the JVM (connector worker) PID or via IP address and port number. If authentication is enabled, username and password are required as well. If no authentication is used, these can be left empty.</p> <p></p> <p>Once connected, we can view all the details about JVM's operating metrics such as CPU, memory, class utilization, threads...etc. </p> <p> </p>"},{"location":"monitoring/jmx_monitor/#visualize-debezium-jmx-mbeans","title":"Visualize Debezium JMX MBeans","text":"<p>The last tab is MBeans, which contains the Debezium specific metrics for schema history, snapshot and streaming stages.</p> <p> </p> <p>Based on the connector type, the MBean metrics may be different. Refer to Debezium connector documentation on the list of metrics captured:</p> <ul> <li>MBeans for MySQL</li> <li>MBeans for SQL Server</li> <li>MBeans for Oracle</li> </ul>"},{"location":"monitoring/jvm_mem/","title":"JVM Memory Usage","text":""},{"location":"monitoring/jvm_mem/#dump-jvm-memory-usage","title":"Dump JVM Memory Usage","text":"<p>We can use an utility function <code>synchdb_log_jvm_meminfo</code> to dump current JVM's current heap and non-heap memory usage in the logfile. This is purely informational and is intended to give user an idea the memory usage of different workload, which may be important to configure a suitable value for max heap memory to be allocated to JVM of a connector. <pre><code>SELECT synchdb_log_jvm_meminfo('mysqlconn');\n</code></pre></p> <p>Check the PostgreSQL log file: <pre><code>2024-12-09 14:34:21.910 PST [25491] LOG:  Requesting memdump for mysqlconn connector\n2024-12-09 14:34:21 WARN  DebeziumRunner:297 - Heap Memory:\n2024-12-09 14:34:21 WARN  DebeziumRunner:298 -   Used: 19272600 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:299 -   Committed: 67108864 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:300 -   Max: 2147483648 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:302 - Non-Heap Memory:\n2024-12-09 14:34:21 WARN  DebeziumRunner:303 -   Used: 42198864 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:304 -   Committed: 45023232 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:305 -   Max: -1 bytes\n</code></pre></p>"},{"location":"monitoring/state_view/","title":"Connector Running State","text":""},{"location":"monitoring/state_view/#check-connector-running-state","title":"Check Connector Running State","text":"<p>Use <code>synchdb_state_view()</code> to examine all connectors' running states.</p> <p>See below for an example output: <pre><code>postgres=# select * from synchdb_state_view;\n     name      | connector_type |  pid   |        stage        |  state  |   err    |                                           last_dbz_offset\n---------------+----------------+--------+---------------------+---------+----------+------------------------------------------------------------------------------------------------------\n sqlserverconn | sqlserver      | 579820 | change data capture | polling | no error | {\"commit_lsn\":\"0000006a:00006608:0003\",\"snapshot\":true,\"snapshot_completed\":false}\n mysqlconn     | mysql          | 579845 | change data capture | polling | no error | {\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}\n oracleconn    | oracle         | 580053 | change data capture | polling | no error | offset file not flushed yet\n(3 rows)\n</code></pre></p> <p>Column Details:</p> fields description name the associated connector info name created by <code>synchdb_add_conninfo()</code> connector_type the type of connector (mysql, oracle, sqlserver...etc) pid the PID of the connector worker process stage the stage of the connector. See below. state the state of the connector. See below. err the last error message encountered by the worker which would have caused it to exit. This error could originated from PostgreSQL while processing a change, or originated from Debezium running engine while accessing data from heterogeneous database. last_dbz_offset the last Debezium offset captured by synchdb. Note that this may not reflect the current and real-time offset value of the connector engine. Rather, this is shown as a checkpoint that we could restart from this offeet point if needed. <p>Possible States:</p> <ul> <li>\ud83d\udd34 <code>stopped</code> - Inactive</li> <li>\ud83d\udfe1 <code>initializing</code> - Starting up</li> <li>\ud83d\udfe0 <code>paused</code> - Temporarily halted</li> <li>\ud83d\udfe2 <code>syncing</code> - Actively polling</li> <li>\ud83d\udd35 <code>parsing</code> - Processing events</li> <li>\ud83d\udfe3 <code>converting</code> - Transforming data</li> <li>\u26aa <code>executing</code> - Applying changes</li> <li>\ud83d\udfe4 <code>updating offset</code> - Updating checkpoint</li> <li>\ud83d\udfe8 <code>restarting</code> - Reinitializing</li> <li>\u26aa <code>dumping memory</code> - JVM is prepaaring to dump memory info in log file</li> <li>\u26ab <code>unknown</code> - Indeterminate state</li> </ul> <p>Possible Stages:</p> <ul> <li><code>initial snapshot</code> - connector is performing initial snapshot (building table schema and optionally the initial data)</li> <li><code>change data capture</code> - connector is streaming subsequent table changes (CDC)</li> <li><code>schema sync</code> - connector is copying table schema only (no data)</li> </ul>"},{"location":"monitoring/stats_view/","title":"Connector Statistics","text":""},{"location":"monitoring/stats_view/#check-connector-running-statistics","title":"Check Connector Running Statistics","text":"<p>SynchDB keeps a record of statistics per connector. These statistics are separate from Debezium's or JVM's JMX based statistics though they may have similar or overlapping parameters.</p> <p>There are 3 categories of statistics:</p> <ul> <li>General Statistics</li> <li>Snapshot Statistics</li> <li>CDC Statistics</li> </ul> <p>Please note that these statistics are not persistent and will be lost/reset upon PostgreSQL restarts.</p>"},{"location":"monitoring/stats_view/#general-statistics","title":"General Statistics","text":"<p>Obtained via \"synchdb_genstats\" view: <pre><code>select * from synchdb_genstats;\n\n  name   | bad_events | total_events | batches_done | average_batch_size | first_src_ts  |  first_pg_ts  |  last_src_ts  |  last_pg_ts\n---------+------------+--------------+--------------+--------------------+---------------+---------------+---------------+---------------\n olrconn |        191 |          453 |           14 |                 32 | 1761170446000 | 1761170450120 | 1761170448000 | 1761170450120\n(1 row)\n</code></pre></p> <p>Column Details:</p> fields description name the associated connector info name created by <code>synchdb_add_conninfo()</code> bad_events number of bad events ignored (such as empty events, unsupported DDL events..etc) total_events total number of events processed (including bad_events) batches_done number of batches completed average_batch_size average batch size (total_events / batches_done) first_src_ts the timestamp in milliseconds when the last batch's first event is produced at the external database first_pg_ts the timestamp in milliseconds when the last batch's first event is applied to PostgreSQL last_src_ts the timestamp in milliseconds when the last batch's last event is produced at the external database last_pg_ts the timestamp in milliseconds when the last batch's last event is applied to PostgreSQL"},{"location":"monitoring/stats_view/#snapshot-statistics","title":"Snapshot Statistics","text":"<p>Obtained via \"synchdb_snapstats\" view: <pre><code>select * from synchdb_snapstats;\n\n  name   | tables |  rows  | snapshot_begin_ts | snapshot_end_ts\n---------+--------+--------+-------------------+-----------------\n olrconn |      2 | 100032 |     1761160017191 |   1761160033250\n(1 row)\n</code></pre></p> <p>Column Details:</p> fields description name the associated connector info name created by <code>synchdb_add_conninfo()</code> tables number of table schemas migrated during snapshot process rows number of rows migrated during snapshot process snapshot_begin_ts the timestamp in milliseconds when the snapshot process begins snapshot_end_ts the timestamp in milliseconds when the snapshot process ends"},{"location":"monitoring/stats_view/#cdc-statistics","title":"CDC Statistics","text":"<p>Obtained via \"synchdb_cdcstats\" view: <pre><code>select * from synchdb_cdcstats;\n\n  name   | ddls | dmls | creates | updates | deletes | txs | truncates\n---------+------+------+---------+---------+---------+-----+-----------\n olrconn |  161 |  124 |      10 |      47 |      67 | 562 |         0\n(1 row)\n</code></pre></p> <p>Column Details:</p> fields description name the associated connector info name created by <code>synchdb_add_conninfo()</code> ddls number of DDLs operations completed dmls number of DMLs operations completed creates number of CREATES events completed during CDC stage updates number of UPDATES events completed during CDC stage deletes number of DELETES events completed during CDC stage txs number of transaction events processed such as begin and commit truncates number of truncate events processed"},{"location":"monitoring/stats_view/#synchdb_reset_stats","title":"synchdb_reset_stats","text":"<p>Purpose: Resets all statistic information of given connector name</p> <pre><code>SELECT synchdb_reset_stats('olrconn');\n</code></pre>"},{"location":"tutorial/mysql_cdc_to_postgresql/","title":"MySQL -&gt; PostgreSQL","text":""},{"location":"tutorial/mysql_cdc_to_postgresql/#prepare-mysql-database-for-synchdb","title":"Prepare MySQL Database for SynchDB","text":"<p>Before SynchDB can be used to replicate from MySQL, MySQL needs to be configured according to the procedure outlined here</p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#create-a-mysql-connector","title":"Create a MySQL Connector","text":"<p>Create a connector that targets all the tables under <code>inventory</code> database in MySQL. <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'null', \n    'null', 'null', 'mysql');\n</code></pre></p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#initial-snapshot","title":"Initial Snapshot","text":"<p>\"Initial snapshot\" (or table snapshot) in SynchDB means to copy table schema plus initial data for all designated tables. This is similar to the term \"table sync\" in PostgreSQL logical replication. When a connector is started using the default <code>initial</code> mode, it will automatically perform the initial snapshot before going to Change Data Capture (CDC) stage. This can be omitted entirely with mode <code>never</code> or partially omitted with mode <code>no_data</code>. See here for all snapshot options.</p> <p>Once the initial snapshot is completed, the connector will not do it again upon subsequent restarts and will just resume with CDC since the last incomplete offset. This behavior is controled by the metadata files managed by Debezium engine. See here for more about metadata files.</p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#different-connector-launch-modes","title":"Different Connector Launch Modes","text":""},{"location":"tutorial/mysql_cdc_to_postgresql/#initial-snapshot-cdc","title":"Initial Snapshot + CDC","text":"<p>Start the connector using <code>initial</code> mode will perform the initial snapshot of all designated tables (all in this case). After this is completed, the change data capture (CDC) process will begin to stream for new changes.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'initial');\n\nor \n\nSELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre> <p>The stage of this connector should be in <code>initial snapshot</code> the first time it runs: <pre><code>postgres=# select * from synchdb_state_view;\n    name    | connector_type |  pid   |      stage       |  state  |   err    |                      last_dbz_offs\net\n------------+----------------+--------+------------------+---------+----------+-----------------------------------\n-------------------------\n mysqlconn  | mysql          | 522195 | initial snapshot | polling | no error | {\"ts_sec\":1750375008,\"file\":\"mysql\n-bin.000003\",\"pos\":1500}\n(1 row)\n</code></pre></p> <p>A new schema called <code>inventory</code> will be created and all tables streamed by the connector will be replicated under that schema. <pre><code>postgres=# set search_path=inventory;\nSET\npostgres=# \\d\n                    List of relations\n  Schema   |          Name           |   Type   | Owner\n-----------+-------------------------+----------+--------\n inventory | addresses               | table    | ubuntu\n inventory | addresses_id_seq        | sequence | ubuntu\n inventory | customers               | table    | ubuntu\n inventory | customers_id_seq        | sequence | ubuntu\n inventory | geom                    | table    | ubuntu\n inventory | geom_id_seq             | sequence | ubuntu\n inventory | orders                  | table    | ubuntu\n inventory | orders_order_number_seq | sequence | ubuntu\n inventory | products                | table    | ubuntu\n inventory | products_id_seq         | sequence | ubuntu\n inventory | products_on_hand        | table    | ubuntu\n</code></pre></p> <p>After the initial snapshot is completed, and at least one subsequent changes is received and processed, the connector stage shall change from <code>initial snapshot</code> to <code>Change Data Capture</code>. <pre><code>postgres=# select * from synchdb_state_view;\n    name    | connector_type |  pid   |        stage        |  state  |   err    |                      last_dbz_o\nffset\n------------+----------------+--------+---------------------+---------+----------+--------------------------------\n----------------------------\n mysqlconn  | mysql          | 522195 | change data capture | polling | no error | {\"ts_sec\":1750375008,\"file\":\"my\nsql-bin.000003\",\"pos\":1500}\n</code></pre></p> <p>This means that the connector is now streaming for new changes of the designated tables. Restarting the connector in <code>initial</code> mode will proceed replication since the last successful point and initial snapshot will not be re-run.</p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#initial-snapshot-only-and-no-cdc","title":"Initial Snapshot Only and no CDC","text":"<p>Start the connector using <code>initial_only</code> mode will perform the initial snapshot of all designated tables (all in this case) only and will not perform CDC after.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'initial_only');\n</code></pre> <p>The connector would still appear to be <code>polling</code> from the connector but no change will be captured because Debzium internally has stopped the CDC. You have the option to shut it down. Restarting the connector in <code>initial_only</code> mode will not rebuild the tables as they have already been built.</p> <pre><code>postgres=# select * from synchdb_state_view;\n    name    | connector_type |  pid   |      stage       |  state  |   err    |       last_dbz_offset\n------------+----------------+--------+------------------+---------+----------+-----------------------------\n mysqlconn  | mysql          | 522330 | initial snapshot | polling | no error | offset file not flushed yet\n</code></pre>"},{"location":"tutorial/mysql_cdc_to_postgresql/#capture-table-schema-only-cdc","title":"Capture Table Schema Only + CDC","text":"<p>Start the connector using <code>no_data</code> mode will perform the schema capture only, build the corresponding tables in PostgreSQL and it does not replicate existing table data (skip initial snapshot). After the schema capture is completed, the connector goes into CDC mode and will start capture subsequent changes to the tables.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'no_data');\n</code></pre> <p>Restarting the connector in <code>no_data</code> mode will not rebuild the schema again, and it will resume CDC since the last successful point.</p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#cdc-only","title":"CDC only","text":"<p>Start the connector using <code>never</code> will skip schema capture and initial snapshot entirely and will go to CDC mode to capture subsequent changes. Please note that the connector expects all the capture tables have been created in PostgreSQL prior to starting in <code>never</code> mode. If the tables do not exist, the connector will encounter an error when it tries to apply a CDC change to a non-existent table.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'never');\n</code></pre> <p>Restarting the connector in <code>never</code> mode will resume CDC since the last successful point.</p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#always-do-initial-snapahot-cdc","title":"Always do Initial Snapahot + CDC","text":"<p>Start the connector using <code>always</code> mode will always capture the schemas of capture tables, always redo the initial snapshot and then go to CDC. This is similar to a reset button because everything will be rebuilt using this mode. Use it with caution especially when you have large number of tables being captured, which could take a long time to finish. After the rebuild, CDC resumes as normal.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre> <p>However, it is possible to select partial tables to redo the initial snapshot by using the <code>snapshottable</code> option of the connector. Tables matching the criteria in <code>snapshottable</code> will redo the inital snapshot, if not, their initial snapshot will be skipped. If <code>snapshottable</code> is null or empty, by default, all the tables specified in <code>table</code> option of the connector will redo the initial snapshot under <code>always</code> mode.</p> <p>This example makes the connector only redo the initial snapshot of <code>inventory.customers</code> table. All other tables will have their snapshot skipped. <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{snapshottable}', '\"inventory.customers\"') \nWHERE name = 'mysqlconn';\n</code></pre></p> <p>After the initial snapshot, CDC will begin. Restarting a connector in <code>always</code> mode will repeat the same process described above.</p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#possible-snapshot-modes-for-mysql-connector","title":"Possible Snapshot Modes for MySQL Connector","text":"<ul> <li>initial (default)</li> <li>initial_only</li> <li>no_data</li> <li>never</li> <li>always</li> <li>schemasync</li> </ul>"},{"location":"tutorial/mysql_cdc_to_postgresql/#preview-source-and-destination-table-relationships-with-schemasync-mode","title":"Preview Source and Destination Table Relationships with schemasync mode","text":"<p>Before attempting to do an initial snapshot of current table and data, which may be huge, it is possible to \"preview\" all the tables and data type mappings between source and destination tables before the actual data migration. This gives you an opportunity to modify a data type mapping, or an object name before actual migration happens. This can be done with the special \"schemasync\" initial snapshot mode. Refer to object mapping workflow for a detailed example.</p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#selective-table-sync","title":"Selective Table Sync","text":""},{"location":"tutorial/mysql_cdc_to_postgresql/#select-desired-tables-and-start-it-for-the-first-time","title":"Select Desired Tables and Start it for the First Time","text":"<p>Table selection is done during connector creation phase via <code>synchdb_add_conninfo()</code> where we specify a list of tables (expressed in FQN, separated by a comma) to replicate from.</p> <p>For example, the following command creates a connector that only replicates change from <code>inventory.orders</code> and <code>inventory.products</code> tables from remote MySQL database. <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', \n    '127.0.0.1', \n    3306, \n    'mysqluser', \n    'mysqlpwd', \n    'inventory', \n    'null', \n    'inventory.orders,inventory.products', \n    'null', \n    'mysql'\n);\n</code></pre></p> <p>Starting this connector for the very first time will trigger an initial snapshot being performed and selected 2 tables' schema and data will be replicated.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre>"},{"location":"tutorial/mysql_cdc_to_postgresql/#verify-the-connector-state-and-tables","title":"Verify the Connector State and Tables","text":"<p>Examine the connector state and the new tables: <pre><code>postgres=# Select name, state, err from synchdb_state_view;\n     name      |  state  |   err\n---------------+---------+----------\n mysqlconn     | polling | no error\n(1 row)\n\npostgres=# \\dt inventory.*\n            List of tables\n  Schema   |   Name   | Type  | Owner\n-----------+----------+-------+--------\n inventory | orders   | table | ubuntu\n inventory | products | table | ubuntu\n</code></pre></p> <p>Once the snapshot is complete, the <code>mysqlconn</code> connector will continue capturing subsequent changes to the <code>inventory.orders</code> and <code>inventory.products</code> tables.</p>"},{"location":"tutorial/mysql_cdc_to_postgresql/#add-more-tables-to-replicate-during-run-time","title":"Add More Tables to Replicate During Run Time.","text":"<p>The <code>mysqlconn</code> from previous section has already completed the initial snapshot and obtained the table schemas of the selected table. If we would like to add more tables to replicate from, we will need to notify the Debezium engine about the updated table section and perform the initial snapshot again. Here's how it is done:</p> <ol> <li>Update the <code>synchdb_conninfo</code> table to include additional tables.</li> <li>In this example, we add the <code>inventory.customers</code> table to the sync list: <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"inventory.orders,inventory.products,inventory.customers\"') \nWHERE name = 'mysqlconn';\n</code></pre></li> <li>Configure the snapshot table parameter to include only the new table <code>inventory.customers</code> to that SynchDB does not try to rebuild the 2 tables that have already finished the snapshot. <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{snapshottable}', '\"inventory.customers\"') \nWHERE name = 'mysqlconn';\n</code></pre></li> <li>Restart the connector with the snapshot mode set to <code>always</code> to perform another initial snapshot: <pre><code>SELECT synchdb_restart_connector('mysqlconn', 'always');\n</code></pre> This forces Debezium to re-snapshot only the new table <code>inventory.customers</code> while leaving the old tables <code>inventory.orders</code> and <code>inventory.products</code> untouched. The CDC for all tables will resume once snapshot is complete. </li> </ol>"},{"location":"tutorial/mysql_cdc_to_postgresql/#verify-the-updated-tables","title":"Verify the Updated Tables","text":"<p>Now, we can examine our tables again: <pre><code>postgres=# \\dt inventory.*\n             List of tables\n  Schema   |   Name    | Type  | Owner\n-----------+-----------+-------+--------\n inventory | customers | table | ubuntu\n inventory | orders    | table | ubuntu\n inventory | products  | table | ubuntu\n</code></pre></p>"},{"location":"tutorial/object_mapping_workflow/","title":"Object Mapping Workflow","text":""},{"location":"tutorial/object_mapping_workflow/#create-a-connector-and-start-it-in-schemasync-mode","title":"Create a Connector and Start it in <code>schemasync</code> Mode","text":"<p><code>schemasync</code> is a special mode that makes the connector connects to remote database and attempt to sync only the schema of designated tables. After this is done, the connector is put to <code>paused</code> state and user is able to review all the tables and data types created using the default rules and make change if needed.</p> <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn',\n    '127.0.0.1',\n    3306,\n    'mysqluser',\n    'mysqlpwd',\n    'inventory',\n    'null',\n    'null',\n    'mysql');\n\nSELECT synchdb_start_engine_bgw('mysqlconn', 'schemasync');\n</code></pre>"},{"location":"tutorial/object_mapping_workflow/#ensure-the-connector-is-put-to-paused-state","title":"Ensure the connector is put to paused state","text":"<pre><code>SELECT name, connector_type, pid, stage, state FROM synchdb_state_view;\n     name      | connector_type |  pid   |    stage    |  state\n---------------+----------------+--------+-------------+---------\n mysqlconn     | mysql          | 579845 | schema sync | polling\n</code></pre>"},{"location":"tutorial/object_mapping_workflow/#review-the-tables-created-by-default-mapping-rules","title":"Review the tables created by default mapping rules","text":"<pre><code>postgres=# select * from synchdb_att_view;\n   name    | type  | attnum |         ext_tbname         |         pg_tbname          | ext_attname | pg_attname  | ext_atttypename | pg_atttypename | transform\n-----------+-------+--------+----------------------------+----------------------------+-------------+-------------+-----------------+----------------+-----------\n mysqlconn | mysql |      1 | inventory.addresses        | inventory.addresses        | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.addresses        | inventory.addresses        | customer_id | customer_id | INT             | int4           |\n mysqlconn | mysql |      3 | inventory.addresses        | inventory.addresses        | street      | street      | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.addresses        | inventory.addresses        | city        | city        | VARCHAR         | varchar        |\n mysqlconn | mysql |      5 | inventory.addresses        | inventory.addresses        | state       | state       | VARCHAR         | varchar        |\n mysqlconn | mysql |      6 | inventory.addresses        | inventory.addresses        | zip         | zip         | VARCHAR         | varchar        |\n mysqlconn | mysql |      7 | inventory.addresses        | inventory.addresses        | type        | type        | ENUM            | text           |\n mysqlconn | mysql |      1 | inventory.customers        | inventory.customers        | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.customers        | inventory.customers        | first_name  | first_name  | VARCHAR         | varchar        |\n mysqlconn | mysql |      3 | inventory.customers        | inventory.customers        | last_name   | last_name   | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.customers        | inventory.customers        | email       | email       | VARCHAR         | varchar        |\n mysqlconn | mysql |      1 | inventory.geom             | inventory.geom             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.geom             | inventory.geom             | g           | g           | GEOMETRY        | text           |\n mysqlconn | mysql |      3 | inventory.geom             | inventory.geom             | h           | h           | GEOMETRY        | text           |\n mysqlconn | mysql |      1 | inventory.products         | inventory.products         | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products         | inventory.products         | name        | name        | VARCHAR         | varchar        |\n mysqlconn | mysql |      3 | inventory.products         | inventory.products         | description | description | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.products         | inventory.products         | weight      | weight      | FLOAT           | float4         |\n mysqlconn | mysql |      1 | inventory.products_on_hand | inventory.products_on_hand | product_id  | product_id  | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products_on_hand | inventory.products_on_hand | quantity    | quantity    | INT             | int4           |\n(20 rows)\n</code></pre>"},{"location":"tutorial/object_mapping_workflow/#define-custom-mapping-rules","title":"Define custom mapping rules","text":"<p>User can use <code>synchdb_add_objmap</code> function to create custom mapping rules. It can be used to map table name, column name, data types and defines a data transform expression rule</p> <pre><code>SELECT synchdb_add_objmap('mysqlconn','table','inventory.products','stuff');\nSELECT synchdb_add_objmap('mysqlconn','table','inventory.customers','schema1.people');\nSELECT synchdb_add_objmap('mysqlconn','column','inventory.customers.last_name','family_name');\nSELECT synchdb_add_objmap('mysqlconn','column','inventory.customers.email','contact');\nSELECT synchdb_add_objmap('mysqlconn','datatype','inventory.geom.g','geometry|0');\nSELECT synchdb_add_objmap('mysqlconn','datatype','inventory.orders.quantity','bigint|0');\nSELECT synchdb_add_objmap('mysqlconn','transform','inventory.products.name','''&gt;&gt;&gt;&gt;&gt;'' || ''%d'' || ''&lt;&lt;&lt;&lt;&lt;''');\n</code></pre>"},{"location":"tutorial/object_mapping_workflow/#review-all-object-mapping-rules-created-so-far","title":"Review all object mapping rules created so far","text":"<pre><code>postgres=# select * from synchdb_objmap;\n   name    |  objtype  | enabled |            srcobj             |           dstobj\n-----------+-----------+---------+-------------------------------+----------------------------\n mysqlconn | table     | t       | inventory.products            | stuff\n mysqlconn | column    | t       | inventory.customers.last_name | family_name\n mysqlconn | column    | t       | inventory.customers.email     | contact\n mysqlconn | table     | t       | inventory.customers           | schema1.people\n mysqlconn | transform | t       | inventory.products.name       | '&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\n mysqlconn | datatype  | t       | inventory.geom.g              | geometry|0\n mysqlconn | datatype  | t       | inventory.orders.quantity     | bigint|0\n(7 rows)\n</code></pre>"},{"location":"tutorial/object_mapping_workflow/#reload-the-object-mapping-rules","title":"Reload the object mapping rules","text":"<p>Once all custom rules have been defined, we need to signal the connector to load them. This will cause the connector to read and apply the object mapping rules. If it sees a discrepancy between current PostgreSQL values and the object mapping values, it will attempt to correct the mapping. <pre><code>SELECT synchdb_reload_objmap('mysqlconn');\n</code></pre></p>"},{"location":"tutorial/object_mapping_workflow/#review-synchdb_att_view-again-for-changes","title":"Review <code>synchdb_att_view</code> again for changes","text":"<pre><code>SELECT * from synchdb_att_view;\n   name    | type  | attnum |         ext_tbname         |         pg_tbname          | ext_attname | pg_attname  | ext_atttypename | pg_atttypename |         transform\n-----------+-------+--------+----------------------------+----------------------------+-------------+-------------+-----------------+----------------+----------------------------\n mysqlconn | mysql |      1 | inventory.addresses        | inventory.addresses        | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.addresses        | inventory.addresses        | customer_id | customer_id | INT             | int4           |\n mysqlconn | mysql |      3 | inventory.addresses        | inventory.addresses        | street      | street      | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.addresses        | inventory.addresses        | city        | city        | VARCHAR         | varchar        |\n mysqlconn | mysql |      5 | inventory.addresses        | inventory.addresses        | state       | state       | VARCHAR         | varchar        |\n mysqlconn | mysql |      6 | inventory.addresses        | inventory.addresses        | zip         | zip         | VARCHAR         | varchar        |\n mysqlconn | mysql |      7 | inventory.addresses        | inventory.addresses        | type        | type        | ENUM            | text           |\n mysqlconn | mysql |      1 | inventory.customers        | schema1.people             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.customers        | schema1.people             | first_name  | first_name  | VARCHAR         | varchar        |\n mysqlconn | mysql |      3 | inventory.customers        | schema1.people             | last_name   | family_name | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.customers        | schema1.people             | email       | contact     | VARCHAR         | varchar        |\n mysqlconn | mysql |      1 | inventory.geom             | inventory.geom             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.geom             | inventory.geom             | g           | g           | GEOMETRY        | geometry           |\n mysqlconn | mysql |      3 | inventory.geom             | inventory.geom             | h           | h           | GEOMETRY        | text           |\n mysqlconn | mysql |      1 | inventory.products         | public.stuff               | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products         | public.stuff               | name        | name        | VARCHAR         | varchar        | '&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\n mysqlconn | mysql |      3 | inventory.products         | public.stuff               | description | description | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.products         | public.stuff               | weight      | weight      | FLOAT           | float4         |\n mysqlconn | mysql |      1 | inventory.products_on_hand | inventory.products_on_hand | product_id  | product_id  | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products_on_hand | inventory.products_on_hand | quantity    | quantity    | INT             | int8           |\n</code></pre>"},{"location":"tutorial/object_mapping_workflow/#resume-the-connector-or-redo-the-entire-snapshot","title":"Resume the connector or redo the entire snapshot","text":"<p>Once the object mappings have been confirmed correct, we can resume the connector. Please note that, resume will proceed to streaming only the new table changes. The existing data of the tables will not be copied. <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p> <p>To capture the table's existing data, we can also redo the entire snapshot with the new object mapping rules: <pre><code>SELECT synchdb_restart_connector('mysqlconn', 'always');\n</code></pre></p>"},{"location":"tutorial/oracle_cdc_to_postgresql/","title":"Oracle -&gt; PostgreSQL","text":""},{"location":"tutorial/oracle_cdc_to_postgresql/#prepare-oracle-database-for-synchdb","title":"Prepare Oracle Database for SynchDB","text":"<p>Before SynchDB can be used to replicate from Oracle, Oracle needs to be configured according to the procedure outlined here</p> <p>Please ensure that supplemental log data is enabled for all columns for each desired table to be replicated by SynchDB. This is needed for SynchDB to correctly handle UPDATE and DELETE oeprations.</p> <p>For example, the following enables supplemental log data for all columns for <code>customer</code> and <code>products</code> table. Please add more tables as needed.</p> <pre><code>ALTER TABLE customer ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;\nALTER TABLE products ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;\n... etc\n</code></pre>"},{"location":"tutorial/oracle_cdc_to_postgresql/#initial-snapshot","title":"Initial Snapshot","text":"<p>\"Initial snapshot\" (or table snapshot) in SynchDB means to copy table schema plus initial data for all designated tables. This is similar to the term \"table sync\" in PostgreSQL logical replication. When a connector is started using the default <code>initial</code> mode, it will automatically perform the initial snapshot before going to Change Data Capture (CDC) stage. This can be partially omitted with mode <code>no_data</code>. See here for all snapshot options.</p> <p>Once the initial snapshot is completed, the connector will not do it again upon subsequent restarts and will just resume with CDC since the last incomplete offset. This behavior is controled by the metadata files managed by Debezium engine. See here for more about metadata files.</p>"},{"location":"tutorial/oracle_cdc_to_postgresql/#different-connector-launch-modes","title":"Different Connector Launch Modes","text":""},{"location":"tutorial/oracle_cdc_to_postgresql/#create-a-oracle-connector","title":"Create a Oracle Connector","text":"<p>Create a connector that targets all the tables under <code>FREE</code> database and <code>DBZUSER</code> schema in Oracle. <pre><code>SELECT \n  synchdb_add_conninfo(\n    'oracleconn', '127.0.0.1', 1521, \n    'DBZUSER', 'dbz', 'FREE', 'DBZUSER', \n    'null', 'null', 'oracle');\n</code></pre></p>"},{"location":"tutorial/oracle_cdc_to_postgresql/#initial-snapshot-cdc","title":"Initial Snapshot + CDC","text":"<p>Start the connector using <code>initial</code> mode will perform the initial snapshot of all designated tables (all in this case). After this is completed, the change data capture (CDC) process will begin to stream for new changes.</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn', 'initial');\n\nor \n\nSELECT synchdb_start_engine_bgw('oracleconn');\n</code></pre> <p>The stage of this connector should be in <code>initial snapshot</code> the first time it runs: <pre><code>postgres=# select * from synchdb_state_view where name='oracleconn';\n    name    | connector_type |  pid   |      stage       |  state  |   err    |       last_dbz_offset\n------------+----------------+--------+------------------+---------+----------+-----------------------------\n oracleconn | oracle         | 528146 | initial snapshot | polling | no error | offset file not flushed yet\n</code></pre></p> <p>A new schema called <code>inventory</code> will be created and all tables streamed by the connector will be replicated under that schema. <pre><code>postgres=# set search_path=free;\nSET\npostgres=# \\d\n              List of relations\n Schema |        Name        | Type  | Owner\n--------+--------------------+-------+--------\n free   | orders             | table | ubuntu\n</code></pre></p> <p>After the initial snapshot is completed, and at least one subsequent changes is received and processed, the connector stage shall change from <code>initial snapshot</code> to <code>Change Data Capture</code>. <pre><code>postgres=# select * from synchdb_state_view where name='oracleconn';\n    name    | connector_type |  pid   |        stage        |  state  |   err    |\n    last_dbz_offset\n------------+----------------+--------+---------------------+---------+----------+-------------------------------\n-------------------------------------------------------\n oracleconn | oracle         | 528414 | change data capture | polling | no error | {\"commit_scn\":\"3118146:1:02001\nf00c0020000\",\"snapshot_scn\":\"3081987\",\"scn\":\"3118125\"}\n</code></pre></p> <p>This means that the connector is now streaming for new changes of the designated tables. Restarting the connector in <code>initial</code> mode will proceed replication since the last successful point and initial snapshot will not be re-run.</p>"},{"location":"tutorial/oracle_cdc_to_postgresql/#initial-snapshot-only-and-no-cdc","title":"Initial Snapshot Only and no CDC","text":"<p>Start the connector using <code>initial_only</code> mode will perform the initial snapshot of all designated tables (all in this case) only and will not perform CDC after.</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn', 'initial_only');\n</code></pre> <p>The connector would still appear to be <code>polling</code> from the connector but no change will be captured because Debzium internally has stopped the CDC. You have the option to shut it down. Restarting the connector in <code>initial_only</code> mode will not rebuild the tables as they have already been built.</p>"},{"location":"tutorial/oracle_cdc_to_postgresql/#capture-table-schema-only-cdc","title":"Capture Table Schema Only + CDC","text":"<p>Start the connector using <code>no_data</code> mode will perform the schema capture only, build the corresponding tables in PostgreSQL and it does not replicate existing table data (skip initial snapshot). After the schema capture is completed, the connector goes into CDC mode and will start capture subsequent changes to the tables.</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn', 'no_data');\n</code></pre> <p>Restarting the connector in <code>no_data</code> mode will not rebuild the schema again, and it will resume CDC since the last successful point.</p>"},{"location":"tutorial/oracle_cdc_to_postgresql/#always-do-initial-snapahot-cdc","title":"Always do Initial Snapahot + CDC","text":"<p>Start the connector using <code>always</code> mode will always capture the schemas of capture tables, always redo the initial snapshot and then go to CDC. This is similar to a reset button because everything will be rebuilt using this mode. Use it with caution especially when you have large number of tables being captured, which could take a long time to finish. After the rebuild, CDC resumes as normal.</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn', 'always');\n</code></pre> <p>After the initial snapshot, CDC will begin. Restarting a connector in <code>always</code> mode will repeat the same process described above.</p>"},{"location":"tutorial/oracle_cdc_to_postgresql/#possible-snapshot-modes-for-oracle-connector","title":"Possible Snapshot Modes for Oracle Connector","text":"<ul> <li>initial (default)</li> <li>initial_only</li> <li>no_data</li> <li>always</li> <li>schemasync</li> </ul>"},{"location":"tutorial/oracle_cdc_to_postgresql/#preview-source-and-destination-table-relationships-with-schemasync-mode","title":"Preview Source and Destination Table Relationships with schemasync mode","text":"<p>Before attempting to do an initial snapshot of current table and data, which may be huge, it is possible to \"preview\" all the tables and data type mappings between source and destination tables before the actual data migration. This gives you an opportunity to modify a data type mapping, or an object name before actual migration happens. This can be done with the special \"schemasync\" initial snapshot mode. Refer to object mapping workflow for a detailed example.</p>"},{"location":"tutorial/oracle_cdc_to_postgresql/#selective-table-sync","title":"Selective Table Sync","text":""},{"location":"tutorial/oracle_cdc_to_postgresql/#select-desired-tables-and-start-it-for-the-first-time","title":"Select Desired Tables and Start it for the First Time","text":"<p>Table selection is done during connector creation phase via <code>synchdb_add_conninfo()</code> where we specify a list of tables (expressed in FQN, separated by a comma) to replicate from.</p> <p>For example, the following command creates a connector that only replicates change from <code>inventory.orders</code> and <code>inventory.products</code> tables from remote MySQL database. <pre><code>SELECT synchdb_add_conninfo(\n    'oracleconn', \n    '127.0.0.1', \n    1521, \n    'DBZUSER', \n    'dbz', \n    'FREE', \n    'DBZUSER', \n    'DBZUSER.ORDERS', \n    'null', \n    'oracle'\n);\n</code></pre></p> <p>Starting this connector for the very first time will trigger an initial snapshot being performed and selected tables' schema and data will be replicated.</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn');\n</code></pre>"},{"location":"tutorial/oracle_cdc_to_postgresql/#verify-the-connector-state-and-tables","title":"Verify the Connector State and Tables","text":"<p>Examine the connector state and the new tables: <pre><code>postgres=# Select name, state, err from synchdb_state_view;\n    name    |  state  |   err\n------------+---------+----------\n oracleconn | polling | no error\n\npostgres=# \\dt free.*\n          List of tables\n Schema |  Name  | Type  | Owner\n--------+--------+-------+--------\n free   | orders | table | ubuntu\n</code></pre> By default, source database name is mapped to a schema in destination with letter casing strategy = lowercase, so <code>FREE.ORDERS</code> becomes <code>free.orders</code> in postgreSQL. Once the tables have done the initial snapshot, the connector will start CDC to stream subsequent changes for these tables.</p>"},{"location":"tutorial/oracle_cdc_to_postgresql/#add-more-tables-to-replicate-during-run-time","title":"Add More Tables to Replicate During Run Time.","text":"<p>The <code>oracleconn</code> from previous section has already completed the initial snapshot and obtained the table schemas of the selected table. If we would like to add more tables to replicate from, we will need to notify the Debezium engine about the updated table section and perform the initial snapshot again. Here's how it is done:</p> <ol> <li>Update the <code>synchdb_conninfo</code> table to include additional tables.</li> <li>In this example, we add the <code>DBZUSER.CUSTOMERS</code> table to the sync list: <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"DBZUSER.ORDERS,DBZUSER.CUSTOMERS\"') \nWHERE name = 'oracleconn';\n</code></pre></li> <li>Restart the connector with the snapshot mode set to <code>always</code> to perform another initial snapshot: <pre><code>DROP table free.orders;\nSELECT synchdb_restart_connector('oracleconn', 'always');\n</code></pre> This forces Debezium to re-snapshot all the tables again, including the existing tables <code>free.orders</code> and the new <code>free.customers</code> before going to CDC streaming. This means, to add a new table, the existing tables have to be dropped (to prevent duplicate table and primary key errors) and do the entire initial snapshot again. This is quite redundant and Debezium suggests using incremental snasphot to add the addition tables without re-snapshotting. We will update this procedure once we add the incremental snapshot support to SynchDB.</li> </ol>"},{"location":"tutorial/oracle_cdc_to_postgresql/#verify-the-updated-tables","title":"Verify the Updated Tables","text":"<p>Now, we can examine our tables again: <pre><code>postgres=# \\dt free.*\n          List of tables\n Schema      |  Name  | Type  | Owner\n-------------+--------+-------+--------\n free        | orders | table | ubuntu\n customers   | orders | table | ubuntu\n</code></pre></p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/","title":"Postgres -&gt; Postgres","text":""},{"location":"tutorial/postgresql_cdc_to_postgresql/#prepare-postgresql-database-for-synchdb","title":"Prepare PostgreSQL Database for SynchDB","text":"<p>Before SynchDB can be used to replicate from PotgreSQL, PostgreSQL server needs to be configured according to the procedure outlined here</p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#create-a-postgresql-connector","title":"Create a PostgreSQL Connector","text":"<p>Create a connector that targets all the tables under database <code>postgres</code> and schema <code>public</code>. <pre><code>SELECT \n  synchdb_add_conninfo(\n    'pgconn', '127.0.0.1', 5432, \n    'myuser', 'mypass', 'postgres', 'public', \n    'null', 'null', 'postgres');\n</code></pre></p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#initial-snapshot","title":"Initial Snapshot","text":"<p>\"Initial snapshot\" (or table snapshot) in SynchDB means to copy table schema plus initial data for all designated tables. This is similar to the term \"table sync\" in PostgreSQL logical replication. When a connector is started using the default <code>initial</code> mode, it will automatically perform the initial snapshot before going to Change Data Capture (CDC) stage. This can be partially omitted with mode <code>no_data</code>. See here for all snapshot options.</p> <p>Once the initial snapshot is completed, the connector will not do it again upon subsequent restarts and will just resume with CDC since the last incomplete offset. This behavior is controled by the metadata files managed by Debezium engine. See here for more about metadata files.</p> <p>PostgreSQL connector's initial snapshot is a little different. Debezium engine does not build the initial table schema like other connectors do. This is because PostgreSQL does not explicitly emits DDL WAL events. PostgreSQL's native logical replication also behaves the same. The user must pre-create the table schema at the destination before launching logical replication. So, when launching the Debezium based PostgreSQL connector for the first time, it assumes you have already created the designated table schemas and their initial data, and would enter CDC streaming mode immediately, without actually doing initial snapshot.</p> <p>This can be remedied by FDW based initial snapshot, which uses <code>postgres_fdw</code> to build the initial table schema and data, before transitioning to CDC streaming via Debezium. To use it, you must set <code>synchdb.olr_snapshot_engine</code> to <code>fdw</code> before launching the connector. </p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#different-connector-launch-modes","title":"Different Connector Launch Modes","text":""},{"location":"tutorial/postgresql_cdc_to_postgresql/#initial-snapshot-cdc","title":"Initial Snapshot + CDC","text":"<p>with synchdb.olr_snapshot_engine = 'debezium':</p> <p>You are expected to create the initial table schema and data at the destination database. Debezium will not create them.</p> <p>with synchdb.olr_snapshot_engine = 'fdw':</p> <p>Start the connector using <code>initial</code> mode will perform the initial snapshot of all designated tables (via postgres_fdw). After this is completed, the change data capture (CDC) process will begin to stream for new changes (via Debezium).</p> <pre><code>SELECT synchdb_start_engine_bgw('pgconn', 'initial');\n\nor \n\nSELECT synchdb_start_engine_bgw('pgconn');\n</code></pre> <p>The stage of this connector should be in <code>initial snapshot</code> the first time it runs: <pre><code>postgres=# select * from synchdb_state_view where name='oracleconn';\n  name  | connector_type |  pid   |      stage       |  state  |   err    |       last_dbz_offset\n--------+----------------+--------+------------------+---------+----------+-----------------------------\n pgconn | postgres       | 528746 | initial snapshot | polling | no error | offset file not flushed yet\n</code></pre></p> <p>A new schema called <code>postgres</code> will be created and all tables streamed by the connector will be replicated under that schema. <pre><code>postgres=# set search_path=postgres;\nSET\npostgres=# \\d\n              List of relations\n  Schema  |        Name        | Type  | Owner\n----------+--------------------+-------+--------\n postgres | orders             | table | ubuntu\n</code></pre></p> <p>After the initial snapshot is completed, and at least one subsequent changes is received and processed, the connector stage shall change from <code>initial snapshot</code> to <code>Change Data Capture</code>. <pre><code>postgres=# select * from synchdb_state_view where name='pgconn';\n  name  | connector_type |   pid   |        stage        |  state  |   err    |\n       last_dbz_offset\n--------+----------------+---------+---------------------+---------+----------+-----------------------------------\n-----------------------------------------------------------------\n pgconn | postgres       | 1604388 | change data capture | polling | no error | {\"lsn_proc\":37396384,\"messageType\"\n:\"INSERT\",\"lsn\":37396384,\"txId\":1015,\"ts_usec\":1767740340957961}\n</code></pre></p> <p>This means that the connector is now streaming for new changes of the designated tables. Restarting the connector in <code>initial</code> mode will proceed replication since the last successful point and initial snapshot will not be re-run.</p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#initial-snapshot-only-and-no-cdc","title":"Initial Snapshot Only and no CDC","text":"<p>with synchdb.olr_snapshot_engine = 'debezium':</p> <p>You are expected to create the initial table schema and data at the destination database. Debezium will not create them.</p> <p>with synchdb.olr_snapshot_engine = 'fdw':</p> <p>Start the connector using <code>initial_only</code> mode will perform the initial snapshot of all designated tables (all in this case) only and will not perform CDC after.</p> <pre><code>SELECT synchdb_start_engine_bgw('pgconn', 'initial_only');\n</code></pre> <p>The connector would still appear to be <code>polling</code> from the connector but no change will be captured because Debzium internally has stopped the CDC. You have the option to shut it down. Restarting the connector in <code>initial_only</code> mode will not rebuild the tables as they have already been built.</p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#capture-table-schema-only-cdc","title":"Capture Table Schema Only + CDC","text":"<p>with synchdb.olr_snapshot_engine = 'debezium':</p> <p>You are expected to create the initial table schema and data at the destination database. Debezium will not create them.</p> <p>with synchdb.olr_snapshot_engine = 'fdw':</p> <p>Start the connector using <code>no_data</code> mode will perform the schema capture only, build the corresponding tables in PostgreSQL and it does not replicate existing table data (skip initial snapshot). After the schema capture is completed, the connector goes into CDC mode and will start capture subsequent changes to the tables.</p> <pre><code>SELECT synchdb_start_engine_bgw('pgconn', 'no_data');\n</code></pre> <p>Restarting the connector in <code>no_data</code> mode will not rebuild the schema again, and it will resume CDC since the last successful point.</p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#always-do-initial-snapahot-cdc","title":"Always do Initial Snapahot + CDC","text":"<p>with synchdb.olr_snapshot_engine = 'debezium':</p> <p>You are expected to create the initial table schema and data at the destination database. Debezium will not create them.</p> <p>with synchdb.olr_snapshot_engine = 'fdw':</p> <p>Start the connector using <code>always</code> mode will always capture the schemas of capture tables, always redo the initial snapshot and then go to CDC. This is similar to a reset button because everything will be rebuilt using this mode. Use it with caution especially when you have large number of tables being captured, which could take a long time to finish. After the rebuild, CDC resumes as normal.</p> <pre><code>SELECT synchdb_start_engine_bgw('pgconn', 'always');\n</code></pre> <p>However, it is possible to select partial tables to redo the initial snapshot by using the <code>snapshottable</code> option of the connector. Tables matching the criteria in <code>snapshottable</code> will redo the inital snapshot, if not, their initial snapshot will be skipped. If <code>snapshottable</code> is null or empty, by default, all the tables specified in <code>table</code> option of the connector will redo the initial snapshot under <code>always</code> mode.</p> <p>This example makes the connector only redo the initial snapshot of <code>inventory.customers</code> table. All other tables will have their snapshot skipped. <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{snapshottable}', '\"public.customers\"') \nWHERE name = 'pgconn';\n</code></pre></p> <p>After the initial snapshot, CDC will begin. Restarting a connector in <code>always</code> mode will repeat the same process described above.</p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#possible-snapshot-modes-for-postgres-connector","title":"Possible Snapshot Modes for Postgres Connector","text":"<ul> <li>initial (default)</li> <li>initial_only</li> <li>no_data</li> <li>always</li> <li>schemasync</li> </ul>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#preview-source-and-destination-table-relationships-with-schemasync-mode","title":"Preview Source and Destination Table Relationships with schemasync mode","text":"<p>Before attempting to do an initial snapshot of current table and data, which may be huge, it is possible to \"preview\" all the tables and data type mappings between source and destination tables before the actual data migration. This gives you an opportunity to modify a data type mapping, or an object name before actual migration happens. This can be done with the special \"schemasync\" initial snapshot mode. Refer to object mapping workflow for a detailed example.</p> <p>Please note that you must set <code>synchdb.olr_snapshot_engine</code> to 'fdw' in order to use <code>schemasync</code> mode to preview the tables.</p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#selective-table-sync","title":"Selective Table Sync","text":""},{"location":"tutorial/postgresql_cdc_to_postgresql/#select-desired-tables-and-start-it-for-the-first-time","title":"Select Desired Tables and Start it for the First Time","text":"<p>Table selection is done during connector creation phase via <code>synchdb_add_conninfo()</code> where we specify a list of tables (expressed in FQN, separated by a comma) to replicate from.</p> <p>For example, the following command creates a connector that only replicates change from <code>public.orders</code> tables from remote PostgreSQL database. <pre><code>SELECT synchdb_add_conninfo(\n    'pgconn', \n    '127.0.0.1', \n    5433, \n    'pguser', \n    'pgpass', \n    'postgres', \n    'public', \n    'public.orders', \n    'null', \n    'postgres'\n);\n</code></pre></p> <p>Starting this connector for the very first time will trigger an initial snapshot being performed and selected tables' schema and data will be replicated.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#verify-the-connector-state-and-tables","title":"Verify the Connector State and Tables","text":"<p>Examine the connector state and the new tables: <pre><code>postgres=# Select name, state, err from synchdb_state_view;\n  name  |  state  |   err\n--------+---------+----------\n pgconn | polling | no error\n\n\npostgres=# \\dt postgres.*\n           List of tables\n  Schema  |  Name  | Type  | Owner\n----------+--------+-------+--------\n postgres | orders | table | pguser\n</code></pre></p> <p>Once the snapshot is complete, the connector will continue capturing subsequent changes to the table.</p>"},{"location":"tutorial/postgresql_cdc_to_postgresql/#add-more-tables-to-replicate-during-run-time","title":"Add More Tables to Replicate During Run Time.","text":"<p>The <code>mysqlconn</code> from previous section has already completed the initial snapshot and obtained the table schemas of the selected table. If we would like to add more tables to replicate from, we will need to notify the Debezium engine about the updated table section and perform the initial snapshot again. Here's how it is done:</p> <ol> <li>Update the <code>synchdb_conninfo</code> table to include additional tables.</li> <li>In this example, we add the <code>inventory.customers</code> table to the sync list: <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"public.orders,public.customers\"') \nWHERE name = 'pgconn';\n</code></pre></li> <li>Configure the snapshot table parameter to include only the new table <code>inventory.customers</code> to that SynchDB does not try to rebuild the 2 tables that have already finished the snapshot. <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{snapshottable}', '\"public.customers\"') \nWHERE name = 'pgconn';\n</code></pre></li> <li>Restart the connector with the snapshot mode set to <code>always</code> to perform another initial snapshot: <pre><code>SELECT synchdb_stop_engine_bgw('pgconn');\nSELECT synchdb_start_engine_bgw('pgconn', 'always');\n</code></pre> &lt;&gt; Please note that we do not use <code>synchdb_restart_connector</code> to restart the connector here because this function is mostly designed for restarting Debezium engine with a different snapshot mode. Since Postgres connector uses FDW instead of Debezium to build the initial tables, we have to explicity do a <code>stop engine</code>, followed by <code>start engine</code> calls to trigger FDW routines to run again."},{"location":"tutorial/postgresql_cdc_to_postgresql/#verify-the-updated-tables","title":"Verify the Updated Tables","text":"<p>Now, we can examine our tables again: <pre><code>postgres=# \\dt inventory.*\n             List of tables\n  Schema   |   Name    | Type  | Owner\n-----------+-----------+-------+--------\n inventory | customers | table | ubuntu\n inventory | orders    | table | ubuntu\n inventory | products  | table | ubuntu\n</code></pre></p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/","title":"SQL Server -&gt; PostgreSQL","text":""},{"location":"tutorial/sqlserver_cdc_to_postgresql/#prepare-sql-server-database-for-synchdb","title":"Prepare SQL Server Database for SynchDB","text":"<p>Before SynchDB can be used to replicate from SQL Server, SQL Server needs to be configured according to the procedure outlined here</p> <p>Please ensure the desired tables have already been enabled as CDC table in SQL Server. The following commands can be run on SQL Server client to enable CDC for <code>dbo.customer</code>, <code>dbo.district</code>, and <code>dbo.history</code>. You will continue to add new tables as needed.</p> <pre><code>USE testDB\nGO\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'customer', @role_name = NULL, @supports_net_changes = 0;\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'district', @role_name = NULL, @supports_net_changes = 0;\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'history', @role_name = NULL, @supports_net_changes = 0;\nGO\n</code></pre>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#create-a-sql-server-connector","title":"Create a SQL Server Connector","text":"<p>Create a connector that targets all the tables under <code>testDB</code> database and <code>dbo</code> schema in SQL Server. <pre><code>SELECT \n  synchdb_add_conninfo(\n    'sqlserverconn', '127.0.0.1', 1433, \n    'sa', 'Password!', 'testDB', 'dbo', \n    'null', 'null', 'sqlserver');\n</code></pre></p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#initial-snapshot","title":"Initial Snapshot","text":"<p>\"Initial snapshot\" (or table snapshot) in SynchDB means to copy table schema plus initial data for all designated tables. This is similar to the term \"table sync\" in PostgreSQL logical replication. When a connector is started using the default <code>initial</code> mode, it will automatically perform the initial snapshot before going to Change Data Capture (CDC) stage. This can be partially omitted with mode <code>no_data</code>. See here for all snapshot options.</p> <p>Once the initial snapshot is completed, the connector will not do it again upon subsequent restarts and will just resume with CDC since the last incomplete offset. This behavior is controled by the metadata files managed by Debezium engine. See here for more about metadata files. **</p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#different-connector-launch-modes","title":"Different Connector Launch Modes","text":""},{"location":"tutorial/sqlserver_cdc_to_postgresql/#initial-snapshot-cdc","title":"Initial Snapshot + CDC","text":"<p>Start the connector using <code>initial</code> mode will perform the initial snapshot of all designated tables (all in this case). After this is completed, the change data capture (CDC) process will begin to stream for new changes.</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn', 'initial');\n\nor \n\nSELECT synchdb_start_engine_bgw('sqlserverconn');\n</code></pre> <p>The stage of this connector should be in <code>initial snapshot</code> the first time it runs: <pre><code>postgres=# select * from synchdb_state_view where name='sqlserverconn';\n     name      | connector_type |  pid   |      stage       |  state  |   err    |       last_dbz_offset\n---------------+----------------+--------+------------------+---------+----------+-----------------------------\n sqlserverconn | sqlserver      | 526003 | initial snapshot | polling | no error | offset file not flushed yet\n(1 row)\n</code></pre></p> <p>A new schema called <code>testdb</code> will be created and all tables streamed by the connector will be replicated under that schema. <pre><code>postgres=# set search_path=testdb;\nSET\npostgres=# \\d\n                  List of relations\n Schema |          Name           |   Type   | Owner\n--------+-------------------------+----------+--------\n testdb | customers               | table    | ubuntu\n testdb | customers_id_seq        | sequence | ubuntu\n testdb | orders                  | table    | ubuntu\n testdb | orders_order_number_seq | sequence | ubuntu\n testdb | products                | table    | ubuntu\n testdb | products_id_seq         | sequence | ubuntu\n testdb | products_on_hand        | table    | ubuntu\n</code></pre></p> <p>After the initial snapshot is completed, and at least one subsequent changes is received and processed, the connector stage shall change from <code>initial snapshot</code> to <code>Change Data Capture</code>. <pre><code>postgres=# select * from synchdb_state_view where name='sqlserverconn';\n     name      | connector_type |  pid   |        stage        |  state  |   err    |\n             last_dbz_offset\n---------------+----------------+--------+---------------------+---------+----------+-----------------------------\n----------------------------------------------------------------------\n sqlserverconn | sqlserver      | 526290 | change data capture | polling | no error | {\"event_serial_no\":1,\"commit\n_lsn\":\"0000002b:000004d8:0004\",\"change_lsn\":\"0000002b:000004d8:0003\"}\n</code></pre></p> <p>This means that the connector is now streaming for new changes of the designated tables. Restarting the connector in <code>initial</code> mode will proceed replication since the last successful point and initial snapshot will not be re-run.</p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#initial-snapshot-only-and-no-cdc","title":"Initial Snapshot Only and no CDC","text":"<p>Start the connector using <code>initial_only</code> mode will perform the initial snapshot of all designated tables (all in this case) only and will not perform CDC after.</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn', 'initial_only');\n</code></pre> <p>The connector would still appear to be <code>polling</code> from the connector but no change will be captured because Debzium internally has stopped the CDC. You have the option to shut it down. Restarting the connector in <code>initial_only</code> mode will not rebuild the tables as they have already been built.</p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#capture-table-schema-only-cdc","title":"Capture Table Schema Only + CDC","text":"<p>Start the connector using <code>no_data</code> mode will perform the schema capture only, build the corresponding tables in PostgreSQL and it does not replicate existing table data (skip initial snapshot). After the schema capture is completed, the connector goes into CDC mode and will start capture subsequent changes to the tables.</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn', 'no_data');\n</code></pre> <p>Restarting the connector in <code>no_data</code> mode will not rebuild the schema again, and it will resume CDC since the last successful point.</p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#always-do-initial-snapahot-cdc","title":"Always do Initial Snapahot + CDC","text":"<p>Start the connector using <code>always</code> mode will always capture the schemas of capture tables, always redo the initial snapshot and then go to CDC. This is similar to a reset button because everything will be rebuilt using this mode. Use it with caution especially when you have large number of tables being captured, which could take a long time to finish. After the rebuild, CDC resumes as normal.</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn', 'always');\n</code></pre> <p>After the initial snapshot, CDC will begin. Restarting a connector in <code>always</code> mode will repeat the same process described above.</p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#possible-snapshot-modes-for-sql-server-connector","title":"Possible Snapshot Modes for SQL Server Connector","text":"<ul> <li>initial (default)</li> <li>initial_only</li> <li>no_data</li> <li>always</li> <li>schemasync</li> </ul>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#preview-source-and-destination-table-relationships-with-schemasync-mode","title":"Preview Source and Destination Table Relationships with schemasync mode","text":"<p>Before attempting to do an initial snapshot of current table and data, which may be huge, it is possible to \"preview\" all the tables and data type mappings between source and destination tables before the actual data migration. This gives you an opportunity to modify a data type mapping, or an object name before actual migration happens. This can be done with the special \"schemasync\" initial snapshot mode. Refer to object mapping workflow for a detailed example.</p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#selective-table-sync","title":"Selective Table Sync","text":""},{"location":"tutorial/sqlserver_cdc_to_postgresql/#select-desired-tables-and-start-it-for-the-first-time","title":"Select Desired Tables and Start it for the First Time","text":"<p>Table selection is done during connector creation phase via <code>synchdb_add_conninfo()</code> where we specify a list of tables (expressed in FQN, separated by a comma) to replicate from.</p> <p>For example, the following command creates a connector that only replicates change from <code>dbo.orders</code> tables from remote SQL Server database. <pre><code>SELECT synchdb_add_conninfo(\n    'sqlserverconn', \n    '127.0.0.1', \n    1433, \n    'sa', \n    'Password!', \n    'testDB', \n    'dbo', \n    'dbo.orders,dbo.products',\n    'null', \n    'sqlserver'\n);\n</code></pre></p> <p>Starting this connector for the very first time will trigger an initial snapshot being performed and selected 2 tables' schema and data will be replicated.</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn');\n</code></pre>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#verify-the-connector-state-and-tables","title":"Verify the Connector State and Tables","text":"<p>Examine the connector state and the new tables: <pre><code>postgres=# Select name, state, err from synchdb_state_view;\n     name      |  state  |   err\n---------------+---------+----------\n sqlserverconn | polling | no error\n\npostgres=# \\dt testdb.*\n           List of tables\n Schema |   Name   | Type  | Owner\n--------+----------+-------+--------\n testdb | orders   | table | ubuntu\n testdb | products | table | ubuntu\n</code></pre></p> <p>By default, source database name is mapped to a schema in destination, so <code>dbo.orders</code> becomes <code>testdb.orders</code> in postgreSQL. Once the tables have done the initial snapshot, the connector will start CDC to stream subsequent changes for these tables.</p>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#add-more-tables-to-replicate-during-run-time","title":"Add More Tables to Replicate During Run Time.","text":"<p>If we would like to add more tables to replicate from, we will need to notify the Debezium engine about the updated table section and perform the initial snapshot again. Here's how it is done:</p> <ol> <li>Update the <code>synchdb_conninfo</code> table to include additional tables.</li> <li>In this example, we add the <code>dbo.customers</code> table to the sync list: <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"dbo.orders,dbo.products,dbo.customers\"') \nWHERE name = 'sqlserverconn';\n</code></pre></li> <li>Restart the connector with the snapshot mode set to <code>always</code> to perform another initial snapshot: <pre><code>DROP table testdb.orders, testdb.products;\nSELECT synchdb_restart_connector('sqlserverconn', 'always');\n</code></pre> This forces Debezium to re-snapshot all the tables again, including the old tables <code>dbo.orders</code> and <code>dbo.products</code> and the new before going to CDC streaming. This means, to add the third table, the existing tables have to be dropped (to prevent duplicate table and primary key errors) and do the entire initial snapshot again. This is quite redundant and Debezium suggests using incremental snasphot to add the addition tables without re-snapshotting. We will update this procedure once we add the incremental snapshot support to SynchDB.</li> </ol>"},{"location":"tutorial/sqlserver_cdc_to_postgresql/#verify-the-updated-tables","title":"Verify the Updated Tables","text":"<p>Now, we can examine our tables again: <pre><code>postgres=# \\dt \"testDB\".*\n           List of tables\n Schema |   Name    | Type  | Owner\n--------+-----------+-------+--------\n testDB | customers | table | ubuntu\n testDB | orders    | table | ubuntu\n testDB | products  | table | ubuntu\n</code></pre></p>"},{"location":"user-guide/configure_error_strategies/","title":"Configure Error Handling Strategies","text":""},{"location":"user-guide/configure_error_strategies/#configure-error-handling-strategies_1","title":"Configure Error Handling Strategies","text":"<p>During initial snapshot or CDC, errors such as conflicting primary keys, invalid data...etc may occur that SynchDB needs to know how to handle them. For errors that occur during Synchdb's processing or during applying to PostgreSQL, there are several available strategies to handle them via the configruation parameter \"synchdb.error_handling_strategy\".</p> <p>Please note that the error strategies mentioned below are only executed if the error originated or detected during the change event processing on C side. If the error originated from Debezium Runner on the Java side, for example, connectivity issues or issues with connection to the remote database, the above strategies will not be executed. In this case, the error messages of Debezium Runner will be propagated to SynchDB on the C side, and displayed in <code>synchdb_state_view()</code> and the connector will exit.</p>"},{"location":"user-guide/configure_error_strategies/#exit-default","title":"exit (default)","text":"<p>This is the default error strategy, which causes the connector worker to exit when an error has occured. The batch that it is currently working on, which resulted in error will not be marked as completed and the change events that have been successfully completed in the same batch will not be committed. User is expected to check the error message as returned in <code>synchdb_state_view()</code> or the log file to resolve the error. When the connector worker is restarted, the connector will automatically retry the same batch that has failed previously.</p>"},{"location":"user-guide/configure_error_strategies/#retry","title":"retry","text":"<p>This strategy adds a <code>restart_time</code> of 5 second to the connector worker, which causes PostgreSQL's bgworker engine to automatically start the worker every 5 second should it has exited. This means that when an error occurs, the connector worker will still exit, but unlike the <code>exit</code> strategy above, it will automatically be restarted by bgworker engine, which will retry on the same batch that has failed. It will continue to exit and restart until the error has been resolved.</p>"},{"location":"user-guide/configure_error_strategies/#skip","title":"skip","text":"<p>As the name suggests, when in <code>skip</code> error strategy, any error that the connector worker encountered will not cause the worker to exit, the error messages, however, will still be written to the log or <code>synchdb_state_view()</code>, but the connector itself will ignore the error and move on to processing the next change event and even the next batch. </p>"},{"location":"user-guide/configure_error_strategies/#view-the-last-error-message-of-a-connector","title":"View the Last Error Message of a Connector","text":"<p>As mentioned above, errors originated from Debezium Runner on the Java side or SynchDB on the C side will have the error messages propagated and displayed in <code>synchdb_state_view()</code>. For example:</p> <pre><code>select name, pid, err from synchdb_state_view;\n\n   name    | pid |                                                                                                          err\n-----------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n mysqlconn |  -1 | Connector configuration is not valid. Unable to connect: Communications link failure  The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n(1 row)\n</code></pre> <p>If the error happens during processing of a JSON change event, and the GUC parameter <code>synchdb.log_change_on_error</code> is set to true, SynchDB will also output the original JSON change event in the PostgreSQL log file that caused the error for troubleshooting. </p>"},{"location":"user-guide/configure_infinispan/","title":"Configure Infinispan for Oracle Connector","text":""},{"location":"user-guide/configure_infinispan/#overview","title":"Overview","text":"<p>By default, Debezium's Oracle connector uses the JVM heap to cache incoming change events before passing them to SynchDB for processing. The maximum heap size is controlled via the <code>synchdb.jvm_max_heap_size</code> GUC. When the JVM heap runs out of memory (especially under large transactions or schemas with many columns), the connector may fail with OutOfMemoryError, making heap sizing a critical tuning challenge.</p> <p>As an alternative, Debezium can be configured to use Infinispan as its caching layer. Infinispan supports memory storage on both the JVM heap and off-heap (direct memory), offering more flexibility. Additionally, it supports passivation, allowing excess data to be spilled to disk when memory limits are reached. This makes it far more resilient under heavy workloads and ensures large transactions or schema changes can be handled gracefully without running out of memory.</p>"},{"location":"user-guide/configure_infinispan/#synchdb_add_infinispan","title":"<code>synchdb_add_infinispan()</code>","text":"<p>Signature:</p> <pre><code>synchdb_add_infinispan(\n    connectorName NAME,     -- Name of the connector\n    memoryType NAME,        -- memory type, can be \"heap\" or \"off heap\"\n    memorySize INT          -- size of memory in MB to reserve as cache\n)\n</code></pre> <p>Registers an Infinispan-backed caching configuration for a given connector. This allows the connector to use Infinispan for buffering change events, supporting both heap-based and off-heap memory allocation with spill-to-disk (passivation).</p> <p>Note:</p> <ul> <li>If called on a connector that is currently running, the setting will take effect on next restart.</li> <li>If an Infinispan cache already exists for the connector, it will be replaced.</li> <li>memoryType='off_heap' utilizes native (direct) memory and is not limited by JVM heap, but should be sized carefully.</li> <li>The cache will automatically support passivation to disk when memory fills.</li> </ul> <p>Example: <pre><code>SELECT synchdb_add_infinispan('oracleconn', 'off_heap', 2048);\n</code></pre></p>"},{"location":"user-guide/configure_infinispan/#synchdb_del_infinispan","title":"<code>synchdb_del_infinispan()</code>","text":"<p>Signature:</p> <pre><code>synchdb_add_infinispan(\n    connectorName NAME         -- Name of the connector\n)\n</code></pre> <p>Removes the Infinispan cache configuration and associated on-disk metadata for a given connector. This operation will delete:</p> <ul> <li>All cache files</li> <li>Any passivated (spilled-to-disk) state</li> <li>The associated Infinispan configuration</li> </ul> <p>Note:</p> <ul> <li>This function can only be executed when the connector is stopped.</li> <li>Attempting to run it while the connector is active will result in an error.</li> <li>Use this command to clean up after permanently disabling or reconfiguring a connector\u2019s cache backend.</li> </ul> <p>Example: <pre><code>SELECT synchdb_del_infinispan('oracleconn');\n</code></pre></p>"},{"location":"user-guide/configure_infinispan/#passivation","title":"<code>Passivation</code>","text":"<p>Passivation simply means infinispan will eject and write data on disk if cache memory is full. As long as there is space in memory to hold change events, disk write will not occur. The data is written to <code>$PGDATA/pg_synchdb/ispn_[connector name]_[destination database name]</code></p>"},{"location":"user-guide/configure_infinispan/#example-oracle-sqls-to-test-infinispan-with-a-large-transaction","title":"Example Oracle SQLs to test Infinispan with a Large Transaction","text":"<p>Create a test table in Oracle: <pre><code>CREATE TABLE big_tx_test (\n    id       NUMBER PRIMARY KEY,\n    payload  VARCHAR2(4000),\n    created  DATE DEFAULT SYSDATE\n);\n</code></pre></p> <p>Create a relatively large transaction: <pre><code>BEGIN\n  FOR i IN 1..100000 LOOP\n    INSERT INTO big_tx_test (id, payload)\n    VALUES (i, RPAD('x', 4000, 'x'));\n  END LOOP;\n  COMMIT;\nEND;\n/\n</code></pre></p> <p>Behaviors Under Large Transaction</p> <p>no infinispan setting + low JVM heap (synchdb.jvm_max_heap_size=128)</p> <ul> <li>\u2192 OutOfMemory error will occur</li> </ul> <p>low JVM heap (128) + high infinispan off heap (2048)</p> <ul> <li>\u2192 large transaction handled successfully</li> </ul> <p>low JVM heap (128) + low infinispan off heap (128)</p> <ul> <li>\u2192 passivation will occur</li> <li>\u2192 <code>ispn_[connector name]_[destination database name]</code> size will grow during processing and reduce once large transaction finished processing</li> <li>\u2192 large transaction handled successfully but at slower speed.</li> </ul> <p>low JVM heap (128) + high infinispan heap (2048)</p> <ul> <li>\u2192 OutOfMemory error will occur</li> <li>\u2192 do not configure infinispan to use more heap memory than JVM max heap.</li> </ul> <p>low JVM heap (128) + low infinispan heap (64)</p> <ul> <li>\u2192 passivation will occur</li> <li>\u2192 <code>ispn_[connector name]_[destination database name]</code> size will grow during processing and reduce once large transaction finished processing</li> <li>\u2192 not recommended as half of the JVM heap can potentially be used by infinispan and may not have enough left for other Debezium operations</li> </ul> <p>low JVM heap (128) + same infinispan heap (128)</p> <ul> <li>\u2192 not recommended as all of the JVM heap can potentially be used by infinispan and eventually causing OutOfMemory error</li> </ul> <p>high JVM heap (2048) + low infinispan heap (128)</p> <ul> <li>\u2192 passivation will occur</li> <li>\u2192 <code>ispn_[connector name]_[destination database name]</code> size will grow during processing and reduce once large transaction finished processing</li> <li>\u2192 large transaction handled successfully</li> <li>\u2192 not efficient - as only a small portion of JVM heap is used as cache + unnessary passivation.</li> </ul>"},{"location":"user-guide/configure_olr/","title":"Configure Openlog Replicator for Oracle","text":""},{"location":"user-guide/configure_olr/#overview","title":"Overview","text":"<p>In addition to LogMiner-based Oracle replication, SynchDB also supports Openlog Replicator (OLR) to stream from Oracle databases. There are 2 types of Openlog Replicator supported in SynchDB:</p> <ol> <li>Debezium based Openlog Replicator</li> <li>Native Openlog Replicator (not via Debezium) - at BETA</li> </ol> <p>Both require Openlog Replicator to be configured according to the setup example below and connected to Oracle prior to streaming in SynchDB.</p>"},{"location":"user-guide/configure_olr/#requirements","title":"Requirements","text":"<ul> <li>Openlog Replicator Version: <code>1.3.0</code> (verified compatibility for Debezium 2.7.x)</li> <li>Oracle instance with redo logs accessible to OLR</li> <li>Additional permissions must be granted for OLR.  Refer to here for exact permission requirement.</li> <li>Openlog Replicator must be configured and running</li> <li>An existing Oracle connector in SynchDB (created using <code>synchdb_add_conninfo()</code>)</li> </ul> <p>Refer to this external guide for details on deploying Openlog Replicator via Docker.</p>"},{"location":"user-guide/configure_olr/#openlog-replicator-configuration-example","title":"Openlog Replicator Configuration Example","text":"<p>SynchDB's OLR support is built against the configuration example below. </p> <p>Version 1.3.0 <pre><code>{\n  \"version\": \"1.3.0\",\n  \"source\": [\n    {\n      \"alias\": \"SOURCE\",\n      \"name\": \"ORACLE\",\n      \"reader\": {\n        \"type\": \"online\",\n        \"user\": \"DBZUSER\",\n        \"password\": \"dbz\",\n        \"server\": \"//ora19c:1521/FREE\"\n      },\n      \"format\": {\n        \"type\": \"json\",\n        \"column\": 2,\n        \"db\": 3,\n        \"interval-dts\": 9,\n        \"interval-ytm\": 4,\n        \"message\": 2,\n        \"rid\": 1,\n        \"schema\": 7,\n        \"timestamp-all\": 1,\n        \"scn-all\": 1\n      },\n      \"memory\": {\n        \"min-mb\": 64,\n        \"max-mb\": 1024\n      },\n      \"filter\": {\n        \"table\": [\n          {\"owner\": \"DBZUSER\", \"table\": \".*\"}\n        ]\n      },\n      \"flags\": 32\n    }\n  ],\n  \"target\": [\n    {\n      \"alias\": \"SYNCHDB\",\n      \"source\": \"SOURCE\",\n      \"writer\": {\n        \"type\": \"network\",\n        \"uri\": \"0.0.0.0:7070\"\n      }\n    }\n  ]\n}\n</code></pre></p> <p>Version 1.8.5 <pre><code>{\n  \"version\": \"1.8.5\",\n  \"source\": [\n    {\n      \"alias\": \"SOURCE\",\n      \"name\": \"ORACLE\",\n      \"reader\": {\n        \"type\": \"online\",\n        \"user\": \"DBZUSER\",\n        \"password\": \"dbz\",\n        \"server\": \"//ora19c:1521/FREE\"\n      },\n      \"format\": {\n        \"type\": \"json\",\n        \"column\": 2,\n        \"db\": 3,\n        \"interval-dts\": 9,\n        \"interval-ytm\": 4,\n        \"message\": 2,\n        \"rid\": 1,\n        \"schema\": 7,\n        \"timestamp-all\": 1,\n        \"scn-type\": 1\n      },\n      \"memory\": {\n        \"min-mb\": 64,\n        \"max-mb\": 1024,\n        \"swap-path\": \"/opt/OpenLogReplicator/olrswap\"\n      },\n      \"filter\": {\n        \"table\": [\n          {\"owner\": \"DBZUSER\", \"table\": \".*\"}\n        ]\n      },\n      \"flags\": 32\n    }\n  ],\n  \"target\": [\n    {\n      \"alias\": \"DEBEZIUM\",\n      \"source\": \"SOURCE\",\n      \"writer\": {\n        \"type\": \"network\",\n        \"uri\": \"0.0.0.0:7070\"\n      }\n    }\n  ]\n}\n</code></pre></p> <p>Please note the following:</p> <ul> <li>\"source\".\"name\": \"ORACLE\" -&gt; this should match the <code>olr_source</code> value when defining OLR parameters via <code>synchdb_add_olr_conninfo()</code> (See below)</li> <li>\"source\".\"reader\".\"user\" -&gt; this should match the <code>username</code> value when creating a connector via <code>synchdb_add_conninfo()</code></li> <li>\"source\".\"reader\".\"password\" -&gt; this should match the <code>password</code> value when creating a connector via <code>synchdb_add_conninfo()</code></li> <li>\"source\".\"reader\".\"server\" -&gt; this should contain the values of <code>hostname</code>, <code>port</code> and <code>source database</code> values when creating a connector via <code>synchdb_add_conninfo()</code></li> <li>\"source\".\"filter\".\"table\":[] -&gt; this filters the change events that Openlog Replicator captures. &lt;&lt;&lt;IMPORTANT&gt;&gt;&gt;: This is currently the only way to filter change events from Oracle as OLR implementations in SynchDB does not do any filtering at this moment. (The <code>table</code> and <code>snapshot table</code> values are ignored when creating a connector via <code>synchdb_add_conninfo()</code>) </li> <li>\"format\":{} -&gt; the specific paylod format ingested by Debezium based or native Openlog Replicator connector. Use these values as specified.</li> <li>\"memory\".\"swap-path\" -&gt; this tells OLR where to write swap files in low memory scenario.</li> <li>\"target\".[0].\"writer\".\"type\": -&gt; this must specify <code>network</code> as both Debezium and native Openlog Replicator connector communicate with Openlog Replicator via network</li> <li>\"target\".[0].\"writer\".\"uri\": -&gt; this is the bind host and port Openlog Replicator listens on that SynchDB should be able to access via <code>olr_host</code> and <code>olr_port</code> when defining OLR parameters via <code>synchdb_add_olr_conninfo()</code>. </li> </ul>"},{"location":"user-guide/configure_olr/#synchdb_add_conninfo","title":"<code>synchdb_add_conninfo()</code>","text":"<p>To create a Debezium-based OLR connector (use <code>type</code> = 'oracle'):</p> <pre><code>SELECT synchdb_add_conninfo('olrconn',\n                            'ora19c',\n                            1521,\n                            'DBZUSER',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'oracle');\n</code></pre> <p>To create a Native OLR connector (use <code>type</code> = 'olr'):</p> <pre><code>SELECT synchdb_add_conninfo('olrconn',\n                            'ora19c',\n                            1521,\n                            'DBZUSER',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'olr');\n</code></pre> <p>&lt;&lt;&lt;IMPORTANT&gt;&gt;&gt; SynchDB must be compiled and built with flag (WITH_OLR=1) to support native openlog replicator connector.</p> <p>More on creating a connector can be found here</p>"},{"location":"user-guide/configure_olr/#synchdb_add_olr_conninfo","title":"<code>synchdb_add_olr_conninfo()</code>","text":"<p>With a connector created, the user then registers an Openlog Replicator endpoint for an existing Oracle connector.</p> <p>Signature:</p> <pre><code>synchdb_add_olr_conninfo(\n    conn_name TEXT,     -- Name of the connector\n    olr_host TEXT,      -- Hostname or IP of the OLR instance\n    olr_port INT,       -- Port number exposed by OLR (typically 7070)\n    olr_source TEXT     -- Oracle source name as configured in OLR\n)\n</code></pre> <p>Example:</p> <p>This instructs SynchDB to stream changes for the connector <code>olrconn</code> from the Openlog Replicator instance running at olrhost:7070, using the Oracle source identifier ORACLE. Call <code>synchdb_start_engine_bgw</code> to start this connector.</p> <pre><code>SELECT synchdb_add_olr_conninfo('olrconn', 'olrhost', 7070, 'ORACLE');\n</code></pre>"},{"location":"user-guide/configure_olr/#synchdb_del_olr_conninfo","title":"synchdb_del_olr_conninfo","text":"<p>Removes the OLR configuration for a specific connector, reverting it to use LogMiner.</p> <p>Signature:</p> <pre><code>synchdb_del_olr_conninfo(conn_name TEXT)\n</code></pre> <p>Example:</p> <p>This command disables the use of OLR for oracleconn. Starting the connector with <code>synchdb_start_engine_bgw</code> will fall back to the default logmining strategy (Debezium based OLR connector). If using native Openlog Replicator connector, the absense of OLR configuration will result in error at connector startup.</p> <pre><code>SELECT synchdb_del_olr_conninfo('olrconn');\n</code></pre>"},{"location":"user-guide/configure_olr/#behavior-notes-for-debezium-based-openlog-replicator-connector","title":"Behavior Notes for Debezium based Openlog Replicator Connector","text":"<ul> <li>When both LogMiner and OLR configurations exist, SynchDB defaults to using Openlog Replicator for change capture.</li> <li>If OLR configurations are absent, SynchDB uses logmining strategy to stream changes.</li> <li>Restarting the connector is required after modifying its OLR configuration.</li> </ul>"},{"location":"user-guide/configure_olr/#behavior-notes-for-native-based-openlog-replicator-connector","title":"Behavior Notes for Native based Openlog Replicator Connector","text":"<ul> <li>Currently at BETA version.</li> <li>SynchDB manages connections to Openlog Replicator and streams changes without using Debezium.</li> <li>Requires OLR configuration or connector will error on startup.</li> <li>Relies on Debezium's oracle connector to complete initial snapshot and shuts down when done, subsequent CDC is done natively within SynchDB against Openlog Replicator.</li> <li>Relies on IvorySQL's oracle parser to handle DDL events. This must be compiled and installed prior to using native openlog replicator connector.</li> <li>Visit here for more information about Openlog Replicator.</li> </ul>"},{"location":"user-guide/configure_snapshot_engine/","title":"Configure Snapshot Engine","text":""},{"location":"user-guide/configure_snapshot_engine/#initial-snapshot-vs-change-data-capture-cdc","title":"Initial Snapshot vs Change Data Capture (CDC)","text":"<p>Initial snapshot refers to the process of migrating both the table schema and the initial data from remote database to SynchDB. For most connector types, this is done only once on first connector start via embedded Debezium runner as the only engine that can perform initial snapshot. After the initial snapshot completes, the Change Data Capture will begin to stream live changes to SynchDB. The \"snapshot modes\" can further control the behavior of initial snapshot and CDC. Refer to here for more information.</p> <p>In addition to Debezium based initial snapshot, which may be slow when there is a huge number of tables, SynchdB provides an alternative FDW-based native initial snapshot engine. FDW based snapshot is only supported in native Openlog Replicator (OLR) connector as of now. All other connectors still rely on debezium to carry out the snapshot.</p>"},{"location":"user-guide/configure_snapshot_engine/#fdw-based-initial-snapshot","title":"FDW Based Initial Snapshot","text":"<ul> <li>Enabled in <code>postgresql.conf</code> by setting \"synchdb.olr_snapshot_engine\" to \"fdw\"</li> <li>Start a OLR connector with a snapshot mode that requires doing a snapshot. For example:</li> </ul> <pre><code>SELECT synchdb_start_engine_bgw('olrconn', 'no_data');\n\n-- or\nSELECT synchdb_start_engine_bgw('olrconn', 'always');\n\n-- or\nSELECT synchdb_start_engine_bgw('olrconn', 'schemasync');\n</code></pre>"},{"location":"user-guide/configure_snapshot_engine/#build-and-install-oracle_fdw","title":"Build and Install oracle_fdw","text":"<p>If \"fdw\" is selected as snapshot engine, you need to ensure the corresponding Foreign Data Wrapper has been installed or available for synchdb. For your reference, below is a brief procedure to build and install oracle_fdw from source code.</p>"},{"location":"user-guide/configure_snapshot_engine/#install-oci","title":"Install OCI","text":"<p>OCI is required to build and run oracle_fdw. For this example, I am using version 23.9.0:</p> <pre><code># Get the pre-build packages:\nwget https://download.oracle.com/otn_software/linux/instantclient/2390000/instantclient-basic-linux.x64-23.9.0.25.07.zip\nwget https://download.oracle.com/otn_software/linux/instantclient/2390000/instantclient-sdk-linux.x64-23.9.0.25.07.zip\n\n# unzip them: Select 'Y' to overwrite metadata files\nunzip instantclient-basic-linux.x64-23.9.0.25.07.zip\nunzip instantclient-sdk-linux.x64-23.9.0.25.07.zip\n</code></pre> <p>Update environment variables so the system knows where to find OCI headers and libraries.</p> <pre><code>export OCI_HOME=/home/$USER/instantclient_23_9\nexport OCI_LIB_DIR=$OCI_HOME\nexport OCI_INC_DIR=$OCI_HOME/sdk/include\nexport LD_LIBRARY_PATH=$OCI_HOME:${LD_LIBRARY_PATH}\nexport PATH=$OCI_HOME:$PATH\n</code></pre> <p>You could add the above commands to the end of <code>~/.bashrc</code> to automatically set the PATHs every time you login to your system.</p> <p>You can also add $OCI_HOME to <code>/etc/ld.so.conf.d/x86_64-linux-gnu.conf</code> (ubuntu example), as a new path to find shared libraries.</p> <p>You should do a ldconfig so your linker knows where to find shared libraries:</p>"},{"location":"user-guide/configure_snapshot_engine/#build-oracle_fdw-280","title":"Build oracle_fdw 2.8.0","text":"<pre><code>git clone https://github.com/laurenz/oracle_fdw.git --branch ORACLE_FDW_2_8_0\n</code></pre> <p>Ensure oracle_fdw's Makefile can find OCI includes and libraries by adjusting these 2 lines in Makefile:</p> <pre><code>FIND_INCLUDE := $(wildcard /usr/include/oracle/*/client64 /usr/include/oracle/*/client /home/$USER/instantclient_23_9/sdk/include)\nFIND_LIBDIRS := $(wildcard /usr/lib/oracle/*/client64/lib /usr/lib/oracle/*/client/lib /home/$USER/instantclient_23_9)\n</code></pre> <p>Build and install oracle_fdw:</p> <pre><code>make PG_CONFIG=/usr/local/pgsql/bin/pg_config\nsudo make install PG_CONFIG=/usr/local/pgsql/bin/pg_config\n</code></pre> <p>Oralce_fdw is ready to go. </p> <p>&lt;&gt; You do not have to run <code>CREATE EXTENSION oracle_fdw</code> prior to using FDW based initial snapshot, nor do you have to <code>CREATE SERVER</code> or <code>CREATE USER MAPPING</code>. SynchDB takes care of all of these when it performs the snapshot.."},{"location":"user-guide/connector_auto_launcher/","title":"Connector Auto Launcher","text":""},{"location":"user-guide/connector_auto_launcher/#enable-synchdb-auto-launcher","title":"Enable SynchDB Auto Launcher","text":"<p>A connection worker becomes eligible for automatic Launch when <code>synchdb_start_engine_bgw()</code> is issued on a particular <code>connector name</code>. Likewise, it becomes ineligible when <code>synchdb_stop_engine_bgw()</code> is issued. </p> <p>Automatic connector launcher can be enabled by:</p> <ul> <li>Add <code>synchdb</code> to <code>shared_preload_libraries</code> GUC option in postgresql.conf</li> <li>Set new GUC option <code>synchdb.synchdb_auto_launcher</code> to true in postgresql.conf</li> <li>Restart the PostgreSQL server for the changes to take effect</li> </ul> <p>For example: <pre><code>shared_preload_libraries = 'synchdb'\nsynchdb.synchdb_auto_launcher = true\n</code></pre></p> <p>At startup, SynchDB extension will be preloaded very early. With <code>synchdb.synchdb_auto_launcher</code> set to true, SynchDB will spawn a <code>synchdb_auto_launcher</code> background worker that will retrieve all the conninfos in <code>synchdb_conninfo</code> table that is marked as <code>active</code> (has <code>isactive</code> flag set to <code>true</code>). Then, it will start them automatically as a separate background worker in the same way as when <code>synchdb_start_engine_bgw()</code> is called. <code>synchdb_auto_launcher</code> will exit after.</p>"},{"location":"user-guide/connector_auto_launcher/#known-issue","title":"Known Issue","text":"<p><code>synchdb_auto_launcher</code> worker will login to the default <code>postgres</code> database and try to find active connectors from <code>synchdb_conninfo</code> table. </p> <p>If SynchDB has been installed from non-default database, then <code>synchdb_auto_launcher</code> will fail to find the table, and thus not automatically starting the connector worker. </p> <p>In the future, we will make <code>synchdb_auto_launcher</code> check for all the databases and automatically start connector workers based on every database's <code>synchdb_conninfo</code> tables.</p> <p>Ref [Issue #71] for detail and updates.</p>"},{"location":"user-guide/create_a_connector/","title":"Create a Connector","text":""},{"location":"user-guide/create_a_connector/#create-a-connector_1","title":"Create a Connector","text":"<p>A connector represents a connection to a particular source database, replicate one set of tables and apply to PostgreSQL. If you have multiple source databases that need replication, multiple connectors are required (one for each). It is also possible to create multiple connectors that connect to the same source database but replicate different sets of tables.</p> <p>Creating a connector can be done with utility SQL function <code>synchdb_add_conninfo()</code>.</p> <p>synchdb_add_conninfo takes these arguments:</p> argumet description name a unique identifier that represents this connector info hostname the IP address or hostname of the heterogeneous database. port the port number to connect to the heterogeneous database. username user name to use to authenticate with heterogeneous database. password password to authenticate the username source database this is the name of source database in heterogeneous database that we want to replicate changes from. destination database (deprecated) always defaults to the same database as where synchDB is installed table (optional) - expressed in the form of <code>[database].[table]</code> or <code>[database].[schema].[table]</code> that must exists in heterogeneous database so the engine will only replicate the specified tables. If left empty, all tables are replicated. Alternatively, a table list file can be specified with <code>file:</code> prefix snapshot table (optional) - expressed in the form of <code>[database].[table]</code> or <code>[database].[schema].[table]</code> that must exists in the <code>table</code> setting above, so the engine will only rebuild the snapshot of these tables if snapshot mode is set to <code>always</code>. If left empty or null, all tables specified in <code>table</code> setting above will be rebuilt when snapshot mode is set to <code>always</code>. Alternatively, a snapshot table list file can be specified with <code>file:</code> prefix connector the connector type (See below) <p>&lt;&lt;Note&gt;&gt; If connector type is <code>olr</code>, SynchDB will still use Debezium to perform an initial snapshot with tables and snapshot tables as specified in <code>table</code> and <code>snapshot table</code> parameters. After this is done, SynchDB will connect to Openlog Replicator for replication without filtering desired tables specified in <code>table</code> parameter. The table filtering is instead done on the Openlog Replicator's configuration. So, please ensure that both Openlog Replicator and SynchDB connector's <code>table</code> filtering parameters are configured consistently to avoid potential descrepancies</p>"},{"location":"user-guide/create_a_connector/#connector-types","title":"Connector Types","text":"<p>SynchDb supports these connector types:</p> <ul> <li>mysql         -&gt; MySQL database</li> <li>sqlserver     -&gt; Microsoft SQL Server database</li> <li>oracle        -&gt; Oracle database</li> <li>olr           -&gt; Native Openlog Replicator (BETA)</li> </ul>"},{"location":"user-guide/create_a_connector/#check-created-connectors","title":"Check Created Connectors","text":"<p>Created connectors are shown in the table <code>synchdb_conninfo</code>. We are free to view its content and make modification as required. Please note that the password of a user credential is encrypted by pgcrypto using a key only known to synchdb. So please do not modify the password field directly as it will be decrypted incorrectly if tempered. See below for an example output:</p> <pre><code>postgres=# \\x\nExpanded display is on.\n\npostgres=# select * from synchdb_conninfo;\n-[ RECORD 1 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nname     | sqlserverconn\nisactive | t\ndata     | {\"pwd\": \"\\\\xc30d0407030245ca4a983b6304c079d23a0191c6dabc1683e4f66fc538db65b9ab2788257762438961f8201e6bcefafa60460fbf441e55d844e7f27b31745f04e7251c0123a159540676c4\", \"port\": 1433, \"user\": \"sa\", \"dstdb\": \"postgres\", \"srcdb\": \"testDB\", \"table\": \"null\", \"hostname\": \"192.168.1.86\", \"connector\": \"sqlserver\"}\n-[ RECORD 2 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nname     | mysqlconn\nisactive | t\ndata     | {\"pwd\": \"\\\\xc30d04070302986aff858065e96b62d23901b418a1f0bfdf874ea9143ec096cd648a1588090ee840de58fb6ba5a04c6430d8fe7f7d466b70a930597d48b8d31e736e77032cb34c86354e\", \"port\": 3306, \"user\": \"mysqluser\", \"dstdb\": \"postgres\", \"srcdb\": \"inventory\", \"table\": \"null\", \"hostname\": \"192.168.1.86\", \"connector\": \"mysql\"}\n-[ RECORD 3 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nname     | oracleconn\nisactive | t\ndata     | {\"pwd\": \"\\\\xc30d04070302e3baf1293d0d553066d234014f6fc52e6eea425884b1f65f1955bf504b85062dfe538ca2e22bfd6db9916662406fc45a3a530b7bf43ce4cfaa2b049a1c9af8\", \"port\": 1528, \"user\": \"c##dbzuser\", \"dstdb\": \"postgres\", \"srcdb\": \"FREE\", \"table\": \"null\", \"hostname\": \"192.168.1.86\", \"connector\": \"oracle\"}\n</code></pre> <p>&lt;&lt;&lt;IMPORTANT&gt;&gt;&gt; Native Openlog Replicator connector currently does not support specifying whitelist tables via <code>table</code> and <code>snapshot tables</code> parameters so the sections below do not apply to Native Openlog Replicator connector.</p>"},{"location":"user-guide/create_a_connector/#use-a-table-list-file-to-specify-tables","title":"Use a Table List File to Specify Tables","text":"<p>If there is a large number of tables to replicate, it is possible to use a table list file to specifiy the tables. The list must be formatted as JSON like below:</p> <p><pre><code>{\n    \"table_list\":\n    [\n        \"mydb.myschema.mytable1\",\n        \"mydb.myschema.mytable2\",\n        ...\n        ...\n    ],\n    \"snapshot_table_list\":\n    [\n        \"mydb.myschema.mytable1\",\n        \"mydb.myschema.mytable2\",\n        ...\n        ...\n    ]\n}\n</code></pre> SynchDB looks for these key JSON arrays by names: * <code>table_list</code> is a JSON array, containing the tables to replicate expressed as string. This is required when the <code>table</code> parameter starts with prefix <code>file:</code> followed by path to the file * <code>snapshot_table_list</code> is also a JSON array, containing the tables to perform snapshot on. This is required when <code>snapshot table</code> parameter starts with prefix <code>file:</code> followed by path to the file.</p> <p>the file path can be relative to where PostgreSQL data directory or an absolute path.</p>"},{"location":"user-guide/create_a_connector/#when-to-specify-snapshot-table-list","title":"When to Specify Snapshot Table List?","text":"<p>We can normally leave <code>snapshot table list</code> parameter to either empty or as <code>null</code>, which would default to the same value as the <code>table</code> parameter. This means that SynchDB will perform an initial snapshot (replicate the schema and copy initial data) on all the tables specified in <code>table</code> parameter when needed. In some cases, we may only want a subset of <code>table</code> to perform the initial snapshot, if that is the case, we would set a different <code>snapshot table list</code> to indicate to SynchDB to only rebuild the table snapshot specified.</p>"},{"location":"user-guide/create_a_connector/#example-create-a-connector-for-each-supported-source-database-to-replicate-all-tables","title":"Example: Create a Connector for each Supported Source Database to Replicate All Tables","text":"<ol> <li> <p>Create a MySQL connector called <code>mysqlconn</code> to replicate all tables under <code>inventory</code> in MySQL to destination database <code>postgres</code> in PostgreSQL: <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'postgres', \n    'null', 'null', 'mysql');\n</code></pre></p> </li> <li> <p>Create a SQLServer connector called <code>sqlserverconn</code> to replicate all tables under <code>testDB</code> to destination database 'postgres' in PostgreSQL: <pre><code>SELECT \n  synchdb_add_conninfo(\n    'sqlserverconn', '127.0.0.1', 1433, \n    'sa', 'Password!', 'testDB', 'postgres', \n    'null', 'null', 'sqlserver');\n</code></pre></p> </li> <li> <p>Create a Oracle connector called <code>oracleconn</code> to replicate all tables under <code>FREE</code> to destination database 'postgres' in PostgreSQL: <pre><code>SELECT \n  synchdb_add_conninfo(\n    'oracleconn', '127.0.0.1', 1521, \n    'c##dbzuser', 'dbz', 'FREE', 'postgres', \n    'null', 'null', 'oracle');\n</code></pre></p> </li> </ol>"},{"location":"user-guide/create_a_connector/#example-create-a-connector-to-replicate-specified-tables","title":"Example: Create a Connector to Replicate Specified Tables","text":"<p>Note that the tables must be specified in fully-qualified names such as <code>[database].[table]</code> or <code>[database].[schema].[table]</code> and exist in the source database.</p> <p>Create a MySQL connector called <code>mysqlconn</code> to replicate <code>orders</code> and <code>customers</code> tables under <code>inventory</code> in MySQL to destination database <code>postgres</code> in PostgreSQL: <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'postgres', \n    'inventory.orders,inventory.customers', 'null', 'mysql');\n</code></pre></p>"},{"location":"user-guide/create_a_connector/#example-create-a-connector-to-replicate-specified-tables-using-a-file","title":"Example: Create a Connector to Replicate Specified Tables Using a File","text":"<p>Create a MySQL connector called <code>mysqlconn</code> to replicate the tables specified in the table file under <code>inventory</code> in MySQL to destination database <code>postgres</code> in PostgreSQL: <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'postgres', \n    'file:/path/to/mytablefile.json', 'file:/path/to/mytablefile.json', 'mysql');\n</code></pre></p> <p>where <code>/path/to/mytablefile.json</code> could be:</p> <pre><code>{\n    \"table_list\":\n    [\n        \"inventory.orders\",\n        \"inventory.customers\"\n    ],\n    \"snapshot_table_list\":\n    [\n        \"inventory.orders\",\n        \"inventory.customers\"\n    ]\n}\n</code></pre>"},{"location":"user-guide/customize_transform/","title":"Customize Transformation Rules","text":""},{"location":"user-guide/default_datatype_mapping/","title":"Default Data Type Mapping","text":"<p>The default data type mapping is a hash table built internally inside SynchDB with:</p> <ul> <li>key: {data type, auto_increment} </li> <li>value: {data type, size}</li> </ul> <p>where:</p> <ul> <li>data type: the string representation of a data type such as int, text, numeric</li> <li>auto_increment: a flag indicating if the data type has auto_increment attribute.</li> <li>size: the translated size value. -1: no change, 0: no size specified</li> </ul> <p>The default data type mapping entries can be overwritten by defining a object mapping rules. See object mapping rules for more information.</p>"},{"location":"user-guide/default_datatype_mapping/#mysql-default-data-type-mapping","title":"MySQL Default Data Type Mapping","text":"<pre><code>DatatypeHashEntry mysql_defaultTypeMappings[] =\n{\n    {{\"int\", true}, \"serial\", 0},\n    {{\"bigint\", true}, \"bigserial\", 0},\n    {{\"smallint\", true}, \"smallserial\", 0},\n    {{\"mediumint\", true}, \"serial\", 0},\n    {{\"enum\", false}, \"text\", 0},\n    {{\"set\", false}, \"text\", 0},\n    {{\"bigint\", false}, \"bigint\", 0},\n    {{\"bigint unsigned\", false}, \"numeric\", -1},\n    {{\"numeric unsigned\", false}, \"numeric\", -1},\n    {{\"dec\", false}, \"decimal\", -1},\n    {{\"dec unsigned\", false}, \"decimal\", -1},\n    {{\"decimal unsigned\", false}, \"decimal\", -1},\n    {{\"fixed\", false}, \"decimal\", -1},\n    {{\"fixed unsigned\", false}, \"decimal\", -1},\n    {{\"bit(1)\", false}, \"boolean\", 0},\n    {{\"bit\", false}, \"bit\", -1},\n    {{\"bool\", false}, \"boolean\", -1},\n    {{\"double\", false}, \"double precision\", 0},\n    {{\"double precision\", false}, \"double precision\", 0},\n    {{\"double precision unsigned\", false}, \"double precision\", 0},\n    {{\"double unsigned\", false}, \"double precision\", 0},\n    {{\"real\", false}, \"real\", 0},\n    {{\"real unsigned\", false}, \"real\", 0},\n    {{\"float\", false}, \"real\", 0},\n    {{\"float unsigned\", false}, \"real\", 0},\n    {{\"int\", false}, \"int\", 0},\n    {{\"int unsigned\", false}, \"bigint\", 0},\n    {{\"integer\", false}, \"int\", 0},\n    {{\"integer unsigned\", false}, \"bigint\", 0},\n    {{\"mediumint\", false}, \"int\", 0},\n    {{\"mediumint unsigned\", false}, \"int\", 0},\n    {{\"year\", false}, \"int\", 0},\n    {{\"smallint\", false}, \"smallint\", 0},\n    {{\"smallint unsigned\", false}, \"int\", 0},\n    {{\"tinyint\", false}, \"smallint\", 0},\n    {{\"tinyint unsigned\", false}, \"smallint\", 0},\n    {{\"datetime\", false}, \"timestamp\", -1},\n    {{\"timestamp\", false}, \"timestamptz\", -1},\n    {{\"binary\", false}, \"bytea\", 0},\n    {{\"varbinary\", false}, \"bytea\", 0},\n    {{\"blob\", false}, \"bytea\", 0},\n    {{\"mediumblob\", false}, \"bytea\", 0},\n    {{\"longblob\", false}, \"bytea\", 0},\n    {{\"tinyblob\", false}, \"bytea\", 0},\n    {{\"long varchar\", false}, \"text\", -1},\n    {{\"longtext\", false}, \"text\", -1},\n    {{\"mediumtext\", false}, \"text\", -1},\n    {{\"tinytext\", false}, \"text\", -1},\n    {{\"json\", false}, \"jsonb\", -1},\n    {{\"geometry\", false}, \"text\", -1},\n    {{\"geometrycollection\", false}, \"text\", -1},\n    {{\"geomcollection\", false}, \"text\", -1},\n    {{\"linestring\", false}, \"text\", -1},\n    {{\"multilinestring\", false}, \"text\", -1},\n    {{\"multipoint\", false}, \"text\", -1},\n    {{\"multipolygon\", false}, \"text\", -1},\n    {{\"point\", false}, \"text\", -1},\n    {{\"polygon\", false}, \"text\", -1}\n};\n</code></pre>"},{"location":"user-guide/default_datatype_mapping/#sql-server-default-data-type-mapping","title":"SQL Server Default Data Type Mapping","text":"<pre><code>DatatypeHashEntry sqlserver_defaultTypeMappings[] =\n{\n    {{\"int identity\", true}, \"serial\", 0},\n    {{\"bigint identity\", true}, \"bigserial\", 0},\n    {{\"smallint identity\", true}, \"smallserial\", 0},\n    {{\"enum\", false}, \"text\", 0},\n    {{\"int\", false}, \"int\", 0},\n    {{\"bigint\", false}, \"bigint\", 0},\n    {{\"smallint\", false}, \"smallint\", 0},\n    {{\"tinyint\", false}, \"smallint\", 0},\n    {{\"numeric\", false}, \"numeric\", -1},\n    {{\"decimal\", false}, \"numeric\", -1},\n    {{\"bit(1)\", false}, \"bool\", 0},\n    {{\"bit\", false}, \"bit\", 0},\n    {{\"money\", false}, \"money\", 0},\n    {{\"smallmoney\", false}, \"money\", 0},\n    {{\"real\", false}, \"real\", 0},\n    {{\"float\", false}, \"real\", 0},\n    {{\"date\", false}, \"date\", 0},\n    {{\"time\", false}, \"time\", 0},\n    {{\"datetime\", false}, \"timestamp\", 0},\n    {{\"datetime2\", false}, \"timestamp\", 0},\n    {{\"datetimeoffset\", false}, \"timestamptz\", 0},\n    {{\"smalldatetime\", false}, \"timestamp\", 0},\n    {{\"char\", false}, \"char\", -1},\n    {{\"varchar\", false}, \"varchar\", -1},\n    {{\"text\", false}, \"text\", 0},\n    {{\"nchar\", false}, \"char\", 0},\n    {{\"nvarchar\", false}, \"varchar\", -1},\n    {{\"ntext\", false}, \"text\", 0},\n    {{\"binary\", false}, \"bytea\", 0},\n    {{\"varbinary\", false}, \"bytea\", 0},\n    {{\"image\", false}, \"bytea\", 0},\n    {{\"uniqueidentifier\", false}, \"uuid\", 0},\n    {{\"xml\", false}, \"xml\", 0},\n    {{\"json\", false}, \"jsonb\", -1},\n    {{\"hierarchyid\", false}, \"text\", 0},\n    {{\"vector\", false}, \"text\", 0},\n    {{\"geometry\", false}, \"text\", 0},\n    {{\"geography\", false}, \"text\", 0},\n};\n</code></pre>"},{"location":"user-guide/default_datatype_mapping/#oracle-default-data-type-mapping","title":"Oracle Default Data Type Mapping","text":"<pre><code>DatatypeHashEntry oracle_defaultTypeMappings[] =\n{\n    {{\"binary_double\", false}, \"double precision\", 0},\n    {{\"binary_float\", false}, \"real\", 0},\n    {{\"float\", false}, \"real\", 0},\n    {{\"number(0,0)\", false}, \"numeric\", -1},\n    {{\"number(1,0)\", false}, \"smallint\", 0},\n    {{\"number(2,0)\", false}, \"smallint\", 0},\n    {{\"number(3,0)\", false}, \"smallint\", 0},\n    {{\"number(4,0)\", false}, \"smallint\", 0},\n    {{\"number(5,0)\", false}, \"int\", 0},\n    {{\"number(6,0)\", false}, \"int\", 0},\n    {{\"number(7,0)\", false}, \"int\", 0},\n    {{\"number(8,0)\", false}, \"int\", 0},\n    {{\"number(9,0)\", false}, \"int\", 0},\n    {{\"number(10,0)\", false}, \"bigint\", 0},\n    {{\"number(11,0)\", false}, \"bigint\", 0},\n    {{\"number(12,0)\", false}, \"bigint\", 0},\n    {{\"number(13,0)\", false}, \"bigint\", 0},\n    {{\"number(14,0)\", false}, \"bigint\", 0},\n    {{\"number(15,0)\", false}, \"bigint\", 0},\n    {{\"number(16,0)\", false}, \"bigint\", 0},\n    {{\"number(17,0)\", false}, \"bigint\", 0},\n    {{\"number(18,0)\", false}, \"bigint\", 0},\n    {{\"number(19,0)\", false}, \"numeric\", -1},\n    {{\"number(20,0)\", false}, \"numeric\", -1},\n    {{\"number(21,0)\", false}, \"numeric\", -1},\n    {{\"number(22,0)\", false}, \"numeric\", -1},\n    {{\"number(23,0)\", false}, \"numeric\", -1},\n    {{\"number(24,0)\", false}, \"numeric\", -1},\n    {{\"number(25,0)\", false}, \"numeric\", -1},\n    {{\"number(26,0)\", false}, \"numeric\", -1},\n    {{\"number(27,0)\", false}, \"numeric\", -1},\n    {{\"number(28,0)\", false}, \"numeric\", -1},\n    {{\"number(29,0)\", false}, \"numeric\", -1},\n    {{\"number(30,0)\", false}, \"numeric\", -1},\n    {{\"number(31,0)\", false}, \"numeric\", -1},\n    {{\"number(32,0)\", false}, \"numeric\", -1},\n    {{\"number(33,0)\", false}, \"numeric\", -1},\n    {{\"number(34,0)\", false}, \"numeric\", -1},\n    {{\"number(35,0)\", false}, \"numeric\", -1},\n    {{\"number(36,0)\", false}, \"numeric\", -1},\n    {{\"number(37,0)\", false}, \"numeric\", -1},\n    {{\"number(38,0)\", false}, \"numeric\", -1},\n    {{\"number\", false}, \"numeric\", -1},\n    {{\"numeric\", false}, \"numeric\", -1},\n    {{\"date\", false}, \"timestamp\", -1},\n    {{\"long\", false}, \"text\", -1},\n    {{\"interval day to second\", false}, \"interval day to second\", -1},\n    {{\"interval year to month\", false}, \"interval year to month\", 0},\n    {{\"timestamp\", false}, \"timestamp\", -1},\n    {{\"timestamp with local time zone\", false}, \"timestamptz\", -1},\n    {{\"timestamp with time zone\", false}, \"timestamptz\", -1},\n    {{\"date\", false}, \"date\", -1},\n    {{\"char\", false}, \"char\", -1},\n    {{\"nchar\", false}, \"char\", -1},\n    {{\"nvarchar2\", false}, \"varchar\", -1},\n    {{\"varchar\", false}, \"varchar\", -1},\n    {{\"varchar2\", false}, \"varchar\", -1},\n    {{\"long raw\", false}, \"bytea\", 0},\n    {{\"raw\", false}, \"bytea\", 0},\n    {{\"decimal\", false}, \"decimal\", -1},\n    {{\"rowid\", false}, \"text\", 0},\n    {{\"urowid\", false}, \"text\", 0},\n    {{\"xmltype\", false}, \"text\", 0},\n    {{\"bfile\", false}, \"text\", 0},\n    {{\"blob\", false}, \"bytea\", 0},\n    {{\"clob\", false}, \"text\", 0},\n    {{\"nclob\", false}, \"text\", 0},\n    {{\"sdo_geometry\", false}, \"text\", 0},\n    {{\"sdo_topo_geometry\", false}, \"text\", 0},\n    {{\"sdo_georaster\", false}, \"text\", 0},\n    {{\"uritype\", false}, \"text\", 0},\n    {{\"anytype\", false}, \"text\", 0},\n    {{\"anydata\", false}, \"text\", 0},\n    {{\"anydataset\", false}, \"text\", 0},\n};\n</code></pre>"},{"location":"user-guide/object_mapping_rules/","title":"Configure Object Mapping and Transform Rules","text":"<p>SynchDB has a default name and data type mapping rules to handle incoming change events. In most cases, the defaults work fine. However, if you have specific transform requirements or when the defaults do not work for you, you can configure your own object mapping rules to a particular connector. </p>"},{"location":"user-guide/object_mapping_rules/#synchdb_add_objmap","title":"synchdb_add_objmap","text":"<p>This utility function can be used to configure table name, column name, data types as well as transform rules. it takes 4 parameters:</p> Parameter Description Required Example Notes <code>name</code> Unique identifier for this connector \u2713 <code>'mysqlconn'</code> Must be unique across all connectors <code>object type</code> type of object mapping \u2713 <code>'table'</code> can be <code>table</code> to map a table name, <code>column</code> to map a column name, <code>datatype</code> to map a data type, or <code>transform</code> to run a data transform expression <code>source object</code> source object represented as fully-qualified name \u2713 <code>inventory.customers</code> the object name as represented in the remote database <code>destination object</code> destination object name \u2713 <code>'schema1.people'</code> The destination object name in PostgreSQL side. Can be a fully-qualified table name, a column name, a data type or transform expression"},{"location":"user-guide/object_mapping_rules/#configure-table-name-mappings","title":"Configure Table Name Mappings","text":"<ul> <li><code>source object</code> represents the table in fully-qualified name in remote database</li> <li><code>destination object</code> represents the table name in PostgreSQL. It can be just a name (default to public schema) or in schema.name format. </li> </ul> <p>This example maps <code>inventory.customers</code> table in the source database to <code>schema1.people</code> in PostgreSQL. <pre><code>SELECT synchdb_add_objmap('mysqlconn','table','inventory.customers','schema1.people');\n</code></pre></p>"},{"location":"user-guide/object_mapping_rules/#configure-column-name-mappings","title":"Configure Column Name Mappings","text":"<ul> <li><code>source object</code> represents the column in fully-qualified name in remote database</li> <li><code>destination object</code> represents the column name in PostgreSQL. No need to format it as fully-qualified column name.</li> </ul> <p>This example maps <code>inventory.customers.emaiL</code> column in the source table to <code>contact</code> in PostgreSQL. <pre><code>SELECT synchdb_add_objmap('mysqlconn','column','inventory.customers.email','contact');\n</code></pre></p>"},{"location":"user-guide/object_mapping_rules/#configure-data-type-mappings","title":"Configure Data Type Mappings","text":"<ul> <li> <p><code>source object</code> can be expressed as one of:</p> <ul> <li>a fully-qualified column (inventory.geom.g). This means the data type mapping applies to this particular column only.</li> <li>a general data type string (int). Use a pipe (|) to add if it is a autoincrement data type (int|true for autoincremented int) or (int|false for a non-autoincremented int). This means data type mapping applies to all data type with the matching condition.</li> </ul> </li> <li> <p><code>destination object</code> should be expressed as a general data type string that exists in PostgreSQL. Use a pipe (|) to overwrite the size (text|0 to overwrite the size to 0 because text is variable size) or (varchar|-1 to use whatever size that comes with the change event)</p> </li> </ul> <p>This example maps all non-autoincrement <code>point</code> data type to <code>text</code> data type in PostgreSQL. <pre><code>SELECT synchdb_add_objmap('mysqlconn','datatype','point|false','text|0');\n</code></pre></p> <p>This example maps the table <code>inventory.geom</code>'s column <code>g</code>'s data type to <code>geometry</code> in PostgreSQL. <pre><code>SELECT synchdb_add_objmap('mysqlconn','datatype','inventory.geom.g','geometry|0');\n</code></pre></p>"},{"location":"user-guide/object_mapping_rules/#configure-transform-rules","title":"Configure Transform Rules","text":"<ul> <li><code>source object</code> represents the column to be transformed</li> <li><code>destination object</code> represents an expression to be run on the column data before it is applied to PostgreSQL. Use %d as a placeholder for input column data. In case of geometry type, use %w for WKB and %s for SRID. </li> </ul> <p>This example will prepend '&gt;&gt;&gt;&gt;&gt;' and append '&lt;&lt;&lt;&lt;&lt;' to whatever value SynchDB receives for column 'inventory.products.name' <pre><code>SELECT synchdb_add_objmap('mysqlconn','transform','inventory.products.name','''&gt;&gt;&gt;&gt;&gt;'' || ''%d'' || ''&lt;&lt;&lt;&lt;&lt;''');\n</code></pre></p> <p>This example will always add 500 to whatever value SynchDB receives for column 'inventory.orders.quantity': <pre><code>SELECT synchdb_add_objmap('mysqlconn','transform','inventory.orders.quantity','%d + 500');\n</code></pre></p>"},{"location":"user-guide/object_mapping_rules/#apply-the-rules","title":"Apply the Rules","text":"<p>If the connector is not running, the rules are automatically applied at the next startup via <code>synchdb_start_engine_bgw</code>.</p> <p>If the connector is already running, the rules are not automatically applied, we have to tell the connector to reload the object mapping rules and apply using utility function <code>synchdb_reload_objmap</code>.</p> <pre><code>SELECT synchdb_reload_objmap('mysqlconn');\n</code></pre>"},{"location":"user-guide/secured_connection/","title":"Secured Connection","text":""},{"location":"user-guide/secured_connection/#configure-secured-connection","title":"Configure Secured Connection","text":"<p>to secure the connection to remote database, we need to configure additional SSL related parameters to a connector that has been created by <code>synchdb_add_conninfo</code>. The SSL certificates and private keys must be packaged as Java keystore file with a passphrase. These information is then passed to SynchDB via synchdb_add_extra_conninfo().</p> <p>&lt;&lt;IMPORTANT&gt;&gt; Secured connection is not available for Openlog Replicator Connector</p>"},{"location":"user-guide/secured_connection/#synchdb_add_extra_conninfo","title":"synchdb_add_extra_conninfo","text":"<p>Purpose: Configures extra connector parameters to an existing connector created by <code>synchdb_add_conninfo</code></p> Parameter Description Required Example Notes <code>name</code> Unique identifier for this connector \u2713 <code>'mysqlconn'</code> Must be unique across all connectors <code>ssl_mode</code> SSL mode \u2610 <code>'verify_ca'</code> can be one of: <ul><li> \"disabled\" - no SSL is used. </li><li> \"preferred\" - SSL is used if server supports it. </li><li> \"required\" - SSL must be used to establish a connection. </li><li> \"verify_ca\" - connector establishes TLS with the server and will also verify server's TLS certificate against configured truststore. </li><li> \"verify_identity\" - same behavior as verify_ca but it also checks the server certificate's common name to match the hostname of the system. <code>ssl_keystore</code> keystore path \u2610 <code>/path/to/keystore</code> path to the keystore file <code>ssl_keystore_pass</code> keystore password \u2610 <code>'mykeystorepass'</code> password to access the keystore file <code>ssl_truststore</code> trust store path \u2610 <code>'/path/to/truststore'</code> path to the truststore file <code>ssl_truststore_pass</code> trust store password \u2610 <code>'mytruststorepass'</code> password to access the truststore file <pre><code>SELECT synchdb_add_extra_conninfo('mysqlconn', 'verify_ca', '/path/to/keystore', 'mykeystorepass', '/path/to/truststore', 'mytruststorepass');\n</code></pre>"},{"location":"user-guide/secured_connection/#synchdb_del_extra_conninfo","title":"synchdb_del_extra_conninfo","text":"<p>Purpose: Deletes extra connector paramters created by <code>synchdb_add_extra_conninfo</code> <pre><code>SELECT synchdb_del_extra_conninfo('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/set_offset/","title":"Custom Start Offset Values","text":"<p>A start offset value represents a point to start replication from in the similar way as PostgreSQL's resume LSN. When Debezium runner engine starts, it will start the replication from this offset value. Setting this offset value to a earlier value will cause Debezium runner engine to start replication from earlier records, possibly replicating duplicate data records. We should be extra cautious when setting start offset values on Debezium.</p>"},{"location":"user-guide/set_offset/#record-settable-offset-values","title":"Record Settable Offset Values","text":"<p>During operation, new offsets will be generated nd flushed to disk by Debezium runner engine. The last flushed offset can be retrieved from <code>synchdb_state_view()</code> utility command:</p> <pre><code>postgres=# select name, last_dbz_offset from synchdb_state_view;\n     name      |                                           last_dbz_offset\n---------------+------------------------------------------------------------------------------------------------------\n sqlserverconn | {\"commit_lsn\":\"0000006a:00006608:0003\",\"snapshot\":true,\"snapshot_completed\":false}\n mysqlconn     | {\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}\n oracleconn    | {\"commit_scn\":\"2311579\",\"snapshot_scn\":\"2311578\",\"scn\":\"2311578\"}\n(3 rows)\n</code></pre> <p>Depending on the connector type, this offset value differs. From the example above, the <code>mysql</code> connector's last flushed offset is <code>{\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}</code> and <code>sqlserver</code>'s last flushed offset is <code>{\"commit_lsn\":\"0000006a:00006608:0003\",\"snapshot\":true,\"snapshot_completed\":false}</code>. </p> <p>We should save this values regularly, so in case we run into a problem, we know the offset location in the past that can be set to resume the replication operation.</p>"},{"location":"user-guide/set_offset/#pause-the-connector","title":"Pause the Connector","text":"<p>A connector must be in a <code>paused</code> state before a new offset value can be set.</p> <p>Use <code>synchdb_pause_engine()</code> SQL function to pause a runnng connector. This will halt the Debezium runner engine from replicating from the heterogeneous database. When paused, it is possible to alter the Debezium connector's offset value to replicate from a specific point in the past using <code>synchdb_set_offset()</code> SQL routine. It takes <code>conninfo_name</code> as its argument which can be found from the output of <code>synchdb_get_state()</code> view.</p> <p>For example: <pre><code>SELECT synchdb_pause_engine('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/set_offset/#set-the-new-offset","title":"Set the new Offset","text":"<p>Use <code>synchdb_set_offset()</code> SQL function to change a connector worker's starting offset. This can only be done when the connector is put into <code>paused</code> state. The function takes 2 parameters, <code>conninfo_name</code> and <code>a valid offset string</code>, both of which can be found from the output of <code>synchdb_get_state()</code> view.</p> <p>For example: <pre><code>SELECT \n  synchdb_set_offset(\n    'mysqlconn', '{\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}'\n  );\n</code></pre></p>"},{"location":"user-guide/set_offset/#resume-the-connector","title":"Resume the Connector","text":"<p>Use <code>synchdb_resume_engine()</code> SQL function to resume Debezium operation from a paused state. This function takes <code>connector name</code> as its only parameter, which can be found from the output of <code>synchdb_get_state()</code> view. The resumed Debezium runner engine will start the replication from the newly set offset value.</p> <p>For example: <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/start_stop_connector/","title":"Start / Stop a Connector","text":""},{"location":"user-guide/start_stop_connector/#control-a-connector","title":"Control a Connector","text":"<p>SynchDB provides several utility function to control the behavior and life cycle or a created connector.</p>"},{"location":"user-guide/start_stop_connector/#start-a-connector-with-default-snapshot-mode","title":"Start a Connector with Default Snapshot Mode","text":"<p>synchdb_start_engine_bgw() can be used to start a connector with default snapshot mode called <code>initial</code>.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre>"},{"location":"user-guide/start_stop_connector/#start-a-connector-with-custom-snapshot-mode","title":"Start a Connector with Custom Snapshot Mode","text":"<p>Using the same function synchdb_start_engine_bgw(), it is possible to include snapshot mode to start the connector with, otherwise the <code>initial</code> mode will be used by default.</p> <pre><code>-- capture table schema and proceed to stream new changes\nSELECT synchdb_start_engine_bgw('mysqlconn', 'no_data');\n\n-- always re-build the table schema, existing data and proceed to stream new changes\nSELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre>"},{"location":"user-guide/start_stop_connector/#supported-snapshot-modes","title":"Supported Snapshot Modes","text":"Mode Description Use Case <code>always</code> Full snapshot on every start Complete data verification <code>initial</code> First-time snapshot only Normal operations <code>initial_only</code> One-time snapshot, then stop Data migration <code>no_data</code> Structure only, no data Schema synchronization <code>never</code> Skip snapshot, stream only Real-time updates <code>recovery</code> Rebuilds from source Disaster recovery <code>when_needed</code> Conditional snapshot Automatic recovery <code>schemasync</code> Structure only, no data, no CDC normal operations <p>Refer to the tutorial on when to use what mode</p>"},{"location":"user-guide/start_stop_connector/#pause-and-resume-a-connector","title":"Pause and Resume a Connector","text":"<p>Pause a connector with <code>synchdb_pause_engine</code>, which temporarily halts a running connector <pre><code>SELECT synchdb_pause_engine('mysqlconn');\n</code></pre></p> <p>Resume a paused connector with <code>synchdb_resume_engine</code>. <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/start_stop_connector/#stop-or-restart-a-running-connector","title":"Stop or Restart a Running Connector","text":"<p>Stops a running connector with <code>synchdb_stop_engine_bgw</code> <pre><code>SELECT synchdb_stop_engine_bgw('mysqlconn');\n</code></pre></p> <p>Restarts a running connector with <code>synchdb_restart_connector</code> with a different snapshot mode. <pre><code>-- Restart with specific snapshot mode\nSELECT synchdb_restart_connector('mysqlconn', 'initial');\n\n-- Start with specific snapshot mode\nSELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre></p>"},{"location":"user-guide/utility_functions/","title":"Function Reference","text":"<p>This page documents all the SQL functions / views added by SynchDB.</p>"},{"location":"user-guide/utility_functions/#connector-management","title":"Connector Management","text":""},{"location":"user-guide/utility_functions/#synchdb_add_conninfo","title":"synchdb_add_conninfo","text":"<p>Purpose: Creates a new connector configuration</p> <p>Parameters:</p> Parameter Description Required Example Notes <code>name</code> Unique identifier for this connector \u2713 <code>'mysqlconn'</code> Must be unique across all connectors <code>hostname</code> IP/hostname of heterogeneous database \u2713 <code>'127.0.0.1'</code> Support IPv4, IPv6, and hostnames <code>port</code> Port number for database connection \u2713 <code>3306</code> Default: MySQL(3306), SQLServer(1433) <code>username</code> Authentication username \u2713 <code>'mysqluser'</code> Requires appropriate permissions <code>password</code> Authentication password \u2713 <code>'mysqlpwd'</code> Stored securely <code>source database</code> Source database name \u2713 <code>'inventory'</code> Must exist in source system <code>destination database</code> Target PostgreSQL database \u2713 <code>'postgres'</code> (deprecated) will always be adjusted to the same database where SynchDB is installed <code>table</code> Table specification pattern \u2610 <code>'[db].[table]'</code> Empty = replicate all tables, support regular expressions (for example, mydb.testtable*), use <code>file:</code> prefix to make connector read table list from a JSON file (for example, file:/path/to/filelist.json). See below for file format <code>connector</code> Connector type (<code>mysql</code>/<code>sqlserver</code>) \u2713 <code>'mysql'</code> See supported connectors above <p>Tablelist File Example: <pre><code>{\n    \"table_list\":\n    [\n        \"mydb.table1\",\n        \"mydb.table2\",\n        \"mydb.table3\",\n        \"mydb.table4\"\n    ]\n}\n</code></pre></p> <p>Example Usage: <pre><code>-- MySQL Example\nSELECT synchdb_add_conninfo(\n    'mysqlconn',    -- Connector name\n    '127.0.0.1',    -- Host\n    3306,           -- Port\n    'mysqluser',    -- Username\n    'mysqlpwd',     -- Password\n    'inventory',    -- Source DB\n    'postgres',     -- Target DB\n    '',             -- Tables (empty for all)\n    'mysql'         -- Connector type\n);\n\n-- SQL Server Example\nSELECT synchdb_add_conninfo(\n    'sqlserverconn',\n    '127.0.0.1',\n    1433,\n    'sa',\n    'MyPassword123',\n    'testDB',\n    'postgres',\n    'dbo.orders',   -- Specific table\n    'sqlserver'\n);\n\n-- Oracle Example\nSELECT synchdb_add_conninfo(\n    'oracleconn',\n    '127.0.0.1',\n    1521,\n    'c##dbzuser',\n    'dbz',\n    'mydb',\n    'postgres',\n    '',   -- all tables\n    'oracle'\n);\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_add_objmap","title":"synchdb_add_objmap","text":"<p>Purpose: Adds an object mapping rule per connector</p> Parameter Description Required Example Notes <code>name</code> Unique identifier for this connector \u2713 <code>'mysqlconn'</code> Must be unique across all connectors <code>object type</code> type of object mapping \u2713 <code>'table'</code> can be <code>table</code> to map a table name, <code>column</code> to map a column name, <code>datatype</code> to map a data type, or <code>transform</code> to run a data transform expression <code>source object</code> source object represented as fully-qualified name \u2713 <code>inventory.customers</code> the object name as represented in the remote database <code>destination object</code> destination object name \u2713 <code>'schema1.people'</code> The destination object name in PostgreSQL side. Can be a fully-qualified table name, a column name, a data type or transform expression <p><pre><code>SELECT synchdb_add_objmap('mysqlconn','table','inventory.customers','schema1.people');\nSELECT synchdb_add_objmap('mysqlconn','column','inventory.customers.email','contact');\nSELECT synchdb_add_objmap('mysqlconn','datatype','point|false','text|0');\nSELECT synchdb_add_objmap('mysqlconn','datatype','inventory.geom.g','geometry|0');\nSELECT synchdb_add_objmap('mysqlconn','transform','inventory.products.name','''&gt;&gt;&gt;&gt;&gt;'' || ''%d'' || ''&lt;&lt;&lt;&lt;&lt;''');\n</code></pre> Ways to represent a <code>table</code> mapping: * <code>source object</code> represents the table in fully-qualified name in remote database * <code>destination object</code> represents the table name in PostgreSQL. It can be just a name (default to public schema) or in schema.name format. </p> <p>Ways to represent a <code>column</code> mapping: * <code>source object</code> represents the column in fully-qualified name in remote database * <code>destination object</code> represents the column name in PostgreSQL. No need to format it as fully-qualified column name.</p> <p>Ways to represent a <code>datatype</code> mapping: * <code>source object</code> can be expressed as one of:     * a fully-qualified column (inventory.geom.g). This means the data type mapping applies to this particular column only.     * a general data type string (int). Use a pipe (|) to add if it is a autoincrement data type (int|true for autoincremented int) or (int|false for a non-autoincremented int). This means data type mapping applies to all data type with the matching condition.</p> <ul> <li><code>destination object</code> should be expressed as a general data type string that exists in PostgreSQL. Use a pipe (|) to overwrite the size (text|0 to overwrite the size to 0 because text is variable size) or (varchar|-1 to use whatever size that comes with the change event)</li> </ul> <p>Ways to represent a <code>transform</code> mapping: * <code>source object</code> represents the column to be transformed * <code>destination object</code> represents an expression to be run on the column data before it is applied to PostgreSQL. Use %d as a placeholder for input column data. In case of geometry type, use %w for WKB and %s for SRID. </p>"},{"location":"user-guide/utility_functions/#synchdb_add_extra_conninfo","title":"synchdb_add_extra_conninfo","text":"<p>Purpose: Configures extra connector parameters to an existing connector created by <code>synchdb_add_conninfo</code></p> Parameter Description Required Example Notes <code>name</code> Unique identifier for this connector \u2713 <code>'mysqlconn'</code> Must be unique across all connectors <code>ssl_mode</code> SSL mode \u2610 <code>'verify_ca'</code> can be one of: <ul><li> \"disabled\" - no SSL is used. </li><li> \"preferred\" - SSL is used if server supports it. </li><li> \"required\" - SSL must be used to establish a connection. </li><li> \"verify_ca\" - connector establishes TLS with the server and will also verify server's TLS certificate against configured truststore. </li><li> \"verify_identity\" - same behavior as verify_ca but it also checks the server certificate's common name to match the hostname of the system. <code>ssl_keystore</code> keystore path \u2610 <code>/path/to/keystore</code> path to the keystore file <code>ssl_keystore_pass</code> keystore password \u2610 <code>'mykeystorepass'</code> password to access the keystore file <code>ssl_truststore</code> trust store path \u2610 <code>'/path/to/truststore'</code> path to the truststore file <code>ssl_truststore_pass</code> trust store password \u2610 <code>'mytruststorepass'</code> password to access the truststore file <pre><code>SELECT synchdb_add_extra_conninfo('mysqlconn', 'verify_ca', '/path/to/keystore', 'mykeystorepass', '/path/to/truststore', 'mytruststorepass');\n</code></pre>"},{"location":"user-guide/utility_functions/#synchdb_del_extra_conninfo","title":"synchdb_del_extra_conninfo","text":"<p>Purpose: Deletes extra connector paramters created by <code>synchdb_add_extra_conninfo</code> <pre><code>SELECT synchdb_del_extra_conninfo('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_del_conninfo","title":"synchdb_del_conninfo","text":"<p>Purpose: Deletes connector information created by <code>synchdb_add_conninfo</code> <pre><code>SELECT synchdb_del_extra_conninfo('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_del_objmap","title":"synchdb_del_objmap","text":"<p>Purpose: Disables object mapping records created by <code>synchdb_add_objmap</code></p> Parameter Description Required Example Notes <code>name</code> Unique identifier for this connector \u2713 <code>'mysqlconn'</code> Must be unique across all connectors <code>object type</code> type of object mapping \u2713 <code>'table'</code> can be <code>table</code> to map a table name, <code>column</code> to map a column name, <code>datatype</code> to map a data type, or <code>transform</code> to run a data transform expression <code>source object</code> source object represented as fully-qualified name \u2713 <code>inventory.customers</code> the object name as represented in the remote database <pre><code>SELECT synchdb_del_extra_conninfo('mysqlconn', 'transform', 'inventory.products.name');\n</code></pre>"},{"location":"user-guide/utility_functions/#basic-control-functions","title":"Basic Control Functions","text":""},{"location":"user-guide/utility_functions/#synchdb_start_engine_bgw","title":"synchdb_start_engine_bgw","text":"<p>Purpose: Starts a connector <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre> You may also include snapshot mode to start the connector with, otherwise the <code>initial</code> mode will be used by default. See below for list of different snapshot modes. <pre><code>-- capture table schema and proceed to stream new changes\nSELECT synchdb_start_engine_bgw('mysqlconn', 'no_data');\n\n-- always re-capture table schema, existing data and proceed to stream new changes\nSELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_pause_engine","title":"synchdb_pause_engine","text":"<p>Purpose: Temporarily halts a running connector <pre><code>SELECT synchdb_pause_engine_bgw('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_resume_engine","title":"synchdb_resume_engine","text":"<p>Purpose: Resumes a paused connector <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_stop_engine_bgw","title":"synchdb_stop_engine_bgw","text":"<p>Purpose: Terminates a connector <pre><code>SELECT synchdb_stop_engine('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_reload_objmap","title":"synchdb_reload_objmap","text":"<p>Purpose: Causes a connector to load object mapping rules again <pre><code>SELECT synchdb_reload_objmap('mysqlconn');\n</code></pre></p>"},{"location":"user-guide/utility_functions/#state-management","title":"State Management","text":""},{"location":"user-guide/utility_functions/#synchdb_state_view","title":"synchdb_state_view","text":"<p>Purpose: Monitors connector states and status</p> <pre><code>SELECT * FROM synchdb_state_view();\n</code></pre> <p>Return Fields:</p> Field Description Type <code>name</code> Associated connector name Text <code>connector_type</code> Connector type (<code>mysql</code> or <code>sqlserver</code>) Text <code>pid</code> Worker process ID Integer <code>stage</code> Current connector stage Text <code>state</code> Current connector state Text <code>err</code> Latest error message Text <code>last_dbz_offset</code> Last recorded Debezium offset JSON <p>Possible States:</p> <ul> <li>\ud83d\udd34 <code>stopped</code> - Inactive</li> <li>\ud83d\udfe1 <code>initializing</code> - Starting up</li> <li>\ud83d\udfe0 <code>paused</code> - Temporarily halted</li> <li>\ud83d\udfe2 <code>syncing</code> - Actively polling</li> <li>\ud83d\udd35 <code>parsing</code> - Processing events</li> <li>\ud83d\udfe3 <code>converting</code> - Transforming data</li> <li>\u26aa <code>executing</code> - Applying changes</li> <li>\ud83d\udfe4 <code>updating offset</code> - Updating checkpoint</li> <li>\ud83d\udfe8 <code>restarting</code> - Reinitializing</li> <li>\u26aa <code>dumping memory</code> - JVM is prepaaring to dump memory info in log file</li> <li>\u26ab <code>unknown</code> - Indeterminate state</li> </ul> <p>Possible Stages:</p> <ul> <li><code>initial snapshot</code> - connector is performing initial snapshot (building table schema and optionally the initial data)</li> <li><code>change data capture</code> - connector is streaming subsequent table changes (CDC)</li> <li><code>schema sync</code> - connector is copying table schema only</li> </ul>"},{"location":"user-guide/utility_functions/#synchdb_stats_view","title":"synchdb_stats_view","text":"<p>Purpose: Collects connector processing statistics cumulatiely</p> <pre><code>SELECT * FROM synchdb_stats_view();\n</code></pre> Field Description Type name Associated connector name Text ddls Number of DDLs operations completed Bigint dmls Number of DMLs operations completed Bigint reads Number of READ events completed during initial snapshot stage Bigint creates Number of CREATES events completed during CDC stage Bigint updates Number of UPDATES events completed during CDC stage Bigint deletes Number of DELETES events completed during CDC stage Bigint bad_events Number of bad events ignored (such as empty events, unsupported DDL events..etc) Bigint total_events Total number of events processed (including bad_events) Bigint batches_done Number of batches completed Bigint avg_batch_size Average batch size (total_events / batches_done) Bigint"},{"location":"user-guide/utility_functions/#synchdb_reset_stats","title":"synchdb_reset_stats","text":"<p>Purpose: Resets all statistic information of given connector name</p> <pre><code>SELECT synchdb_reset_stats('mysqlconn');\n</code></pre>"},{"location":"user-guide/utility_functions/#synchdb_set_offset","title":"synchdb_set_offset","text":"<p>Purpose: Configures custom start position</p> <p>Example for MySQL: <pre><code>SELECT synchdb_set_offset(\n    'mysqlconn', \n    '{\"ts_sec\":1725644339,\"file\":\"mysql-bin.000004\",\"pos\":138466,\"row\":1,\"server_id\":223344,\"event\":2}'\n);\n</code></pre></p> <p>Example for SQL Server: <pre><code>SELECT synchdb_set_offset(\n    'sqlserverconn',\n    '{\"event_serial_no\":1,\"commit_lsn\":\"00000100:00000c00:0003\",\"change_lsn\":\"00000100:00000c00:0002\"}'\n);\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_log_jvm_meminfo","title":"synchdb_log_jvm_meminfo","text":"<p>Purpose: Cause the Java Virtual Machine (JVM) to log the current heap and non-heap usages statistics. <pre><code>SELECT synchdb_log_jvm_meminfo('mysqlconn');\n</code></pre></p> <p>Check the PostgreSQL log file: <pre><code>2024-12-09 14:34:21.910 PST [25491] LOG:  Requesting memdump for mysqlconn connector\n2024-12-09 14:34:21 WARN  DebeziumRunner:297 - Heap Memory:\n2024-12-09 14:34:21 WARN  DebeziumRunner:298 -   Used: 19272600 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:299 -   Committed: 67108864 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:300 -   Max: 2147483648 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:302 - Non-Heap Memory:\n2024-12-09 14:34:21 WARN  DebeziumRunner:303 -   Used: 42198864 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:304 -   Committed: 45023232 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:305 -   Max: -1 bytes\n</code></pre></p>"},{"location":"user-guide/utility_functions/#synchdb_att_view","title":"synchdb_att_view","text":"<p>Purpose: Displays a side-by-side view of a connector's data type, name mapping and transform rule relationships between foreign and local tables.</p> <pre><code>SELECT * FROM synchdb_att_view();\n</code></pre> <p>Return Fields:</p> Field Description Type <code>name</code> Connector identifier Text <code>attnum</code> Attribute number Integer <code>ext_tbname</code> table name as appeared remotely Text <code>pg_tbname</code> mapped table name in PostgreSQL Text <code>ext_attname</code> column name as appeared remotely Text <code>pg_attname</code> mapped column name in PostgreSQL Text <code>ext_atttypename</code> data type as appeared remotely Text <code>pg_atttypename</code> mapped data type in PostgreSQL Text <code>transform</code> transform expression Text"},{"location":"user-guide/utility_functions/#snapshot-management","title":"Snapshot Management","text":""},{"location":"user-guide/utility_functions/#synchdb_restart_connector","title":"synchdb_restart_connector","text":"<p>Purpose: Reinitializes connector with specified snapshot mode</p> <p>Snapshot Modes:</p> Mode Description Use Case <code>always</code> Full snapshot on every start Complete data verification <code>initial</code> First-time snapshot only Normal operations <code>initial_only</code> One-time snapshot, then stop Data migration <code>no_data</code> Structure only, no data Schema synchronization <code>never</code> Skip snapshot, stream only Real-time updates <code>recovery</code> Rebuilds from source Disaster recovery <code>when_needed</code> Conditional snapshot Automatic recovery <code>schemasync</code> Structure only, no data, no CDC normal operations <p>Example: <pre><code>-- Restart with specific snapshot mode\nSELECT synchdb_restart_connector('mysqlconn', 'initial');\n\n-- Start with specific snapshot mode\nSELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre></p> <p>\ud83d\udcdd Additional Notes:</p> <ul> <li>Always validate connector configuration before starting</li> <li>Monitor system resources during snapshot operations</li> <li>Back up PostgreSQL destination database before major operations</li> <li>Test connectivity from PostgreSQL server to source database</li> <li>Ensure source database has required permissions configured</li> <li>Regular monitoring of error logs recommended</li> </ul>"},{"location":"es/","title":"Bienvenido a SynchDB","text":"<p>SynchDB es una extensi\u00f3n de PostgreSQL para sincronizar datos de diferentes fuentes de bases de datos.</p>"},{"location":"es/#introduccion","title":"Introducci\u00f3n","text":"<p>SynchDB es una extensi\u00f3n de PostgreSQL dise\u00f1ada para replicar datos de una o m\u00e1s bases de datos heterog\u00e9neas (como MySQL, MS SQLServer, Oracle, etc.) directamente a PostgreSQL de una manera r\u00e1pida y confiable. PostgreSQL sirve como destino de m\u00faltiples fuentes de bases de datos heterog\u00e9neas. No se requiere ning\u00fan middleware ni software de terceros para orquestar la sincronizaci\u00f3n de datos entre bases de datos heterog\u00e9neas y PostgreSQL. La extensi\u00f3n SynchDB en s\u00ed es capaz de manejar todas las necesidades de sincronizaci\u00f3n de datos.</p> <p>Proporciona dos modos de trabajo clave que se pueden invocar utilizando las funciones SQL integradas: * Modo de sincronizaci\u00f3n (para la sincronizaci\u00f3n de datos inicial) * Modo de seguimiento (para replicar cambios incrementales despu\u00e9s de la sincronizaci\u00f3n inicial)</p> <p>El modo de sincronizaci\u00f3n copia tablas de bases de datos heterog\u00e9neas a PostgreSQL, incluido su esquema, \u00edndices, activadores, otras propiedades de tabla, as\u00ed como los datos actuales que contiene. El modo de seguimiento se suscribe a las tablas de una base de datos heterog\u00e9nea para obtener cambios incrementales y aplicarlos a las mismas tablas en PostgreSQL, de forma similar a la replicaci\u00f3n l\u00f3gica de PostgreSQL</p>"},{"location":"es/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Sincronizaci\u00f3n de datos eficiente</li> <li>Compatibilidad con m\u00faltiples fuentes de bases de datos</li> <li>Integraci\u00f3n sencilla con bases de datos PostgreSQL existentes</li> </ul>"},{"location":"es/#primeros-pasos","title":"Primeros pasos","text":"<p>Consulte nuestra Gu\u00eda de instalaci\u00f3n para comenzar a utilizar SynchDB.</p>"},{"location":"es/changelog/","title":"Registro de Cambios","text":"<p>Todos los cambios notables de este proyecto ser\u00e1n documentados en este archivo.</p> <p>El formato est\u00e1 basado en Keep a Changelog y este proyecto se adhiere a Versionado Sem\u00e1ntico.</p>"},{"location":"es/changelog/#synchdb-10-beta1-2024-10-23","title":"[SynchDB 1.0 Beta1] - 2024-10-23","text":"<p>La primera versi\u00f3n de SynchDB que establece una base s\u00f3lida para la replicaci\u00f3n perfecta desde bases de datos heterog\u00e9neas a PostgreSQL.</p>"},{"location":"es/changelog/#anadido","title":"A\u00f1adido","text":"<ul> <li>Replicaci\u00f3n l\u00f3gica desde bases de datos heterog\u00e9neas: (MySQL y SQLServer)</li> <li>Replicaci\u00f3n DDL (CREATE TABLE, DROP TABLE, ALTER TABLE ADD COLUMN, ALTER TABLE DROP COLUMN, ALTER TABLE ALTER COLUMN)</li> <li>Replicaci\u00f3n DML (INSERT, UPDATE, DELETE)</li> <li>M\u00e1ximo 30 trabajadores de conectores concurrentes</li> <li>Lanzador autom\u00e1tico de conectores al inicio de PostgreSQL</li> <li>Vistas de estado global del conector y \u00faltimos mensajes de error</li> <li>Replicaci\u00f3n selectiva de bases de datos y tablas</li> <li>Eventos de cambios en lotes</li> <li>Reinicios de conectores en diferentes modos de instant\u00e1nea</li> <li>Interfaces de gesti\u00f3n de offset para seleccionar punto de reanudaci\u00f3n de replicaci\u00f3n personalizado</li> <li>Reglas de transformaci\u00f3n predeterminadas de tipos de datos y nombres de objetos para bases de datos heterog\u00e9neas soportadas</li> <li>Archivo de reglas JSON para definir personalizaciones: (tipo de datos, nombre de columna, nombre de tabla y reglas de transformaci\u00f3n de expresiones de datos)</li> <li>2 modos de aplicaci\u00f3n de datos (SPI, HeapAM API)</li> <li>Varias funciones de utilidad para realizar operaciones de conector: (iniciar, detener, pausar, reanudar)</li> </ul>"},{"location":"es/changelog/#cambios","title":"Cambios","text":"<p>No aplica</p>"},{"location":"es/changelog/#correcciones","title":"Correcciones","text":"<p>No aplica</p>"},{"location":"es/architecture/architecture/","title":"Arquitectura","text":""},{"location":"es/architecture/architecture/#diagrama-de-arquitectura","title":"Diagrama de Arquitectura","text":"<p>La extensi\u00f3n SynchDB consta de seis componentes principales: * Motor Debezium Runner (Java) * Iniciador SynchDB * Trabajador SynchDB * Conversor de Formato * Agente de Replicaci\u00f3n * Agente de Sincronizaci\u00f3n de Tablas (Por determinar)</p> <p>Consulte el diagrama de arquitectura para una representaci\u00f3n visual de los componentes y sus interacciones. </p>"},{"location":"es/architecture/architecture/#motor-debezium-runner-java","title":"Motor Debezium Runner (Java)","text":"<ul> <li>Una aplicaci\u00f3n Java que utiliza la biblioteca integrada de Debezium.</li> <li>Soporta diversas implementaciones de conectores para replicar datos de cambios desde varios tipos de bases de datos como MySQL, Oracle, SQL Server, etc.</li> <li>Es invocado por el <code>Trabajador SynchDB</code> para inicializar la biblioteca integrada de Debezium y recibir datos de cambios.</li> <li>Env\u00eda los datos de cambios al <code>Trabajador SynchDB</code> en formato JSON generalizado para su posterior procesamiento.</li> </ul>"},{"location":"es/architecture/architecture/#iniciador-synchdb","title":"Iniciador SynchDB","text":"<ul> <li>Responsable de crear y destruir trabajadores SynchDB utilizando las APIs de trabajadores en segundo plano de PostgreSQL.</li> <li>Configura el tipo de conector, IPs de bases de datos de destino, puertos, etc. de cada trabajador.</li> </ul>"},{"location":"es/architecture/architecture/#trabajador-synchdb","title":"Trabajador SynchDB","text":"<ul> <li>Instancia un <code>Motor Debezium Runner</code> para replicar cambios desde un tipo espec\u00edfico de conector.</li> <li>Se comunica con Debezium Runner a trav\u00e9s de JNI para recibir datos de cambios en formatos JSON.</li> <li>Transfiere los datos de cambios JSON al m\u00f3dulo <code>Conversor de Formato</code> para su posterior procesamiento.</li> </ul>"},{"location":"es/architecture/architecture/#conversor-de-formato","title":"Conversor de Formato","text":"<ul> <li>Analiza los datos de cambios JSON utilizando las APIs Jsonb de PostgreSQL</li> <li>Transforma los detalles de cambios DDL en consultas SQL compatibles con PostgreSQL siguiendo reglas de traducci\u00f3n definidas por el usuario.</li> <li>Transforma los detalles de cambios DML en representaci\u00f3n de datos compatible con PostgreSQL proces\u00e1ndolos seg\u00fan los tipos de datos de las columnas. Produce HeapTupleData sin procesar que puede alimentarse directamente al M\u00e9todo de Acceso Heap dentro de PostgreSQL para ejecuciones m\u00e1s r\u00e1pidas.</li> </ul>"},{"location":"es/architecture/architecture/#agente-de-replicacion","title":"Agente de Replicaci\u00f3n","text":"<ul> <li>Procesa las salidas del <code>Conversor de Formato</code>.</li> <li>El <code>Conversor de Formato</code> producir\u00e1 salidas en formato HeapTupleData, luego el <code>Agente de Replicaci\u00f3n</code> invocar\u00e1 las rutinas del m\u00e9todo de acceso heap de PostgreSQL para manejarlas.</li> <li>Para consultas DDL, el <code>Agente de Replicaci\u00f3n</code> invocar\u00e1 el SPI de PostgreSQL para manejarlas.</li> </ul>"},{"location":"es/architecture/architecture/#agente-de-sincronizacion-de-tablas","title":"Agente de Sincronizaci\u00f3n de Tablas","text":"<ul> <li>Los detalles de dise\u00f1o e implementaci\u00f3n a\u00fan no est\u00e1n disponibles. Por determinar</li> <li>Destinado a proporcionar una alternativa m\u00e1s eficiente para realizar la sincronizaci\u00f3n inicial de tablas.</li> </ul>"},{"location":"es/architecture/architecture/#interfaz-nativa-de-java-jni","title":"Interfaz Nativa de Java (JNI)","text":"<p>La Interfaz Nativa de Java (JNI) es un marco que permite a las aplicaciones Java interactuar con c\u00f3digo nativo escrito en lenguajes como C o C++. Permite que los programas Java llamen y sean llamados por aplicaciones y bibliotecas nativas, proporcionando un puente entre la independencia de plataforma de Java y las ventajas de rendimiento del c\u00f3digo nativo. JNI se utiliza com\u00fanmente para integrar caracter\u00edsticas espec\u00edficas de la plataforma, optimizar secciones cr\u00edticas de rendimiento de una aplicaci\u00f3n, o acceder a bibliotecas heredadas que no est\u00e1n disponibles en Java. Requiere una gesti\u00f3n cuidadosa de los recursos, ya que implica cambiar entre la M\u00e1quina Virtual de Java (JVM) y entornos nativos, lo que puede introducir complejidad.</p> <p>SynchDB requiere JNI para intercambiar recursos entre el motor Debezium runner y la extensi\u00f3n PostgreSQL de SynchDB. JNI est\u00e1 disponible con la Instalaci\u00f3n de Java (ej. openjdk).</p>"},{"location":"es/architecture/batch_change_handling/","title":"Manejo de Cambios por Lotes","text":""},{"location":"es/architecture/batch_change_handling/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>SynchDB obtiene peri\u00f3dicamente un lote de solicitudes de cambios del motor Debezium runner en un per\u00edodo de <code>synchdb.naptime</code> milisegundos (por defecto 500). Este lote de solicitudes de cambios es luego procesado por SynchDB. Si todas las solicitudes de cambios dentro del lote han sido procesadas exitosamente (analizadas, transformadas y aplicadas a PostgreSQL), SynchDB notificar\u00e1 al motor Debezium runner que este lote ha sido completado. Esto se\u00f1ala a Debezium runner que debe confirmar el offset hasta el \u00faltimo registro de cambio completado con \u00e9xito. Con este mecanismo implementado, SynchDB puede rastrear cada registro de cambio e instruir a Debezium runner para que no obtenga un cambio antiguo que ya haya sido procesado, o no env\u00ede un registro de cambio duplicado.</p>"},{"location":"es/architecture/batch_change_handling/#manejo-de-lotes-en-caso-de-exito","title":"Manejo de Lotes en Caso de \u00c9xito","text":"<p>Si todas las solicitudes de cambios dentro de un lote han sido procesadas exitosamente, SynchDB simplemente env\u00eda un mensaje al motor Debezium runner para marcar el lote como procesado y completado, lo que causa que los offsets sean confirmados y finalmente escritos en disco.</p> <p></p>"},{"location":"es/architecture/batch_change_handling/#manejo-de-lotes-en-caso-de-exito-parcial","title":"Manejo de Lotes en Caso de \u00c9xito Parcial","text":"<p>En el caso de que una de las solicitudes de cambios haya fallado en procesarse debido a errores internos de PostgreSQL, como violaci\u00f3n de clave duplicada, SynchDB a\u00fan notificar\u00e1 al motor Debezium runner sobre un lote parcialmente completado. Este mensaje de notificaci\u00f3n contiene un indicador sobre el \u00faltimo registro procesado exitosamente. Debezium entonces marcar\u00e1 todos los registros completados como procesados, mientras que dejar\u00e1 los registros no procesados y fallidos como est\u00e1n. Con esto, cuando SynchDB y Debezium runner reinicien, reanudar\u00e1n desde el \u00faltimo registro de cambio fallido y solo continuar\u00e1n cuando la falla haya sido resuelta.</p> <p></p>"},{"location":"es/architecture/metadata_files/","title":"Archivos de Metadatos","text":"<p>Durante la operaci\u00f3n, el motor Debezium Runner genera archivos de metadatos bajo $PGDATA/pg_synchdb. Actualmente se generan y persisten 2 tipos de archivos de metadatos: * archivo de offset: contiene el offset para reanudar la operaci\u00f3n de replicaci\u00f3n al inicio * archivo de historial de esquema: contiene la informaci\u00f3n del esquema para construir todas las tablas para una replicaci\u00f3n. Esto se crea durante la sincronizaci\u00f3n inicial de datos instant\u00e1neos y puede actualizarse durante la operaci\u00f3n.</p> <p>Estos nombres de archivos de metadatos consisten en: * (tipo de conector)(nombre del conector)_offsets.dat * (tipo de conector)(nombre del conector)_schemahistory.dat</p> <pre><code>ls $PGDATA/pg_synchdb\nmysql_mysqlconn_offsets.dat        sqlserver_sqlserverconn_offsets.dat\nmysql_mysqlconn_schemahistory.dat  sqlserver_sqlserverconn_schemahistory.dat\n</code></pre> <p>El contenido de estos archivos binarios puede visualizarse con el comando hexdump: <pre><code>hexdump -C $PGDATA/pg_synchdb/mysql_mysqlconn_offsets.dat\nhexdump -C $PGDATA/pg_synchdb/mysql_mysqlconn_schemahistory.dat\n</code></pre></p>"},{"location":"es/user-guide/connector_auto_launcher/","title":"Lanzador Autom\u00e1tico de Conectores","text":""},{"location":"es/user-guide/connector_auto_launcher/#habilitar-el-lanzador-automatico-de-synchdb","title":"Habilitar el Lanzador Autom\u00e1tico de SynchDB","text":"<p>Un trabajador de conexi\u00f3n se vuelve elegible para el lanzamiento autom\u00e1tico cuando se emite <code>synchdb_start_engine_bgw()</code> en un <code>connector name</code> espec\u00edfico. Del mismo modo, se vuelve inelegible cuando se emite <code>synchdb_stop_engine_bgw()</code>.</p> <p>El lanzador autom\u00e1tico de conectores se puede habilitar mediante:</p> <ul> <li>Agregar <code>synchdb</code> a la opci\u00f3n GUC <code>shared_preload_libraries</code> en postgresql.conf</li> <li>Establecer la nueva opci\u00f3n GUC <code>synchdb.synchdb_auto_launcher</code> en true en postgresql.conf</li> <li>Reiniciar el servidor PostgreSQL para que los cambios surtan efecto</li> </ul> <p>Por ejemplo: <pre><code>shared_preload_libraries = 'synchdb'\nsynchdb.synchdb_auto_launcher = true\n</code></pre></p> <p>Al inicio, la extensi\u00f3n SynchDB se precargar\u00e1 muy temprano. Con <code>synchdb.synchdb_auto_launcher</code> establecido en true, SynchDB generar\u00e1 un trabajador en segundo plano <code>synchdb_auto_launcher</code> que recuperar\u00e1 todas las conexiones en la tabla <code>synchdb_conninfo</code> marcadas como <code>active</code> (tiene la bandera <code>isactive</code> establecida en <code>true</code>). Luego, los iniciar\u00e1 autom\u00e1ticamente como un trabajador en segundo plano separado de la misma manera que cuando se llama a <code>synchdb_start_engine_bgw()</code>. <code>synchdb_auto_launcher</code> saldr\u00e1 despu\u00e9s.</p>"},{"location":"es/user-guide/connector_auto_launcher/#problema-conocido","title":"Problema Conocido","text":"<p>El trabajador <code>synchdb_auto_launcher</code> iniciar\u00e1 sesi\u00f3n en la base de datos <code>postgres</code> predeterminada e intentar\u00e1 encontrar conectores activos en la tabla <code>synchdb_conninfo</code>. Si SynchDB se ha instalado desde una base de datos no predeterminada, entonces <code>synchdb_auto_launcher</code> no podr\u00e1 encontrar la tabla y, por lo tanto, no iniciar\u00e1 autom\u00e1ticamente el trabajador del conector. En el futuro, haremos que <code>synchdb_auto_launcher</code> verifique todas las bases de datos e inicie autom\u00e1ticamente los trabajadores del conector bas\u00e1ndose en las tablas <code>synchdb_conninfo</code> de cada base de datos.</p> <p>Para m\u00e1s informaci\u00f3n y actualizaciones, consulte [Issue #71].</p>"},{"location":"es/user-guide/default_datatype_mapping/","title":"Mapeo Predeterminado de Tipos de Datos","text":"<p>El mapeo predeterminado de tipos de datos es una tabla hash construida internamente dentro de SynchDB con: * clave: {tipo de dato, auto_increment} * valor: {tipo de dato, tama\u00f1o}</p> <p>donde: * tipo de dato: la representaci\u00f3n en cadena de un tipo de dato como INT, TEXT, NUMERIC * auto_increment: una bandera que indica si el tipo de dato tiene atributo auto_increment * tama\u00f1o: el valor de tama\u00f1o traducido. -1: sin cambios, 0: sin tama\u00f1o especificado</p> <p>Las entradas del mapeo predeterminado de tipos de datos pueden sobrescribirse definiendo reglas de transformaci\u00f3n de tipos de datos con un archivo de reglas. Consulte archivo de reglas de transformaci\u00f3n para m\u00e1s informaci\u00f3n.</p>"},{"location":"es/user-guide/default_datatype_mapping/#mysql-default-data-type-mapping","title":"MySQL Default Data Type Mapping","text":"<pre><code>DatatypeHashEntry mysql_defaultTypeMappings[] =\n{\n    {{\"INT\", true}, \"SERIAL\", 0},\n    {{\"BIGINT\", true}, \"BIGSERIAL\", 0},\n    {{\"SMALLINT\", true}, \"SMALLSERIAL\", 0},\n    {{\"MEDIUMINT\", true}, \"SERIAL\", 0},\n    {{\"ENUM\", false}, \"TEXT\", 0},\n    {{\"SET\", false}, \"TEXT\", 0},\n    {{\"BIGINT\", false}, \"BIGINT\", 0},\n    {{\"BIGINT UNSIGNED\", false}, \"NUMERIC\", -1},\n    {{\"NUMERIC UNSIGNED\", false}, \"NUMERIC\", -1},\n    {{\"DEC\", false}, \"DECIMAL\", -1},\n    {{\"DEC UNSIGNED\", false}, \"DECIMAL\", -1},\n    {{\"DECIMAL UNSIGNED\", false}, \"DECIMAL\", -1},\n    {{\"FIXED\", false}, \"DECIMAL\", -1},\n    {{\"FIXED UNSIGNED\", false}, \"DECIMAL\", -1},\n    {{\"BIT(1)\", false}, \"BOOLEAN\", 0},\n    {{\"BIT\", false}, \"BIT\", -1},\n    {{\"BOOL\", false}, \"BOOLEAN\", -1},\n    {{\"DOUBLE\", false}, \"DOUBLE PRECISION\", 0},\n    {{\"DOUBLE PRECISION\", false}, \"DOUBLE PRECISION\", 0},\n    {{\"DOUBLE PRECISION UNSIGNED\", false}, \"DOUBLE PRECISION\", 0},\n    {{\"DOUBLE UNSIGNED\", false}, \"DOUBLE PRECISION\", 0},\n    {{\"REAL\", false}, \"REAL\", 0},\n    {{\"REAL UNSIGNED\", false}, \"REAL\", 0},\n    {{\"FLOAT\", false}, \"REAL\", 0},\n    {{\"FLOAT UNSIGNED\", false}, \"REAL\", 0},\n    {{\"INT\", false}, \"INT\", 0},\n    {{\"INT UNSIGNED\", false}, \"BIGINT\", 0},\n    {{\"INTEGER\", false}, \"INT\", 0},\n    {{\"INTEGER UNSIGNED\", false}, \"BIGINT\", 0},\n    {{\"MEDIUMINT\", false}, \"INT\", 0},\n    {{\"MEDIUMINT UNSIGNED\", false}, \"INT\", 0},\n    {{\"YEAR\", false}, \"INT\", 0},\n    {{\"SMALLINT\", false}, \"SMALLINT\", 0},\n    {{\"SMALLINT UNSIGNED\", false}, \"INT\", 0},\n    {{\"TINYINT\", false}, \"SMALLINT\", 0},\n    {{\"TINYINT UNSIGNED\", false}, \"SMALLINT\", 0},\n    {{\"DATETIME\", false}, \"TIMESTAMP\", -1},\n    {{\"TIMESTAMP\", false}, \"TIMESTAMPTZ\", -1},\n    {{\"BINARY\", false}, \"BYTEA\", 0},\n    {{\"VARBINARY\", false}, \"BYTEA\", 0},\n    {{\"BLOB\", false}, \"BYTEA\", 0},\n    {{\"MEDIUMBLOB\", false}, \"BYTEA\", 0},\n    {{\"LONGBLOB\", false}, \"BYTEA\", 0},\n    {{\"TINYBLOB\", false}, \"BYTEA\", 0},\n    {{\"LONG VARCHAR\", false}, \"TEXT\", -1},\n    {{\"LONGTEXT\", false}, \"TEXT\", -1},\n    {{\"MEDIUMTEXT\", false}, \"TEXT\", -1},\n    {{\"TINYTEXT\", false}, \"TEXT\", -1},\n    {{\"JSON\", false}, \"JSONB\", -1},\n\n    /* spatial types - map to TEXT by default */\n    {{\"GEOMETRY\", false}, \"TEXT\", -1},\n    {{\"GEOMETRYCOLLECTION\", false}, \"TEXT\", -1},\n    {{\"GEOMCOLLECTION\", false}, \"TEXT\", -1},\n    {{\"LINESTRING\", false}, \"TEXT\", -1},\n    {{\"MULTILINESTRING\", false}, \"TEXT\", -1},\n    {{\"MULTIPOINT\", false}, \"TEXT\", -1},\n    {{\"MULTIPOLYGON\", false}, \"TEXT\", -1},\n    {{\"POINT\", false}, \"TEXT\", -1},\n    {{\"POLYGON\", false}, \"TEXT\", -1}\n};\n</code></pre>"},{"location":"es/user-guide/default_datatype_mapping/#sql-server-default-data-type-mapping","title":"SQL Server Default Data Type Mapping","text":"<pre><code>DatatypeHashEntry sqlserver_defaultTypeMappings[] =\n{\n    {{\"int identity\", true}, \"SERIAL\", 0},\n    {{\"bigint identity\", true}, \"BIGSERIAL\", 0},\n    {{\"smallint identity\", true}, \"SMALLSERIAL\", 0},\n    {{\"enum\", false}, \"TEXT\", 0},\n    {{\"int\", false}, \"INT\", 0},\n    {{\"bigint\", false}, \"BIGINT\", 0},\n    {{\"smallint\", false}, \"SMALLINT\", 0},\n    {{\"tinyint\", false}, \"SMALLINT\", 0},\n    {{\"numeric\", false}, \"NUMERIC\", 0},\n    {{\"decimal\", false}, \"NUMERIC\", 0},\n    {{\"bit(1)\", false}, \"BOOL\", 0},\n    {{\"bit\", false}, \"BIT\", 0},\n    {{\"money\", false}, \"MONEY\", 0},\n    {{\"smallmoney\", false}, \"MONEY\", 0},\n    {{\"real\", false}, \"REAL\", 0},\n    {{\"float\", false}, \"REAL\", 0},\n    {{\"date\", false}, \"DATE\", 0},\n    {{\"time\", false}, \"TIME\", 0},\n    {{\"datetime\", false}, \"TIMESTAMP\", 0},\n    {{\"datetime2\", false}, \"TIMESTAMP\", 0},\n    {{\"datetimeoffset\", false}, \"TIMESTAMPTZ\", 0},\n    {{\"smalldatetime\", false}, \"TIMESTAMP\", 0},\n    {{\"char\", false}, \"CHAR\", 0},\n    {{\"varchar\", false}, \"VARCHAR\", -1},\n    {{\"text\", false}, \"TEXT\", 0},\n    {{\"nchar\", false}, \"CHAR\", 0},\n    {{\"nvarchar\", false}, \"VARCHAR\", -1},\n    {{\"ntext\", false}, \"TEXT\", 0},\n    {{\"binary\", false}, \"BYTEA\", 0},\n    {{\"varbinary\", false}, \"BYTEA\", 0},\n    {{\"image\", false}, \"BYTEA\", 0},\n    {{\"uniqueidentifier\", false}, \"UUID\", 0},\n    {{\"xml\", false}, \"TEXT\", 0},\n    /* spatial types - map to TEXT by default */\n    {{\"geometry\", false}, \"TEXT\", 0},\n    {{\"geography\", false}, \"TEXT\", 0},\n};\n</code></pre>"},{"location":"es/user-guide/set_offset/","title":"Valores de desplazamiento inicial personalizados","text":"<p>Un valor de offset de inicio representa un punto desde el cual comenzar la replicaci\u00f3n, de manera similar al LSN de reanudaci\u00f3n de PostgreSQL. Cuando el motor Debezium runner inicia, comenzar\u00e1 la replicaci\u00f3n desde este valor de offset. Establecer este valor de offset a un valor anterior har\u00e1 que el motor Debezium runner comience la replicaci\u00f3n desde registros anteriores, posiblemente replicando registros de datos duplicados. Debemos ser extremadamente cautelosos al establecer valores de offset de inicio en Debezium.</p>"},{"location":"es/user-guide/set_offset/#registrar-valores-de-offset-configurables","title":"Registrar Valores de Offset Configurables","text":"<p>Durante la operaci\u00f3n, se generar\u00e1n nuevos offsets y se guardar\u00e1n en disco por el motor Debezium runner. El \u00faltimo offset guardado puede recuperarse desde el comando de utilidad <code>synchdb_state_view()</code>:</p> <pre><code>postgres=# select * from synchdb_state_view;\n id | connector | conninfo_name  |  pid   |  state  |   err    |                                          last_dbz_offset\n----+-----------+----------------+--------+---------+----------+---------------------------------------------------------------------------------------------------\n  0 | mysql     | mysqlconn      | 461696 | syncing | no error | {\"ts_sec\":1725644339,\"file\":\"mysql-bin.000004\",\"pos\":138466,\"row\":1,\"server_id\":223344,\"event\":2}\n  1 | sqlserver | sqlserverconn  | 461739 | syncing | no error | {\"event_serial_no\":1,\"commit_lsn\":\"00000100:00000c00:0003\",\"change_lsn\":\"00000100:00000c00:0002\"}\n  3 | null      |                |     -1 | stopped | no error | no offset\n  [... el resto de las filas ...]\n</code></pre> <p>Dependiendo del tipo de conector, este valor de offset difiere. Del ejemplo anterior, el \u00faltimo offset guardado del conector <code>mysql</code> es <code>{\"ts_sec\":1725644339,\"file\":\"mysql-bin.000004\",\"pos\":138466,\"row\":1,\"server_id\":223344,\"event\":2}</code> y el \u00faltimo offset guardado de <code>sqlserver</code> es <code>{\"event_serial_no\":1,\"commit_lsn\":\"00000100:00000c00:0003\",\"change_lsn\":\"00000100:00000c00:0002\"}</code>. </p> <p>Debemos guardar estos valores regularmente, para que en caso de que tengamos un problema, conozcamos la ubicaci\u00f3n del offset en el pasado que se puede establecer para reanudar la operaci\u00f3n de replicaci\u00f3n.</p>"},{"location":"es/user-guide/set_offset/#pausar-el-conector","title":"Pausar el Conector","text":"<p>Un conector debe estar en estado <code>paused</code> antes de que se pueda establecer un nuevo valor de offset.</p> <p>Use la funci\u00f3n SQL <code>synchdb_pause_engine()</code> para pausar un conector en ejecuci\u00f3n. Esto detendr\u00e1 el motor Debezium runner de replicar desde la base de datos heterog\u00e9nea. Cuando est\u00e1 pausado, es posible alterar el valor de offset del conector Debezium para replicar desde un punto espec\u00edfico en el pasado usando la rutina SQL <code>synchdb_set_offset()</code>. Toma <code>conninfo_name</code> como su argumento, que se puede encontrar en la salida de la vista <code>synchdb_get_state()</code>.</p> <p>Por ejemplo: <pre><code>SELECT synchdb_pause_engine('mysqlconn');\n</code></pre></p>"},{"location":"es/user-guide/set_offset/#establecer-el-nuevo-offset","title":"Establecer el nuevo Offset","text":"<p>Use la funci\u00f3n SQL <code>synchdb_set_offset()</code> para cambiar el offset de inicio de un trabajador del conector. Esto solo se puede hacer cuando el conector est\u00e1 en estado <code>paused</code>. La funci\u00f3n toma 2 par\u00e1metros, <code>conninfo_name</code> y <code>una cadena de offset v\u00e1lida</code>, ambos se pueden encontrar en la salida de la vista <code>synchdb_get_state()</code>.</p> <p>Por ejemplo: <pre><code>SELECT synchdb_set_offset('mysqlconn', '{\"ts_sec\":1725644339,\"file\":\"mysql-bin.000004\",\"pos\":138466,\"row\":1,\"server_id\":223344,\"event\":2}');\n</code></pre></p>"},{"location":"es/user-guide/set_offset/#reanudar-el-conector","title":"Reanudar el Conector","text":"<p>Use la funci\u00f3n SQL <code>synchdb_resume_engine()</code> para reanudar la operaci\u00f3n de Debezium desde un estado pausado. Esta funci\u00f3n toma <code>connector name</code> como su \u00fanico par\u00e1metro, que se puede encontrar en la salida de la vista <code>synchdb_get_state()</code>. El motor Debezium runner reanudado comenzar\u00e1 la replicaci\u00f3n desde el valor de offset reci\u00e9n establecido.</p> <p>Por ejemplo: <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p>"},{"location":"es/user-guide/utility_functions/","title":"Referencia de Funciones","text":""},{"location":"es/user-guide/utility_functions/#gestion-de-conectores","title":"Gesti\u00f3n de Conectores","text":""},{"location":"es/user-guide/utility_functions/#synchdb_add_conninfo","title":"synchdb_add_conninfo","text":"<p>Prop\u00f3sito: Crea una nueva configuraci\u00f3n de conector</p> <p>Par\u00e1metros:</p> Par\u00e1metro Descripci\u00f3n Requerido Ejemplo Notas <code>name</code> Identificador \u00fanico para este conector \u2713 <code>'mysqlconn'</code> Debe ser \u00fanico entre todos los conectores <code>hostname</code> IP/nombre de host de la base de datos heterog\u00e9nea \u2713 <code>'127.0.0.1'</code> Soporta IPv4, IPv6 y nombres de host <code>port</code> N\u00famero de puerto para la conexi\u00f3n \u2713 <code>3306</code> Por defecto: MySQL(3306), SQLServer(1433) <code>username</code> Nombre de usuario para autenticaci\u00f3n \u2713 <code>'mysqluser'</code> Requiere permisos apropiados <code>password</code> Contrase\u00f1a de autenticaci\u00f3n \u2713 <code>'mysqlpwd'</code> Almacenada de forma segura <code>source database</code> Nombre de la base de datos origen \u2713 <code>'inventory'</code> Debe existir en el sistema origen <code>destination database</code> Base de datos PostgreSQL destino \u2713 <code>'postgres'</code> Debe existir en PostgreSQL <code>table</code> Patr\u00f3n de especificaci\u00f3n de tabla \u2610 <code>'[db].[table]'</code> Vac\u00edo = replicar todas las tablas <code>connector</code> Tipo de conector (<code>mysql</code>/<code>sqlserver</code>) \u2713 <code>'mysql'</code> Ver conectores soportados arriba <code>rule file</code> Reglas de traducci\u00f3n de tipos de datos \u2610 <code>'myrule.json'</code> Debe estar en el directorio $PGDATA <p>Ejemplos de Uso: <pre><code>-- Ejemplo MySQL\nSELECT synchdb_add_conninfo(\n    'mysqlconn',    -- Nombre del conector\n    '127.0.0.1',    -- Host\n    3306,           -- Puerto\n    'mysqluser',    -- Usuario\n    'mysqlpwd',     -- Contrase\u00f1a\n    'inventory',    -- BD origen\n    'postgres',     -- BD destino\n    '',             -- Tablas (vac\u00edo para todas)\n    'mysql',        -- Tipo de conector\n    'myrule.json'   -- Archivo de reglas\n);\n\n-- Ejemplo SQL Server\nSELECT synchdb_add_conninfo(\n    'sqlserverconn',\n    '127.0.0.1',\n    1433,\n    'sa',\n    'MyPassword123',\n    'testDB',\n    'postgres',\n    'dbo.orders',   -- Tabla espec\u00edfica\n    'sqlserver',\n    'mssql_rules.json'\n);\n</code></pre></p>"},{"location":"es/user-guide/utility_functions/#funciones-basicas-de-control","title":"Funciones B\u00e1sicas de Control","text":""},{"location":"es/user-guide/utility_functions/#synchdb_start_engine_bgw","title":"synchdb_start_engine_bgw","text":"<p>Prop\u00f3sito: Inicia un conector <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre></p>"},{"location":"es/user-guide/utility_functions/#synchdb_pause_engine","title":"synchdb_pause_engine","text":"<p>Prop\u00f3sito: Detiene temporalmente un conector en ejecuci\u00f3n <pre><code>SELECT synchdb_pause_engine_bgw('mysqlconn');\n</code></pre></p>"},{"location":"es/user-guide/utility_functions/#synchdb_resume_engine","title":"synchdb_resume_engine","text":"<p>Prop\u00f3sito: Reanuda un conector pausado <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p>"},{"location":"es/user-guide/utility_functions/#synchdb_stop_engine_bgw","title":"synchdb_stop_engine_bgw","text":"<p>Prop\u00f3sito: Termina un conector <pre><code>SELECT synchdb_stop_engine('mysqlconn');\n</code></pre></p>"},{"location":"es/user-guide/utility_functions/#gestion-de-estado","title":"Gesti\u00f3n de Estado","text":""},{"location":"es/user-guide/utility_functions/#synchdb_state_view","title":"synchdb_state_view","text":"<p>Prop\u00f3sito: Monitorea los estados y el estado de los conectores</p> <pre><code>SELECT * FROM synchdb_state_view();\n</code></pre> <p>Campos de Retorno:</p> Campo Descripci\u00f3n Tipo <code>id</code> Identificador de slot del conector Integer <code>connector</code> Tipo de conector (<code>mysql</code> o <code>sqlserver</code>) Text <code>conninfo_name</code> Nombre del conector asociado Text <code>pid</code> ID del proceso trabajador Integer <code>state</code> Estado actual del conector Text <code>err</code> \u00daltimo mensaje de error Text <code>last_dbz_offset</code> \u00daltimo offset de Debezium registrado JSON <p>Estados Posibles:</p> <ul> <li>\ud83d\udd34 <code>stopped</code> - Inactivo</li> <li>\ud83d\udfe1 <code>initializing</code> - Iniciando</li> <li>\ud83d\udfe0 <code>paused</code> - Pausado temporalmente</li> <li>\ud83d\udfe2 <code>syncing</code> - Sondeando activamente</li> <li>\ud83d\udd35 <code>parsing</code> - Procesando eventos</li> <li>\ud83d\udfe3 <code>converting</code> - Transformando datos</li> <li>\u26aa <code>executing</code> - Aplicando cambios</li> <li>\ud83d\udfe4 <code>updating offset</code> - Actualizando punto de control</li> <li>\ud83d\udfe8 <code>restarting</code> - Reiniciando</li> <li>\u26ab <code>unknown</code> - Estado indeterminado</li> </ul>"},{"location":"es/user-guide/utility_functions/#synchdb_set_offset","title":"synchdb_set_offset","text":"<p>Prop\u00f3sito: Configura una posici\u00f3n de inicio personalizada</p> <p>Ejemplo para MySQL: <pre><code>SELECT synchdb_set_offset(\n    'mysqlconn', \n    '{\"ts_sec\":1725644339,\"file\":\"mysql-bin.000004\",\"pos\":138466,\"row\":1,\"server_id\":223344,\"event\":2}'\n);\n</code></pre></p> <p>Ejemplo para SQL Server: <pre><code>SELECT synchdb_set_offset(\n    'sqlserverconn',\n    '{\"event_serial_no\":1,\"commit_lsn\":\"00000100:00000c00:0003\",\"change_lsn\":\"00000100:00000c00:0002\"}'\n);\n</code></pre></p>"},{"location":"es/user-guide/utility_functions/#gestion-de-instantaneas","title":"Gesti\u00f3n de Instant\u00e1neas","text":""},{"location":"es/user-guide/utility_functions/#synchdb_restart_connector","title":"synchdb_restart_connector","text":"<p>Prop\u00f3sito: Reinicializa un conector con un modo de instant\u00e1nea espec\u00edfico</p> <p>Modos de Instant\u00e1nea:</p> Modo Descripci\u00f3n Caso de Uso <code>always</code> Realiza una instant\u00e1nea completa en cada inicio Verificaci\u00f3n completa de datos <code>initial</code> Solo instant\u00e1nea inicial Operaciones normales <code>initial_only</code> Una \u00fanica instant\u00e1nea, luego se detiene Migraci\u00f3n de datos <code>no_data</code> Solo estructura, sin datos Sincronizaci\u00f3n de esquema <code>never</code> Omite instant\u00e1nea, solo transmite Actualizaciones en tiempo real <code>recovery</code> Reconstruye desde el origen Recuperaci\u00f3n de desastres <code>when_needed</code> Instant\u00e1nea condicional Recuperaci\u00f3n autom\u00e1tica <p>Ejemplo: <pre><code>-- Reiniciar con modo de instant\u00e1nea espec\u00edfico\nSELECT synchdb_restart_connector('mysqlconn', 'initial');\n</code></pre></p> <p>\ud83d\udcdd Notas Adicionales:</p> <ul> <li>Siempre validar la configuraci\u00f3n del conector antes de iniciar</li> <li>Monitorear los recursos del sistema durante operaciones de instant\u00e1nea</li> <li>Respaldar la base de datos PostgreSQL de destino antes de operaciones importantes</li> <li>Probar la conectividad desde el servidor PostgreSQL a la base de datos origen</li> <li>Asegurar que la base de datos origen tenga los permisos requeridos configurados</li> <li>Se recomienda monitoreo regular de los registros de errores</li> </ul>"},{"location":"es/user-guide/configuration/","title":"Configuraci\u00f3n","text":"<p>SynchDB admite las siguientes variables GUC en postgresql.conf:</p> Variable GUC Tipo Valor Predeterminado Descripci\u00f3n synchdb.naptime integer 500 El retraso en milisegundos entre cada sondeo de datos del motor Debezium runner synchdb.dml_use_spi boolean false Opci\u00f3n para usar SPI en el manejo de operaciones DML synchdb.synchdb_auto_launcher boolean true Opci\u00f3n para lanzar autom\u00e1ticamente los trabajadores del conector SynchDB activos. Esta opci\u00f3n solo funciona cuando SynchDB est\u00e1 incluido en la opci\u00f3n GUC <code>shared_preload_library</code>"},{"location":"es/user-guide/configuration/#notas-tecnicas","title":"Notas T\u00e9cnicas","text":"<ul> <li>Las variables GUC (Grand Unified Configuration) son par\u00e1metros de configuraci\u00f3n global en PostgreSQL</li> <li>Los valores se configuran en el archivo <code>postgresql.conf</code></li> <li>Los cambios requieren un reinicio del servidor para tomar efecto</li> <li><code>shared_preload_library</code> es una configuraci\u00f3n cr\u00edtica del sistema que determina qu\u00e9 bibliotecas se cargan al inicio</li> </ul>"},{"location":"es/user-guide/configuration/#ejemplos-de-configuracion","title":"Ejemplos de Configuraci\u00f3n","text":"<pre><code># Ejemplo de configuraci\u00f3n en postgresql.conf\nsynchdb.naptime = 1000               # Aumentar el tiempo de espera a 1 segundo\nsynchdb.dml_use_spi = true           # Habilitar el uso de SPI para operaciones DML\nsynchdb.synchdb_auto_launcher = true # Habilitar el inicio autom\u00e1tico del conector\n</code></pre>"},{"location":"es/user-guide/configuration/#recomendaciones-de-uso","title":"Recomendaciones de Uso","text":"<ol> <li>synchdb.naptime<ul> <li>Valores m\u00e1s bajos: Mayor frecuencia de actualizaci\u00f3n pero m\u00e1s carga del sistema</li> <li>Valores m\u00e1s altos: Menor carga del sistema pero actualizaciones menos frecuentes</li> <li>Ajustar seg\u00fan los requisitos de latencia de datos</li> </ul> </li> <li>synchdb.dml_use_spi<ul> <li>Habilitar si se necesita integraci\u00f3n espec\u00edfica con SPI</li> <li>Mantener en <code>false</code> para operaciones DML est\u00e1ndar</li> </ul> </li> <li>synchdb.synchdb_auto_launcher<ul> <li>Recomendado mantener en <code>true</code> para gesti\u00f3n autom\u00e1tica</li> <li>Cambiar a <code>false</code> solo si se requiere control manual de los conectores</li> </ul> </li> </ol>"},{"location":"es/user-guide/configuration/#consideraciones-de-rendimiento","title":"Consideraciones de Rendimiento","text":"<ul> <li>Ajustar <code>naptime</code> seg\u00fan la carga del sistema y requisitos de latencia</li> <li>Monitorear el rendimiento del sistema al modificar estas configuraciones</li> <li>Considerar el impacto en recursos del sistema al habilitar funciones adicionales</li> </ul>"},{"location":"es/user-guide/ddl_replication/","title":"Replicaci\u00f3n DDL","text":""},{"location":"es/user-guide/ddl_replication/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>SynchDB proporciona soporte integral para operaciones de Lenguaje de Definici\u00f3n de Datos (DDL), permitiendo la sincronizaci\u00f3n de esquemas en tiempo real entre diferentes sistemas de bases de datos.</p>"},{"location":"es/user-guide/ddl_replication/#comandos-ddl-soportados","title":"Comandos DDL Soportados","text":"<p>SynchDB soporta las siguientes operaciones DDL:</p> <p>\u2705 CREATE [table] \u2705 ALTER [table] ADD COLUMN \u2705 ALTER [table] DROP COLUMN \u2705 ALTER [table] ALTER COLUMN \u2705 DROP [table]  </p>"},{"location":"es/user-guide/ddl_replication/#soporte-detallado-de-comandos","title":"Soporte Detallado de Comandos","text":""},{"location":"es/user-guide/ddl_replication/#create-table","title":"CREATE TABLE","text":"<p>SynchDB captura estas propiedades durante los eventos CREATE TABLE:</p> Propiedad Descripci\u00f3n Nombre de Tabla Formato de Nombre Completamente Calificado (FQN) Nombres de Columnas Identificadores individuales de columnas Tipos de Datos Especificaciones de tipos de datos de columnas Longitud de Datos Especificaciones de longitud/precisi\u00f3n (si aplica) Marcador Unsigned Restricciones unsigned para tipos num\u00e9ricos Nulabilidad Restricciones NULL/NOT NULL Valores Predeterminados Expresiones de valores predeterminados Claves Primarias Definiciones de columnas de clave primaria <p>Nota: Propiedades adicionales de CREATE TABLE no est\u00e1n soportadas actualmente</p>"},{"location":"es/user-guide/ddl_replication/#drop-table","title":"DROP TABLE","text":"<p>Propiedades capturadas: - Nombre de la tabla (en formato FQN) a eliminar</p>"},{"location":"es/user-guide/ddl_replication/#alter-table-add-column","title":"ALTER TABLE ADD COLUMN","text":"<p>Captura las siguientes propiedades:</p> Propiedad Descripci\u00f3n Nombres de Columnas Nombres de las columnas nuevas Tipos de Datos Tipos de datos para nuevas columnas Longitud de Datos Especificaciones de longitud (si aplica) Marcador Unsigned Restricciones unsigned Nulabilidad Especificaciones NULL/NOT NULL Valores Predeterminados Expresiones de valores predeterminados Claves Primarias Definiciones actualizadas de clave primaria <p>Otras propiedades que pueden especificarse durante ALTER TABLE ADD COLUMN no est\u00e1n soportadas en este momento.</p>"},{"location":"es/user-guide/ddl_replication/#alter-table-drop-column","title":"ALTER TABLE DROP COLUMN","text":"<p>Captura: - Lista de nombres de columnas a eliminar</p>"},{"location":"es/user-guide/ddl_replication/#alter-table-alter-column","title":"ALTER TABLE ALTER COLUMN","text":"<p>Modificaciones soportadas:</p> Modificaci\u00f3n Descripci\u00f3n Tipo de Dato Cambiar tipo de dato de la columna Longitud de Tipo Modificar longitud/precisi\u00f3n del tipo Valor Predeterminado Alterar/eliminar valores predeterminados NOT NULL Modificar/eliminar restricci\u00f3n NOT NULL <p>Otras propiedades que pueden especificarse durante ALTER TABLE ALTER COLUMN no est\u00e1n soportadas en este momento.</p> <p>Por favor, tenga en cuenta que SynchDB solo soporta cambios b\u00e1sicos de tipo de datos en una columna existente. Por ejemplo, <code>INT</code> \u2192 <code>BIGINT</code> o <code>VARCHAR</code> \u2192 <code>TEXT</code>. Cambios complejos de tipo de datos como <code>TEXT</code> \u2192 <code>INT</code> o <code>INT</code> \u2192 <code>TIMESTAMP</code> no est\u00e1n soportados actualmente. Esto se debe a que PostgreSQL requiere que el usuario proporcione adicionalmente una funci\u00f3n de conversi\u00f3n de tipo para realizar la conversi\u00f3n como resultado del cambio complejo de tipo de datos. SynchDB actualmente no tiene conocimiento de qu\u00e9 funciones de conversi\u00f3n usar para conversiones espec\u00edficas de tipo. En el futuro, podr\u00edamos permitir que el usuario proporcione sus propias funciones de conversi\u00f3n para usar en conversiones espec\u00edficas de tipo a trav\u00e9s del archivo de reglas, pero por ahora, no est\u00e1 soportado.</p>"},{"location":"es/user-guide/ddl_replication/#comportamiento-especifico-por-base-de-datos","title":"Comportamiento Espec\u00edfico por Base de Datos","text":""},{"location":"es/user-guide/ddl_replication/#eventos-ddl-en-mysql","title":"Eventos DDL en MySQL","text":"<p>Dado que MySQL registra tanto operaciones DDL como DML en el binlog, SynchDB puede replicar tanto DDLs como DMLs seg\u00fan ocurren. No se necesitan acciones especiales en el lado de MySQL para habilitar la replicaci\u00f3n de DDLs.</p>"},{"location":"es/user-guide/ddl_replication/#eventos-ddl-en-sqlserver","title":"Eventos DDL en SQLServer","text":"<p>SQLServer no soporta nativamente la replicaci\u00f3n DDL en modo streaming. El esquema de tabla es construido por SynchDB durante la fase de construcci\u00f3n del snapshot inicial cuando el conector se inicia por primera vez. Despu\u00e9s de esta fase, SynchDB intentar\u00e1 detectar cualquier cambio de esquema, pero necesitan ser agregados expl\u00edcitamente a la lista de tablas CDC de SQL Server.</p>"},{"location":"es/user-guide/ddl_replication/#activar-evento-create-table-en-sqlserver","title":"Activar evento CREATE TABLE en SQLServer","text":"<p>Para crear una nueva tabla en SQL Server y agregarla a su lista de tablas CDC: <pre><code>CREATE TABLE dbo.altertest (\n    a INT,\n    b TEXT\n    );\nGO\n\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @role_name = NULL,\n    @supports_net_changes = 0,\n    @capture_instance = 'dbo_altertest_1'\nGO\n</code></pre></p> <p>El comando agrega la tabla <code>dbo.altertest</code> a la lista de tablas CDC y causar\u00e1 que SynchDB reciba un evento DDL CREATE TABLE.</p>"},{"location":"es/user-guide/ddl_replication/#activar-eventos-alter-table","title":"Activar Eventos ALTER TABLE","text":"<p>Si se altera una tabla existente (agregar, eliminar o modificar columna), necesita ser actualizada expl\u00edcitamente en la lista de tablas CDC de SQLServer, para que SynchDB pueda recibir los eventos ALTER TABLE.</p> <p>Por ejemplo:</p> <p>Alterar una tabla en SQLServer: <pre><code>ALTER TABLE altertest ADD c NVARCHAR(MAX),\n    d INT DEFAULT 0 NOT NULL,\n    e NVARCHAR(255) NOT NULL,\n    f INT DEFAULT 5 NOT NULL,\n    CONSTRAINT PK_altertest PRIMARY KEY (\n    d,\n    f\n    );\nGO\n</code></pre></p> <p>Deshabilitar la instancia de captura anterior: <pre><code>EXEC sys.sp_cdc_disable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @capture_instance = 'dbo_altertest_1';\nGO\n</code></pre></p> <p>Habilitar como una nueva instancia de captura: <pre><code>EXEC sys.sp_cdc_enable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @role_name = NULL,\n    @supports_net_changes = 0,\n    @capture_instance = 'dbo_altertest_2';\nGO\n</code></pre></p> <p>Agregar nuevo registro: <pre><code>INSERT INTO altertest VALUES(1, 's', 'c', 1, 'v', 5);\nGO\n</code></pre></p> <p>El ejemplo anterior deber\u00eda permitir que SynchDB reciba un evento ALTER TABLE ADD COLUMN y un evento INSERT. No es necesario reiniciar SQL Server ni SynchDB para capturar estos eventos. Lo mismo aplica para los eventos ALTER TABLE DROP COLUMN y ALTER TABLE ALTER COLUMN tambi\u00e9n.</p>"},{"location":"es/user-guide/installation/","title":"Instalaci\u00f3n","text":""},{"location":"es/user-guide/installation/#requisitos","title":"Requisitos","text":"<p>Se requiere el siguiente software para construir y ejecutar SynchDB. Las versiones listadas son las versiones probadas durante el desarrollo. Las versiones anteriores pueden seguir funcionando. * Java Development Kit 22. Descargar aqu\u00ed * Apache Maven 3.9.8. Descargar aqu\u00ed * PostgreSQL 16.3 Source. Clonar Git aqu\u00ed. Consulte esta wiki para los requisitos de compilaci\u00f3n de PostgreSQL * Docker compose 2.28.1 (para pruebas). Consultar aqu\u00ed * Sistema operativo basado en Unix como Ubuntu 22.04 o MacOS</p>"},{"location":"es/user-guide/installation/#preparar-fuente","title":"Preparar Fuente","text":"<p>Clone el c\u00f3digo fuente de PostgreSQL y cambie a la etiqueta de la versi\u00f3n 16.3 <pre><code>git clone https://github.com/postgres/postgres.git\ncd postgres\ngit checkout REL_16_3\n</code></pre></p> <p>Clone el c\u00f3digo fuente de SynchDB desde dentro de la carpeta de extensiones Nota: La rama (synchdb-devel)[https://github.com/Hornetlabs/synchdb/tree/synchdb-devel] se usa para desarrollo hasta ahora. <pre><code>cd contrib/\ngit clone https://github.com/Hornetlabs/synchdb.git\n</code></pre></p>"},{"location":"es/user-guide/installation/#preparar-herramientas","title":"Preparar Herramientas","text":""},{"location":"es/user-guide/installation/#instalar-maven","title":"Instalar Maven","text":"<p>Si est\u00e1 trabajando en Ubuntu 22.04.4 LTS, instale Maven como se muestra a continuaci\u00f3n: <pre><code>sudo apt install maven\n</code></pre></p> <p>Si est\u00e1 usando MacOS, puede usar el comando brew para instalar maven (consulte (aqu\u00ed)[https://brew.sh/] para saber c\u00f3mo instalar Homebrew) sin ninguna otra configuraci\u00f3n: <pre><code>brew install maven\n</code></pre></p>"},{"location":"es/user-guide/installation/#instalar-java-sdk-openjdk","title":"Instalar Java SDK (OpenJDK)","text":"<p>Si est\u00e1 trabajando en Ubuntu 22.04.4 LTS, instale OpenJDK como se muestra a continuaci\u00f3n: <pre><code>sudo apt install openjdk-21-jdk\n</code></pre></p> <p>Si est\u00e1 trabajando en MacOS, instale JDK con el comando brew: <pre><code>brew install openjdk@22\n</code></pre></p>"},{"location":"es/user-guide/installation/#compilar-e-instalar-postgresql","title":"Compilar e Instalar PostgreSQL","text":"<p>Siga la documentaci\u00f3n oficial de PostgreSQL aqu\u00ed para compilar e instalar PostgreSQL desde el c\u00f3digo fuente. Generalmente, el procedimiento consiste en:</p> <pre><code>cd /home/$USER/postgres\n./configure\nmake\nsudo make install\n</code></pre> <p>Tambi\u00e9n debe compilar e instalar las extensiones predeterminadas: <pre><code>cd /home/$USER/postgres/contrib\nmake\nsudo make install\n</code></pre></p>"},{"location":"es/user-guide/installation/#compilar-e-instalar-el-motor-debezium-runner","title":"Compilar e Instalar el Motor Debezium Runner","text":"<p>Con Java y Maven configurados, estamos listos para compilar el Motor Debezium Runner. Esto instala el archivo jar de Debezium Runner Engine en la carpeta lib de PostgreSQL.</p> <pre><code>cd /home/$USER/postgres/contrib/synchdb\nmake build_dbz\nsudo make install_dbz\n</code></pre>"},{"location":"es/user-guide/installation/#compilar-e-instalar-la-extension-postgresql-de-synchdb","title":"Compilar e Instalar la Extensi\u00f3n PostgreSQL de SynchDB","text":"<p>Con la <code>lib</code> y el <code>include</code> de Java instalados en su sistema, SynchDB puede compilarse mediante:</p> <pre><code>cd /home/$USER/postgres/contrib/synchdb\nmake\nsudo make install\n</code></pre>"},{"location":"es/user-guide/installation/#configurar-su-enlazador-ubuntu","title":"Configurar su Enlazador (Ubuntu)","text":"<p>Por \u00faltimo, tambi\u00e9n necesitamos indicarle al enlazador de su sistema d\u00f3nde se encuentra la biblioteca Java reci\u00e9n agregada. El siguiente procedimiento est\u00e1 basado en Ubuntu 22.04.</p> <p><pre><code># Configurar din\u00e1micamente las rutas de JDK\nJAVA_PATH=$(which java)\nJDK_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJDK_LIB_PATH=${JDK_HOME_PATH}/lib\n\necho $JDK_LIB_PATH\necho $JDK_LIB_PATH/server\n\nsudo echo \"$JDK_LIB_PATH\" \uff5c sudo tee -a /etc/ld.so.conf.d/x86_64-linux-gnu.conf\nsudo echo \"$JDK_LIB_PATH/server\" | sudo tee -a /etc/ld.so.conf.d/x86_64-linux-gnu.conf\n</code></pre> Nota: para mac con chips M1/M2, necesita agregar las dos l\u00edneas en /etc/ld.so.conf.d/aarch64-linux-gnu.conf <pre><code>sudo echo \"$JDK_LIB_PATH\"       \uff5c sudo tee -a /etc/ld.so.conf.d/aarch64-linux-gnu.conf\nsudo echo \"$JDK_LIB_PATH/server\" | sudo tee -a /etc/ld.so.conf.d/aarch64-linux-gnu.conf\n</code></pre></p> <p>Ejecute ldconfig para recargar: <pre><code>sudo ldconfig\n</code></pre></p>"},{"location":"es/user-guide/installation/#verificar-instalacion","title":"Verificar Instalaci\u00f3n","text":"<p>Aseg\u00farese de que la extensi\u00f3n synchdb.so pueda enlazarse con la biblioteca Java libjvm en su sistema: <pre><code>ldd synchdb.so\n        linux-vdso.so.1 (0x00007ffeae35a000)\n        libjvm.so =&gt; /usr/lib/jdk-22.0.1/lib/server/libjvm.so (0x00007fc1276c1000)\n        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fc127498000)\n        libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fc127493000)\n        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fc12748e000)\n        librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007fc127489000)\n        libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007fc1273a0000)\n        /lib64/ld-linux-x86-64.so.2 (0x00007fc128b81000)\n</code></pre></p>"},{"location":"es/user-guide/prepare_tests_env/","title":"Entorno de prueba r\u00e1pida","text":"<p>Los procedimientos mencionados aqu\u00ed est\u00e1n destinados a iniciar r\u00e1pidamente bases de datos heterog\u00e9neas para verificaci\u00f3n r\u00e1pida y demostraci\u00f3n de funcionalidades. Los archivos y scripts necesarios para iniciar bases de datos heterog\u00e9neas de ejemplo se pueden encontrar en el repositorio de SynchDB aqu\u00ed</p>"},{"location":"es/user-guide/prepare_tests_env/#preparar-una-base-de-datos-mysql-de-ejemplo","title":"Preparar una Base de Datos MySQL de Ejemplo","text":"<p>Podemos iniciar una base de datos MySQL de ejemplo para pruebas usando docker compose. Las credenciales de usuario est\u00e1n descritas en el archivo <code>synchdb-mysql-test.yaml</code> <pre><code>docker compose -f synchdb-mysql-test.yaml up -d\n</code></pre></p> <p>Inicie sesi\u00f3n en MySQL como <code>root</code> y otorgue permisos al usuario <code>mysqluser</code> para realizar CDC en tiempo real <pre><code>mysql -h 127.0.0.1 -u root -p\n\nGRANT replication client on *.* to mysqluser;\nGRANT replication slave  on *.* to mysqluser;\nGRANT RELOAD ON *.* TO 'mysqluser'@'%';\nFLUSH PRIVILEGES;\n</code></pre></p> <p>Salga de la herramienta cliente de mysql: <pre><code>\\q\n</code></pre></p>"},{"location":"es/user-guide/prepare_tests_env/#preparar-una-base-de-datos-sql-server-de-ejemplo","title":"Preparar una Base de Datos SQL Server de Ejemplo","text":"<p>Podemos iniciar una base de datos SQL Server de ejemplo para pruebas usando docker compose. Las credenciales de usuario est\u00e1n descritas en el archivo <code>synchdb-sqlserver-test.yaml</code> <pre><code>docker compose -f synchdb-sqlserver-test.yaml up -d\n</code></pre> use el archivo synchdb-sqlserver-withssl-test.yaml para SQL Server con certificado SSL habilitado.</p> <p>Es posible que no tenga instalada la herramienta cliente de SQL Server, puede iniciar sesi\u00f3n en el contenedor de SQL Server para acceder a su herramienta cliente.</p> <p>Encuentre el ID del contenedor para SQL Server: <pre><code>id=$(docker ps | grep sqlserver | awk '{print $1}')\n</code></pre></p> <p>Copie el esquema de la base de datos en el contenedor de SQL Server: <pre><code>docker cp inventory.sql $id:/\n</code></pre></p> <p>Inicie sesi\u00f3n en el contenedor de SQL Server: <pre><code>docker exec -it $id bash\n</code></pre></p> <p>Construya la base de datos seg\u00fan el esquema: <pre><code>/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -i /inventory.sql\n</code></pre></p> <p>Ejecute algunas consultas simples (agregue -N -C si est\u00e1 usando SQL Server con SSL habilitado): <pre><code>/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -d testDB -Q \"insert into orders(order_date, purchaser, quantity, product_id) values( '2024-01-01', 1003, 2, 107)\"\n\n/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -d testDB -Q \"select * from orders\"\n</code></pre></p>"},{"location":"es/user-guide/quick_start/","title":"Gu\u00eda de Inicio R\u00e1pido","text":"<p>Es muy sencillo comenzar a usar SynchDB para realizar replicaci\u00f3n de datos desde bases de datos heterog\u00e9neas a PostgreSQL, siempre que tenga la informaci\u00f3n de conexi\u00f3n correcta para sus bases de datos heterog\u00e9neas.</p>"},{"location":"es/user-guide/quick_start/#instalar-la-extension-synchdb","title":"Instalar la Extensi\u00f3n SynchDB","text":"<p>La extensi\u00f3n SynchDB requiere pgcrypto para cifrar ciertos datos sensibles de credenciales. Aseg\u00farese de que est\u00e9 instalado antes de instalar SynchDB. Alternativamente, puede incluir la cl\u00e1usula <code>CASCADE</code> en <code>CREATE EXTENSION</code> para instalar autom\u00e1ticamente las dependencias:</p> <pre><code>CREATE EXTENSION synchdb CASCADE;\n</code></pre>"},{"location":"es/user-guide/quick_start/#crear-una-informacion-de-conexion","title":"Crear una Informaci\u00f3n de Conexi\u00f3n","text":"<p>Esto se puede hacer con la funci\u00f3n SQL de utilidad <code>synchdb_add_conninfo()</code>.</p> <p>synchdb_add_conninfo toma estos argumentos:</p> argumento descripci\u00f3n name un identificador \u00fanico que representa esta informaci\u00f3n del conector hostname la direcci\u00f3n IP o nombre de host de la base de datos heterog\u00e9nea port el n\u00famero de puerto para conectarse a la base de datos heterog\u00e9nea username nombre de usuario para autenticarse con la base de datos heterog\u00e9nea password contrase\u00f1a para autenticar el nombre de usuario source database este es el nombre de la base de datos fuente en la base de datos heterog\u00e9nea de la que queremos replicar los cambios destination database este es el nombre de la base de datos de destino en PostgreSQL para aplicar los cambios. Debe ser una base de datos v\u00e1lida que exista en PostgreSQL table (opcional) - expresado en la forma de <code>[database].[table]</code> o <code>[database].[schema].[table]</code> que debe existir en la base de datos heterog\u00e9nea para que el motor solo replique las tablas especificadas. Si se deja vac\u00edo, se replican todas las tablas connector el tipo de conector a utilizar (MySQL, Oracle, SQLServer... etc) rule file un archivo de reglas con formato JSON colocado bajo $PGDATA que este conector aplicar\u00e1 a sus reglas de traducci\u00f3n de tipo de datos predeterminadas. Consulte aqu\u00ed para m\u00e1s informaci\u00f3n <p>Ejemplos:</p> <ol> <li> <p>Crear un conector MySQL llamado <code>mysqlconn</code> para replicar desde la base de datos fuente <code>inventory</code> en MySQL a la base de datos de destino <code>postgres</code> en PostgreSQL, usando el archivo de reglas <code>myrule.json</code>: <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn',\n    '127.0.0.1',\n    3306,\n    'mysqluser',\n    'mysqlpwd',\n    'inventory',\n    'postgres',\n    '',\n    'mysql',\n    'myrule.json');\n</code></pre></p> </li> <li> <p>Crear un conector MySQL llamado <code>mysqlconn2</code> para replicar desde la base de datos fuente <code>inventory</code> a la base de datos de destino <code>mysqldb2</code> en PostgreSQL usando la regla de traducci\u00f3n predeterminada: <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn2', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'mysqldb2', \n    '', 'mysql', ''\n  );\n</code></pre></p> </li> <li> <p>Crear un conector SQLServer llamado 'sqlserverconn' para replicar desde la base de datos fuente 'testDB' a la base de datos de destino 'sqlserverdb' en PostgreSQL usando la regla de traducci\u00f3n predeterminada: <pre><code>SELECT \n  synchdb_add_conninfo(\n    'sqlserverconn', '127.0.0.1', 1433, \n    'sa', 'Password!', 'testDB', 'sqlserverdb', \n    '', 'sqlserver', ''\n  );\n</code></pre></p> </li> <li> <p>Crear un conector MySQL llamado <code>mysqlconn3</code> para replicar desde las tablas <code>orders</code> y <code>customers</code> de la base de datos fuente <code>inventory</code> a la base de datos de destino <code>mysqldb3</code> en PostgreSQL usando el archivo de reglas <code>myrule2.json</code>: <pre><code>SELECT \n  synchdb_add_conninfo(\n    'mysqlconn3', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'mysqldb3', \n    'inventory.orders,inventory.customers', \n    'mysql', 'myrule2.json'\n  );\n</code></pre></p> </li> </ol>"},{"location":"es/user-guide/quick_start/#puntos-a-tener-en-cuenta","title":"Puntos a Tener en Cuenta","text":"<ul> <li>Es posible crear m\u00faltiples conectores conect\u00e1ndose al mismo tipo de conector (ej, MySQL, SQLServer..etc). SynchDB generar\u00e1 conexiones separadas para obtener datos de cambios.</li> <li>El certificado X509 definido por el usuario y la clave privada para la conexi\u00f3n TLS a la base de datos remota ser\u00e1n compatibles en un futuro cercano. Mientras tanto, aseg\u00farese de que la configuraci\u00f3n TLS est\u00e9 configurada como opcional.</li> </ul>"},{"location":"es/user-guide/quick_start/#verificar-la-informacion-de-conexion-creada","title":"Verificar la Informaci\u00f3n de Conexi\u00f3n Creada","text":"<p>Toda la informaci\u00f3n de conexi\u00f3n se crea en la tabla <code>synchdb_conninfo</code>. Podemos ver su contenido y hacer modificaciones seg\u00fan sea necesario. Tenga en cuenta que la contrase\u00f1a de las credenciales de usuario est\u00e1 cifrada por pgcrypto usando una clave que solo conoce synchdb. As\u00ed que por favor no modifique el campo de contrase\u00f1a o puede descifrarse incorrectamente si se manipula. Vea a continuaci\u00f3n un ejemplo de salida:</p> <pre><code>postgres=# \\x\nExpanded display is on.\n\npostgres=# select * from synchdb_conninfo;\n-[ RECORD 1 ]-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nname | mysqlconn\ndata | {\"pwd\": \"\\\\xc30d040703024828cc4d982e47b07bd23901d03e40da5995d2a631fb89d49f748b87247aee94070f71ecacc4990c3e71cad9f68d57c440de42e35bcc78fd145feab03452e454284289db\", \"port\": 3306, \"user\": \"mysqluser\", \"dstdb\": \"postgres\", \"srcdb\": \"inventory\", \"table\": \"null\", \"hostname\": \"192.168.1.86\", \"connector\": \"mysql\"i, \"myrule.json\"}\n-[ RECORD 2 ]-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nname | sqlserverconn\ndata | {\"pwd\": \"\\\\xc30d0407030231678e1bb0f8d3156ad23a010ca3a4b0ad35ed148f8181224885464cdcfcec42de9834878e2311b343cd184fde65e0051f75d6a12d5c91d0a0403549fe00e4219215eafe1b\", \"port\": 1433, \"user\": \"sa\", \"dstdb\": \"sqlserverdb\", \"srcdb\": \"testDB\", \"table\": \"null\", \"hostname\": \"192.168.1.86\", \"connector\": \"sqlserver\", \"null\"}\n</code></pre>"},{"location":"es/user-guide/quick_start/#iniciar-un-conector","title":"Iniciar un Conector","text":"<p>Use la funci\u00f3n <code>synchdb_start_engine_bgw()</code> para iniciar un trabajador conector. Toma un argumento que es el nombre de conexi\u00f3n creado anteriormente. Este comando generar\u00e1 un nuevo trabajador en segundo plano para conectarse a la base de datos heterog\u00e9nea con las configuraciones especificadas.</p> <p>Por ejemplo, lo siguiente generar\u00e1 2 trabajadores en segundo plano en PostgreSQL, uno replicando desde una base de datos MySQL, el otro desde SQL Server:</p> <pre><code>select synchdb_start_engine_bgw('mysqlconn');\nselect synchdb_start_engine_bgw('sqlserverconn');\n</code></pre>"},{"location":"es/user-guide/quick_start/#verificar-el-estado-de-ejecucion-del-conector","title":"Verificar el Estado de Ejecuci\u00f3n del Conector","text":"<p>Use la vista <code>synchdb_state_view()</code> para examinar todos los conectores en ejecuci\u00f3n y sus estados. Actualmente, synchdb puede soportar hasta 30 trabajadores en ejecuci\u00f3n.</p> <p>Vea a continuaci\u00f3n un ejemplo de salida: <pre><code>postgres=# select * from synchdb_state_view;\n id | connector | conninfo_name  |  pid   |  state  |   err    |                                          last_dbz_offset\n----+-----------+----------------+--------+---------+----------+---------------------------------------------------------------------------------------------------\n  0 | mysql     | mysqlconn      | 461696 | syncing | no error | {\"ts_sec\":1725644339,\"file\":\"mysql-bin.000004\",\"pos\":138466,\"row\":1,\"server_id\":223344,\"event\":2}\n  1 | sqlserver | sqlserverconn  | 461739 | syncing | no error | {\"event_serial_no\":1,\"commit_lsn\":\"00000100:00000c00:0003\",\"change_lsn\":\"00000100:00000c00:0002\"}\n  2 | null      |                |     -1 | stopped | no error | no offset\n  3 | null      |                |     -1 | stopped | no error | no offset\n  4 | null      |                |     -1 | stopped | no error | no offset\n  5 | null      |                |     -1 | stopped | no error | no offset\n  ...\n  ...\n</code></pre></p> <p>Detalles de las Columnas:</p> campos descripci\u00f3n id identificador \u00fanico de un slot de conector connector el tipo de conector (mysql, oracle, sqlserver...etc) conninfo_name el nombre de informaci\u00f3n del conector asociado creado por <code>synchdb_add_conninfo()</code> pid el PID del proceso trabajador del conector state el estado del conector. Los estados posibles son: <ul><li>stopped - el conector no est\u00e1 ejecut\u00e1ndose</li><li>initializing - el conector est\u00e1 inicializando</li><li>paused - el conector est\u00e1 pausado</li><li>syncing - el conector est\u00e1 sondeando regularmente eventos de cambio</li><li>parsing - el conector est\u00e1 analizando un evento de cambio recibido</li><li>converting - el conector est\u00e1 convirtiendo un evento de cambio a representaci\u00f3n PostgreSQL</li><li>executing - el conector est\u00e1 aplicando el evento de cambio convertido a PostgreSQL</li><li>updating offset - el conector est\u00e1 escribiendo un nuevo valor de offset a la gesti\u00f3n de offset de Debezium</li><li>restarting - el conector est\u00e1 reiniciando</li><li>unknown</li></ul> err el \u00faltimo mensaje de error encontrado por el trabajador que habr\u00eda causado su salida. Este error podr\u00eda originarse desde PostgreSQL mientras procesa un cambio, o originarse desde el motor de ejecuci\u00f3n Debezium mientras accede a datos desde la base de datos heterog\u00e9nea last_dbz_offset el \u00faltimo offset de Debezium capturado por synchdb. Tenga en cuenta que esto puede no reflejar el valor de offset actual y en tiempo real del motor del conector. M\u00e1s bien, esto se muestra como un punto de control desde el que podr\u00edamos reiniciar si es necesario"},{"location":"es/user-guide/quick_start/#detener-un-conector","title":"Detener un Conector","text":"<p>Use la funci\u00f3n SQL <code>synchdb_stop_engine_bgw()</code> para detener un trabajador conector en ejecuci\u00f3n o pausado. Esta funci\u00f3n toma <code>conninfo_name</code> como su \u00fanico par\u00e1metro, que se puede encontrar en la salida de la vista <code>synchdb_get_state()</code>.</p> <p>Por ejemplo: <pre><code>select synchdb_stop_engine_bgw('mysqlconn');\n</code></pre></p> <p>La funci\u00f3n <code>synchdb_stop_engine_bgw()</code> tambi\u00e9n marca una informaci\u00f3n de conexi\u00f3n como <code>inactive</code>, lo que evita que este trabajador se relance autom\u00e1ticamente en los reinicios del servidor.</p>"},{"location":"es/user-guide/selective_table_sync/","title":"Sincronizaci\u00f3n Selectiva de Tablas","text":"<p>Es posible seleccionar solo tablas espec\u00edficas de una base de datos heterog\u00e9nea remota para enfocarse en la replicaci\u00f3n. Esto podr\u00eda evitar que se gasten recursos en replicar tablas no deseadas. </p>"},{"location":"es/user-guide/selective_table_sync/#seleccione-las-tablas-deseadas-e-inicielo-por-primera-vez","title":"Seleccione las tablas deseadas e in\u00edcielo por primera vez","text":"<p>La selecci\u00f3n de tablas se realiza durante la fase de creaci\u00f3n del conector a trav\u00e9s de <code>synchdb_add_conninfo()</code>, donde especificamos una lista de tablas (expresadas en FQN, separadas por una coma) para replicar desde.</p> <p>Por ejemplo, el siguiente comando crea un conector que solo replica los cambios de las tablas <code>inventory.orders</code> e <code>inventory.products</code> de la base de datos remota MySQL: <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', \n    '192.168.1.86', \n    3306, \n    'mysqluser', \n    'mysqlpwd', \n    'inventory', \n    'postgres', \n    'inventory.orders,inventory.products', \n    'mysql', \n    'myrule.json'\n);\n</code></pre></p> <p>Iniciar este conector por primera vez activar\u00e1 una instant\u00e1nea inicial y se replicar\u00e1n el esquema y los datos de las 2 tablas seleccionadas.</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre>"},{"location":"es/user-guide/selective_table_sync/#verifique-el-estado-del-conector-y-las-tablas","title":"Verifique el estado del conector y las tablas","text":"<p>Examine el estado del conector y las nuevas tablas: <pre><code>postgres=# SELECT * FROM synchdb_state_view WHERE conninfo_name='mysqlconn';\n id | connector | conninfo_name |  pid   |  state  |   err    |       last_dbz_offset\n----+-----------+---------------+--------+---------+----------+-----------------------------\n  0 | mysql     | mysqlconn     | 807536 | syncing | no error | offset file not flushed yet\n(1 row)\n\npostgres=# SET search_path TO inventory;\nSET\npostgres=# \\d\n                 List of relations\n  Schema   |        Name        |   Type   | Owner\n-----------+--------------------+----------+--------\n inventory | products           | table    | ubuntu\n inventory | products_id_seq    | sequence | ubuntu\n inventory | orders             | table    | ubuntu\n inventory | orders_ididid_seq  | sequence | ubuntu\n public    | synchdb_conninfo   | table    | ubuntu\n public    | synchdb_state_view | view     | ubuntu\n(6 rows)\n\npostgres=#\n</code></pre></p> <p>Una vez que se complete la instant\u00e1nea, el conector <code>mysqlconn</code> continuar\u00e1 capturando cambios posteriores en las tablas <code>inventory.orders</code> e <code>inventory.products</code>..</p>"},{"location":"es/user-guide/selective_table_sync/#agregue-mas-tablas-para-replicar-durante-el-tiempo-de-ejecucion","title":"Agregue m\u00e1s tablas para replicar durante el tiempo de ejecuci\u00f3n","text":"<p>El <code>mysqlconn</code> de la secci\u00f3n anterior ya ha completado la instant\u00e1nea inicial y obtenido los esquemas de tabla de la tabla seleccionada. Si desea agregar m\u00e1s tablas para replicar desde, deber\u00e1 notificar al motor Debezium sobre la secci\u00f3n de tabla actualizada y realizar la instant\u00e1nea inicial nuevamente. As\u00ed es como se hace:</p> <ol> <li>Actualice la tabla <code>synchdb_conninfo</code> para incluir tablas adicionales.</li> <li>En este ejemplo, agregamos la tabla inventory.customers a la lista de sincronizaci\u00f3n: <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"inventory.orders,inventory.products,inventory.customers\"') \nWHERE name = 'mysqlconn';\n</code></pre></li> <li>Reinicie el conector con el modo de instant\u00e1nea establecido en always para realizar otra instant\u00e1nea inicial: <pre><code>SELECT synchdb_restart_connector('mysqlconn', 'always');\n</code></pre> Esto obliga a Debezium a volver a realizar una instant\u00e1nea de todas las tablas especificadas, incluso si dos de ellas ya tienen los datos.</li> </ol> <p>Tenga en cuenta que si el tipo de base de datos heterog\u00e9nea no admite la replicaci\u00f3n de DDL (como SQLServer), es posible que obtenga un error de conflicto de datos cuando se reconstruye la instant\u00e1nea en las 2 tablas previamente seleccionadas para la replicaci\u00f3n. Si este es el caso, es posible que deba eliminarlas o truncarlas antes de reiniciar el conector con el modo de instant\u00e1nea = 'always'.</p>"},{"location":"es/user-guide/selective_table_sync/#verifique-las-tablas-actualizadas","title":"Verifique las tablas actualizadas","text":"<p>Ahora, podemos examinar nuestras tablas nuevamente: <pre><code>postgres=# SET search_path TO inventory;\nSET\npostgres=# \\d\n                 List of relations\n  Schema   |        Name        |   Type   | Owner\n-----------+--------------------+----------+--------\n inventory | products           | table    | ubuntu\n inventory | products_id_seq    | sequence | ubuntu\n inventory | orders             | table    | ubuntu\n inventory | orders_ididid_seq  | sequence | ubuntu\n inventory | customers          | table    | ubuntu\n inventory | customers_id_seq   | sequence | ubuntu\n public    | synchdb_conninfo   | table    | ubuntu\n public    | synchdb_state_view | view     | ubuntu\n(8 rows)\n\npostgres=#\n</code></pre></p>"},{"location":"es/user-guide/selective_table_sync/#modos-de-instantanea","title":"Modos de instant\u00e1nea","text":"<p>SynchDB ofrece diferentes modos de instant\u00e1nea, seg\u00fan sus necesidades de replicaci\u00f3n:</p> setting description always El conector realiza una instant\u00e1nea cada vez que se inicia. La instant\u00e1nea incluye la estructura y los datos de las tablas capturadas. Despu\u00e9s de que se completa la instant\u00e1nea, el conector comienza a transmitir registros de eventos para cambios posteriores en la base de datos. initial (default) El conector realiza una instant\u00e1nea de la base de datos si a\u00fan no se ha realizado. Despu\u00e9s de que se completa la instant\u00e1nea, el conector comienza a transmitir registros de eventos para cambios posteriores en la base de datos. initial_only El conector realiza una instant\u00e1nea de la base de datos. Despu\u00e9s de que se completa la instant\u00e1nea, el conector se detiene y no transmite registros de eventos para cambios posteriores en la base de datos. no_data El conector captura la estructura de todas las tablas relevantes, pero no los datos que contienen. never Cuando se inicia el conector, en lugar de realizar una instant\u00e1nea, comienza inmediatamente a transmitir registros de eventos para cambios posteriores en la base de datos. recovery Configure esta opci\u00f3n para restaurar un historial de esquema de base de datos que est\u00e1 perdido o da\u00f1ado. Despu\u00e9s de un reinicio, el conector ejecuta una instant\u00e1nea que reconstruye el tema de las tablas de origen when_needed Despu\u00e9s de que se inicia el conector, realiza una instant\u00e1nea solo si detecta una de las siguientes circunstancias:<ul><li>No puede detectar ning\u00fan desplazamiento del tema</li><li>Una compensaci\u00f3n registrada previamente especifica una posici\u00f3n de registro que no est\u00e1 disponible en el servidor</li></ul>"},{"location":"es/user-guide/transform_rule_file/","title":"Archivo de Reglas de Transformaci\u00f3n","text":"<p>El archivo de reglas de transformaci\u00f3n es un archivo de configuraci\u00f3n adicional escrito en formato JSON que describe varias reglas de transformaci\u00f3n que un conector SynchDB debe seguir al recibir datos de tabla desde una base de datos heterog\u00e9nea remota. Este archivo debe colocarse en el directorio <code>$PGDATA</code> y se selecciona cuando se crea un conector utilizando la funci\u00f3n SQL <code>synchdb_add_conninfo()</code>. Es posible no utilizar un archivo de reglas de transformaci\u00f3n personalizado al crear un nuevo conector; en este caso, se aplicar\u00e1n las reglas de transformaci\u00f3n predeterminadas.</p>"},{"location":"es/user-guide/transform_rule_file/#sample-rule-file","title":"Sample rule file","text":"<pre><code>{\n  \"transform_datatype_rules\": [\n    {\n      \"translate_from\": \"GEOMETRY\",\n      \"translate_from_autoinc\": false,\n      \"translate_to\": \"TEXT\",\n      \"translate_to_size\": -1\n    },\n    {\n      \"translate_from\": \"POINT\",\n      \"translate_from_autoinc\": false,\n      \"translate_to\": \"TEXT\",\n      \"translate_to_size\": -1\n    },\n    {\n      \"translate_from\": \"inventory.geom.g.GEOMETRY\",\n      \"translate_from_autoinc\": false,\n      \"translate_to\": \"GEOMETRY\",\n      \"translate_to_size\": 0\n    },\n    {\n      \"translate_from\": \"inventory.orders.quantity.INT\",\n      \"translate_from_autoinc\": false,\n      \"translate_to\": \"BIGINT\",\n      \"translate_to_size\": 0\n    }\n  ],\n  \"transform_objectname_rules\": [\n    {\n      \"object_type\": \"table\",\n      \"source_object\": \"inventory.orders\",\n      \"destination_object\": \"schema1.orders\"\n    },\n    {\n      \"object_type\": \"table\",\n      \"source_object\": \"inventory.products\",\n      \"destination_object\": \"products\"\n    },\n    {\n      \"object_type\": \"column\",\n      \"source_object\": \"inventory.orders.order_number\",\n      \"destination_object\": \"ididid\"\n    },\n    {\n      \"object_type\": \"column\",\n      \"source_object\": \"inventory.orders.purchaser\",\n      \"destination_object\": \"the_dude\"\n    },\n    {\n      \"object_type\": \"column\",\n      \"source_object\": \"inventory.orders.quantity\",\n      \"destination_object\": \"the_numba\"\n    },\n    {\n      \"object_type\": \"column\",\n      \"source_object\": \"testDB.dbo.customers.first_name\",\n      \"destination_object\": \"the_awesome_first_name\"\n    }\n  ],\n  \"transform_expression_rules\": [\n    {\n      \"transform_from\": \"inventory.orders.quantity\",\n      \"transform_expression\": \"case when %d &lt; 500 then 0 else %d end\"\n    },\n    {\n      \"transform_from\": \"inventory.geom.g\",\n      \"transform_expression\": \"ST_SetSRID(ST_GeomFromWKB(decode('%w', 'base64')),%s)\"\n    },\n    {\n      \"transform_from\": \"inventory.products.name\",\n      \"transform_expression\": \"'&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\"\n    },\n    {\n      \"transform_from\": \"inventory.products.description\",\n      \"transform_expression\": \"'&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\"\n    }\n  ]\n}\n</code></pre>"},{"location":"es/user-guide/transform_rule_file/#transform-data-type-rules","title":"Transform Data Type Rules","text":"<p>Las reglas de transformaci\u00f3n de tipos de datos influyen en c\u00f3mo SynchDB mapea un tipo de dato desde una base de datos heterog\u00e9nea de origen a un tipo de dato equivalente en PostgreSQL. Estas reglas pueden escribirse para aplicarse a todas las tablas de origen o solo a tablas seleccionadas. Si no hay una regla de tipo de dato disponible para un tipo particular, SynchDB utilizar\u00e1 las reglas de mapeo de tipos de datos predeterminadas.</p> <p>Custom data type transform rules can be defined with a JSON array with name <code>\"transform_datatype_rules\"</code> and each element in the array must contain the following objects:</p> Description Example translate_from the data type name or Fully Qualified Name (FQN) from heterogeneous database to transform from. The FQN consists of: [database].[schema (if present)].[table name].[column name].[data type]: <ul><li>If FQN is specified, then the transformation will only be applied to a specific table's specific column.</li><li> If FQN is not used, the transformation will be applied globally if data type name matches. </li></ul> GEOMETRYPOINTinventory.geom.g.GEOMETRYinventory.orders.quantity.INT translate_from_autoinc indicate if the data type specified in <code>\"translate_from\"</code> is marked as auto increment. falsetrue translate_to the PostgreSQL data type to translate to. See below for list of supported PostgreSQL data types. It is possible to specify data types not natively supported by PostgreSQL, for example GEOMETRY, please ensure that the data type has already been installed before starting a connector using it. TEXTVARCHARBIGINTGEOMETRY translate_to_size indicate if we should transform the size of the data type specifed in <code>\"translate_to\"</code>: <ul><li> 0: Remove any length specifier because the PostgreSQL data type transformed does not need length specifier. For example: TEXT </li><li> -1: Use whatever length specifier from the source heterogeneous database (if available) and map it directly to the translated datatype. For example: VARCHAR(32).</li><li> others: put any other values to force the size of translated data type. Use it with caution. </li></ul> 0-1457000"},{"location":"es/user-guide/transform_rule_file/#tipos-de-datos-postgresql-soportados","title":"Tipos de Datos PostgreSQL Soportados","text":"<p>SynchDB es compatible con los siguientes tipos de datos nativos de PostgreSQL que pueden transformarse durante la creaci\u00f3n de la tabla. Sin embargo, es posible transformar un tipo de dato externo a un tipo de dato PostgreSQL que no est\u00e9 en la lista siguiente. Por ejemplo, el tipo de dato <code>GEOMETRY</code> a\u00f1adido por PostGIS. En este caso, la tabla se crea con el tipo de dato <code>GEOMETRY</code>, pero los datos que SynchDB recibe se formatear\u00e1n e insertar\u00e1n como <code>TEXT</code>. Depende de usted decidir si estos datos necesitan ser procesados por una expresi\u00f3n o funci\u00f3n SQL (ver reglas de expresi\u00f3n de transformaci\u00f3n m\u00e1s abajo) antes de que puedan aplicarse a PostgreSQL.</p> <ul> <li>BOOLEAN (BOOLOID)</li> <li>BIGINT (INT8OID)</li> <li>SMALLINT (INT2OID)</li> <li>INT (INT4OID)</li> <li>INTEGER (INT4OID)</li> <li>DOUBLE PRECISION (FLOAT8OID)</li> <li>REAL (FLOAT4OID)</li> <li>MONEY (MONEYOID)</li> <li>NUMERIC (NUMERICOID)</li> <li>CHAR (BPCHAROID)</li> <li>CHARACTER (BPCHAROID)</li> <li>TEXT (TEXTOID)</li> <li>VARCHAR (VARCHAROID)</li> <li>CHARACTER VARYING (VARCHAROID)</li> <li>TIMESTAMPTZ (TIMESTAMPTZOID)</li> <li>JSONB (JSONBOID)</li> <li>UUID (UUIDOID)</li> <li>VARBIT (VARBITOID)</li> <li>BIT VARYING (VARBITOID)</li> <li>BIT (BITOID)</li> <li>DATE (DATEOID)</li> <li>TIMESTAMP (TIMESTAMPOID)</li> <li>TIME (TIMEOID)</li> <li>BYTEA (BYTEAOID)</li> </ul>"},{"location":"es/user-guide/transform_rule_file/#reglas-de-transformacion-de-nombres-de-objetos","title":"Reglas de Transformaci\u00f3n de Nombres de Objetos","text":"<p>Las reglas de transformaci\u00f3n de nombres de objetos determinan c\u00f3mo SynchDB mapea un nombre de tabla o columna desde una base de datos heterog\u00e9nea a nombres de tabla o columna de PostgreSQL.</p> <p>Las reglas de transformaci\u00f3n de tipos de datos se pueden definir con un array JSON con el nombre <code>\"transform_objectname_rules\"</code> y cada elemento en el array debe contener los siguientes objetos:</p> description example object type el tipo de objeto de este elemento de transformaci\u00f3n. Puede ser: <ul><li> <code>table</code> para indicar que la transformaci\u00f3n se realizar\u00e1 en nombres de tablas. </li><li><code>column</code> para indicar que la transformaci\u00f3n se realizar\u00e1 en nombres de columnas. </li></ul> tablecolumn source_object El Nombre Completamente Calificado (FQN) del objeto fuente desde la base de datos heterog\u00e9nea. <ul><li> Si <code>object_type</code> es <code>table</code>, el FQN consiste en [database].[schema].[table] o [database].[table]. </li><li> Si <code>object_type</code> es <code>column</code>, el FQN consiste en [database].[schema].[table].[column] o [database].[table].[column]. </li></ul> Tenga en cuenta que algunas bases de datos heterog\u00e9neas (como SQLServer) son sensibles a may\u00fasculas y min\u00fasculas con los nombres, as\u00ed que aseg\u00farese de que el FQN est\u00e9 construido correctamente con las may\u00fasculas y min\u00fasculas correctas. falsetrue destination_object El nombre a utilizar en PostgreSQL para representar el <code>source_object</code> de la base de datos heterog\u00e9nea: <ul><li>Si <code>object_type</code> es <code>table</code>, el <code>destination_object</code> puede contener un nombre de esquema opcional seguido de un nombre de tabla separado por un punto. Si no se indica esquema, se utilizar\u00e1 el esquema <code>public</code> por defecto.</li><li> Si <code>object_type</code> es <code>column</code>, el <code>destination_object</code> solo puede contener un nombre (sin esquema). myschema1.mytable1mytable2the_dudethe_numba <p>Si un nombre de tabla o columna no tiene reglas de transformaci\u00f3n de nombres de objetos coincidentes, la transformaci\u00f3n predeterminada se aplicar\u00e1 autom\u00e1ticamente como se indica a continuaci\u00f3n:</p> Remote object FQN Regla de transformaci\u00f3n predeterminada de nombres de objetos en PostgreSQL [database].[table] <ul><li> [database] \u2192 [schema]. </li><li> [table] \u2192 [table]. </li></ul> [database].[schema].[table] <ul><li> [database] \u2192 [schema]. </li><li> [schema] es ignorado. </li><li> [table] \u2192 [table]. </li></ul>"},{"location":"es/user-guide/transform_rule_file/#reglas-de-expresion-de-transformacion","title":"Reglas de Expresi\u00f3n de Transformaci\u00f3n","text":"<p>Las reglas de expresi\u00f3n de transformaci\u00f3n indican a SynchDB si necesita realizar \"expresiones\" adicionales en los datos recibidos antes de aplicarlos a PostgreSQL. Esta caracter\u00edstica permite a SynchDB cambiar la representaci\u00f3n de los datos sin l\u00f3gica adicional de aplicaci\u00f3n en el lado de PostgreSQL.</p> <p>Las reglas de tipos de datos de transformaci\u00f3n se pueden definir con un array JSON con el nombre <code>\"transform_expression_rules\"</code> y cada elemento en el array debe contener los siguientes objetos:</p> Description Example transform_from el Nombre Completamente Calificado (FQN) de una columna remota que puede tener uno de estos formatos:<ul><li> [database].[schema].[table].[column] </li><li> [database].[table].[column] </li></ul> inventory.orders.quantitytestDB.dbo.products.description transform_expression la expresi\u00f3n a ejecutar en los datos recibidos. Puede usar estos tokens de marcador de posici\u00f3n para construir una expresi\u00f3n: <ul><li> %d: se reemplazar\u00e1 con los datos recibidos </li><li> %w: representaci\u00f3n binaria conocida. Estar\u00e1 presente si los datos representan datos de geometr\u00eda o geograf\u00eda </li><li> %s: SRID. Estar\u00e1 presente si los datos representan datos de geometr\u00eda o geograf\u00eda </li></ul> la expresi\u00f3n puede escribirse en cualquier sintaxis SQL est\u00e1ndar soportada por PostgreSQL. 1. <code>case when %d &lt; 500 then 0 else %d end</code>  establece un valor a 0 si es menor que 500, de lo contrario mantiene su valor original  2.<code>ST_SetSRID(ST_GeomFromWKB(decode('%w', 'base64')),%s)</code> Convierte datos de geometr\u00eda WKB codificados en base64 a un objeto de geometr\u00eda PostGIS con un sistema de referencia espacial especificado (SRID) 3. <code>'&gt;&gt;&gt;&gt;&gt;' \\|\\| '%d' \\|\\| '&lt;&lt;&lt;&lt;&lt;'</code> agrega marcadores visuales alrededor de un valor"},{"location":"zh/","title":"\u5173\u4e8e","text":""},{"location":"zh/#synchdb","title":"\u5173\u4e8e SynchDB","text":"<p>SynchDB \u662f\u4e00\u4e2a PostgreSQL \u6269\u5c55\uff0c\u652f\u6301\u4ece\u5f02\u6784\u6570\u636e\u5e93\uff08\u4f8b\u5982 MySQL\u3001SQL Server \u548c Oracle\uff09\u76f4\u63a5\u5feb\u901f\u53ef\u9760\u5730\u590d\u5236\u5230 PostgreSQL\u3002\u4e0e\u4f20\u7edf\u7684\u6570\u636e\u7ba1\u9053\u4e0d\u540c\uff0cSynchDB \u5728 PostgreSQL \u5185\u90e8\u539f\u751f\u5904\u7406\u6574\u4e2a\u540c\u6b65\u548c\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\uff0c\u65e0\u9700\u4efb\u4f55\u4e2d\u95f4\u4ef6\u6216\u5916\u90e8\u7f16\u6392\u5de5\u5177\u3002\u5b83\u4e3b\u8981\u7ba1\u7406\u4ee5\u4e0b\u7aef\u5230\u7aef\u4efb\u52a1\uff1a</p> <ul> <li>\u5efa\u7acb\u5e76\u7ef4\u62a4\u4e0e\u5916\u90e8\u6570\u636e\u5e93\u7684\u8fde\u63a5</li> <li>\u4ece\u6e90\u7cfb\u7edf\u6355\u83b7\u53d8\u66f4\u4e8b\u4ef6</li> <li>\u5c06\u8fd9\u4e9b\u4e8b\u4ef6\u8f6c\u6362\u4e3a\u4e0e PostgreSQL \u517c\u5bb9\u7684\u683c\u5f0f</li> <li>\u5c06\u5b83\u4eec\u5e94\u7528\u4e8e PostgreSQL</li> </ul> <p>SynchDB \u7684\u6838\u5fc3\u96c6\u6210\u4e86 Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e Java \u7684\u5f3a\u5927\u53d8\u66f4\u6570\u636e\u6355\u83b7 (CDC) \u5e93\uff0c\u652f\u6301\u591a\u79cd\u6570\u636e\u5e93\u8fde\u63a5\u5668\u3002 SynchDB \u4f7f\u7528 Java \u539f\u751f\u63a5\u53e3 (JNI) \u8fde\u63a5 PostgreSQL \u57fa\u4e8e C \u8bed\u8a00\u7684\u8fd0\u884c\u65f6\u548c Debezium \u7684 Java \u73af\u5883\uff0c\u4ece\u800c\u5b9e\u73b0\u4e24\u8005\u4e4b\u95f4\u7684\u65e0\u7f1d\u534f\u4f5c\u3002</p> <p>\u8fd9\u79cd\u67b6\u6784\u4f7f PostgreSQL \u80fd\u591f\u5145\u5206\u5229\u7528 Debezium \u4e30\u5bcc\u7684\u8fde\u63a5\u5668\u751f\u6001\u7cfb\u7edf\uff0c\u540c\u65f6\u4fdd\u6301\u6269\u5c55\u7684\u8f7b\u91cf\u7ea7\u3001\u7075\u6d3b\u6027\u548c\u6613\u4e8e\u90e8\u7f72\u3002</p> <p>\ud83d\udd17 \u4e86\u89e3\u66f4\u591a\u5173\u4e8e Debezium \u7684\u4fe1\u606f\uff0c\u8bf7\u70b9\u51fb\u6b64\u5904 (https://debezium.io/documentation/reference/stable/index.html)\u3002</p>"},{"location":"zh/#_2","title":"\u4e3b\u8981\u7279\u6027","text":"<ul> <li>\u9ad8\u6548\u7684\u6570\u636e\u540c\u6b65</li> <li>\u652f\u6301\u4ece MySQL\u3001SQL Server \u548c Oracle \u6570\u636e\u5e93\u590d\u5236</li> <li>\u7075\u6d3b\u7684\u6570\u636e\u8f6c\u6362\u89c4\u5219\uff0c\u5305\u62ec\u8868\u540d\u3001\u5217\u540d\u3001\u6570\u636e\u7c7b\u578b\u548c\u81ea\u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u8868\u8fbe\u5f0f</li> <li>\u8f7b\u677e\u4e0e\u73b0\u6709 PostgreSQL \u6570\u636e\u5e93\u96c6\u6210</li> <li>\u521d\u59cb\u5feb\u7167\u548c\u53d8\u66f4\u6570\u636e\u6355\u83b7 (CDC) \u6a21\u5f0f</li> <li>\u652f\u6301 DDL \u548c DML \u903b\u8f91\u590d\u5236</li> <li>\u5168\u5c40\u8fde\u63a5\u5668\u72b6\u6001\u3001\u9519\u8bef\u548c\u7edf\u8ba1\u4fe1\u606f\u914d\u7f6e</li> </ul>"},{"location":"zh/#postgresql","title":"\u652f\u6301\u7684 PostgreSQL \u7248\u672c","text":"<ul> <li>PostgreSQL\uff1a16\u300117\u300118</li> <li>IvorySQL\uff1a4\u30015</li> </ul>"},{"location":"zh/#_3","title":"\u652f\u6301\u7684\u6e90\u6570\u636e\u5e93","text":"<ul> <li>MySQL\uff1a8.0.x\u30018.2</li> <li>SQL Server\uff1a2017\u30012019\u30012022</li> <li>Oracle\uff1a12c\u300119c\u300121c\u300123ai</li> <li>Openlog Replicator\uff1a1.3.0 ~ 1.8.5</li> </ul>"},{"location":"zh/#_4","title":"\u6240\u9700\u7684\u7b2c\u4e09\u65b9\u5e93","text":"<ul> <li>Java Runtime Environment\uff08JRE\uff0917 \u6216\u66f4\u9ad8\u7248\u672c</li> <li>libprotobuf-c v1.5.2\uff08\u5982\u679c\u9700\u8981 Openlog Replicator \u652f\u6301\uff09</li> </ul>"},{"location":"zh/#_5","title":"\u6240\u9700\u7684\u7b2c\u4e09\u65b9\u5e93\u548c\u63d2\u4ef6","text":"<ul> <li>Java \u57f7\u884c\u6642\u671f\u74b0\u5883 (JRE) 17 \u6216\u66f4\u9ad8\u7248\u672c</li> <li>pgcrypto \u64f4\u5145 - \u7528\u65bc\u52a0\u5bc6\u548c\u89e3\u5bc6\u6191\u8b49</li> </ul>"},{"location":"zh/#_6","title":"\u53ef\u9078\u7684\u7b2c\u4e09\u65b9\u5eab\u548c\u63d2\u4ef6","text":"<ul> <li>libprotobuf-c v1.5.2\uff08\u5df2\u6e2c\u8a66\u7248\u672c\uff09\uff08Openlog Replicator \u652f\u63f4\u53ef\u9078\uff09</li> <li>oracle_fdw \u64f4\u5145\u529f\u80fd v2.8.0\uff08\u5df2\u6e2c\u8a66\u7248\u672c\uff09\uff08\u5982\u679c\u60a8\u9078\u64c7\u4f7f\u7528\u57fa\u65bc fdw \u7684\u521d\u59cb\u5feb\u7167\u4f86\u5efa\u7acb OLR \u6216 Oracle \u9023\u63a5\u5668\uff0c\u5247\u9700\u8981\u6b64\u64f4\u5145\uff09</li> <li>mysql_fdw \u64f4\u5145\u529f\u80fd v2.9.3\uff08\u5df2\u6e2c\u8a66\u7248\u672c\uff09\uff08\u5982\u679c\u60a8\u9078\u64c7\u4f7f\u7528\u57fa\u65bc fdw \u7684\u521d\u59cb\u5feb\u7167\u4f86\u5efa\u7acb MySQL \u9023\u63a5\u5668\uff0c\u5247\u9700\u8981\u6b64\u64f4\u5145\u529f\u80fd\uff09</li> <li>postgres_fdw \u64f4\u5145\u529f\u80fd -\uff08\u5982\u679c\u60a8\u9700\u8981\u70ba PostgreSQL \u9023\u63a5\u5668\u5efa\u7acb\u521d\u59cb\u5feb\u7167\uff0c\u5247\u9700\u8981\u6b64\u64f4\u5145\u529f\u80fd\uff09</li> </ul>"},{"location":"zh/#_7","title":"\u7248\u672c\u5386\u53f2","text":"<ul> <li>SynchDB v1.3</li> <li>SynchDB v1.2</li> <li>SynchDB v1.1</li> <li>SynchDB v1.0</li> <li>SynchDB v1.0 Beta1</li> </ul>"},{"location":"zh/#_8","title":"\u5feb\u901f\u5165\u95e8","text":"<p>\u5f00\u59cb\u4f7f\u7528 SynchDB \u7684\u6700\u5feb\u65b9\u6cd5\u662f\u4f7f\u7528\u9884\u7f16\u8bd1\u7684 Docker \u955c\u50cf\u4ee5\u53ca\u6e90\u6570\u636e\u5e93\u7cfb\u7edf\uff08MySQL\u3001SQL Server\u3001Oracle \u7b49\uff09\u7684\u914d\u5957\u955c\u50cf\uff0c\u6240\u6709\u8fd9\u4e9b\u955c\u50cf\u5747\u7531\u6e90\u5b58\u50a8\u5e93\u4e2d\u7684 <code>ezdeploy.sh</code> \u5de5\u5177\u9a71\u52a8\u3002\u6b64\u4ea4\u4e92\u5f0f\u5de5\u5177\u53ef\u4ee5\u542f\u52a8 SynchDB\u3001\u4e00\u4e2a\u6216\u591a\u4e2a\u6e90\u6570\u636e\u5e93\uff0c\u4ee5\u53ca\u53ef\u9009\u7684 Prometheus + Grafana \u7528\u4e8e\u76d1\u63a7\uff0c\u975e\u5e38\u9002\u5408\u8fdb\u884c\u5feb\u901f\u7684\u7aef\u5230\u7aef\u6d4b\u8bd5\u3002\u8bf7\u53c2\u9605 \u5feb\u901f\u5165\u95e8\u6307\u5357\u3002</p> <p>\u5176\u4ed6\u5b9e\u7528\u94fe\u63a5\uff1a</p> <ul> <li>SynchDB \u67b6\u6784\u51b3\u7b56</li> <li>\u5b89\u88c5\u6307\u5357</li> <li>\u6e90\u6570\u636e\u5e93\u8bbe\u7f6e</li> </ul>"},{"location":"zh/changelog/","title":"\u53d8\u66f4\u65e5\u5fd7","text":"<p>\u672c\u9879\u76ee\u7684\u6240\u6709\u91cd\u8981\u53d8\u66f4\u90fd\u5c06\u8bb0\u5f55\u5728\u6b64\u6587\u4ef6\u4e2d\u3002</p> <p>\u672c\u6587\u683c\u5f0f\u57fa\u4e8e Keep a Changelog\uff0c \u4e14\u672c\u9879\u76ee\u9075\u5faa \u8bed\u4e49\u5316\u7248\u672c\u3002</p>"},{"location":"zh/changelog/#synchdb-13-2025-11-25","title":"SynchDB 1.3 - 2025-11-25","text":"<p>SynchDB 1.3 \u6191\u85c9\u5168\u65b0\u7684\u57fa\u65bc FDW \u7684\u5feb\u7167\u5f15\u64ce\uff0c\u986f\u8457\u63d0\u5347\u4e86\u6548\u80fd\uff0c\u521d\u59cb\u5feb\u7167\u901f\u5ea6\u9060\u8d85 Debezium\u3002\u9019\u9805\u6539\u9032\u4f7f\u5f97 OpenLog Replicator (OLR) \u9023\u63a5\u5668\u6210\u70ba\u4e00\u500b\u5b8c\u5168\u539f\u751f\u7684\u5feb\u7167 + CDC \u7ba1\u7dda\uff08\u7121\u9700\u4f7f\u7528 Debezium\uff09\uff0c\u5f9e\u800c\u986f\u8457\u964d\u4f4e\u4e86\u5927\u578b Oracle \u8cc7\u6599\u96c6\u7684\u5ef6\u9072\u548c\u958b\u92b7\u3002\u5e73\u53f0\u652f\u63f4\u4e5f\u5f97\u5230\u4e86\u64f4\u5c55\u3002 SynchDB \u73fe\u5728\u53ef\u5728 PostgreSQL 18 \u548c IvorySQL 5 \u4e0a\u904b\u884c\uff0c\u4e26\u91dd\u5c0d\u6574\u500b\u7cfb\u7d71\u9032\u884c\u4e86\u4e00\u7cfb\u5217\u6548\u80fd\u6700\u4f73\u5316\u548c I/O \u6539\u9032\u3002</p>"},{"location":"zh/changelog/#_2","title":"\u65b0\u589e","text":""},{"location":"zh/changelog/#fdw","title":"\u57fa\u65bc FDW \u7684\u5feb\u7167\u5f15\u64ce","text":"<ul> <li>\u57fa\u65bc FDW \u7684\u5feb\u7167\u5f15\u64ce\u6bd4 Debezium \u7684\u521d\u59cb\u5feb\u7167\u6d41\u7a0b\u901f\u5ea6\u66f4\u5feb\u3002</li> <li>\u65b0\u589e GUC \u53c3\u6578\u201csynchdb.snapshot_engine\u201d\uff0c\u7528\u65bc\u9078\u64c7\u5feb\u7167\u5f15\u64ce\uff0c\u53ef\u4ee5\u662f\u201cdebezium\u201d\u6216\u201cfdw\u201d\u3002</li> <li>\u65b0\u589e GUC \u53c3\u6578\u201csynchdb.cdc_start_delay_ms\u201d\uff0c\u7528\u65bc\u5728\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\u3001CDC \u555f\u52d5\u524d\u65b0\u589e\u6beb\u79d2\u5ef6\u9072\u3002</li> <li>\u65b0\u589e GUC \u53c3\u6578\u201csynchdb.fdw_migrate_with_subtx\u201d\uff0c\u7528\u65bc\u5728\u57fa\u65bc FDW \u7684\u5feb\u7167\u6d41\u7a0b\u4e2d\u662f\u5426\u4f7f\u7528\u5b50\u4ea4\u6613\u9077\u79fb\u6bcf\u500b\u8cc7\u6599\u8868\u3002</li> <li>\u50c5\u9069\u7528\u65bc\u900f\u904e oracle_fdw 2.8.0 \u9023\u63a5\u7684 Openlog Replicator \u548c Oracle \u9023\u63a5\u5668\u985e\u578b\u3002\u5176\u4ed6\u9023\u63a5\u5668\u985e\u578b\u53ef\u80fd\u6703\u5728\u672a\u4f86\u7684\u7248\u672c\u4e2d\u5f97\u5230\u652f\u63f4\u3002</li> <li>\u652f\u63f4\u91cd\u8a66\u6a5f\u5236\uff1a\u5982\u679c\u67d0\u4e9b\u8868\u5feb\u7167\u5931\u6557\uff0c\u932f\u8aa4\u8a0a\u606f\u5c07\u4fdd\u5b58\u5230 synchdb_fdw_snapshot_errors_xxx \u8868\u4e2d\uff0c\u53ef\u4ee5\u900f\u904e\u6062\u5fa9\u9023\u63a5\u5668\u9032\u884c\u91cd\u8a66\u3002\u6210\u529f\u5feb\u7167\u7684\u8868\u5c07\u4fdd\u7559\u3002</li> <li>\u5982\u679c\u4f7f\u7528\u300cschemasync\u300d\u6216\u300cnodata\u300d\u5feb\u7167\u6a21\u5f0f\uff0cFDW \u5f15\u64ce\u5c07\u50c5\u540c\u6b65\u8868\u6a21\u5f0f\u3002</li> <li>\u900f\u904e FDW \u5f15\u64ce\u5efa\u7acb\u7684\u8868\u683c\u548c\u8cc7\u6599\u53d7\u300csynchdb_objmap\u300d\u4e2d\u5b9a\u7fa9\u7684\u540d\u7a31\u548c\u8868\u9054\u5f0f\u8f49\u63db\u898f\u5247\u7684\u7d04\u675f\u3002</li> <li>\u65b0\u589e\u51fd\u6578 synchdb_translate_datatype()\uff0c\u8a72\u51fd\u6578\u6703\u6839\u64da\u6240\u9078\u9023\u63a5\u5668\u985e\u578b\u50b3\u56de SynchDB \u7684\u8cc7\u6599\u985e\u578b\u8f49\u63db\u7d50\u679c\u3002</li> </ul>"},{"location":"zh/changelog/#_3","title":"\u6539\u9032\u7684\u7d71\u8a08\u8996\u5716","text":"<ul> <li>\u6539\u9032\u4e86\u7d71\u8a08\u8996\u5716\uff0c\u5c07\u4e0d\u540c\u7684\u7d71\u8a08\u8cc7\u6599\u5206\u7d44\u5230\u9069\u7576\u7684\u985e\u5225\u3002</li> <li>\u5df2\u79fb\u9664 synchdb_stats_view() \u51fd\u6578\u3002</li> <li>\u65b0\u589e\u4e86 synchdb_genstats \u8996\u5716\uff0c\u7528\u65bc\u8a18\u9304\u5df2\u8655\u7406\u4e8b\u4ef6\u6279\u6b21\u7684\u7d71\u8a08\u8cc7\u6599\u3002</li> <li>\u65b0\u589e\u4e86 synchdb_snapstats \u8996\u5716\uff0c\u7528\u65bc\u8a18\u9304\u521d\u59cb\u5feb\u7167\u904e\u7a0b\u7684\u7d71\u8a08\u8cc7\u6599\u3002</li> <li>\u65b0\u589e\u4e86 synchdb_cdcstats \u8996\u5716\uff0c\u7528\u65bc\u8a18\u9304 CDC \u6d41\u7a0b\u7684\u7d71\u8a08\u8cc7\u6599\u3002</li> </ul>"},{"location":"zh/changelog/#postgresql-18-ivorysql-5","title":"PostgreSQL 18 \u548c IvorySQL 5 \u76f8\u5bb9\u6027","text":"<ul> <li>SynchDB \u8207 PostgreSQL 18 \u548c IvorySQL 5 \u76f8\u5bb9\u3002</li> <li>\u5728 IvorySQL 5 \u4e0b\u4ee5\u300coracle\u300d\u76f8\u5bb9\u6a21\u5f0f\u904b\u884c\u57fa\u65bc FDW \u7684\u5feb\u7167\u6642\uff0c\u7531\u65bc PL/pgSQL \u51fd\u6578\u662f\u7528 PostgreSQL \u6a19\u6e96\u7de8\u5beb\u7684\uff0c\u56e0\u6b64\u5728\u5feb\u7167\u671f\u9593\uff0c\u8a72\u6a21\u5f0f\u5c07\u5207\u63db\u56de\u300cpg\u300d\u6a21\u5f0f\u3002</li> <li>SynchDB \u5c07\u5728 SynchDB \u5de5\u4f5c\u9032\u7a0b\u4e2d\u5c07\u201civorysql.identifier_case_switch\u201d\u8a2d\u5b9a\u8a2d\u70ba\u201cnormal\u201d\uff0c\u4ee5\u9632\u6b62\u5b57\u6bcd\u5927\u5c0f\u5beb\u88ab\u932f\u8aa4\u5730\u53cd\u8f49\u3002</li> <li>\u5c07 liboracle_parser.so \u53ca\u5176\u5167\u90e8\u7684 oracle_raw_parser() \u7b26\u865f\u91cd\u65b0\u547d\u540d\u70ba libsynchdb_oracle_parser.so \u548c synchdb_oracle_raw_parser()\uff0c\u4ee5\u9632\u6b62\u7b26\u865f\u540d\u7a31\u8207 IvorySQL \u885d\u7a81\u3002</li> </ul>"},{"location":"zh/changelog/#_4","title":"\u53d8\u66f4","text":"<ul> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u589e\u5f37\u4e86 Oracle \u89e3\u6790\u5668\uff0c\u4ee5\u652f\u63f4\u66f4\u591a\u7d04\u675f\u904b\u7b97\u5b50\uff1aenable\u3001disable\u3001novalidate \u548c validate\u3002</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u589e\u5f37\u4e86 Oracle \u89e3\u6790\u5668\uff0c\u4ee5\u652f\u63f4\u5e36\u6709\u62ec\u865f\u548c\u4e0d\u5e36\u62ec\u865f\u7684 MODIFY \u5b50\u53e5\u3002</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u589e\u5f37\u4e86 Oracle \u89e3\u6790\u5668\uff0c\u4ee5\u652f\u63f4 DEFAULT ON NULL \u5b50\u53e5\u3002</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u900f\u904e\u79fb\u9664\u4e00\u500b\u9810\u6383\u63cf\u5faa\u74b0\u4f86\u63d0\u9ad8\u8655\u7406\u6548\u80fd\u3002</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u6700\u4f73\u5316\u4e86\u4ee5 PostgreSQL \u6587\u5b57\u985e\u578b\u8655\u7406\u975e\u7a7a\u7d42\u6b62\u4e8b\u4ef6\u7684\u64cd\u4f5c\uff0c\u5f9e\u800c\u6e1b\u5c11\u4e86\u4e00\u6b21\u8907\u88fd\u64cd\u4f5c\u3002 (PG17+)</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u9810\u8a2d\u8b80\u53d6\u7de9\u885d\u5340\u5927\u5c0f\u8b8a\u66f4\u70ba 128MB</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u65b0\u589e GUC \u53c3\u6578\u201csynchdb.olr_read_timeout_ms\u201d\uff0c\u7528\u65bc\u8a2d\u5b9a\u8b80\u53d6\u903e\u6642\u6642\u9593\u3002</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u65b0\u589e GUC \u53c3\u6578\u201csynchdb.olr_connect_timeout_ms\u201d\uff0c\u7528\u65bc\u8a2d\u5b9a\u9023\u7dda\u903e\u6642\u6642\u9593\u3002</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u5c07\u5ffd\u7565 Debezium \u5efa\u7acb\u7684\u300clog_mining_flush\u300d\u8868\u3002</li> <li>\u66f4\u65b0\u4e86\u6240\u6709\u9023\u63a5\u5668\u985e\u578b\u7684\u9810\u8a2d\u8cc7\u6599\u985e\u578b\u6620\u5c04</li> <li>\u66f4\u5065\u58ef\u7684 JSON \u8655\u7406\uff1a\u4e0d\u518d\u56e0\u70ba JSON \u5143\u7d20\u67e5\u627e\u5931\u6557\u800c\u5d29\u6f70</li> </ul>"},{"location":"zh/changelog/#_5","title":"\u5df2\u4fee\u5fa9","text":"<ul> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u4fee\u6b63\u4e86\u5728 PostgreSQL 16 \u4e0b\u57f7\u884c\u6642\u9593 Oracle \u89e3\u6790\u5668\u89e3\u6790\u5931\u6557\u7684\u554f\u984c\u3002</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u4fee\u6b63\u4e86\u5c07\u5305\u542b\u7cfb\u7d71\u64c1\u6709\u8005\u7684\u610f\u5916 DDL \u8a9e\u53e5\u932f\u8aa4\u5730\u50b3\u905e\u7d66 SynchDB \u7684\u554f\u984c\u3002</li> <li>Openlog Replicator \u9023\u63a5\u5668\uff1a\u8abf\u6574\u4e86 SCN \u548c C_SCN \u503c\uff0c\u4f7f\u5176\u6062\u5fa9 CDC \u6642\u4f7f\u7528\u504f\u79fb\u6a94\u6848\u4e2d\u5132\u5b58\u7684\u503c\uff0c\u800c\u4e0d\u662f\u52a0 1\uff0c\u5f9e\u800c\u907f\u514d\u5728\u5fa9\u539f\u6642\u8df3\u904e\u5148\u524d\u5931\u6557\u7684\u8b8a\u66f4\u4e8b\u4ef6\u3002</li> <li>SynchDB \u73fe\u5728\u5141\u8a31\u4f86\u6e90\u8868\u6216\u6a21\u5f0f\u540d\u7a31\u5305\u542b\u7a7a\u683c\u3002</li> <li>\u4fee\u6b63\u4e86\u5c0d\u8ca0\u5341\u9032\u5236\u503c\u8655\u7406\u4e0d\u6b63\u78ba\u7684\u554f\u984c\u3002</li> <li>\u4fee\u6b63\u4e86\u5c0d\u5927\u5341\u9032\u5236\u6ea2\u51fa\u503c\u8655\u7406\u4e0d\u6b63\u78ba\u7684\u554f\u984c\u3002</li> <li>\u4fee\u6b63\u4e86 Oracle \u9810\u8a2d NUMBER \u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u4e2d\u932f\u8aa4\u5730\u7701\u7565\u9577\u5ea6\u548c\u5c0f\u6578\u4f4d\u6578\u7684\u554f\u984c\u3002</li> <li>\u4fee\u6b63\u4e86 MySQL \u9023\u63a5\u5668\u4e2d\u5e36\u6709\u81ea\u589e\u5c6c\u6027\u7684\u7f3a\u5931\u9810\u8a2d\u8cc7\u6599\u985e\u578b\u6620\u5c04</li> </ul>"},{"location":"zh/changelog/#_6","title":"\u5df2\u77e5\u554f\u984c\u548c\u5176\u4ed6\u4fe1\u606f","text":"<ul> <li>SynchDB \u5728\u5c07\u50b3\u5165\u7684\u8868\u540d\u3001\u6a21\u5f0f\u540d\u548c\u5217\u540d\u5957\u7528\u5230 PostgreSQL \u4e4b\u524d\uff0c\u7e3d\u662f\u6703\u5c07\u5b83\u5011\u898f\u7bc4\u5316\u70ba\u5c0f\u5beb\u5b57\u6bcd\u3002\u5982\u679c\u4f86\u6e90\u8868\u652f\u63f4\u540d\u7a31\u76f8\u540c\u4f46\u5927\u5c0f\u5beb\u4e0d\u540c\u7684\u5c0d\u8c61\uff0c\u5247\u6703\u51fa\u73fe\u554f\u984c\u3002\u4f8b\u5982\uff0c'mytable' \u548c 'MYTABLE' \u5728 MySQL \u548c Oracle \u4e2d\u88ab\u8996\u70ba\u4e0d\u540c\u7684\u8868\u540d\u3002\u554f\u984c\u9023\u7d50\u6b64\u8655</li> <li>\u76ee\u524d\u5c1a\u4e0d\u652f\u63f4\u57fa\u65bc FDW \u7684 MySQL \u548c SQL Server \u5feb\u7167\uff0c\u6211\u5011\u53ef\u80fd\u6703\u5728\u672a\u4f86\u7684\u7248\u672c\u4e2d\u65b0\u589e\u652f\u63f4\u3002\u66f4\u591a\u8cc7\u8a0a\u6b64\u8655</li> </ul>"},{"location":"zh/changelog/#synchdb-12-2025-09-04","title":"SynchDB 1.2 - 2025-09-04","text":"<p>SynchDB 1.2 \u5f15\u5165\u4e86\u539f\u751f Openlog Replicator \u8fde\u63a5\u5668\uff08\u6d4b\u8bd5\u7248\uff09\u3001\u589e\u5f3a\u7684 JMX \u548c Grafana \u76d1\u63a7\u529f\u80fd\uff0c\u4ee5\u53ca\u7528\u4e8e\u5feb\u901f\u90e8\u7f72\u548c\u6d4b\u8bd5\u7684\u5168\u65b0 ezdeploy.sh \u5de5\u5177\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u589e\u52a0\u4e86\u5feb\u7167\u8868\u9009\u62e9\u529f\u80fd\u3001\u6027\u80fd\u6539\u8fdb\u548c\u5173\u952e\u4fee\u590d\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u8fde\u63a5\u5668\u9694\u79bb\u548c\u7a33\u5b9a\u6027\u95ee\u9898\u3002</p>"},{"location":"zh/changelog/#_7","title":"\u65b0\u589e","text":""},{"location":"zh/changelog/#openlog-replicator-","title":"\u539f\u751f Openlog Replicator \u8fde\u63a5\u5668 - \u6d4b\u8bd5\u7248","text":"<ul> <li>\u65b0\u589e <code>synchdb_add_olr_conninfo</code> \u548c <code>synchdb_del_olr_conninfo</code>\uff0c\u7528\u4e8e\u542f\u7528\u6216\u7981\u7528\u57fa\u4e8e Openlog Replicator \u7684\u6d41\u5f0f\u4f20\u8f93\u3002</li> <li>\u6dfb\u52a0\u4e86\u65b0\u7684\u8fde\u63a5\u5668\u7c7b\u578b\u201colr\u201d\uff0c\u5b83\u662f\u4e00\u4e2a\u539f\u751f\uff08\u975e Debezium\uff09Openlog \u590d\u5236\u5668\u5ba2\u6237\u7aef\uff0c\u53ef\u4ece\u5916\u90e8 Openlog Replicator \u670d\u52a1\u6d41\u5f0f\u4f20\u8f93 Oracle \u6570\u636e\u5e93\u66f4\u6539\u3002</li> <li>\u652f\u6301\u7684 DML\uff1a\u63d2\u5165\u3001\u66f4\u65b0/\u5220\u9664</li> <li>\u652f\u6301\u7684 DDL\uff1a\u521b\u5efa\u8868\u3001\u5220\u9664\u8868\u3001\u4fee\u6539\u8868\u3001\u6dfb\u52a0/\u5220\u9664\u5217\u3001\u6dfb\u52a0/\u5220\u9664\u7ea6\u675f\u3001\u622a\u65ad</li> <li>\u57fa\u4e8e libprotobuf-c \u4e0e Openlog Replicator \u548c IvorySQL \u7684 Oracle \u89e3\u6790\u5668\u901a\u4fe1\uff0c\u4ee5\u5904\u7406\u4f20\u5165\u7684 DDL \u67e5\u8be2\u4e8b\u4ef6\u3002</li> <li>\u652f\u6301\u7684\u5feb\u7167\u6a21\u5f0f\uff1ainitial\u3001initial_only\u3001no_data\u3001always\u3001never</li> <li>\u4e0e\u5176\u4ed6\u57fa\u4e8e Debezium \u7684\u8fde\u63a5\u5668\u4e00\u6837\uff0c\u652f\u6301\u6279\u5904\u7406\u3001\u6a21\u5f0f\u5386\u53f2\u8bb0\u5f55\u548c\u504f\u79fb\u91cf\u7ba1\u7406\u3002</li> <li>\u9664\u539f\u751f\u8fde\u63a5\u5668\u5916\uff0c\u8fd8\u652f\u6301\u57fa\u4e8e Debezium \u7684 Openlog Replicator \u8fde\u63a5\u5668\u3002</li> </ul>"},{"location":"zh/changelog/#_8","title":"\u76d1\u63a7","text":"<ul> <li>\u65b0\u589e <code>synchdb_add_jmx_conninfo</code> \u548c <code>synchdb_del_jmx_conninfo</code>\uff0c\u7528\u4e8e\u542f\u7528\u6216\u7981\u7528\u57fa\u4e8e JMX \u7684\u76d1\u63a7\u3002</li> <li>\u65b0\u589e <code>synchdb_add_jmx_exporter_conninfo</code> \u548c <code>synchdb_del_jmx_exporter_conninfo</code>\uff0c\u7528\u4e8e\u542f\u7528\u6216\u7981\u7528 Prometheus \u548c Grafana \u7684\u76d1\u63a7\u652f\u6301\u3002</li> <li>\u65b0\u589e\u57fa\u4e8e Grafana \u7684\u4eea\u8868\u677f\u6a21\u677f\uff0c\u7528\u4e8e\u652f\u6301\u57fa\u4e8e Debezium \u7684\u8fde\u63a5\u5668\uff08MySQL\u3001SQL Server \u548c Oracle\uff09\u3002</li> </ul>"},{"location":"zh/changelog/#ezdeploysh","title":"ezdeploy.sh","text":"<ul> <li>\u65b0\u589e <code>ezdeploy.sh</code> \u5de5\u5177\uff0c\u53ef\u5feb\u901f\u90e8\u7f72\u9884\u6784\u5efa\u7684 SynchDB \u548c\u6240\u9009\u7684\u6e90\u6570\u636e\u5e93\u7c7b\u578b\uff0c\u4ee5\u4fbf\u5feb\u901f\u8fdb\u884c\u8fde\u63a5\u5668\u6d4b\u8bd5\u3002</li> <li>\u652f\u6301\u90e8\u7f72\uff1aMySQL\u3001SQL Server\u3001Oracle23ai\u3001Oracle19c\u3001Openlog Replicator 1.3.0</li> <li>\u652f\u6301\u9884\u52a0\u8f7d\u4eea\u8868\u677f\u7684 Prometheus \u548c Grafana \u90e8\u7f72\u3002</li> <li>\u652f\u6301\u9884\u7f16\u8bd1\u7684 SynchDB v1.2\uff0c\u4ee5\u4fbf\u5feb\u901f\u90e8\u7f72\u548c\u6d4b\u8bd5\u3002</li> </ul>"},{"location":"zh/changelog/#_9","title":"\u53d8\u66f4","text":"<ul> <li>\u5728 <code>synchdb_add_conninfo</code> \u4e2d\u6dfb\u52a0\u4e86\u4e00\u4e2a\u540d\u4e3a <code>snapshot table</code> \u7684\u65b0\u53c2\u6570\uff0c\u5141\u8bb8\u7528\u6237\u5728\u4ee5 <code>always</code> \u5feb\u7167\u6a21\u5f0f\u542f\u52a8\u65f6\u9009\u62e9\u8981\u91cd\u505a\u521d\u59cb\u5feb\u7167\u7684\u8868\u3002</li> <li>\u66f4\u65b0\u4e86 pytest \u6846\u67b6\uff0c\u4ee5\u652f\u6301\u57fa\u4e8e hammerdb \u7684 Oracle TPC \u6d4b\u8bd5\u3002</li> <li>\u901a\u8fc7\u4f7f\u7528\u76f4\u63a5\u7f13\u51b2\u533a\u4ee3\u66ff\u9891\u7e41\u7684 JNI \u8c03\u7528\uff0c\u589e\u5f3a\u4e86 Debezium \u5f15\u64ce\u548c SynchDB \u4e4b\u95f4\u4e8b\u4ef6\u8f6e\u8be2\u7684\u6027\u80fd\u3002</li> <li>\u5f53\u8fde\u63a5\u5668\u901a\u8fc7 <code>synchdb_resume_engine</code> \u6062\u590d\u65f6\uff0c\u5b83\u5c06\u59cb\u7ec8\u4ee5 <code>initial</code> \u5feb\u7167\u6a21\u5f0f\u6062\u590d\uff0c\u800c\u4e0d\u662f\u9996\u6b21\u542f\u52a8\u65f6\u7684\u6a21\u5f0f\u3002</li> <li><code>synchdb_state_view</code> \u548c <code>synchdb_stats_view</code> \u73b0\u5728\u4ec5\u663e\u793a\u5f53\u524d SynchDB \u6269\u5c55\u521b\u5efa\u7684\u8fde\u63a5\u5668\u4fe1\u606f\u3002\u5176\u4ed6 SynchDB \u6269\u5c55\u5728\u4e0d\u540c\u6570\u636e\u5e93\u4e2d\u521b\u5efa\u7684\u8fde\u63a5\u5668\u5c06\u4e0d\u663e\u793a\u3002</li> </ul>"},{"location":"zh/changelog/#_10","title":"\u5df2\u4fee\u590d","text":"<ul> <li>\u4fee\u590d\u4e86 <code>spi_execute_select_one()</code> \u51fd\u6570\u5d29\u6e83\u7684\u95ee\u9898\uff0c\u8be5\u51fd\u6570\u5728 SPI \u6267\u884c\u6210\u529f\u540e\u4f1a\u8fd4\u56de\u4e00\u4e2a\u5df2\u88ab SPI \u5185\u5b58\u4e0a\u4e0b\u6587\u9500\u6bc1\u7684\u5f15\u7528\u3002</li> <li>\u89e3\u51b3\u4e86\u4f7f\u7528 cassert \u6784\u5efa PostgreSQL \u65f6 SynchDB \u7684\u7f16\u8bd1\u95ee\u9898\u3002</li> <li>\u4fee\u590d\u4e86\u591a\u4e2a SynchDB \u6269\u5c55\uff08\u521b\u5efa\u4e8e\u4e0d\u540c\u6570\u636e\u5e93\u4e2d\uff09\u521b\u5efa\u7684\u540c\u540d\u8fde\u63a5\u5668\u4f1a\u76f8\u4e92\u8986\u76d6\u5171\u4eab\u5185\u5b58\u6570\u636e\u7684\u95ee\u9898\u3002</li> </ul>"},{"location":"zh/changelog/#_11","title":"\u5df2\u77e5\u95ee\u9898\u53ca\u5176\u4ed6\u4fe1\u606f","text":"<ul> <li>\u539f\u751f Openlog Replicator \u8fde\u63a5\u5668\u76ee\u524d\u4f1a\u6d41\u5f0f\u4f20\u8f93\u6307\u5b9a\u6570\u636e\u5e93\u4e0b\u7684\u6240\u6709\u8868\u3002\u8868\u8fc7\u6ee4\u529f\u80fd\u9700\u8981\u5728 Openlog Replicator \u4e2d\u914d\u7f6e\uff0c\u800c\u4e0d\u662f\u5728 SynchDB \u4e2d\u3002</li> <li>\u57fa\u4e8e Prometheus \u548c Grafana \u7684\u76d1\u63a7\u9700\u8981 JMX Exporter\uff0c\u53ef\u4ee5\u4ece\u6b64\u5904 \u4e0b\u8f7d</li> </ul>"},{"location":"zh/changelog/#synchdb-11-2025-04-17","title":"SynchDB 1.1 - 2025-04-17","text":"<p>SynchDB 1.1 \u7248\u672c\u5f15\u5165\u4e86 Oracle \u8fde\u63a5\u5668\u652f\u6301\uff0c\u589e\u5f3a\u4e86\u6570\u636e\u7c7b\u578b\u8f6c\u6362\u80fd\u529b\uff0c\u5e76\u663e\u8457\u6539\u8fdb\u4e86\u6838\u5fc3\u6570\u636e\u5904\u7406\u5f15\u64ce\u3002\u672c\u6b21\u66f4\u65b0\u901a\u8fc7\u667a\u80fd\u7f13\u5b58\u548c\u4f18\u5316\u7684 JSON \u89e3\u6790\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0\uff0c\u540c\u65f6\u6269\u5c55\u4e86\u4e0e PostgreSQL 16\u300117 \u548c IvorySQL 4.4 \u7684\u517c\u5bb9\u6027\u3002</p>"},{"location":"zh/changelog/#_12","title":"\u6dfb\u52a0","text":""},{"location":"zh/changelog/#_13","title":"\u8fde\u63a5\u5668\u652f\u6301","text":"<ul> <li>\u65b0\u589e Oracle \u8fde\u63a5\u5668\u652f\u6301</li> <li>\u65b0\u589e Oracle \u53ef\u53d8\u5927\u5c0f/\u7cbe\u5ea6 NUMBER \u6570\u636e\u7c7b\u578b\u5904\u7406\u652f\u6301</li> <li>\u652f\u6301 PostgreSQL 16\u300117 \u548c IvorySQL 4.4</li> </ul>"},{"location":"zh/changelog/#_14","title":"\u5bf9\u8c61\u6620\u5c04\u4e0e\u6570\u636e\u8f6c\u6362","text":"<ul> <li>\u65b0\u589e <code>synchdb_objmap</code> \u8868\u5b58\u50a8\u5bf9\u8c61\u6620\u5c04\u6761\u76ee</li> <li>\u65b0\u589e <code>synchdb_add_objamp()</code> \u51fd\u6570\u6dfb\u52a0\u5bf9\u8c61\u6620\u5c04\uff0c\u652f\u6301\u8868\u540d\u3001\u5217\u540d\u3001\u6570\u636e\u7c7b\u578b\u548c\u8f6c\u6362\u8868\u8fbe\u5f0f</li> <li>\u65b0\u589e <code>synchdb_reload_objmap()</code> \u51fd\u6570\u5f3a\u5236\u8fde\u63a5\u5668\u91cd\u65b0\u52a0\u8f7d\u5bf9\u8c61\u6620\u5c04</li> <li>\u65b0\u589e <code>synchdb_del_objmap()</code> \u51fd\u6570\u7981\u7528\u5e76\u5220\u9664\u5bf9\u8c61\u6620\u5c04\u6761\u76ee</li> <li>\u5f52\u4e00\u5316\u6240\u6709\u6570\u636e\u7c7b\u578b\u6620\u5c04\u6761\u76ee\uff0c\u4f7f\u7528\u5c0f\u5199\u5b57\u6bcd</li> </ul>"},{"location":"zh/changelog/#_15","title":"\u5143\u6570\u636e\u4e0e\u76d1\u63a7","text":"<ul> <li>\u65b0\u589e <code>synchdb_attribute</code> \u8868\u5b58\u50a8\u8fdc\u7a0b\u8868\u5c5e\u6027\u4fe1\u606f</li> <li>\u65b0\u589e <code>synchdb_att_view</code> \u89c6\u56fe\u663e\u793a\u6570\u636e\u7c7b\u578b\u3001\u8868\u540d\u548c\u5217\u540d\u6620\u5c04\u7684\u5e76\u6392\u6bd4\u8f83</li> <li>\u5728 <code>synchdb_get_stats</code> \u4e2d\u589e\u52a0\u6e90\u65f6\u95f4\u6233\u3001DBZ \u65f6\u95f4\u6233\u548c PG \u65f6\u95f4\u6233\u4fe1\u606f</li> </ul>"},{"location":"zh/changelog/#_16","title":"\u8fde\u63a5\u7ba1\u7406","text":"<ul> <li>\u65b0\u589e <code>synchdb_add_extra_conninfo()</code> \u51fd\u6570\u914d\u7f6e\u989d\u5916\u7684 SSL \u8fde\u63a5\u53c2\u6570</li> <li>\u65b0\u589e <code>synchdb_del_extra_conninfo()</code> \u51fd\u6570\u5220\u9664\u7531 <code>synchdb_add_extra_conninfo()</code> \u521b\u5efa\u7684\u6240\u6709\u989d\u5916\u53c2\u6570</li> <li>\u65b0\u589e <code>synchdb_del_conninfo()</code> \u51fd\u6570\u5220\u9664\u73b0\u6709\u8fde\u63a5\u5668\u4fe1\u606f</li> </ul>"},{"location":"zh/changelog/#_17","title":"\u914d\u7f6e\u4e0e\u63a7\u5236","text":"<ul> <li>\u65b0\u589e <code>synchdb.error_handling_strategy</code> GUC \u53c2\u6570\u63a7\u5236\u9519\u8bef\u5904\u7406\u7b56\u7565\uff08\u8df3\u8fc7\u3001\u9000\u51fa\u6216\u91cd\u8bd5\uff09</li> <li>\u65b0\u589e <code>synchdb.dbz_log_level</code> GUC \u53c2\u6570\u63a7\u5236 Debezium \u8fd0\u884c\u5f15\u64ce\u7684\u65e5\u5fd7\u7ea7\u522b</li> <li>\u65b0\u589e <code>schemasync</code> \u5feb\u7167\u6a21\u5f0f</li> </ul>"},{"location":"zh/changelog/#_18","title":"\u6027\u80fd\u4f18\u5316","text":"<ul> <li>\u4f18\u5316 DML \u89e3\u6790\u5668\uff0c\u4f7f\u7528\u7f13\u5b58\u54c8\u5e0c\u8868\u800c\u975e\u6bcf\u6b21\u66f4\u6539\u4e8b\u4ef6\u90fd\u8bbf\u95ee\u76ee\u5f55\u5e76\u91cd\u5efa\u54c8\u5e0c</li> <li>DML \u89e3\u6790\u5668\u73b0\u4f7f\u7528\u66f4\u9ad8\u6548\u7684 JSONB API \u8c03\u7528\u63d0\u5347\u6027\u80fd</li> <li>\u4f18\u5316 JNI \u8c03\u7528\uff0c\u4f7f\u7528\u7f13\u5b58\u7684 JNI \u53e5\u67c4\u800c\u975e\u6bcf\u6b21\u66f4\u6539\u4e8b\u4ef6\u90fd\u91cd\u65b0\u521b\u5efa</li> <li>\u4ec5\u6807\u8bb0\u6279\u6b21\u4e2d\u7684\u7b2c\u4e00\u4e2a\u548c\u6700\u540e\u4e00\u4e2a\u66f4\u6539\u4e8b\u4ef6\uff0c\u800c\u975e\u6240\u6709\u4e8b\u4ef6</li> <li>\u91cd\u65b0\u8bbe\u8ba1\u6570\u636e\u5904\u7406\u5f15\u64ce\uff0c\u91c7\u7528\u66f4\u6a21\u5757\u5316\u7684\u8bbe\u8ba1\uff0c\u4ee5\u5904\u7406\u66f4\u590d\u6742\u7684\u6570\u636e\u7c7b\u578b\u6620\u5c04</li> </ul>"},{"location":"zh/changelog/#_19","title":"\u53d8\u66f4","text":"<ul> <li>\u5904\u7406 ALTER TABLE \u66f4\u6539\u4e8b\u4ef6\u65f6\uff0c\u4ec5\u5728\u8868\u672c\u8eab\u6ca1\u6709\u4e3b\u952e\u65f6\u6dfb\u52a0\u4e3b\u952e</li> <li>\u79fb\u9664\u5728 <code>synchdb_add_conninfo()</code> \u4e2d\u914d\u7f6e\u8fde\u63a5\u5668\u8fde\u63a5\u5230\u5b89\u88c5\u4e86 synchdb \u4ee5\u5916\u7684\u76ee\u6807 PostgreSQL \u6570\u636e\u5e93\u7684\u529f\u80fd</li> <li>\u5728\u6bcf\u4e2a DDL \u66f4\u6539\u4e8b\u4ef6\u5904\u7406\u7ed3\u675f\u65f6\uff0c\u66f4\u65b0\u65b0\u7684 <code>synchdb_attribute</code> \u8868</li> <li>\u8fde\u63a5\u5668\u5c06\u6839\u636e\u914d\u7f6e\u7684\u5bf9\u8c61\u6620\u5c04\u5728\u542f\u52a8\u6216\u91cd\u65b0\u52a0\u8f7d\u65f6\u66f4\u6b63\u8868\u540d\u3001\u5217\u540d\u548c\u6570\u636e\u7c7b\u578b</li> <li>\u89c4\u5219\u6587\u4ef6\u5df2\u88ab <code>synchdb_add_objmap()</code> \u5de5\u5177\u66ff\u4ee3</li> <li>\u6240\u6709\u57fa\u4e8e ID \u7684 SQL \u51fd\u6570\u5217\u5b9a\u4e49\uff0c\u6570\u636e\u7c7b\u578b\u4ece TEXT \u66f4\u6539\u4e3a NAME</li> <li>\u4ece <code>synchdb_add_conninfo()</code> \u4e2d\u79fb\u9664 rulefile \u53c2\u6570</li> <li>\u975e\u539f\u751f\u6570\u636e\u7c7b\u578b\u73b0\u5728\u57fa\u4e8e\u7c7b\u522b\u5904\u7406\uff0c\u800c\u975e\u5168\u90e8\u4f5c\u4e3a\u6587\u672c\u5904\u7406</li> </ul>"},{"location":"zh/changelog/#_20","title":"\u4fee\u590d","text":"<ul> <li>\u4fee\u590d SPI \u66f4\u65b0\u6216\u5220\u9664\u53ef\u80fd\u56e0\u4ec5\u5728 WHERE \u5b50\u53e5\u4e2d\u5305\u542b\u4e3b\u952e\u5b57\u6bb5\u800c\u5bfc\u81f4\u66f4\u65b0\u6216\u5220\u9664\u5931\u8d25\u7684\u95ee\u9898</li> <li>\u4fee\u590d ALTER TABLE \u5728\u5c1d\u8bd5\u6dfb\u52a0\u91cd\u590d\u4e3b\u952e\u65f6\u51fa\u9519\u7684\u95ee\u9898</li> <li>\u4fee\u590d synchdb \u5076\u5c14\u4ece JSON \u66f4\u6539\u4e8b\u4ef6\u4e2d\u9519\u8bef\u67e5\u627e\u5217\u67b6\u6784\u503c\u7684\u95ee\u9898</li> <li>\u4fee\u590d\"\u8df3\u8fc7\u9519\u8bef\"\u6a21\u5f0f\u4e0b\u56e0\u9519\u8bef\u5806\u6808\u6ea2\u51fa\u800c\u5bfc\u81f4\u5d29\u6e83\u7684\u95ee\u9898</li> <li>\u4fee\u590d ALTER TABLE ADD \u548c DROP \u5217\u64cd\u4f5c\u4e2d\u672a\u610f\u8bc6\u5230\u5217\u540d\u53ef\u80fd\u5728 PostgreSQL \u4e2d\u6620\u5c04\u5230\u4e0d\u540c\u503c\u7684\u95ee\u9898</li> </ul>"},{"location":"zh/changelog/#synchdb-10-2024-12-24","title":"SynchDB 1.0 - 2024-12-24","text":"<p>\u6b64\u7248\u672c\u4fa7\u91cd\u4e8e v1.0 Beta1 \u7248\u672c\u4e4b\u540e\u7684\u9519\u8bef\u4fee\u590d\u548c\u6027\u80fd\u589e\u5f3a\uff0c\u4f7f\u5176\u5728\u4e2d\u9ad8\u6570\u636e\u8d1f\u8f7d\u4e0b\u66f4\u6613\u4e8e\u4f7f\u7528\u3002\u66f4\u591a\u4e0e Debezium \u8c03\u4f18\u76f8\u5173\u7684\u53c2\u6570\u4e5f\u5df2\u4f5c\u4e3a PostgreSQL GUC \u516c\u5f00\uff0c\u5141\u8bb8\u7528\u6237\u4f7f\u7528\u4e0d\u540c\u7684\u53c2\u6570\u8fdb\u884c\u6d4b\u8bd5\u3002</p>"},{"location":"zh/changelog/#_21","title":"\u6dfb\u52a0","text":"<ul> <li>\u5728 DML \u89e3\u6790\u9636\u6bb5\u6dfb\u52a0\u4e86\u6570\u636e\u7f13\u5b58\uff0c\u4ee5\u9632\u6b62\u9891\u7e41\u8bbf\u95ee PostgreSQL catalog \u4ee5\u83b7\u53d6\u8868\u7684\u5143\u7ec4\u63cf\u8ff0\u7b26\u7ed3\u6784\u3002</li> <li>\u6dfb\u52a0 <code>synchdb_start_engine_bgw(name, mode)</code> \u7684\u53d8\u4f53\uff0c\u5b83\u63a5\u53d7\u7b2c\u4e8c\u4e2a\u53c2\u6570\u6765\u6307\u793a\u542f\u52a8\u8fde\u63a5\u5668\u65f6\u4f7f\u7528\u7684\u81ea\u5b9a\u4e49\u5feb\u7167\u6a21\u5f0f\u3002</li> <li>\u6dfb\u52a0\u591a\u4e2a\u53ef\u4ee5\u8c03\u6574 Debezium Runner \u6027\u80fd\u7684 GUC\u3002\u5b8c\u6574\u5217\u8868\u8bf7\u53c2\u9605\u6b64\u5904\u3002</li> <li>\u6dfb\u52a0\u4e00\u4e2a\u8c03\u8bd5 SQL \u51fd\u6570 <code>synchdb_log_jvm_meminfo(name)</code>\uff0c\u8be5\u51fd\u6570\u4f7f\u6307\u5b9a\u7684\u8fde\u63a5\u5668\u5728 PostgreSQL \u65e5\u5fd7\u6587\u4ef6\u4e2d\u8f93\u51fa\u5f53\u524d JVM \u5806\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\u6458\u8981\u3002</li> <li>\u6dfb\u52a0\u4e00\u4e2a\u65b0\u89c6\u56fe <code>synchdb_stats_view</code>\uff0c\u7528\u4e8e\u6253\u5370\u6240\u6709\u8fde\u63a5\u5668\u7684\u7edf\u8ba1\u4fe1\u606f\u3002</li> <li>\u589e\u52a0\u4e86\u65b0\u7684SQL\u51fd\u6570 <code>synchdb_reset_stats(name)</code> \u6765\u6e05\u9664\u6307\u5b9a\u8fde\u63a5\u5668\u7684\u7edf\u8ba1\u4fe1\u606f\u3002</li> <li>\u6dfb\u52a0\u4e00\u4e2a\u6d4b\u8bd5\u6570\u636e\u521b\u5efa\u811a\u672c\uff0c\u7528\u4e8e\u5feb\u901f\u751f\u6210 MySQL \u6570\u636e\u5e93\u7c7b\u578b\u7684\u6d4b\u8bd5\u8868\u548c\u6570\u636e\u3002</li> </ul>"},{"location":"zh/changelog/#_22","title":"\u53d8\u66f4","text":"<ul> <li>synchdb_state_view()\uff1a\u6dfb\u52a0\u4e86\u4e00\u4e2a\u540d\u4e3a <code>stage</code> \u7684\u65b0\u5b57\u6bb5\uff0c\u7528\u4e8e\u6807\u8bc6 connector \u7684\u5f53\u524d\u9636\u6bb5\uff08\u503c\u53ef\u4ee5\u662f <code>Initial Snapshot</code> \u6216 <code>Change Data Capture</code>\uff09\u3002</li> <li>synchdb_state_view()\uff1a\u4ec5\u663e\u793a\u6709\u6548\u8fde\u63a5\u5668\u7684\u72b6\u6001\u3002</li> <li>\u5220\u9664\u4e86\u5728\u53d1\u751f\u9519\u8bef\u65f6\u5411 Debezium Runner \u53d1\u9001 \u201c\u90e8\u5206\u6279\u5904\u7406\u5b8c\u6210\u201d \u901a\u77e5\uff0c\u56e0\u4e3a\u6279\u5904\u7406\u73b0\u5728\u7531\u4e00\u4e2a PostgreSQL \u4e8b\u52a1\u5904\u7406\uff0c\u4e14\u4e0d\u5141\u8bb8\u90e8\u5206\u5b8c\u6210\u3002</li> <li>\u73b0\u5728\u53ef\u4ee5\u5728\u89c4\u5219\u6587\u4ef6\u4e2d\u6307\u5b9a connector \u6240\u9700\u7684 SSL \u76f8\u5173\u53c2\u6570\u3002</li> <li>\u73b0\u5728\u53ef\u4ee5\u901a\u8fc7 GUC \u914d\u7f6e\u5206\u914d\u7ed9\u8fd0\u884c Debezium Runner \u7684 JVM \u7684\u6700\u5927\u5806\u5185\u5b58\u3002</li> <li>\u73b0\u5728\u53ef\u4ee5\u914d\u7f6e\u8fde\u63a5\u5668\u540e\u53f0\u8fdb\u7a0b\u7684\u6700\u5927\u6570\u91cf\uff0c\u800c\u4e0d\u662f\u786c\u7f16\u7801\u7684 30\u3002</li> </ul>"},{"location":"zh/changelog/#_23","title":"\u4fee\u590d","text":"<ul> <li>\u5728 Debezium runner \u5185\u6dfb\u52a0\u8282\u6d41\u63a7\u5236\uff0c\u4fee\u590d\u4e86 Debezium Runner \u5728\u6570\u636e\u91cf\u5927\u65f6\u5185\u5b58\u5feb\u901f\u79ef\u7d2f\u95ee\u9898\u3002</li> <li>\u89e3\u51b3\u4e86 SynchDB \u548c Debezium runner \u7ec4\u4ef6\u4e2d\u7684\u5927\u90e8\u5206\u5185\u5b58\u6cc4\u6f0f\u95ee\u9898\u3002</li> <li>\u66f4\u6b63\u4e86 SynchDB \u4e2d memory context \u7684\u4f7f\u7528\uff0c\u4ee5\u4fbf\u5728\u6bcf\u6b21\u66f4\u6539\u4e8b\u4ef6\u5904\u7406\u7ed3\u675f\u65f6\u6b63\u786e\u91ca\u653e\u5185\u5b58\u3002</li> <li>\u901a\u8fc7\u5728\u5355\u4e2a PostgreSQL \u4e8b\u52a1\u4e2d\u5904\u7406\u4e00\u6279\u6539\u52a8\uff0c\u663e\u8457\u63d0\u9ad8\u4e86 SynchDB \u7684\u5904\u7406\u901f\u5ea6\u3002</li> <li>\u5c06 SQLServer \u7684 <code>char</code> \u7c7b\u578b\u7684\u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u5927\u5c0f\u6620\u5c04\u4ece 0 \u66f4\u6b63\u4e3a -1\u3002</li> <li>\u89e3\u51b3\u4e86\u4f7f\u7528 SPI \u8fdb\u884c DML \u5904\u7406\u671f\u95f4\u5185\u5b58\u4f7f\u7528\u7387\u8fc7\u9ad8\u7684\u95ee\u9898\u3002</li> </ul>"},{"location":"zh/changelog/#synchdb-10-beta1-2024-10-23","title":"SynchDB 1.0 Beta1 - 2024-10-23","text":"<p>\u7b2c\u4e00\u7248 SynchDB \u8f6f\u4ef6\u53d1\u5e03\uff0c\u4e3a\u4ece\u5f02\u6784\u6570\u636e\u5e93\u5230 PostgreSQL \u7684\u65e0\u7f1d\u590d\u5236\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840</p>"},{"location":"zh/changelog/#_24","title":"\u65b0\u589e","text":"<ul> <li>\u4ece\u5f02\u6784\u6570\u636e\u5e93\u8fdb\u884c\u903b\u8f91\u590d\u5236\uff1a\uff08MySQL \u548c SQLServer\uff09\u3002</li> <li>DDL \u590d\u5236 (CREATE TABLE\u3001DROP TABLE\u3001ALTER TABLE ADD COLUMN\u3001ALTER TABLE DROP COLUMN\u3001ALTER TABLE ALTER COLUMN)</li> <li>DML \u590d\u5236\uff08INSERT\u3001UPDATE\u3001DELETE\uff09\u3002</li> <li>\u6700\u591a 30 \u4e2a\u5e76\u53d1\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u3002</li> <li>PostgreSQL \u542f\u52a8\u65f6 \u81ea\u52a8\u8fde\u63a5\u5668\u542f\u52a8\u5668\u3002</li> <li>\u5168\u5c40\u8fde\u63a5\u5668\u72b6\u6001\u548c\u6700\u540e\u9519\u8bef\u6d88\u606f\u89c6\u56fe\u3002</li> <li>\u9009\u62e9\u6027\u6570\u636e\u5e93\u548c\u8868\u590d\u5236\u3002</li> <li>\u6279\u91cf\u66f4\u6539\u4e8b\u4ef6\u3002</li> <li>\u8fde\u63a5\u5668\u4ee5\u4e0d\u540c\u7684\u5feb\u7167\u6a21\u5f0f\u91cd\u65b0\u542f\u52a8\u3002</li> <li>\u504f\u79fb\u7ba1\u7406\u63a5\u53e3 \u7528\u4e8e\u9009\u62e9\u81ea\u5b9a\u4e49\u590d\u5236\u6062\u590d\u70b9\u3002</li> <li>\u652f\u6301\u7684\u5f02\u6784\u6570\u636e\u5e93\u7684\u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u548c\u5bf9\u8c61\u540d\u79f0\u8f6c\u6362\u89c4\u5219\u3002</li> <li>JSON \u89c4\u5219\u6587\u4ef6 \u7528\u4e8e\u5b9a\u4e49\u81ea\u5b9a\u4e49\uff1a\uff08\u6570\u636e\u7c7b\u578b\u3001\u5217\u540d\u3001\u8868\u540d\u548c\u6570\u636e\u8868\u8fbe\u5f0f\u8f6c\u6362\u89c4\u5219\uff09\u3002</li> <li>2 \u79cd\u6570\u636e\u5e94\u7528\u6a21\u5f0f\uff08SPI\u3001HeapAM API\uff09</li> <li>\u65b0\u589e\u5b9e\u7528\u51fd\u6570\u7528\u4e8e\u6267\u884c\u8fde\u63a5\u5668\u64cd\u4f5c\uff1a\uff08\u542f\u52a8\u3001\u505c\u6b62\u3001\u6682\u505c\u3001\u6062\u590d\uff09\u3002</li> </ul>"},{"location":"zh/changelog/#_25","title":"\u53d8\u66f4","text":""},{"location":"zh/changelog/#_26","title":"\u4fee\u590d","text":""},{"location":"zh/architecture/architecture/","title":"\u67b6\u6784\u6982\u8ff0","text":""},{"location":"zh/architecture/architecture/#_2","title":"\u603b\u4f53\u67b6\u6784\u56fe","text":"<p>SynchDB \u6269\u5c55\u5305\u542b\u4e24\u4e2a\u4ee3\u7801\u7a7a\u95f4\uff08Java \u548c C\uff09\uff0cJNI \u4f4d\u4e8e\u4e24\u8005\u4e4b\u95f4\u4f5c\u4e3a\u534f\u8c03\u5458\u3002</p> <p>Debezium Runner - Java</p> <ul> <li>Debezium Runner \u9a71\u52a8\u7a0b\u5e8f</li> <li>\u5d4c\u5165\u5f0f Debezium \u5f15\u64ce</li> </ul> <p>SynchDB \u6269\u5c55 - C</p> <ul> <li>SynchDB \u542f\u52a8\u5668</li> <li>SynchDB Worker</li> <li>\u683c\u5f0f\u8f6c\u6362\u5668</li> <li>\u590d\u5236\u4ee3\u7406</li> <li>\u8868\u540c\u6b65\u4ee3\u7406\uff08\u5f85\u5b9a\uff09</li> </ul> <p>\u8fd9\u4e24\u4e2a\u4ee3\u7801\u7a7a\u95f4\u901a\u8fc7 Java \u539f\u751f\u63a5\u53e3 (JNI) \u4e92\u8fde\u3002JNI \u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u5141\u8bb8 Java \u5e94\u7528\u7a0b\u5e8f\u4e0e\u7528 C \u6216 C++ \u7b49\u8bed\u8a00\u7f16\u5199\u7684\u539f\u751f\u4ee3\u7801\u4ea4\u4e92\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u5b83\u4f7f Java \u7a0b\u5e8f\u80fd\u591f\u8c03\u7528\u539f\u751f\u5e94\u7528\u7a0b\u5e8f\u548c\u5e93\uff0c\u5e76\u88ab\u539f\u751f\u5e94\u7528\u7a0b\u5e8f\u548c\u5e93\u8c03\u7528\uff0c\u4ece\u800c\u5728 Java \u7684\u5e73\u53f0\u72ec\u7acb\u6027\u548c\u539f\u751f\u4ee3\u7801\u7684\u6027\u80fd\u4f18\u52bf\u4e4b\u95f4\u67b6\u8d77\u4e86\u4e00\u5ea7\u6865\u6881\u3002JNI \u901a\u5e38\u7528\u4e8e\u96c6\u6210\u7279\u5b9a\u4e8e\u5e73\u53f0\u7684\u529f\u80fd\u3001\u4f18\u5316\u5e94\u7528\u7a0b\u5e8f\u4e2d\u6027\u80fd\u5173\u952e\u90e8\u5206\uff0c\u6216\u8bbf\u95ee Java \u4e2d\u4e0d\u53ef\u7528\u7684\u65e7\u5e93\u3002\u5b83\u9700\u8981\u8c28\u614e\u7ba1\u7406\u8d44\u6e90\uff0c\u56e0\u4e3a\u5b83\u6d89\u53ca\u5728 Java \u865a\u62df\u673a (JVM) \u548c\u672c\u673a\u73af\u5883\u4e4b\u95f4\u5207\u6362\uff0c\u8fd9\u53ef\u80fd\u4f1a\u589e\u52a0\u590d\u6742\u6027\u3002</p> <p>\u56e0\u6b64\uff0cSynchDB \u9700\u8981 JNI \u5728 Debezium \u8fd0\u884c\u5668\u5f15\u64ce\u548c SynchDB PostgreSQL \u6269\u5c55\u4e4b\u95f4\u4ea4\u6362\u8d44\u6e90\u3002JNI \u53ef\u5728 Java \u5b89\u88c5\uff08\u4f8b\u5982 openjdk\uff09\u4e2d\u4f7f\u7528\u3002</p>"},{"location":"zh/architecture/architecture/#debezium-runner-java","title":"Debezium Runner - Java","text":"<p>\u8fd9\u662f\u4e00\u4e2a Java \u9a71\u52a8\u7a0b\u5e8f\uff0c\u5b83\u5229\u7528 Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u4ee5\u53ca\u5404\u79cd\u8fde\u63a5\u5230\u4e0d\u540c\u6570\u636e\u5e93\u6e90\u7684\u201c\u8fde\u63a5\u5668\u201d\u3002\u5b83\u662f\u5b9e\u73b0\u4ece\u591a\u4e2a\u6570\u636e\u5e93\u4f9b\u5e94\u5546\u8fdb\u884c\u903b\u8f91\u590d\u5236\u7684\u5173\u952e\u5e95\u5c42\u7ec4\u4ef6\u3002\u5b83\u7684\u4e3b\u8981\u804c\u8d23\u662f\u8fde\u63a5\u5230\u6307\u5b9a\u7684\u8fdc\u7a0b\u6570\u636e\u5e93\uff0c\u5e76\u5b9a\u671f\u83b7\u53d6\u5176\u66f4\u6539\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u901a\u7528\u7684 JSON \u7ed3\u6784\u3002\u7136\u540e\uff0c\u6b64 JSON \u7ed3\u6784\u5c06\u4f20\u9012\u7ed9\u201cC \u8bed\u8a00 SynchDB \u6269\u5c55\u201d\u8fdb\u884c\u5904\u7406\uff0c\u5e76\u6700\u7ec8\u5c06\u66f4\u6539\u5e94\u7528\u4e8e PostgreSQL\u3002</p> <p>Debezium Runner \u7ec4\u4ef6\u67b6\u6784</p>"},{"location":"zh/architecture/architecture/#synchdb-c","title":"SynchDB \u6269\u5c55 - C","text":"<p>\u8fd9\u662f\u521d\u59cb\u5316 Java \u865a\u62df\u673a (JVM) \u5e76\u5728\u5176\u4e0a\u8fd0\u884c Debezium Runner \u7684\u4e3b\u8981\u5165\u53e3\u70b9\u3002\u5b83\u4f1a\u5b9a\u671f\u4ece Debezium Runner \u83b7\u53d6\u4e00\u6279 JSON \u53d8\u66f4\u4e8b\u4ef6\uff0c\u5904\u7406\u8fd9\u4e9b\u6570\u636e\u5e76\u5c06\u5176\u5e94\u7528\u5230 PostgreSQL\u3002\u5b83\u8fd8\u8d1f\u8d23\u901a\u77e5 Debezium \u5df2\u6210\u529f\u5b8c\u6210\u4e00\u6279 JSON \u53d8\u66f4\u4e8b\u4ef6\uff0c\u4ee5\u4fbf\u4e24\u4e2a\u7ec4\u4ef6\u5728\u590d\u5236\u8fdb\u5ea6\u65b9\u9762\u4fdd\u6301\u540c\u6b65\u3002</p> <ul> <li>Debezium \u4e8b\u4ef6\u5904\u7406\u5668\u67b6\u6784</li> <li>Openlog Replicator \u4e8b\u4ef6\u5904\u7406\u5668\u67b6\u6784</li> </ul>"},{"location":"zh/architecture/batch_change_handling/","title":"\u6279\u91cf\u53d8\u66f4\u5904\u7406","text":""},{"location":"zh/architecture/batch_change_handling/#_2","title":"\u6982\u8ff0","text":"<p>SynchDB \u4ee5 <code>synchdb.naptime</code> \u6beb\u79d2\uff08\u9ed8\u8ba4 100\uff09\u7684\u5468\u671f\u4ece Debezium \u8fd0\u884c\u5f15\u64ce\u5b9a\u671f\u83b7\u53d6\u4e00\u6279\u53d8\u66f4\u8bf7\u6c42\u3002\u8fd9\u6279\u53d8\u66f4\u8bf7\u6c42\u968f\u540e\u7531 SynchDB \u5904\u7406\u3002\u5982\u679c\u6279\u6b21\u4e2d\u7684\u6240\u6709\u53d8\u66f4\u8bf7\u6c42\u90fd\u5df2\u6210\u529f\u5904\u7406\uff08\u89e3\u6790\u3001\u8f6c\u6362\u5e76\u5e94\u7528\u5230 PostgreSQL\uff09\uff0cSynchDB \u5c06\u901a\u77e5 Debezium \u8fd0\u884c\u5f15\u64ce\u8be5\u6279\u6b21\u5df2\u5b8c\u6210\u3002\u8fd9\u5411 Debezium \u8fd0\u884c\u5668\u53d1\u51fa\u4fe1\u53f7\uff0c\u63d0\u4ea4\u76f4\u5230\u6700\u540e\u4e00\u6761\u6210\u529f\u5b8c\u6210\u7684\u53d8\u66f4\u8bb0\u5f55\u7684\u504f\u79fb\u91cf\u3002\u901a\u8fc7\u8fd9\u79cd\u673a\u5236\uff0cSynchDB \u80fd\u591f\u8ddf\u8e2a\u6bcf\u6761\u53d8\u66f4\u8bb0\u5f55\uff0c\u5e76\u6307\u793a Debezium \u8fd0\u884c\u5668\u4e0d\u8981\u83b7\u53d6\u4e4b\u524d\u5df2\u5904\u7406\u7684\u65e7\u53d8\u66f4\uff0c\u6216\u4e0d\u8981\u53d1\u9001\u91cd\u590d\u7684\u53d8\u66f4\u8bb0\u5f55\u3002</p>"},{"location":"zh/architecture/batch_change_handling/#_3","title":"\u6279\u91cf\u5904\u7406","text":"<p>SynchDB \u5728\u4e00\u4e2a\u4e8b\u52a1\u5185\u5904\u7406\u4e00\u6279\u53d8\u66f4\uff08\u4e5f\u53eb\u4e00\u4e2a batch\uff09\u3002\u8fd9\u610f\u5473\u7740\u4e00\u6279\u5185\u7684\u53d8\u66f4\u4e8b\u4ef6\u8981\u4e48\u5168\u90e8\u5904\u7406\uff0c\u8981\u4e48\u5168\u90e8\u4e0d\u5904\u7406\u3002\u5f53\u6240\u6709\u66f4\u6539\u90fd\u6210\u529f\u5904\u7406\u540e\uff0cSynchDB \u4f1a\u5411 Debezium \u8fd0\u884c\u5668\u5f15\u64ce\u53d1\u9001\u4e00\u6761\u6d88\u606f\uff0c\u5c06\u6279\u5904\u7406\u6807\u8bb0\u4e3a\u5df2\u5904\u7406\u5b8c\u6210\u3002\u6b64\u64cd\u4f5c\u4f1a\u5bfc\u81f4\u504f\u79fb\u91cf\uff08offset\uff09\u88ab\u63d0\u4ea4\u5e76\u6700\u7ec8\u5237\u65b0\u5230\u78c1\u76d8\u3002\u504f\u79fb\u91cf\u8868\u793a\u590d\u5236\u671f\u95f4\u7684\u903b\u8f91\u4f4d\u7f6e\uff0c\u7c7b\u4f3c\u4e8e PostgreSQL \u4e2d\u7684 LSN\uff08\u65e5\u5fd7\u5e8f\u5217\u53f7\uff09\u3002</p> <p></p> <p>\u5982\u679c\u4e00\u6279\u66f4\u6539\u5728 PostgreSQL \u4e0a\u90e8\u5206\u6210\u529f\uff0c\u5219\u4f1a\u5bfc\u81f4\u4e8b\u52a1\u56de\u6eda\uff0c\u5e76\u4e14 SynchDB \u4e0d\u4f1a\u901a\u77e5 Debezium \u8fd0\u884c\u5668\u6279\u5904\u7406\u5df2\u5b8c\u6210\u3002\u5f53\u8fde\u63a5\u5668\u91cd\u65b0\u542f\u52a8\u65f6\uff0c\u540c\u4e00\u6279\u5c06\u518d\u6b21\u6062\u590d\u5904\u7406\u3002</p>"},{"location":"zh/architecture/batch_change_handling/#openlog-replicator-connector","title":"Openlog Replicator Connector \u6279\u91cf\u5904\u7406","text":"<p>\u7531\u65bc Openlog Replicator Connector \u4e0d\u4f9d\u8cf4 Debezium \u4f86\u5354\u8abf\u8b8a\u66f4\u4e8b\u4ef6\u7684\u6279\u6b21\u8655\u7406\uff0c\u5176\u6279\u6b21\u5b8c\u5168\u53d6\u6c7a\u65bc OLR \u7528\u6236\u7aef\u7684\u539f\u59cb\u8b80\u53d6\u7de9\u885d\u5340\u5927\u5c0f\uff08\u7531 GUC <code>synchdb.olr_read_buffer_size</code> \u914d\u7f6e\uff09\u3002\u5ba2\u6236\u7aef\u6703\u5617\u8a66\u5f9e\u5957\u63a5\u5b57\u8b80\u53d6\u76e1\u53ef\u80fd\u591a\u7684\u6578\u64da\uff0c\u9019\u4e9b\u6578\u64da\u53ef\u80fd\u5305\u542b\u591a\u500b\u8b8a\u66f4\u4e8b\u4ef6\u3002\u8b80\u53d6\u7de9\u885d\u5340\u4e2d\u51fa\u73fe\u7684\u591a\u500b\u300c\u5b8c\u6574\u300d\u8b8a\u66f4\u4e8b\u4ef6\u5c07\u88ab\u8996\u70ba\u76f8\u540c\u6279\u6b21\uff0c\u4e26\u5728\u540c\u4e00\u500b PostgreSQL \u4e8b\u52d9\u4e2d\u57f7\u884c\u3002\u5982\u679c\u8b80\u53d6\u7de9\u885d\u5340\u5305\u542b\u4e0d\u5b8c\u6574\u7684\u8b8a\u66f4\u4e8b\u4ef6\uff0c\u5247\u8a72\u4e8b\u4ef6\u4e0d\u6703\u88ab\u8a08\u5165\u76ee\u524d\u6279\u6b21\u3002\u9810\u8a08\u4e0b\u6b21\u8b80\u53d6\u6642\uff0c\u8a72\u4e0d\u5b8c\u6574\u8b8a\u66f4\u4e8b\u4ef6\u7684\u5269\u9918\u8cc7\u6599\u5c07\u6703\u5230\u9054\uff0c\u4e26\u6210\u70ba\u4e0b\u4e00\u6279\u8b8a\u66f4\u4e8b\u4ef6\u7684\u4e00\u90e8\u5206\u3002</p> <p>\u56e0\u6b64\uff0c\u589e\u52a0 <code>synchdb.olr_read_buffer_size</code> \u7684\u503c\u6703\u589e\u52a0\u6279\u6b21\u5927\u5c0f\u3002</p>"},{"location":"zh/architecture/ddl_replication/","title":"DDL \u590d\u5236","text":""},{"location":"zh/architecture/ddl_replication/#_1","title":"\u6982\u8ff0","text":"<p>SynchDB \u4e3a\u6570\u636e\u5b9a\u4e49\u8bed\u8a00\uff08DDL\uff09\u64cd\u4f5c\u63d0\u4f9b\u5168\u9762\u652f\u6301\uff0c\u5b9e\u73b0\u4e0d\u540c\u6570\u636e\u5e93\u7cfb\u7edf\u4e4b\u95f4\u7684\u5b9e\u65f6\u67b6\u6784\u540c\u6b65\u3002</p>"},{"location":"zh/architecture/ddl_replication/#ddl_1","title":"\u652f\u6301\u7684 DDL \u547d\u4ee4","text":"<p>SynchDB \u652f\u6301\u4ee5\u4e0b DDL \u64cd\u4f5c\uff1a</p> <p>\u2705 CREATE [table] \u2705 ALTER [table] ADD COLUMN \u2705 ALTER [table] DROP COLUMN \u2705 ALTER [table] ALTER COLUMN \u2705 DROP [table]  </p> <p>\u5bf9\u4e8e\u57fa\u4e8e Openlog Replicator \u7684\u8fde\u63a5\u5668\uff0c\u652f\u6301\u4ee5\u4e0b Oracle DDL \u8bed\u6cd5\uff1a</p> <p>\u2705 CREATE [table] \u2705 DROP [table] \u2705 ALTER [table] MODIFY \u2705 ALTER [table] ADD COLUMN \u2705 ALTER [table] DROP COLUMN \u2705 ALTER [table] ADD CONSTRAINT \u2705 ALTER [table] DROP CONSTRAINT</p>"},{"location":"zh/architecture/ddl_replication/#_2","title":"\u8be6\u7ec6\u547d\u4ee4\u652f\u6301","text":""},{"location":"zh/architecture/ddl_replication/#create-table","title":"CREATE TABLE","text":"<p>SynchDB \u5728 CREATE TABLE \u4e8b\u4ef6\u671f\u95f4\u6355\u83b7\u4ee5\u4e0b\u5c5e\u6027\uff1a</p> \u5c5e\u6027 \u63cf\u8ff0 \u8868\u540d \u5b8c\u5168\u9650\u5b9a\u540d\u79f0\uff08FQN\uff09\u683c\u5f0f \u5217\u540d \u5355\u72ec\u7684\u5217\u6807\u8bc6\u7b26 \u6570\u636e\u7c7b\u578b \u5217\u6570\u636e\u7c7b\u578b\u89c4\u8303 \u6570\u636e\u957f\u5ea6 \u957f\u5ea6/\u7cbe\u5ea6\u89c4\u8303\uff08\u5982\u9002\u7528\uff09 \u65e0\u7b26\u53f7\u6807\u5fd7 \u6570\u503c\u7c7b\u578b\u7684\u65e0\u7b26\u53f7\u7ea6\u675f \u53ef\u7a7a\u6027 NULL/NOT NULL \u7ea6\u675f \u9ed8\u8ba4\u503c \u9ed8\u8ba4\u503c\u8868\u8fbe\u5f0f \u4e3b\u952e \u4e3b\u952e\u5217\u5b9a\u4e49 <p>\u6ce8\u610f\uff1a\u5f53\u524d\u4e0d\u652f\u6301\u5176\u4ed6 CREATE TABLE \u5c5e\u6027</p>"},{"location":"zh/architecture/ddl_replication/#drop-table","title":"DROP TABLE","text":"<p>\u6355\u83b7\u7684\u5c5e\u6027\uff1a - \u8981\u5220\u9664\u7684\u8868\u540d\uff08FQN \u683c\u5f0f\uff09</p>"},{"location":"zh/architecture/ddl_replication/#alter-table-add-column","title":"ALTER TABLE ADD COLUMN","text":"<p>\u6355\u83b7\u4ee5\u4e0b\u5c5e\u6027\uff1a</p> \u5c5e\u6027 \u63cf\u8ff0 \u5217\u540d \u65b0\u6dfb\u52a0\u5217\u7684\u540d\u79f0 \u6570\u636e\u7c7b\u578b \u65b0\u5217\u7684\u6570\u636e\u7c7b\u578b \u6570\u636e\u957f\u5ea6 \u957f\u5ea6\u89c4\u8303\uff08\u5982\u9002\u7528\uff09 \u65e0\u7b26\u53f7\u6807\u5fd7 \u65e0\u7b26\u53f7\u7ea6\u675f \u53ef\u7a7a\u6027 NULL/NOT NULL \u89c4\u8303 \u9ed8\u8ba4\u503c \u9ed8\u8ba4\u503c\u8868\u8fbe\u5f0f \u4e3b\u952e \u66f4\u65b0\u7684\u4e3b\u952e\u5b9a\u4e49 <p>\u76ee\u524d\u4e0d\u652f\u6301\u5728 ALTER TABLE ADD COLUMN \u671f\u95f4\u53ef\u4ee5\u6307\u5b9a\u7684\u5176\u4ed6\u5c5e\u6027\u3002</p>"},{"location":"zh/architecture/ddl_replication/#alter-table-drop-column","title":"ALTER TABLE DROP COLUMN","text":"<p>\u6355\u83b7\uff1a - \u8981\u5220\u9664\u7684\u5217\u540d\u5217\u8868</p>"},{"location":"zh/architecture/ddl_replication/#alter-table-alter-column","title":"ALTER TABLE ALTER COLUMN","text":"<p>\u652f\u6301\u7684\u4fee\u6539\uff1a</p> \u4fee\u6539 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u66f4\u6539\u5217\u6570\u636e\u7c7b\u578b \u7c7b\u578b\u957f\u5ea6 \u4fee\u6539\u7c7b\u578b\u957f\u5ea6/\u7cbe\u5ea6 \u9ed8\u8ba4\u503c \u66f4\u6539/\u5220\u9664\u9ed8\u8ba4\u503c NOT NULL \u4fee\u6539/\u5220\u9664 NOT NULL \u7ea6\u675f <p>\u76ee\u524d\u4e0d\u652f\u6301\u5728 ALTER TABLE ALTER COLUMN \u671f\u95f4\u53ef\u4ee5\u6307\u5b9a\u7684\u5176\u4ed6\u5c5e\u6027\u3002</p> <p>\u8bf7\u6ce8\u610f\uff0cSynchDB \u4ec5\u652f\u6301\u5bf9\u73b0\u6709\u5217\u8fdb\u884c\u57fa\u672c\u7684\u6570\u636e\u7c7b\u578b\u66f4\u6539\u3002\u4f8b\u5982\uff0c<code>INT</code> \u2192 <code>BIGINT</code> \u6216 <code>VARCHAR</code> \u2192 <code>TEXT</code>\u3002\u76ee\u524d\u4e0d\u652f\u6301\u590d\u6742\u7684\u6570\u636e\u7c7b\u578b\u66f4\u6539\uff0c\u5982 <code>TEXT</code> \u2192 <code>INT</code> \u6216 <code>INT</code> \u2192 <code>TIMESTAMP</code>\u3002\u8fd9\u662f\u56e0\u4e3a PostgreSQL \u8981\u6c42\u7528\u6237\u989d\u5916\u63d0\u4f9b\u7c7b\u578b\u8f6c\u6362\u51fd\u6570\u6765\u6267\u884c\u590d\u6742\u6570\u636e\u7c7b\u578b\u66f4\u6539\u7684\u7c7b\u578b\u8f6c\u6362\u3002SynchDB \u76ee\u524d\u4e0d\u77e5\u9053\u5bf9\u7279\u5b9a\u7c7b\u578b\u8f6c\u6362\u4f7f\u7528\u4ec0\u4e48\u7c7b\u578b\u8f6c\u6362\u51fd\u6570\u3002\u5c06\u6765\uff0c\u6211\u4eec\u53ef\u80fd\u5141\u8bb8\u7528\u6237\u901a\u8fc7\u89c4\u5219\u6587\u4ef6\u63d0\u4f9b\u81ea\u5df1\u7684\u8f6c\u6362\u51fd\u6570\u7528\u4e8e\u7279\u5b9a\u7c7b\u578b\u8f6c\u6362\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u652f\u6301\u3002</p>"},{"location":"zh/architecture/ddl_replication/#_3","title":"\u6570\u636e\u5e93\u7279\u5b9a\u884c\u4e3a","text":""},{"location":"zh/architecture/ddl_replication/#mysql-ddl","title":"MySQL DDL \u66f4\u6539\u4e8b\u4ef6","text":"<p>\u7531\u4e8e MySQL \u5728 binlog \u548c Oracle \u5728 logminer \u4e2d\u540c\u65f6\u8bb0\u5f55 DDL \u548c DML \u64cd\u4f5c\uff0cSynchDB \u80fd\u591f\u5728\u5b83\u4eec\u53d1\u751f\u65f6\u590d\u5236 DDL \u548c DML\u3002\u5728 MySQL \u548c Oracle \u7aef\u4e0d\u9700\u8981\u7279\u6b8a\u64cd\u4f5c\u6765\u542f\u7528 DDL \u590d\u5236\u3002</p>"},{"location":"zh/architecture/ddl_replication/#sqlserver-ddl","title":"SQLServer DDL \u66f4\u6539\u4e8b\u4ef6","text":"<p>SQLServer \u5728\u6d41\u6a21\u5f0f\u4e0b\u4e0d\u539f\u751f\u652f\u6301 DDL \u590d\u5236\u3002\u8868\u67b6\u6784\u662f\u5728\u8fde\u63a5\u5668\u9996\u6b21\u542f\u52a8\u65f6\u7684\u521d\u59cb\u5feb\u7167\u6784\u5efa\u9636\u6bb5\u7531 SynchDB \u6784\u5efa\u7684\u3002\u5728\u6b64\u9636\u6bb5\u4e4b\u540e\uff0cSynchDB \u5c06\u5c1d\u8bd5\u68c0\u6d4b\u4efb\u4f55\u67b6\u6784\u66f4\u6539\uff0c\u4f46\u9700\u8981\u660e\u786e\u5c06\u5176\u6dfb\u52a0\u5230 SQL Server \u7684 CDC \u8868\u5217\u8868\u4e2d\u3002</p>"},{"location":"zh/architecture/ddl_replication/#sqlserver-create-table","title":"\u5728 SQLServer \u4e0a\u89e6\u53d1 CREATE TABLE \u4e8b\u4ef6","text":"<p>\u8981\u5728 SQL Server \u4e0a\u521b\u5efa\u65b0\u8868\u5e76\u6dfb\u52a0\u5230\u5176 CDC \u8868\u5217\u8868\u4e2d\uff1a <pre><code>CREATE TABLE dbo.altertest (\n    a INT,\n    b TEXT\n    );\nGO\n\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @role_name = NULL,\n    @supports_net_changes = 0,\n    @capture_instance = 'dbo_altertest_1'\nGO\n</code></pre></p> <p>\u8be5\u547d\u4ee4\u5c06\u8868 <code>dbo.altertest</code> \u6dfb\u52a0\u5230 CDC \u8868\u5217\u8868\u4e2d\uff0c\u5e76\u5c06\u5bfc\u81f4 SynchDB \u63a5\u6536 CREATE TABLE DDL \u66f4\u6539\u4e8b\u4ef6\u3002</p>"},{"location":"zh/architecture/ddl_replication/#alter-table","title":"\u89e6\u53d1 ALTER TABLE \u4e8b\u4ef6","text":"<p>\u5982\u679c\u66f4\u6539\u4e86\u73b0\u6709\u8868\uff08\u6dfb\u52a0\u3001\u5220\u9664\u6216\u66f4\u6539\u5217\uff09\uff0c\u9700\u8981\u660e\u786e\u66f4\u65b0\u5230 SQLServer \u7684 CDC \u8868\u5217\u8868\u4e2d\uff0c\u4ee5\u4fbf SynchDB \u80fd\u591f\u63a5\u6536 ALTER TABLE \u4e8b\u4ef6\u3002</p> <p>\u4f8b\u5982\uff1a</p> <p>\u5728 SQLServer \u4e2d\u66f4\u6539\u8868\uff1a <pre><code>ALTER TABLE altertest ADD c NVARCHAR(MAX),\n    d INT DEFAULT 0 NOT NULL,\n    e NVARCHAR(255) NOT NULL,\n    f INT DEFAULT 5 NOT NULL,\n    CONSTRAINT PK_altertest PRIMARY KEY (\n    d,\n    f\n    );\nGO\n</code></pre></p> <p>\u7981\u7528\u65e7\u7684\u6355\u83b7\u5b9e\u4f8b\uff1a <pre><code>EXEC sys.sp_cdc_disable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @capture_instance = 'dbo_altertest_1';\nGO\n</code></pre></p> <p>\u542f\u7528\u4e3a\u65b0\u7684\u6355\u83b7\u5b9e\u4f8b\uff1a <pre><code>EXEC sys.sp_cdc_enable_table @source_schema = 'dbo',\n    @source_name = 'altertest',\n    @role_name = NULL,\n    @supports_net_changes = 0,\n    @capture_instance = 'dbo_altertest_2';\nGO\n</code></pre></p> <p>\u6dfb\u52a0\u65b0\u8bb0\u5f55\uff1a <pre><code>INSERT INTO altertest VALUES(1, 's', 'c', 1, 'v', 5);\nGO\n</code></pre></p> <p>\u4e0a\u8ff0\u793a\u4f8b\u5e94\u5141\u8bb8 SynchDB \u63a5\u6536 ALTER TABLE ADD COLUMN \u548c INSERT \u4e8b\u4ef6\u3002\u65e0\u9700\u91cd\u542f SQL Server \u6216 SynchDB \u5373\u53ef\u6355\u83b7\u6b64\u7c7b\u4e8b\u4ef6\u3002\u8fd9\u540c\u6837\u9002\u7528\u4e8e ALTER TABLE DROP COLUMN \u548c ALTER TABLE ALTER COLUMN \u4e8b\u4ef6\u3002</p>"},{"location":"zh/architecture/debezium_event_processor/","title":"Debezium \u4e8b\u4ef6\u5904\u7406\u5668 - C","text":""},{"location":"zh/architecture/debezium_event_processor/#debezium","title":"Debezium \u4e8b\u4ef6\u5904\u7406\u5668\u7ec4\u4ef6\u56fe","text":"<p>Debezium \u4e8b\u4ef6\u5904\u7406\u5668\u662f\u7531 SynchDB \u6269\u5c55\u53d1\u8d77\u548c\u542f\u52a8\u7684 PostgreSQL \u540e\u53f0\u5de5\u4f5c\u8fdb\u7a0b\u3002\u5b83\u8d1f\u8d23\u521d\u59cb\u5316 Java \u865a\u62df\u673a (JVM)\uff0c\u8fd0\u884c Debezium Runner\u6a21\u5757\uff0c\uff08\u5b83\u662f SynchDB \u7684 Java \u90e8\u5206\uff09\uff0c\u5229\u7528\u5d4c\u5165\u5f0f Debezium \u5f15\u64ce\u4ece\u5f02\u6784\u6570\u636e\u5e93\u6e90\u83b7\u53d6\u66f4\u6539\u4e8b\u4ef6\u3002\u6bcf\u4e2a SynchDB \u5de5\u4f5c\u8fdb\u7a0b\u90fd\u7531\u4e0b\u9762\u5217\u51fa\u7684\u7ec4\u4ef6\u548c\u6a21\u5757\u7ec4\u6210\uff1a</p> <ol> <li>\u4e8b\u4ef6\u83b7\u53d6\u5668</li> <li>JVM + DBZ \u521d\u59cb\u5316\u7a0b\u5e8f</li> <li>\u8bf7\u6c42\u5904\u7406\u5668</li> <li>JSON \u89e3\u6790\u5668</li> <li>\u5bf9\u8c61\u6620\u5c04\u5f15\u64ce</li> <li>\u7edf\u8ba1\u4fe1\u606f\u6536\u96c6\u5668</li> <li>DDL \u8f6c\u6362\u5668</li> <li>DML \u8f6c\u6362\u5668</li> <li>\u9519\u8bef\u5904\u7406\u7a0b\u5e8f</li> <li>SPI \u5ba2\u6237\u7aef</li> <li>\u6267\u884c\u5668 API</li> </ol>"},{"location":"zh/architecture/debezium_event_processor/#1","title":"1) \u4e8b\u4ef6\u83b7\u53d6\u5668","text":"<p>\u4e8b\u4ef6\u83b7\u53d6\u5668\u4e3b\u8981\u8d1f\u8d23\u4ece\u8fd0\u884c\u5728 JVM \u4e2d\u7684\u5d4c\u5165\u5f0f Debezium Runner \u83b7\u53d6\u4e00\u6279 JSON \u53d8\u66f4\u4e8b\u4ef6\u3002\u6b64\u64cd\u4f5c\u901a\u8fc7 Java \u63a5\u53e3 (JNI) \u5e93\u5b8c\u6210\uff0c\u901a\u8fc7\u5b9a\u671f\u8c03\u7528 JAVA \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a JAVA <code>String</code> \u5217\u8868\uff0c\u8be5\u5217\u8868\u4ee5 JSON \u683c\u5f0f\u8868\u793a\u6bcf\u4e2a\u53d8\u66f4\u8bf7\u6c42\u3002\u6b64\u5217\u8868 \u8868\u793a\u4e00\u6279 JSON \u53d8\u66f4\u4e8b\u4ef6\u3002\u518d\u6b21\u8c03\u7528 JNI \u5e93\u6765\u8fed\u4ee3\u6b64 <code>List</code>\uff0c\u5c06\u5185\u5bb9\u4ece JAVA <code>String</code> \u8f6c\u6362\u4e3a C \u5b57\u7b26\u4e32\uff0c\u5e76\u5c06\u5176\u53d1\u9001\u5230 <code>4) JSON \u89e3\u6790\u5668</code> \u8fdb\u884c\u8fdb\u4e00\u6b65\u5904\u7406\u3002\u83b7\u53d6\u9891\u7387\u53ef\u901a\u8fc7 <code>synchdb.naptime</code> \u914d\u7f6e\uff0c\u6279\u6b21\u7684\u6700\u5927\u5927\u5c0f\u53ef\u901a\u8fc7 <code>synchdb.dbz_batch_size</code> \u914d\u7f6e\u3002</p> <p>\u5f53\u6279\u6b21\u5b8c\u6210\u65f6\uff0c\u5373\u5176\u4e2d\u7684\u6240\u6709\u66f4\u6539\u4e8b\u4ef6\u90fd\u5df2\u5904\u7406\u5b8c\u6bd5\uff0c\u5b83\u5c06\u901a\u8fc7 JNI \u8c03\u7528 <code>markBatchComplete()</code> JAVA \u51fd\u6570\u4ee5\u6307\u793a\u6b64\u6279\u6b21\u5df2\u6210\u529f\u5b8c\u6210\u3002\u8fd9\u5c06\u5bfc\u81f4 Debezium Runner \u63d0\u4ea4\u5e76\u63a8\u8fdb\u504f\u79fb\u91cf\u3002\u6709\u5173\u6279\u6b21\u7ba1\u7406\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904\u3002</p>"},{"location":"zh/architecture/debezium_event_processor/#2-jvm-debezium-dbz","title":"2) JVM + Debezium (DBZ) \u521d\u59cb\u5316\u7a0b\u5e8f","text":"<p>JVM + DBZ \u521d\u59cb\u5316\u7a0b\u5e8f\u4e3b\u8981\u8d1f\u8d23\u5b9e\u4f8b\u5316\u65b0\u7684 JVM \u73af\u5883\u5e76\u5728\u5176\u4e2d\u8fd0\u884c Debezium Runner (<code>dbz-engine-x.x.x.jar</code>)\u3002\u6b64 .jar \u6587\u4ef6\u9ed8\u8ba4\u5b89\u88c5\u5728 <code>pg_config</code> \u8fd4\u56de\u7684 $LIBDIR \u4e2d\u3002\u60a8\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf <code>DBZ_ENGINE_DIR</code> \u4e3a Debezium Runner .jar \u6587\u4ef6\u6307\u5b9a\u5907\u7528\u8def\u5f84\u3002SynchDB \u5f53\u524d\u4f7f\u7528 <code>JNI_VERSION_10</code> \u4f5c\u4e3a JNI \u7248\u672c\uff0c\u517c\u5bb9 JAVA v10 \u81f3 v18\u3002\u4f46\u662f\uff0c\u5c06\u6765\u6211\u4eec\u53ef\u80fd\u4f1a\u5347\u7ea7 JNI \u7248\u672c\u4ee5\u83b7\u5f97 JNI \u7684\u6700\u65b0\u6539\u8fdb\u548c\u4f18\u52bf\u3002\u53ef\u4ee5\u901a\u8fc7 <code>synchdb.jvm_max_heap_size</code> \u914d\u7f6e\u5206\u914d\u7ed9 JVM \u7684\u6700\u5927heap\u5185\u5b58\u3002\u5982\u679c\u8bbe\u7f6e\u4e3a\u96f6\uff0cJVM \u5c06\u81ea\u52a8\u5206\u914d\u7406\u60f3\u7684heap\u5927\u5c0f\u3002</p> <p>\u8bf7\u6ce8\u610f\uff0c\u6bcf\u4e2a SynchDB \u5de5\u4f5c\u8fdb\u7a0b\u90fd\u4f1a\u521d\u59cb\u5316\u5e76\u8fd0\u884c\u4e00\u4e2a JVM \u5b9e\u4f8b\uff0c\u56e0\u6b64\u8fd0\u884c\u7684\u5de5\u4f5c\u8fdb\u7a0b\u8d8a\u591a\uff0c\u6240\u9700\u7684heap\u5185\u5b58\u5c31\u8d8a\u591a\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528 <code>synchdb_log_jvm_meminfo('$connector_name')</code> \u51fd\u6570\u67e5\u770b SynchDB \u5de5\u4f5c\u8fdb\u7a0b\u7684 JVM \u5f53\u524dheap\u548c\u975eheap\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\uff0c\u5185\u5b58\u6458\u8981\u5c06\u8bb0\u5f55\u5728 PostgreSQL \u65e5\u5fd7\u6587\u4ef6\u4e2d\u3002</p>"},{"location":"zh/architecture/debezium_event_processor/#3","title":"3) \u8bf7\u6c42\u5904\u7406\u5668","text":"<p>\u8bf7\u6c42\u5904\u7406\u5668\u4e3b\u8981\u8d1f\u8d23\u68c0\u67e5\u548c\u5904\u7406\u6765\u81ea SynchDB \u7528\u6237\u7684\u4efb\u4f55\u4f20\u5165\u72b6\u6001\u66f4\u6539\u8bf7\u6c42\u3002\u6b64\u7c7b\u72b6\u6001\u66f4\u6539\u8bf7\u6c42\u7684\u793a\u4f8b\u5305\u62ec\u4ece\u201c\u540c\u6b65\u201d\u5230\u201c\u6682\u505c\u201d\uff0c\u4ece\u201c\u6682\u505c\u201d\u5230\u201c\u66f4\u65b0\u504f\u79fb\u201d\u7b49\u3002\u4ee5\u4e0b\u662f synchdb \u7684\u72b6\u6001\u56fe\u3002\u66f4\u591a\u4fe1\u606f\u53ef\u4ee5\u5728 \u6b64\u5904 \u627e\u5230\u3002</p> <p></p>"},{"location":"zh/architecture/debezium_event_processor/#4-json","title":"4) JSON \u89e3\u6790\u5668","text":"<p>JSON \u89e3\u6790\u5668\u8d1f\u8d23\u5c06\u4f20\u5165\u7684 JSON \u66f4\u6539\u4e8b\u4ef6\u89e3\u6790\u4e3a SynchDB \u53ef\u4ee5\u4f7f\u7528\u7684 C \u7ed3\u6784\u3002SynchDB \u4f9d\u8d56 PostgreSQL \u7684\u539f\u751f JSONB \u89e3\u6790\u5668\u6765\u6ee1\u8db3\u6240\u6709\u89e3\u6790\u548c\u8fed\u4ee3\u9700\u6c42\u3002\u5bf9\u4e8e DML JSON \u4e8b\u4ef6\uff0c\u5b83\u9996\u5148\u89e3\u6790 JSON \u66f4\u6539\u4e8b\u4ef6\u7684\u201c\u67b6\u6784\u201d\u90e8\u5206\uff08\u5728\u672c\u6587\u6863\u4e2d\u4e5f\u79f0\u4e3a\u5143\u6570\u636e\uff09\uff0c\u4ee5\u4e86\u89e3 Debezium \u5982\u4f55\u8868\u793a\u7528\u6237\u6570\u636e\u3002\u8fd9\u5305\u62ec\u6bcf\u4e2a\u5b57\u6bb5\u7684\u6570\u636e\u7c7b\u578b\u8868\u793a\u3001\u503c\u7684\u6bd4\u4f8b\u2026\u2026\u7b49\u7b49\u3002\u7136\u540e\uff0c\u5b83\u89e3\u6790\u201c\u6709\u6548\u8d1f\u8f7d\u201d\u4ee5\u83b7\u53d6\u201c\u4e4b\u524d\u201d\u548c\u201c\u4e4b\u540e\u201d\u7684\u503c\u3002\u6700\u540e\uff0c\u5b83\u89e3\u6790\u201c\u6e90\u201d\u90e8\u5206\u4ee5\u83b7\u53d6\u8868\u540d\u3001\u6570\u636e\u5e93\u540d\u79f0\u548c\u6570\u636e\u6765\u6e90\u7684\u8fde\u63a5\u5668\u7c7b\u578b\u3002</p> <p>\u5bf9\u4e8e DML JSON \u4e8b\u4ef6\uff0c\u5c06\u89e3\u6790\u76f8\u540c\u7684\u90e8\u5206\uff0c\u4f46\u201c\u6709\u6548\u8d1f\u8f7d\u201d\u4e0b\u9884\u671f\u7684\u5c5e\u6027\u4e0d\u540c\u3002\u5b83\u89e3\u6790\u201c\u6709\u6548\u8d1f\u8f7d\u201d\u4e0b\u7684\u201ctableChanges\u201d\u4ee5\u4e86\u89e3\u6307\u5b9a\u8868\u7684\u5217\u540d\u3001\u7c7b\u578b\u548c\u5176\u4ed6\u5c5e\u6027\u3002</p> <p>\u6839\u636e\u64cd\u4f5c\u7684\u6027\u8d28\uff0c\u751f\u6210\u7684 C \u7ed3\u6784\u6570\u636e\u968f\u540e\u88ab\u53d1\u9001\u5230 <code>DDL Converter</code>\uff08\u7528\u4e8e DDL \u8bf7\u6c42\uff09\u6216 <code>DML Converter</code>\uff08\u7528\u4e8e DML \u8bf7\u6c42\uff09\u8fdb\u884c\u4e0b\u4e00\u9636\u6bb5\u7684\u5904\u7406\u3002\u4ee5\u4e0b\u662f JSON \u4e8b\u4ef6\u4e2d DDL \u548c DML\u201c\u6709\u6548\u8d1f\u8f7d\u201d\u7684\u793a\u4f8b\uff1a</p> <p>DML \u6709\u6548\u8d1f\u8f7d\uff1a <pre><code>{\n  \"payload\": {\n    \"before\": null,\n    \"after\": {\n      \"id\": 3,\n      \"g\": {\n        \"wkb\": \"AQMAAAABAAAABQAAAAAAAAAAAAAAAAAAAAAAFEAAAAAAAAAAQAAAAAAAABRAAAAAAAAAAEAAAAAAAAAcQAAAAAAAAAAAAAAAAAAAHEAAAAAAAAAAAAAAAAAAABRA\",\n        \"srid\": null\n      },\n      \"h\": null\n    },\n    \"source\": {\n      \"version\": \"2.6.2.Final\",\n      \"connector\": \"mysql\",\n      \"name\": \"synchdb-connector\",\n      \"ts_ms\": 1743631156000,\n      \"snapshot\": \"last\",\n      \"db\": \"inventory\",\n      \"sequence\": null,\n      \"ts_us\": 1743631156000000,\n      \"ts_ns\": 1743631156000000000,\n      \"table\": \"geom\",\n      \"server_id\": 0,\n      \"gtid\": null,\n      \"file\": \"mysql-bin.000009\",\n      \"pos\": 1026620577,\n      \"row\": 0,\n      \"thread\": null,\n      \"query\": null\n    },\n    \"op\": \"r\",\n    \"ts_ms\": 1743631156410,\n    \"ts_us\": 1743631156410423,\n    \"ts_ns\": 1743631156410423395,\n    \"transaction\": null\n  }\n}\n</code></pre></p> <p>DDL \u6709\u6548\u8d1f\u8f7d\uff1a <pre><code>  \"payload\": {\n    \"source\": {\n      \"version\": \"2.6.2.Final\",\n      \"connector\": \"sqlserver\",\n      \"name\": \"synchdb-connector\",\n      \"ts_ms\": 1728337635149,\n      \"snapshot\": \"true\",\n      \"db\": \"testDB\",\n      \"sequence\": null,\n      \"ts_us\": 1728337635149000,\n      \"ts_ns\": 1728337635149000000,\n      \"schema\": \"dbo\",\n      \"table\": \"customers\",\n      \"change_lsn\": null,\n      \"commit_lsn\": \"00000195:000010a0:0003\",\n      \"event_serial_no\": null\n    },\n    \"ts_ms\": 1728337635150,\n    \"databaseName\": \"testDB\",\n    \"schemaName\": \"dbo\",\n    \"ddl\": null,\n    \"tableChanges\": [\n      {\n        \"type\": \"CREATE\",\n        \"id\": \"\\\"testDB\\\".\\\"dbo\\\".\\\"customers\\\"\",\n        \"table\": {\n          \"defaultCharsetName\": null,\n          \"primaryKeyColumnNames\": [\n            \"id\"\n          ],\n          \"columns\": [\n            {\n              \"name\": \"id\",\n              \"jdbcType\": 4,\n              \"nativeType\": null,\n              \"typeName\": \"int identity\",\n              \"typeExpression\": \"int identity\",\n              \"charsetName\": null,\n              \"length\": 10,\n              \"scale\": 0,\n              \"position\": 1,\n              \"optional\": false,\n              \"autoIncremented\": true,\n              \"generated\": false,\n              \"comment\": null,\n              \"defaultValueExpression\": null,\n              \"enumValues\": null\n            },\n            {\n              \"name\": \"first_name\",\n              \"jdbcType\": 12,\n              \"nativeType\": null,\n              \"typeName\": \"varchar\",\n              \"typeExpression\": \"varchar\",\n              \"charsetName\": null,\n              \"length\": 255,\n              \"scale\": null,\n              \"position\": 2,\n              \"optional\": false,\n              \"autoIncremented\": false,\n              \"generated\": false,\n              \"comment\": null,\n              \"defaultValueExpression\": null,\n              \"enumValues\": null\n            },\n            {\n              \"name\": \"last_name\",\n              \"jdbcType\": 12,\n              \"nativeType\": null,\n              \"typeName\": \"varchar\",\n              \"typeExpression\": \"varchar\",\n              \"charsetName\": null,\n              \"length\": 255,\n              \"scale\": null,\n              \"position\": 3,\n              \"optional\": false,\n              \"autoIncremented\": false,\n              \"generated\": false,\n              \"comment\": null,\n              \"defaultValueExpression\": null,\n              \"enumValues\": null\n            },\n            {\n              \"name\": \"email\",\n              \"jdbcType\": 12,\n              \"nativeType\": null,\n              \"typeName\": \"varchar\",\n              \"typeExpression\": \"varchar\",\n              \"charsetName\": null,\n              \"length\": 255,\n              \"scale\": null,\n              \"position\": 4,\n              \"optional\": false,\n              \"autoIncremented\": false,\n              \"generated\": false,\n              \"comment\": null,\n              \"defaultValueExpression\": null,\n              \"enumValues\": null\n            }\n          ],\n          \"comment\": null\n        }\n      }\n    ]\n  }\n</code></pre></p>"},{"location":"zh/architecture/debezium_event_processor/#5","title":"5) \u5bf9\u8c61\u6620\u5c04\u5f15\u64ce","text":"<p>\u5bf9\u8c61\u6620\u5c04\u5f15\u64ce\u8d1f\u8d23\u52a0\u8f7d\u548c\u7ef4\u62a4\u6bcf\u4e2a\u6d3b\u52a8\u8fde\u63a5\u5668\u4e0b\u7684\u5bf9\u8c61\u6620\u5c04\u4fe1\u606f\u3002\u8fd9\u4e9b\u6620\u5c04\u4fe1\u606f\u544a\u8bc9 SynchDB \u5982\u4f55\u5728 DDL \u548c DML \u5904\u7406\u671f\u95f4\u5c06\u6e90\u5bf9\u8c61\u6620\u5c04\u5230\u76ee\u6807\u5bf9\u8c61\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cSynchdb \u6ca1\u6709\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\uff0c\u5b83\u5c06\u4f7f\u7528\u9ed8\u8ba4\u6620\u5c04\u89c4\u5219\u6765\u5904\u7406\u6570\u636e\u3002</p> <p>\u5bf9\u8c61\u53ef\u4ee5\u5f15\u7528\uff1a * \u8868\u540d\u3002 * \u5217\u540d\u3002 * \u6570\u636e\u7c7b\u578b\u3002 * \u8f6c\u6362\u8868\u8fbe\u5f0f\u3002</p> <p>\u53ef\u4ee5\u4f7f\u7528<code>synchdb_add_objmap()</code> \u51fd\u6570\u521b\u5efa\u6620\u5c04\u89c4\u5219\u4e4b\u524d\u5c06\u6e90\u8868\u540d\u3001\u5217\u540d\u548c\u6570\u636e\u7c7b\u578b\u6620\u5c04\u5230\u4e0d\u540c\u7684\u76ee\u6807\u8868\u540d\u3001\u5217\u540d\u548c\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u67e5\u8be2<code>synchdb_objmap</code> \u8868\u6765\u67e5\u770b\u6240\u6709\u89c4\u5219\u3002\u6709\u5173\u5bf9\u8c61\u6620\u5c04\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904\u3002\u5728<code>synchdb_att_view()</code> \u89c6\u56fe\u4e0b\u53ef\u4ee5\u67e5\u770b\u54ea\u4e9b\u5185\u5bb9\u6620\u5c04\u5230\u54ea\u4e9b\u5185\u5bb9\u7684\u6458\u8981\u3002</p> <p><code>\u8f6c\u6362\u8868\u8fbe\u5f0f</code> \u662f\u4e00\u4e2a SQL \u8868\u8fbe\u5f0f\uff0c\u5c06\u5728\u6570\u636e\u8f6c\u6362\u5b8c\u6210\u540e\u3001\u5e94\u7528\u6570\u636e\u4e4b\u524d\u8fd0\u884c\uff08\u5982\u679c\u6307\u5b9a\uff09\u3002\u6b64\u8868\u8fbe\u5f0f\u53ef\u4ee5\u662f PostgreSQL \u4e2d\u53ef\u8fd0\u884c\u7684\u4efb\u4f55\u8868\u8fbe\u5f0f\uff0c\u4f8b\u5982\u8c03\u7528\u53e6\u4e00\u4e2a SQL \u51fd\u6570\u6216\u4f7f\u7528\u8fd0\u7b97\u7b26\u3002\u6709\u5173\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904\u3002</p>"},{"location":"zh/architecture/debezium_event_processor/#6","title":"6) \u7edf\u8ba1\u6536\u96c6\u5668","text":"<p>\u7edf\u8ba1\u6536\u96c6\u5668\u8d1f\u8d23\u6536\u96c6 SynchDB \u81ea\u64cd\u4f5c\u5f00\u59cb\u4ee5\u6765\u7684\u6570\u636e\u5904\u7406\u7edf\u8ba1\u4fe1\u606f\u3002\u8fd9\u5305\u62ec DDL \u548c DML \u7684\u6570\u91cf\u3001\u5df2\u5904\u7406\u7684 CREATE\u3001INSERT\u3001UPDATE\u3001DELETE \u64cd\u4f5c\u6570\u91cf\u3001\u5904\u7406\u7684\u5e73\u5747\u6279\u5904\u7406\u5927\u5c0f\u4ee5\u53ca\u63cf\u8ff0\u6570\u636e\u5728\u6e90\u4e2d\u9996\u6b21\u751f\u6210\u65f6\u95f4\u3001Debezium \u5904\u7406\u6570\u636e\u7684\u65f6\u95f4\u4ee5\u53ca\u5728 PostgreSQL \u4e2d\u5e94\u7528\u6570\u636e\u7684\u65f6\u95f4\u7684\u51e0\u4e2a\u65f6\u95f4\u6233\u3002\u8fd9\u4e9b\u6307\u6807\u53ef\u4ee5\u5e2e\u52a9\u7528\u6237\u4e86\u89e3 SynchDB \u7684\u5904\u7406\u884c\u4e3a\uff0c\u4ee5\u8c03\u6574\u548c\u4f18\u5316\u8bbe\u7f6e\u4ee5\u63d0\u9ad8\u5904\u7406\u6027\u80fd\u3002\u6709\u5173\u7edf\u8ba1\u6570\u636e\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904\u3002</p>"},{"location":"zh/architecture/debezium_event_processor/#7-ddl","title":"7) DDL \u8f6c\u6362\u5668","text":"<p>DDL \u8f6c\u6362\u5668\u8d1f\u8d23\u5c06\u201cJSON \u89e3\u6790\u5668\u201d\u751f\u6210\u7684 DDL \u6570\u636e\u8f6c\u6362\u4e3a PostgreSQL \u53ef\u4ee5\u7406\u89e3\u7684\u683c\u5f0f\u3002\u5bf9\u4e8e DDL\uff0cSynchDB \u4f9d\u8d56 PostgreSQL SPI \u5f15\u64ce\u8fdb\u884c\u5904\u7406\uff0c\u56e0\u6b64\u8f6c\u6362\u7684\u8f93\u51fa\u662f\u6b63\u5e38\u7684 SQL \u67e5\u8be2\u5b57\u7b26\u4e32\u3002DDL \u8f6c\u6362\u5668\u68c0\u67e5 DDL \u6570\u636e\uff0c\u5e76\u5fc5\u987b\u4e0e\u201c\u5bf9\u8c61\u6620\u5c04\u5f15\u64ce\u201d\u914d\u5408\u4f7f\u7528\uff0c\u4ee5\u6b63\u786e\u8f6c\u6362\u6e90\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u8868\u3001\u5217\u540d\u79f0\u6216\u6570\u636e\u7c7b\u578b\u6620\u5c04\u3002</p> <p>\u5982\u679c\u8981\u6839\u636e\u201c\u5bf9\u8c61\u6620\u5c04\u5f15\u64ce\u201d\u5c06\u540d\u4e3a\u201cemployee\u201d\u7684\u8fdc\u7a0b\u8868\u6620\u5c04\u5230\u76ee\u6807\u4e2d\u7684\u201cstaff\u201d\uff0c\u5219 DDL \u8f6c\u6362\u5668\u8d1f\u8d23\u89e3\u6790\u8fd9\u4e9b\u540d\u79f0\u6620\u5c04\u5e76\u76f8\u5e94\u5730\u4e3a SPI \u521b\u5efa SQL \u67e5\u8be2\u3002</p> <p>\u8f6c\u6362\u5668\u76ee\u524d\u53ef\u4ee5\u5904\u7406\u4ee5\u4e0b DDL \u64cd\u4f5c\uff1a</p> <ul> <li>\u521b\u5efa\u8868 CREATE TABLE</li> <li>\u5220\u9664\u8868 DROP TABLE</li> <li>\u66f4\u6539\u8868\u66f4\u6539\u5217 ALTER TABLE ALTER COLUMN</li> <li>\u66f4\u6539\u8868\u6dfb\u52a0\u5217 ALTER TABLE ADD COLUMN</li> <li>\u66f4\u6539\u8868\u5220\u9664\u5217 ALTER TABLE DROP COLUMN</li> </ul> <p>\u5bf9\u4e8e CREATE \u548c DROP\uff0c\u8f6c\u6362\u5668\u80fd\u591f\u4ece\u8f93\u5165\u7684 DDL \u6570\u636e\u4e2d\u4e3a SPI \u521b\u5efa\u76f8\u5e94\u7684\u67e5\u8be2\u5b57\u7b26\u4e32\u3002\u5bf9\u4e8e ALTER\u3001ADD \u548c DROP COLUMN\uff0c\u8f6c\u6362\u5668\u9700\u8981\u8bbf\u95ee PostgreSQL Catalog\u4ee5\u4e86\u89e3\u73b0\u6709\u8868\u5c5e\u6027\uff0c\u5e76\u786e\u5b9a\u662f\u5426\u6709\u8981\u6dfb\u52a0\u3001\u5220\u9664\u6216\u66f4\u6539\u7684\u5217\u3002Debezium \u7684 JSON \u66f4\u6539\u4e8b\u4ef6\u59cb\u7ec8\u5305\u542b\u6574\u4e2a\u8868\u7684\u4fe1\u606f\uff0c\u5e76\u4e14\u4e0d\u4f1a\u660e\u786e\u6307\u51fa\u5df2\u5220\u9664\u6216\u6dfb\u52a0\u7684\u5185\u5bb9\u3002\u56e0\u6b64\uff0c\u9700\u8981 DDL \u8f6c\u6362\u5668\u7ec4\u4ef6\u6765\u627e\u51fa\u6b64\u4fe1\u606f\u5e76\u751f\u6210\u6b63\u786e\u7684\u67e5\u8be2\u5b57\u7b26\u4e32\u3002\u6709\u5173 DDL \u590d\u5236\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904</p>"},{"location":"zh/architecture/debezium_event_processor/#8-dml","title":"8) DML \u8f6c\u6362\u5668","text":"<p>DML \u8f6c\u6362\u5668\u8d1f\u8d23\u5c06\u201cJSON \u89e3\u6790\u5668\u201d\u751f\u6210\u7684 DML \u6570\u636e\u8f6c\u6362\u4e3a PostgreSQL \u53ef\u4ee5\u7406\u89e3\u7684\u683c\u5f0f\u3002\u5bf9\u4e8e DML\uff0cSynchDB \u4f9d\u8d56 PostgreSQL \u7684\u6267\u884c\u5668 API \u5c06\u6570\u636e\u76f4\u63a5\u5e94\u7528\u4e8e PostgreSQL\uff0c\u56e0\u6b64\u8f6c\u6362\u7684\u8f93\u51fa\u662f PostgreSQL \u6267\u884c\u5668\u53ef\u4ee5\u7406\u89e3\u7684 TupleTableSlot (TTS) \u683c\u5f0f\u3002\u4e3a\u4e86\u8ba9 PostgreSQL \u751f\u6210\u6b63\u786e\u7684 TTS\uff0cDML \u8f6c\u6362\u5668\u4f9d\u8d56\u4e8e\uff1a</p> <ul> <li>\u63cf\u8ff0\u8d1f\u8f7d\u6570\u636e\u683c\u5f0f DBZ \u5143\u6570\u636e</li> <li>PostgreSQL \u76ee\u5f55 (pg_class \u548c pg_type)\uff0c\u7528\u4e8e\u4e86\u89e3\u76ee\u6807\u8868\u7684\u4fe1\u606f\u3001\u6bcf\u5217\u7684\u6570\u636e\u7c7b\u578b\u548c\u5c5e\u6027\u3002</li> <li>\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\uff0c\u7528\u4e8e\u786e\u5b9a\u662f\u5426\u9700\u8981\u5728\u5904\u7406\u7684\u6570\u636e\u4e0a\u8fd0\u884c\u989d\u5916\u7684\u8f6c\u6362\u8868\u8fbe\u5f0f</li> <li>\u8981\u5904\u7406\u7684\u6570\u636e</li> </ul> <p>DML \u8f6c\u6362\u5668\u7531\u51e0\u4e2a\u4f8b\u7a0b\u7ec4\u6210\uff0c\u8fd9\u4e9b\u4f8b\u7a0b\u53ef\u4ee5\u5904\u7406\u7279\u5b9a\u7684\u8f93\u5165\u6570\u636e\u7c7b\u578b\u5e76\u751f\u6210\u7279\u5b9a\u7684\u8f93\u51fa\u7c7b\u578b\u3002\u4e3a\u7279\u5b9a\u8f6c\u6362\u573a\u666f\u9009\u62e9\u6b63\u786e\u7684\u4f8b\u7a0b\u53ef\u80fd\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u56e0\u4e3a\u67d0\u4e9b\u6570\u636e\u7c7b\u578b\u53ef\u80fd\u662f\u7528\u6237\u5b9a\u4e49\u7684\uff0c\u6216\u8005\u7531 SynchDB \u4e0d\u592a\u4e86\u89e3\u7684\u5176\u4ed6\u6269\u5c55\u521b\u5efa\u3002SynchDB \u5fc5\u987b\u8bbe\u8ba1\u4e3a\u5904\u7406 PostgreSQL \u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u672c\u673a\u548c\u975e\u672c\u673a\u6570\u636e\u7c7b\u578b\u3002</p> <p>\u4f8b\u7a0b\u9009\u62e9\u9996\u5148\u67e5\u770b\u5728 PostgreSQL \u4e2d\u521b\u5efa\u7684\u6570\u636e\u7c7b\u578b\uff0c\u8be5\u6570\u636e\u7c7b\u578b\u53ef\u5206\u4e3a 2 \u79cd\u7c7b\u578b\uff0c\u6bcf\u79cd\u7c7b\u578b\u7684\u5904\u7406\u6280\u672f\u7565\u6709\u4e0d\u540c\uff1a</p> <ul> <li>\u539f\u751f\u6570\u636e\u7c7b\u578b\u3002</li> <li>\u975e\u539f\u751f\u6570\u636e\u7c7b\u578b\u3002</li> </ul>"},{"location":"zh/architecture/debezium_event_processor/#_1","title":"\u6570\u636e\u8f6c\u6362","text":"<p>\u5728\u8f93\u5165\u6570\u636e\u901a\u8fc7\u4e0a\u8ff0\u903b\u8f91\u5904\u7406\u540e\uff0c\u8f6c\u6362\u5668\u5c06\u68c0\u67e5\u7528\u6237\u662f\u5426\u5df2\u914d\u7f6e\u201c\u8f6c\u6362\u8868\u8fbe\u5f0f\u201d\uff0c\u8be5\u8868\u8fbe\u5f0f\u5e94\u5728\u5e94\u7528\u4e8e PostgreSQL \u4e4b\u524d\u5e94\u7528\u4e8e\u5df2\u5904\u7406\u7684\u6570\u636e\u3002\u8f6c\u6362\u8868\u8fbe\u5f0f\u53ef\u4ee5\u662f\u4efb\u4f55\u53ef\u4ee5\u5728 psql \u63d0\u793a\u7b26\u4e0a\u8fd0\u884c\u7684 PostgreSQL \u8868\u8fbe\u5f0f\u3001\u547d\u4ee4\u6216 SQL \u51fd\u6570\u3002\u5b83\u4f7f\u7528\u201c%d\u201d\u4f5c\u4e3a\u5360\u4f4d\u7b26\uff0c\u5728\u8f6c\u6362\u671f\u95f4\u5c06\u66ff\u6362\u4e3a\u5df2\u5904\u7406\u7684\u6570\u636e\u3002\u4f8b\u5982\uff0c\u8f6c\u6362\u8868\u8fbe\u5f0f\u201c'&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\u201d\u5c06\u5728\u5df2\u5904\u7406\u7684\u5b57\u7b26\u4e32\u6570\u636e\u524d\u9762\u548c\u540e\u9762\u6dfb\u52a0\u5176\u4ed6\u5b57\u7b26\u3002</p> <p>\u56e0\u6b64\uff0c\u5982\u679c\u975e\u672c\u5730\u6570\u636e\u7c7b\u578b\u5177\u6709 TYPCATEGORY_USER \u7c7b\u522b\uff0cDML \u8f6c\u6362\u5668\u6ca1\u6709\u5408\u9002\u7684\u4f8b\u7a0b\u6765\u5904\u7406\u6b64\u6570\u636e\u5e76\u5c06\u4fdd\u6301\u539f\u6837\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\u4e00\u4e2a\u8f6c\u6362\u8868\u8fbe\u5f0f\u6765\u8c03\u7528\u81ea\u5b9a\u4e49 SQL \u51fd\u6570\uff0c\u5b83\u77e5\u9053\u5982\u4f55\u6b63\u786e\u5904\u7406\u6570\u636e\u5e76\u751f\u6210\u5408\u9002\u7684\u8f93\u51fa\u3002\u4f8b\u5982\uff0c\u8868\u8fbe\u5f0f\u201cto_my_composite_type('%d')\u201d\u5c06\u4f7f\u7528\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u6765\u8c03\u7528\u7528\u6237\u5b9a\u4e49\u7684 SQL \u51fd\u6570\u201cto_my_composite_type\u201d\u3002\u8868\u8fbe\u5f0f\u5fc5\u987b\u5177\u6709\u8fd4\u56de\u503c\uff0c\u56e0\u4e3a\u5b83\u5c06\u5728\u5e94\u7528\u671f\u95f4\u8f93\u5165\u5230 PostgreSQL \u4e2d\u3002</p>"},{"location":"zh/architecture/debezium_event_processor/#9","title":"9) \u9519\u8bef\u5904\u7406\u7a0b\u5e8f","text":"<p>\u9519\u8bef\u5904\u7406\u7a0b\u5e8f\u4e3b\u8981\u8d1f\u8d23\u5904\u7406\u6570\u636e\u540c\u6b65\u5404\u4e2a\u9636\u6bb5\u53ef\u80fd\u51fa\u73b0\u7684\u4efb\u4f55\u9519\u8bef\u3002\u683c\u5f0f\u8f6c\u6362\u5668\u652f\u6301\u591a\u79cd\u9519\u8bef\u5904\u7406\u7b56\u7565\uff0c\u53ef\u901a\u8fc7 \u201csynchdb.error_handling_strategy\u201d \u53c2\u6570\u8fdb\u884c\u914d\u7f6e\u3002\u8be6\u60c5\u8bf7\u53c2\u9605\u6b64\u5904\u3002</p>"},{"location":"zh/architecture/debezium_event_processor/#10-spi-client","title":"10) SPI Client","text":"<p>SPI Client \u7ec4\u4ef6\u5b58\u5728\u4e8e Replication Agent \u4e0b\uff0c\u5b83\u5145\u5f53 PostgreSQL \u6838\u5fc3\u548c SynchDB \u4e4b\u95f4\u7684\u6865\u6881\u3002\u5b83\u8d1f\u8d23\u5efa\u7acb\u4e0e SPI \u670d\u52a1\u5668\u7684\u8fde\u63a5\u3001\u542f\u52a8\u4e8b\u52a1\u3001\u83b7\u53d6\u5feb\u7167\u5e76\u6267\u884c\u7531 <code>DDL Converter</code> \u521b\u5efa\u7684\u7ed9\u5b9a SQL \u67e5\u8be2\u5e76\u9500\u6bc1\u8fde\u63a5\u3002\u5bf9\u4e8e\u8981\u5904\u7406\u7684\u6bcf\u4e2a\u67e5\u8be2\uff0c\u90fd\u4f1a\u521b\u5efa\u548c\u9500\u6bc1 SPI \u8fde\u63a5\uff0c\u8fd9\u4f3c\u4e4e\u6548\u7387\u4e0d\u9ad8\u3002\u7531\u4e8e SPI \u4ec5\u5728 DDL \u671f\u95f4\u4f7f\u7528\uff0c\u800c\u8fd9\u901a\u5e38\u4e0d\u592a\u9891\u7e41\uff0c\u56e0\u6b64\u5728\u6027\u80fd\u65b9\u9762\u5e94\u8be5\u6ca1\u95ee\u9898\u3002</p>"},{"location":"zh/architecture/debezium_event_processor/#11-api","title":"11) \u6267\u884c\u5668 API","text":"<p>\u4e5f\u9a7b\u7559\u5728\u590d\u5236\u4ee3\u7406\u4e2d\u3002\u6b64\u7ec4\u4ef6\u8d1f\u8d23\u521d\u59cb\u5316\u6267\u884c\u5668\u4e0a\u4e0b\u6587\u3001\u6253\u5f00\u8868\u3001\u83b7\u53d6\u9002\u5f53\u7684\u9501\u3001\u4ece DML \u8f6c\u6362\u5668\u7684\u8f93\u51fa\u521b\u5efa TupleTableSlot (TTS)\u3001\u8c03\u7528\u6267\u884c\u5668 API \u6267\u884c INSERT\u3001UPDATE\u3001DELETE \u64cd\u4f5c\u5e76\u8fdb\u884c\u8d44\u6e90\u6e05\u7406\u3002\u8fd9\u901a\u5e38\u662f\u4e00\u79cd\u6bd4 SPI \u66f4\u5feb\u7684\u6570\u636e\u64cd\u4f5c\u65b9\u6cd5\uff0c\u56e0\u4e3a\u5b83\u4e0d\u9700\u8981\u50cf SPI \u90a3\u6837\u89e3\u6790\u8f93\u5165\u67e5\u8be2\u5b57\u7b26\u4e32\u3002</p>"},{"location":"zh/architecture/debezium_runner_components/","title":"Debezium Runner \u7ec4\u4ef6\u67b6\u6784 - Java","text":""},{"location":"zh/architecture/debezium_runner_components/#debezium-runner","title":"Debezium Runner \u7ec4\u4ef6\u56fe","text":"<p>Debezium Runner \u4f4d\u4e8e\u90e8\u7f72\u7684 Java \u7aef\u3002\u5b83\u662f\u5d4c\u5165\u5f0f Debezium \u5f15\u64ce (Java) \u548c SynchDB Worker (C) \u4e4b\u95f4\u7684\u4e3b\u8981\u4e2d\u4ecb\u3002\u5b83\u63d0\u4f9b\u4e86\u4e00\u4e9b Java \u65b9\u6cd5\uff0cSynchDB Worker \u53ef\u4ee5\u901a\u8fc7 JNI \u5e93\u8fdb\u884c\u4ea4\u4e92\u3002\u8fd9\u4e9b\u4ea4\u4e92\u5305\u62ec\u521d\u59cb\u5316 Debezium \u5f15\u64ce\u3001\u542f\u52a8\u6216\u505c\u6b62\u5f15\u64ce\u3001\u83b7\u53d6\u4e00\u6279\u53d8\u66f4\u4e8b\u4ef6\u4ee5\u53ca\u5c06\u4e00\u6279\u6807\u8bb0\u4e3a\u5b8c\u6210\u3002\u8fd9\u4e9b\u64cd\u4f5c\u5bf9\u4e8e\u786e\u4fdd\u590d\u5236\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\u3002\u4e3b\u8981\u7ec4\u4ef6\u5305\u62ec\uff1a</p> <ol> <li>\u53c2\u6570\u7c7b</li> <li>\u63a7\u5236\u5668</li> <li>\u53d1\u5c04\u5668</li> <li>\u6279\u6b21\u7ba1\u7406\u5668</li> </ol>"},{"location":"zh/architecture/debezium_runner_components/#1","title":"1) \u53c2\u6570\u7c7b","text":"<p>\u53c2\u6570\u7c7b\u8868\u793a\u4e00\u4e2a JAVA \u7c7b\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u7cfb\u5217\u516c\u5f00\u7684\u53c2\u6570\u548c\u65b9\u6cd5\uff0c\u5141\u8bb8 SynchDB Worker \u8bbe\u7f6e/\u83b7\u53d6\u53c2\u6570\u503c\u3002\u8fd9\u4e9b\u53c2\u6570\u4f1a\u5f71\u54cd Debezium Runner \u548c\u5d4c\u5165\u5f0f Debezium \u7684\u6027\u80fd\u3002\u8fd9\u4e9b\u53c2\u6570\u4e5f\u5df2\u66b4\u9732\u7ed9 PostgreSQL GUC\uff0c\u4ee5\u4fbf SynchDB Worker \u53ef\u4ee5\u8c03\u7528\u76f8\u5e94\u7684\u65b9\u6cd5\u6765\u8bbe\u7f6e\u53c2\u6570\u503c\u3002\u8fd9\u662f\u76ee\u524d\u5c06\u914d\u7f6e\u4ece\u57fa\u4e8e C \u8bed\u8a00\u7684 SynchDB Worker \u4f20\u9012\u5230\u57fa\u4e8e JAVA \u8bed\u8a00\u7684 Debezium Runner \u7684\u552f\u4e00\u65b9\u6cd5\u3002</p>"},{"location":"zh/architecture/debezium_runner_components/#2","title":"2) \u63a7\u5236\u5668","text":"<p>\u63a7\u5236\u5668\u5141\u8bb8 SynchDB \u542f\u52a8\u6216\u505c\u6b62\u5d4c\u5165\u5f0f Debezium \u5f15\u64ce\u3002\u8fd9\u901a\u8fc7 SynchDB Worker \u53ef\u4ee5\u8c03\u7528\u7684\u51e0\u4e2a JAVA \u65b9\u6cd5\u6765\u5b9e\u73b0\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u63a7\u5236 Debezium \u5f15\u64ce\u3002</p>"},{"location":"zh/architecture/debezium_runner_components/#3","title":"3) \u53d1\u5c04\u5668","text":"<p>\u53d1\u5c04\u5668\u8868\u793a\u4e00\u4e2a JAVA \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7531 SynchDB Worker \u4e2d\u7684\u201c\u4e8b\u4ef6\u83b7\u53d6\u5668\u201d\u7ec4\u4ef6\u5b9a\u671f\u8c03\u7528\u3002\u5b83\u4e3b\u8981\u8d1f\u8d23\u4ece\u201c4) \u6279\u6b21\u7ba1\u7406\u5668\u201d\u5f39\u51fa\u4e00\u4e2a\u6279\u6b21\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a JSON \u4e8b\u4ef6\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u5e76\u901a\u8fc7 JNI \u8fd4\u56de\u7ed9\u201c\u4e8b\u4ef6\u83b7\u53d6\u5668\u201d\u3002\u5982\u679c\u6279\u6b21\u7ba1\u7406\u5668\u6ca1\u6709\u53ef\u7528\u7684\u6279\u6b21\uff0c\u5b83\u5c06\u8fd4\u56de NULL\uff0c\u5e76\u4e14\u201c\u4e8b\u4ef6\u83b7\u53d6\u5668\u201d\u7aef\u4e0d\u4f1a\u8fdb\u884c\u4efb\u4f55\u5904\u7406\u3002</p>"},{"location":"zh/architecture/debezium_runner_components/#4","title":"4) \u6279\u6b21\u7ba1\u7406\u5668","text":"<p>\u6279\u6b21\u7ba1\u7406\u5668\u4e3b\u8981\u8d1f\u8d23\u63a5\u6536\u6765\u81ea\u5d4c\u5165\u5f0f Debezium \u5f15\u64ce\u7684\u65b0\u6279\u6b21\uff0c\u5e76\u5c06\u5176\u5b58\u50a8\u5728\u5176\u5185\u90e8\u961f\u5217\u4e2d\u3002\u8be5\u961f\u5217\u6bd4\u7ec4\u4ef6\u56fe\u4e2d\u5d4c\u5165\u5f0f Debezium \u5f15\u64ce\u5185\u90e8\u7684\u6279\u6b21\u961f\u5217\u5c0f\u5f97\u591a\uff0c\u5e76\u4e14\u6709\u6240\u4e0d\u540c\u3002\u5f53\u6279\u6b21\u7ba1\u7406\u5668\u7684\u5185\u90e8\u961f\u5217\u5df2\u6ee1\u65f6\uff0c\u8282\u6d41\u63a7\u5236\u5c06\u6fc0\u6d3b\uff0c\u6682\u65f6\u505c\u6b62 Debezium \u7aef\u7684\u4e8b\u4ef6\u751f\u6210\uff0c\u76f4\u5230\u8be5\u5c0f\u6279\u6b21\u961f\u5217\u6709\u53ef\u7528\u7a7a\u95f4\u3002\u53ea\u6709\u5f53\u201c\u53d1\u5c04\u5668\u201d\u6536\u5230\u6765\u81ea\u201c\u4e8b\u4ef6\u83b7\u53d6\u5668\u201d\u7684\u83b7\u53d6\u8bf7\u6c42\u5e76\u4ece\u6279\u6b21\u7ba1\u7406\u5668\u5f39\u51fa\u6279\u6b21\u65f6\uff0c\u624d\u4f1a\u4ece\u961f\u5217\u4e2d\u79fb\u9664\u8be5\u6279\u6b21\u3002</p> <p>\u6279\u6b21\u7ba1\u7406\u5668\u8fd8\u4f1a\u4e3a\u6bcf\u4e2a\u5f39\u51fa\u7684\u6279\u6b21\u5206\u914d\u4e00\u4e2a\u6279\u6b21 ID\uff0c\u5e76\u5c06\u5176\u53d1\u9001\u5230\u53d1\u5c04\u5668\uff0c\u6700\u7ec8\u53d1\u9001\u5230 SynchDB \u5de5\u4f5c\u5668\u8fdb\u884c\u5904\u7406\u3002\u6b64\u552f\u4e00 ID \u4e0e\u5176\u5173\u8054\u7684\u201c\u63d0\u4ea4\u5668\u201d\u5bf9\u8c61\u4e00\u8d77\u5b58\u50a8\u5728\u5176\u5185\u90e8\u54c8\u5e0c\u8868\u4e2d\u3002\u8fd9\u4e9b\u4fe1\u606f\u5bf9\u4e8e\u8ddf\u8e2a\u975e\u5e38\u91cd\u8981\u3002\u5f53 SynchDB \u5de5\u4f5c\u8fdb\u7a0b\u5b8c\u6210\u4e00\u4e2a\u6279\u6b21\u65f6\uff0c\u5b83\u4f1a\u5728\u6279\u6b21\u7ba1\u7406\u5668\u4e2d\u8c03\u7528\u201c\u6807\u8bb0\u6279\u6b21\u5b8c\u6210\u201d\u65b9\u6cd5\uff0c\u5e76\u5305\u542b\u76f8\u540c\u7684\u6279\u6b21 ID\uff0c\u8fd9\u6709\u52a9\u4e8e\u6279\u6b21\u7ba1\u7406\u5668\u67e5\u627e\u76f8\u5e94\u7684\u201c\u63d0\u4ea4\u8005\u201d\u5bf9\u8c61\u3002\u63d0\u4ea4\u8005\u5bf9\u8c61\u968f\u540e\u4f1a\u901a\u77e5\u5d4c\u5165\u5f0f Debezium \u5f15\u64ce\u8be5\u6279\u6b21\u5df2\u5b8c\u6210\uff0c\u5f3a\u5236\u5176\u63d0\u4ea4\u5e76\u5c06\u5176\u5185\u90e8\u504f\u79fb\u91cf\u5411\u524d\u79fb\u52a8\u3002\u8fd9\u786e\u4fdd\u4e86\u5728\u5f15\u64ce\u91cd\u542f\u540e\u4e0d\u4f1a\u518d\u6b21\u5904\u7406\u540c\u4e00\u4e2a\u6279\u6b21\uff08\u4e0d\u4f1a\u91cd\u590d\uff09\u3002</p>"},{"location":"zh/architecture/fdw_based_snapshot/","title":"\u57fa\u65bc FDW \u7684\u5feb\u7167","text":""},{"location":"zh/architecture/fdw_based_snapshot/#_1","title":"\u6982\u8ff0","text":"<p>\u6240\u6709\u9023\u63a5\u5668\u90fd\u652f\u63f4\u57fa\u65bc Debezium \u7684\u521d\u59cb\u5feb\u7167\uff08Postgres \u9023\u63a5\u5668\u9664\u5916\uff09\uff0c\u8a72\u5feb\u7167\u6703\u5c07\u9060\u7aef\u8868\u6a21\u5f0f\u9077\u79fb\u5230 PostgreSQL\uff0c\u4e26\u53ef\u9078\u64c7\u662f\u5426\u5305\u542b\u521d\u59cb\u8cc7\u6599\uff08\u53d6\u6c7a\u65bc\u6240\u4f7f\u7528\u7684\u5feb\u7167\u6a21\u5f0f\uff09\u3002\u96d6\u7136\u9019\u7a2e\u65b9\u6cd5\u5728\u5927\u591a\u6578\u60c5\u6cc1\u4e0b\u90fd\u80fd\u6b63\u5e38\u904b\u4f5c\uff0c\u4f46\u7576\u9700\u8981\u9077\u79fb\u5927\u91cf\u8cc7\u6599\u8868\u4e14 JNI \u547c\u53eb\u5f15\u5165\u984d\u5916\u958b\u92b7\u6642\uff0c\u53ef\u80fd\u6703\u51fa\u73fe\u6548\u80fd\u554f\u984c\u3002\u53ea\u8981\u6211\u5011\u80fd\u5920\u4fdd\u8b49\u8cc7\u6599\u4e00\u81f4\u6027\u4e26\u78ba\u5b9a\u4e00\u500b\u5141\u8a31 CDC \u6062\u5fa9\u7684\u201c\u622a\u6b62\u9ede\u201d\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u5916\u90e8\u8cc7\u6599\u5305\u88dd\u5668 (FDW) \u5be6\u73fe\u76f8\u540c\u7684\u521d\u59cb\u5feb\u7167\u3002</p> <p>\u4ee5\u4e0b\u9023\u63a5\u5668\u652f\u63f4\u57fa\u65bc FDW \u7684\u5feb\u7167\uff1a</p> <ul> <li>MySQL \u9023\u63a5\u5668</li> <li>Postgres \u9023\u63a5\u5668</li> <li>Oracle \u548c Openlog Replicator \u9023\u63a5\u5668</li> </ul>"},{"location":"zh/architecture/fdw_based_snapshot/#synchdb","title":"SynchDB \u5982\u4f55\u4fdd\u8b49\u8cc7\u6599\u4e00\u81f4\u6027\u4e26\u53d6\u5f97\u622a\u6b62\u9ede","text":""},{"location":"zh/architecture/fdw_based_snapshot/#mysql","title":"MySQL \u9023\u63a5\u5668","text":"<ul> <li>\u4ee5 repeatable read \u9694\u96e2\u7b49\u7d1a\u555f\u52d5\u4e8b\u52a1\u3002</li> <li>\u66ab\u6642\u5c0d\u6240\u6709\u76ee\u6a19\u8868\u4e0a\u9501\u3002</li> <li>\u8b80\u53d6 <code>binlog_log_file</code>\u3001<code>binlog_pos</code> \u548c <code>server_id</code>\u3002\u9019\u4e9b\u53c3\u6578\u5c07\u4f5c\u70ba\u5feb\u7167\u7684\u300c\u622a\u6b62\u9ede\u300d\u3002</li> <li>\u91cb\u653e\u8868\u9396\u3002</li> <li>\u5728\u540c\u4e00\u500b repeatable read \u4e8b\u52a1\u4e2d\uff0c\u4f7f\u7528\u6b63\u78ba\u7684\u985e\u578b\u8f49\u63db\u9077\u79fb\u6240\u6709\u76ee\u6a19\u8868\u7684\u6a21\u5f0f\u548c\u8cc7\u6599\u3002</li> <li>\u5b8c\u6210\u5f8c\uff0cCDC \u53ef\u4ee5\u5f9e\u622a\u6b62\u9ede\u6062\u5fa9\uff0c\u8655\u7406\u5feb\u7167\u671f\u9593\u767c\u751f\u7684\u8cc7\u6599\u8b8a\u66f4\u3002</li> </ul> <p>\u8b66\u544a\uff1a\u9700\u8981 BACKUP_ADMIN \u6b0a\u9650\u624d\u80fd\u53d6\u5f97\u300c\u622a\u6b62\u9ede\u300d\u53c3\u6578</p>"},{"location":"zh/architecture/fdw_based_snapshot/#postgres","title":"Postgres \u9023\u63a5\u5668","text":"<ul> <li>\u4ee5 repeatable read \u9694\u96e2\u7b49\u7d1a\u555f\u52d5\u4e8b\u52a1\u3002</li> <li>\u66ab\u6642\u5c0d\u6240\u6709\u76ee\u6a19\u8868\u4e0a\u9501\u3002</li> <li>\u8b80\u53d6\u76ee\u524d LSN\uff0c\u5b83\u4f5c\u70ba\u5feb\u7167\u7684\u300c\u622a\u6b62\u300d\u9ede\u3002</li> <li>\u91cb\u653e\u8868\u9396\u3002</li> <li>\u5728\u540c\u4e00\u500b repeatable read \u4e8b\u52a1\u4e2d\uff0c\u4f7f\u7528\u6b63\u78ba\u7684\u985e\u578b\u8f49\u63db\u9077\u79fb\u6240\u6709\u76ee\u6a19\u8868\u7684\u67b6\u69cb\u548c\u8cc7\u6599\u3002</li> <li>\u5b8c\u6210\u5f8c\uff0cCDC \u53ef\u4ee5\u5f9e\u622a\u6b62\u9ede\u6062\u5fa9\uff0c\u8655\u7406\u5feb\u7167\u671f\u9593\u767c\u751f\u7684\u8cc7\u6599\u8b8a\u66f4\u3002</li> </ul>"},{"location":"zh/architecture/fdw_based_snapshot/#oracle-openlog-replicator","title":"Oracle \u548c Openlog Replicator \u9023\u63a5\u5668","text":"<ul> <li>\u5728\u5feb\u7167\u958b\u59cb\u4e4b\u524d\uff0c\u8b80\u53d6\u76ee\u524d SCN \u503c\uff0c\u5b83\u4f5c\u70ba\u5feb\u7167\u7684\u300c\u622a\u6b62\u9ede\u300d\u3002</li> <li>\u5728\u5916\u90e8\u8868\u67b6\u69cb\u9077\u79fb\u671f\u9593\uff0c\u6bcf\u500b\u76ee\u6a19\u5916\u90e8\u8868\u90fd\u6703\u95dc\u806f\u4e00\u500b\u984d\u5916\u7684\u5c6c\u6027 \u201cAS OF SCN xxx\u201d\uff0c\u9019\u5c07\u5c0e\u81f4\u6240\u6709\u5916\u90e8\u8b80\u53d6\u64cd\u4f5c\u90fd\u4f7f\u7528 Oracle \u7684 FLASHBACK \u67e5\u8a62\u3002</li> <li>FLASHBACK \u67e5\u8a62\u50b3\u56de\u6307\u5b9a SCN \u4e0b\u7684\u8868\u7d50\u679c\uff0c\u56e0\u6b64\u53ef\u4ee5\u81ea\u52d5\u4fdd\u8b49\u4e00\u81f4\u6027\u3002\u7121\u9700\u984d\u5916\u4e0a\u9501\u3002</li> <li>\u4f7f\u7528 FLASHBACK \u67e5\u8a62\u9077\u79fb\u6240\u6709\u76ee\u6a19\u8868\u7684\u67b6\u69cb\u548c\u6578\u64da\uff0c\u4e26\u9032\u884c\u6b63\u78ba\u7684\u985e\u578b\u8f49\u63db\u3002</li> <li>\u5b8c\u6210\u5f8c\uff0cCDC \u53ef\u4ee5\u5f9e\u622a\u6b62\u9ede\u6062\u5fa9\u904b\u884c\uff0c\u4e26\u8655\u7406\u5feb\u7167\u671f\u9593\u767c\u751f\u7684\u8cc7\u6599\u8b8a\u66f4\u3002</li> </ul> <p>\u8b66\u544a\uff1a\u53d6\u5f97\u300c\u622a\u6b62\u9ede\u300d\u53c3\u6578\u9700\u8981 FLASHBACK \u6b0a\u9650</p>"},{"location":"zh/architecture/fdw_based_snapshot/#fdw_1","title":"\u57fa\u65bc FDW \u7684\u5feb\u7167\u5982\u4f55\u904b\u4f5c","text":"<p>\u57fa\u65bc FDW \u7684\u5feb\u7167\u5927\u7d04\u5305\u542b 10 \u500b\u6b65\u9a5f\uff1a</p>"},{"location":"zh/architecture/fdw_based_snapshot/#1","title":"1. \u6e96\u5099","text":"<p>\u6b64\u6b65\u9a5f\u6aa2\u67e5 <code>oracle_fdw</code> \u662f\u5426\u5df2\u5b89\u88dd\u4e14\u53ef\u7528\uff0c\u4e26\u6839\u64da <code>synchdb_add_conninfo</code> \u5efa\u7acb\u7684\u9023\u63a5\u5668\u8cc7\u8a0a\u5efa\u7acb <code>server</code> \u548c <code>user</code> \u5c0d\u61c9\u3002</p>"},{"location":"zh/architecture/fdw_based_snapshot/#2-oracle","title":"2. \u5efa\u7acb Oracle \u7269\u4ef6\u8996\u5716","text":"<p>\u6b64\u6b65\u9a5f\u5728 PostgreSQL \u4e2d\uff0c\u5728\u55ae\u7368\u7684\u6a21\u5f0f\uff08\u4f8b\u5982 <code>ora_obj</code>\uff09\u4e2d\u5efa\u7acb\u591a\u500b\u5916\u90e8\u8868\u3002\u9019\u4e9b\u5916\u90e8\u8868\uff08\u67e5\u8a62\u6642\uff09\u900f\u904e oracle_fdw \u9023\u63a5\u5230 Oracle\uff0c\u4e26\u53d6\u5f97 Oracle \u4e0a\u5927\u591a\u6578\uff08\u5982\u679c\u4e0d\u662f\u5168\u90e8\uff09\u53ef\u7528\u7684\u7269\u4ef6\u3002\u9019\u4e9b\u5c0d\u8c61\u5305\u62ec\uff1a</p> <ul> <li>\u8868</li> <li>\u5217</li> <li>\u9375</li> <li>\u7d22\u5f15</li> <li>\u51fd\u6578</li> <li>\u5e8f\u5217</li> <li>\u8996\u5716</li> <li>\u89f8\u767c\u5668</li> <li>\u7b49\u7b49</li> </ul> <p>SynchDB \u7121\u9700\u8003\u616e\u6bcf\u500b\u7269\u4ef6\u5373\u53ef\u5b8c\u6210\u521d\u59cb\u5feb\u7167\uff1b\u5b83\u50c5\u8003\u616e \"\u8868\"\u3001 \"\u5217\" \u548c \"\u9375\" \u7269\u4ef6\u4f86\u5efa\u7acb PostgreSQL \u4e2d\u7684\u8868\u3002</p>"},{"location":"zh/architecture/fdw_based_snapshot/#3","title":"3. \u5efa\u7acb\u5916\u90e8\u8868\u4ee5\u53d6\u5f97\u76ee\u524d\u622a\u6b62\u70b9","text":"<p>\u5c07\u5efa\u7acb\u5916\u90e8\u8868\uff0c\u4ee5\u4fbf\u5f9e\u4e0d\u540c\u7684\u4f86\u6e90\u8cc7\u6599\u5eab\u8b80\u53d6\u622a\u6b62\u503c\uff1a</p> <p>MySQL \u9023\u63a5\u5668</p> <ul> <li>\u5f9e performance_schema.log_status \u8868\u8b80\u53d6 <code>binlog_file</code> \u548c <code>binlog_pos</code> \u8868</li> <li>\u5f9e performance_schema.global_variables \u8868\u8b80\u53d6 <code>server_id</code> \u8868</li> </ul> <p>Postgres \u9023\u63a5\u5668</p> <ul> <li>\u5f9e\u540d\u70ba public.synchdb_wal_lsn \u7684\u81ea\u8a02\u6aa2\u8996\u8b80\u53d6\u76ee\u524d <code>LSN</code> \u503c\u3002\u6b64\u8996\u5716\u5fc5\u9808\u9810\u5148\u5efa\u7acb\u3002</li> </ul> <p>Oracle \u548c Openlog Replicator \u9023\u63a5\u5668</p> <ul> <li>\u5f9e current_scn \u8868\u4e2d\u8b80\u53d6\u76ee\u524d <code>SCN</code> \u503c</li> </ul>"},{"location":"zh/architecture/fdw_based_snapshot/#4","title":"4.\u5efa\u7acb\u6240\u9700\u5916\u90e8\u8868\u683c\u6e05\u55ae","text":"<p>\u6b64\u6b65\u9a5f\u7684\u76ee\u6a19\u662f\u5efa\u7acb\u4e00\u500b\u65b0\u7684\u66ab\u5b58\u6a21\u5f0f\uff08\u4f8b\u5982 ora_stage\uff09\uff0c\u4e26\u57fa\u65bc\u4e0b\u5217\u689d\u4ef6\u70ba\u5feb\u7167\u5efa\u7acb\u6240\u9700\u7684\u5916\u90e8\u8868\uff1a</p> <ul> <li>\u6b65\u9a5f 2 \u4e2d\u5efa\u7acb\u7684 Oracle \u7269\u4ef6\u8996\u5716</li> <li>SynchDB \u5728 <code>synchdb_conninfo</code> \u4e2d\u7684 <code>data-&gt;'snapshottable'</code> \u53c3\u6578 -&gt; \u9019\u662f SynchDB \u57f7\u884c\u5feb\u7167\u6240\u9700\u7684\u8cc7\u6599\u8868\u7684\u7be9\u9078\u5668\u3002\u5982\u679c\u8a2d\u5b9a\u70ba <code>null</code>\uff0c\u5247\u6240\u6709\u8868\u90fd\u5c07\u88ab\u8996\u70ba\u5feb\u7167\u3002</li> <li>\u984d\u5916\u7684\u8cc7\u6599\u985e\u578b\u6620\u5c04\uff0c\u5982 <code>synchdb_objmap</code> \u4e2d\u6240\u8ff0</li> <li>\u6b65\u9a5f 3 \u4e2d\u7372\u5f97\u7684\u622a\u6b62 SCN\uff08\u50c5\u9650 Oracle \u548c Openlog Replicator \u9023\u63a5\u5668\uff09</li> </ul> <p>\u5728\u6b64\u6b65\u9a5f\u7d50\u675f\u6642\uff0c\u66ab\u5b58\u6a21\u5f0f\u5c07\u5305\u542b\u5916\u90e8\u8868\uff0c\u5176\u8cc7\u6599\u985e\u578b\u5c07\u6839\u64da SynchDB \u7684\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u898f\u5247\u9032\u884c\u5c0d\u61c9\u3002\u5c0d\u65bc Oracle \u548c Openlog Replicator \u9023\u63a5\u5668\uff0c\u5916\u90e8\u8868\u5c07\u5177\u6709 <code>AS OF SCN xxx</code> \u5c6c\u6027\uff0c\u5c0e\u81f4\u6bcf\u6b21\u5916\u90e8\u8b80\u53d6\u50c5\u50b3\u56de\u6307\u5b9a SCN \u4e4b\u524d\u7684\u8cc7\u6599\u3002\u5c0d\u65bc\u5176\u4ed6\u9023\u63a5\u5668\u985e\u578b\uff0c\u5916\u90e8\u8b80\u53d6\u5c07\u50b3\u56de\u53ef\u91cd\u8907\u4e8b\u52d9\u958b\u59cb\u6642\u7684\u6240\u6709\u8cc7\u6599\u3002</p>"},{"location":"zh/architecture/fdw_based_snapshot/#5","title":"5.\u7269\u5316\u6a21\u5f0f","text":"<p>\u6b64\u6b65\u9a5f\u7684\u76ee\u6a19\u662f\u50c5\u7269\u5316\u6b65\u9a5f 4 \u4e2d\u5efa\u7acb\u7684\u8868\u6a21\u5f0f\uff08\u5c07\u5916\u90e8\u8868\u8f49\u63db\u70ba\u771f\u6b63\u7684 PostgreSQL \u8868\uff09\uff0c\u4e26\u5c07\u5176\u653e\u5165\u65b0\u7684\u76ee\u6a19\u6a21\u5f0f\uff08\u4f8b\u5982 dst_stage\uff09\u3002\u56e0\u6b64\uff0c\u5728\u6b64\u6b65\u9a5f\u7d50\u675f\u6642\uff0c\u76ee\u6a19\u6a21\u5f0f\u5c07\u5305\u542b\u8207\u66ab\u5b58\u6a21\u5f0f\u4e2d\u7d50\u69cb\u76f8\u540c\u7684\u771f\u5be6\u8868\u3002</p>"},{"location":"zh/architecture/fdw_based_snapshot/#6","title":"6. \u9077\u79fb\u4e3b\u9375","text":"<p>\u57fa\u65bc\u6b65\u9a5f 2 \u4e2d\u5efa\u7acb\u7684 Oracle \u7269\u4ef6\u8996\u5716\uff0c\u5c0d\u6b65\u9a5f 5 \u4e2d\u5efa\u7acb\u7684\u7269\u5316\u8868\u57f7\u884c <code>ALTER TABLE ADD PRIMARY KEY</code> \u547d\u4ee4\uff0c\u4ee5\u6839\u64da\u9700\u8981\u65b0\u589e\u4e3b\u9375\u3002</p>"},{"location":"zh/architecture/fdw_based_snapshot/#7","title":"7. \u61c9\u7528\u5217\u540d\u6620\u5c04","text":"<p>\u57fa\u65bc <code>synchdb_objmap</code> \u4e2d\u6240\u8ff0\u7684\u5217\u540d\u6620\u5c04\uff0c\u5c0d\u6b65\u9a5f 5 \u4e2d\u5efa\u7acb\u7684\u7269\u5316\u8868\u57f7\u884c <code>ALTER TABLE RENAME COLUMN</code> \u547d\u4ee4\uff0c\u4ee5\u6839\u64da\u9700\u8981\u66f4\u6539\u5217\u540d\u3002</p>"},{"location":"zh/architecture/fdw_based_snapshot/#8","title":"8.\u4f7f\u7528\u8f49\u63db\u9077\u79fb\u8cc7\u6599","text":"<p>\u6b64\u6b65\u9a5f\u7684\u76ee\u6a19\u662f\u5c07\u8868\u683c\u8cc7\u6599\u200b\u200b\u5f9e\u66ab\u5b58\u5340\u9077\u79fb\u5230\u76ee\u6a19\u6a21\u5f0f\uff0c\u4e26\u57f7\u884c <code>synchdb_objmap</code> \u4e2d\u63cf\u8ff0\u7684\u4efb\u4f55\u503c\u8f49\u63db\uff0c\u5927\u81f4\u5982\u4e0b\uff1a</p> <ul> <li>\u9060\u7aef\u67e5\u8a62</li> <li>\u6570\u636e\u8f49\u63db</li> <li>\u672c\u5730\u63d2\u5165</li> </ul>"},{"location":"zh/architecture/fdw_based_snapshot/#9","title":"9. \u61c9\u7528\u8868\u540d\u6620\u5c04","text":"<p>\u8cc7\u6599\u9077\u79fb\u5b8c\u6210\u5f8c\uff0cSynchDB \u5c07\u5957\u7528 <code>synchdb_objmap</code> \u4e2d\u6240\u63cf\u8ff0\u7684\u8868\u540d\u6620\u5c04\u3002\u4e4b\u6240\u4ee5\u6700\u5f8c\u57f7\u884c\u6b64\u64cd\u4f5c\uff0c\u662f\u56e0\u70ba\u8868\u540d\u6620\u5c04\u53ef\u80fd\u6703\u5c07\u8868\u79fb\u52d5\u5230\u6211\u5011\u4e0d\u5e0c\u671b\u5728\u7269\u5316\u904e\u7a0b\u4e2d\u767c\u751f\u7684\u5176\u4ed6\u6a21\u5f0f\u3002</p>"},{"location":"zh/architecture/fdw_based_snapshot/#10","title":"10. \u5b8c\u6210\u521d\u59cb\u5feb\u7167","text":"<p>\u6b64\u6642\u521d\u59cb\u5feb\u7167\u5373\u8996\u70ba\u5b8c\u6210\u3002\u6b64\u6b65\u9a5f\u5c07\u57f7\u884c\u4e0b\u5217\u6e05\u7406\u64cd\u4f5c\uff1a</p> <ul> <li>\u522a\u9664\u6b65\u9a5f 1 \u4e2d\u5efa\u7acb\u7684\u4f3a\u670d\u5668\u548c\u4f7f\u7528\u8005\u6620\u5c04</li> <li>\u522a\u9664\u6b65\u9a5f 2 \u4e2d\u5efa\u7acb\u7684 Oracle \u7269\u4ef6\u8996\u5716</li> <li>\u522a\u9664\u6b65\u9a5f 4 \u4e2d\u5efa\u7acb\u7684\u66ab\u5b58\u6a21\u5f0f</li> </ul> <p>\u6b65\u9a5f 5 \u4e2d\u5efa\u7acb\u7684\u76ee\u6a19\u6a21\u5f0f\u4e2d\u7684\u8868\u683c\u662f\u521d\u59cb\u5feb\u7167\u7684\u6700\u7d42\u7d50\u679c\u3002</p>"},{"location":"zh/architecture/metadata_files/","title":"\u5143\u6570\u636e\u6587\u4ef6","text":"<p>\u5728\u64cd\u4f5c\u8fc7\u7a0b\u4e2d\uff0cDebezium \u8fd0\u884c\u5f15\u64ce\u5728 $PGDATA/pg_synchdb \u4e0b\u751f\u6210\u5143\u6570\u636e\u6587\u4ef6\u3002\u76ee\u524d\u751f\u6210\u5e76\u6301\u4e45\u5316\u4e86\u4e24\u79cd\u7c7b\u578b\u7684\u5143\u6570\u636e\u6587\u4ef6\uff1a * \u504f\u79fb\u91cf\u6587\u4ef6\uff1a\u5305\u542b\u5728\u542f\u52a8\u65f6\u6062\u590d\u590d\u5236\u64cd\u4f5c\u7684\u504f\u79fb\u91cf * \u67b6\u6784\u5386\u53f2\u6587\u4ef6\uff1a\u5305\u542b\u4e3a\u590d\u5236\u6784\u5efa\u6240\u6709\u8868\u7684\u67b6\u6784\u4fe1\u606f\u3002\u8fd9\u5728\u521d\u59cb\u6570\u636e\u5feb\u7167\u540c\u6b65\u671f\u95f4\u521b\u5efa\uff0c\u5e76\u53ef\u5728\u64cd\u4f5c\u671f\u95f4\u66f4\u65b0\u3002</p> <p>\u8fd9\u4e9b\u5143\u6570\u636e\u6587\u4ef6\u540d\u7531\u4ee5\u4e0b\u90e8\u5206\u7ec4\u6210\uff1a</p> <ul> <li> <p>(\u8fde\u63a5\u5668\u7c7b\u578b)(\u8fde\u63a5\u5668\u540d\u79f0)(\u76ee\u6807\u6570\u636e\u5e93)_offsets.dat</p> </li> <li> <p>(\u8fde\u63a5\u5668\u7c7b\u578b)(\u8fde\u63a5\u5668\u540d\u79f0)(\u76ee\u6807\u6570\u636e\u5e93)_schemahistory.dat</p> </li> </ul> <pre><code>ls $PGDATA/pg_synchdb\nmysql_mysqlconn_postgres_offsets.dat        sqlserver_sqlserverconn_postgres_offsets.dat\nmysql_mysqlconn_postgres_schemahistory.dat  sqlserver_sqlserverconn_postgres_schemahistory.dat\n</code></pre> <p>\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u5185\u5bb9\u53ef\u4ee5\u4f7f\u7528 hexdump \u547d\u4ee4\u67e5\u770b\uff1a <pre><code>hexdump -C $PGDATA/pg_synchdb/mysql_mysqlconn_postgres_offsets.dat\nhexdump -C $PGDATA/pg_synchdb/mysql_mysqlconn_postgres_schemahistory.dat\n</code></pre></p>"},{"location":"zh/architecture/metadata_files/#_2","title":"\u91cd\u7f6e\u8fde\u63a5\u5668","text":"<p>\u8fde\u63a5\u5668\u53ef\u4ee5\u91cd\u7f6e\uff08\u91cd\u65b0\u590d\u5236\u548c\u91cd\u65b0\u540c\u6b65\uff09\u6240\u6709\u6307\u5b9a\u8868\uff0c\u53ea\u9700\uff1a</p> <ul> <li>\u505c\u6b62\u8fde\u63a5\u5668</li> <li>\u5220\u9664\u504f\u79fb\u91cf\u548c\u67b6\u6784\u5386\u53f2\u6587\u4ef6</li> <li>\u542f\u52a8\u8fde\u63a5\u5668</li> </ul>"},{"location":"zh/architecture/native_datatype_handling/","title":"\u5904\u7406\u539f\u751f\u6570\u636e\u7c7b\u578b","text":""},{"location":"zh/architecture/native_datatype_handling/#_2","title":"\u5904\u7406\u539f\u751f\u6570\u636e\u7c7b\u578b","text":"<p>\u4e0b\u56fe\u663e\u793a\u4e86\u53d7\u652f\u6301\u7684\u672c\u673a\u6570\u636e\u7c7b\u578b\u5217\u8868\u4ee5\u53ca SynchDB \u5982\u4f55\u6839\u636e\u5176\u6027\u8d28\uff08\u6216\u7c7b\u522b\uff09\u5c06\u5b83\u4eec\u5206\u7ec4\u5728\u4e00\u8d77\u3002\u4f8b\u5982\uff0c\u6570\u5b57\u7ec4\u5305\u542b\u6240\u6709\u672c\u8d28\u4e0a\u662f\u6570\u5b57\u7684\u6574\u6570\u6216\u6d6e\u70b9\u6570\u636e\u7c7b\u578b\u3002\u5982\u679c\u6570\u636e\u5305\u542b\u975e\u6570\u5b57\u5b57\u7b26\uff0c\u5b83\u4eec\u5c06\u7ed9\u51fa\u9519\u8bef\u3002\u540c\u6837\uff0c\u4e0d\u540c\u7684\u6570\u636e\u7c7b\u578b\u7ec4\u9700\u8981\u7279\u5b9a\u7684\u6570\u636e\u683c\u5f0f\u624d\u80fd\u5e94\u7528\u3002</p> <p></p> <p>\u73b0\u5728 DML \u8f6c\u6362\u5668\u77e5\u9053\u5982\u4f55\u5728 PostgreSQL \u7aef\u4e3a\u8fd9\u4e9b\u53d7\u652f\u6301\u7684\u672c\u673a\u6570\u636e\u7c7b\u578b\u751f\u6210\u6570\u636e\uff0c\u7136\u540e\u5b83\u4f1a\u67e5\u770b DBZ \u5143\u6570\u636e\u4ee5\u4e86\u89e3\u6e90\u6570\u636e\u7684\u8868\u793a\u65b9\u5f0f\u3002\u8fd9\u662f\u5fc5\u8981\u7684\uff0c\u56e0\u4e3a Debezium \u5f15\u64ce\u53ef\u80fd\u4f1a\u5bf9\u6570\u636e\u8fdb\u884c\u7f16\u7801\u4ee5\u6253\u5305\u66f4\u591a\u9700\u8981\u5728\u5904\u7406\u6570\u636e\u4e4b\u524d\u89e3\u7801\u7684\u4fe1\u606f\uff0c\u6216\u8005\u4f7f\u7528\u7ed3\u6784\u6765\u8868\u793a\u590d\u6742\u7684\u6570\u636e\u7c7b\u578b\uff0c\u5982\u51e0\u4f55\u56fe\u5f62\u3002\u5982\u679c\u4e0d\u77e5\u9053 Debezium \u5982\u4f55\u8868\u793a\u6570\u636e\uff0c\u6570\u636e\u5904\u7406\u53ef\u80fd\u4f1a\u4ea7\u751f\u4e0d\u7406\u60f3\u7684\u7ed3\u679c\uff0c\u5bfc\u81f4 PostgreSQL \u5728\u5e94\u7528\u671f\u95f4\u51fa\u9519\u3002\u4ee5\u4e0b\u662f Debezium \u53ef\u4ee5\u8868\u793a\u6709\u6548\u8d1f\u8f7d\u6570\u636e\u7684\u683c\u5f0f\u7c7b\u578b\u5217\u8868\uff1a</p> <p></p> <p>\u6709\u4e86\u8fd9\u4e24\u6761\u4fe1\u606f\uff0cDML \u8f6c\u6362\u5668\u5c31\u77e5\u9053\u8f93\u5165\u662f\u4ec0\u4e48\u6837\u5b50\uff0c\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48\u6837\u5b50\u3002\u5b83\u5c06\u4ece\u5176\u51fd\u6570\u77e9\u9635\u4e2d\u9009\u62e9\u6700\u4f73\u5904\u7406\u7a0b\u5e8f\u6765\u5904\u7406\u6570\u636e\u3002\u4f8b\u5982\uff0c\u5982\u679c\u76ee\u6807\u7c7b\u578b\u4e3a\u201cFLOAT4\u201d\uff0c\u6e90\u6570\u636e\u7c7b\u578b\u683c\u5f0f\u4e3a\u201cDBZTYPE_BYTES\u201d\uff0c\u5219\u5c06\u9009\u62e9\u51fd\u6570\u201chandle_base64_to_numeric()\u201d\u6765\u5904\u7406\u6570\u636e\u3002\u6240\u9009\u51fd\u6570\u8d1f\u8d23\u89e3\u7801\u4e8c\u8fdb\u5236\u8f93\u5165\u5e76\u5c06\u5176\u8ba1\u7b97\u4e3a\u6570\u5b57\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/","title":"Openlog Replicator \u4e8b\u4ef6\u5904\u7406\u5668","text":""},{"location":"zh/architecture/openlog_replicator_event_processor/#openlog-replicator_1","title":"Openlog Replicator \u4e8b\u4ef6\u5904\u7406\u5668\u7ec4\u4ef6\u56fe","text":"<p>Openlog Replicator \u4e8b\u4ef6\u5904\u7406\u5668\u662f\u4e00\u4e2a\u7531 SynchDB \u6269\u5c55\u542f\u52a8\u7684 PostgreSQL \u540e\u53f0\u5de5\u4f5c\u5668\u3002\u5b83\u8d1f\u8d23\u8fde\u63a5\u5230 Openlog Replicator\u3001\u542f\u52a8\u590d\u5236\u5e76\u83b7\u53d6 JSON \u683c\u5f0f\u7684\u53d8\u66f4\u4e8b\u4ef6\u3002\u8be5\u6a21\u5757\u7684\u5185\u90e8\u7ec4\u4ef6\u5982\u4e0b\uff1a</p> <ol> <li>OLR \u5ba2\u6237\u7aef</li> <li>Oracle \u89e3\u6790\u5668</li> <li>JSON \u89e3\u6790\u5668</li> <li>\u5bf9\u8c61\u6620\u5c04\u5f15\u64ce</li> <li>\u7edf\u8ba1\u4fe1\u606f\u6536\u96c6\u5668</li> <li>DDL \u8f6c\u6362\u5668</li> <li>DML \u8f6c\u6362\u5668</li> <li>\u9519\u8bef\u5904\u7406\u7a0b\u5e8f</li> <li>SPI \u5ba2\u6237\u7aef</li> <li>\u6267\u884c\u5668 API</li> </ol>"},{"location":"zh/architecture/openlog_replicator_event_processor/#1-olr","title":"1) OLR \u5ba2\u6237\u7aef","text":"<p>OLR \u5ba2\u6237\u7aef\u4e0e OpenLog Replicator (OLR) \u670d\u52a1\u5668\u5efa\u7acb TCP/IP \u4f1a\u8bdd\uff0c\u901a\u8fc7\u534f\u8bae\u63e1\u624b\u534f\u5546\u590d\u5236\u6d41\uff08\u4f8b\u5982\uff0c\u534f\u8bae\u7248\u672c\u548c\u8d77\u59cb\u504f\u79fb\u91cf/SCN\uff09\uff0c\u7136\u540e\u6301\u7eed\u63a5\u6536\u4ee5 JSON \u683c\u5f0f\u53d1\u9001\u7684\u53d8\u66f4\u4e8b\u4ef6\u3002\u7ebf\u7ea7\u5e27\uff08\u63e1\u624b\u3001\u786e\u8ba4\u3001\u5fc3\u8df3\uff09\u4f7f\u7528 libprotobuf-c \u8fdb\u884c\u7f16\u7801/\u89e3\u7801\uff0c\u5e76\u4f7f\u7528\u76f4\u63a5\u6765\u81ea\u5b98\u65b9 OpenLog Replicator \u4ed3\u5e93 \u7684 .proto \u5b9a\u4e49\uff0c\u4ee5\u786e\u4fdd\u4e25\u683c\u7684\u534f\u8bae\u517c\u5bb9\u6027\u3002\u89e3\u7801\u540e\uff0c\u4e8b\u4ef6\u88ab\u89c4\u8303\u5316\u4e3a JSON\uff0c\u5e76\u4ea4\u7531 <code>3) JSON \u89e3\u6790\u5668</code> \u8fdb\u884c\u4e0b\u6e38\u5904\u7406\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#2-oracle","title":"2) Oracle \u89e3\u6790\u5668","text":"<p>Oracle \u89e3\u6790\u5668\u8d1f\u8d23\u89e3\u6790 Oracle \u67e5\u8be2\uff08\u4ec5\u9650 DDL\uff09\u5e76\u751f\u6210 PostgreSQL \u539f\u59cb\u89e3\u6790\u6811\uff0c\u4ee5\u4fbf SynchDB \u80fd\u591f\u7406\u89e3\u5176\u9884\u671f\u64cd\u4f5c\u3002SynchDB \u7684 Oracle \u89e3\u6790\u5668\u57fa\u4e8e IvorySQL 4 \u7684 PostgreSQL Oracle \u89e3\u6790\u5668\uff0c\u4f46\u6839\u636e SynchDB \u7684\u9700\u6c42\u8fdb\u884c\u4e86\u4fee\u6539\u3002\u4fee\u6539\u540e\u7684 Oracle \u89e3\u6790\u5668\u7684\u6e90\u4ee3\u7801\u4f4d\u4e8e <code>src/backend/olr/oracle_parser</code> \u4e2d\uff0c\u5b83\u5e76\u4e0d\u652f\u6301\u6240\u6709 Oracle \u8bed\u6cd5\u3002\u4f46\u5b83\u8db3\u4ee5\u652f\u6301\u6211\u4eec\u60f3\u8981\u652f\u6301\u7684\u6240\u6709 DDL \u547d\u4ee4\uff08\u89c1\u4e0b\u6587\uff09\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#3-json","title":"3) JSON \u89e3\u6790\u5668","text":"<p>JSON \u89e3\u6790\u5668\u8d1f\u8d23\u5c06\u4f20\u5165\u7684 JSON \u66f4\u6539\u4e8b\u4ef6\u89e3\u6790\u4e3a SynchDB \u53ef\u4ee5\u4f7f\u7528\u7684 C \u8bed\u8a00\u7ed3\u6784\u3002 SynchDB \u4f9d\u8d56\u4e8e PostgreSQL \u539f\u751f\u7684 JSONB \u5b9e\u7528\u7a0b\u5e8f\u6765\u6ee1\u8db3\u6240\u6709\u89e3\u6790\u548c\u8fed\u4ee3\u9700\u6c42\u3002\u6bcf\u4e2a DML \u4e8b\u4ef6\u90fd\u5305\u542b <code>scn</code> \u548c <code>commit scn</code> \u503c\uff0c\u5e76\u6839\u636e\u6570\u636e\u7c7b\u578b\u8bf4\u660e\u6bcf\u4e2a\u5217\u503c\u7684\u8868\u793a\u65b9\u5f0f\uff0c\u4ee5\u53ca\u6267\u884c\u524d\u540e\u503c\u3002</p> <p>\u5982\u679c\u5c06 DDL \u4e8b\u4ef6\u4e0e Debezium \u89e3\u9664\u5173\u8054\uff0cOpenlog Replicator \u7684 DDL \u4e8b\u4ef6\u5c06\u5305\u542b\u539f\u59cb\u7684 Oracle DDL \u67e5\u8be2\uff0c\u800c\u4e0d\u662f\u5206\u89e3\u540e\u7684\u7ed3\u6784\u3002\u8fd9\u610f\u5473\u7740\u9700\u8981\u4e00\u4e2a <code>2) Oracle \u89e3\u6790\u5668</code> \u6765\u8fdb\u4e00\u6b65\u89e3\u6790\u6b64 DDL \u67e5\u8be2\uff0c\u4ee5\u4e86\u89e3\u5176\u9884\u671f\u64cd\u4f5c\u3002</p> <p>DML \u8d1f\u8f7d\uff1a <pre><code>{\n  \"scn\": 3531590,\n  \"tm\": 1752686342000000000,\n  \"c_scn\": 3531691,\n  \"c_idx\": 2,\n  \"xid\": \"0x0007.01a.000004a1\",\n  \"db\": \"FREE\",\n  \"payload\": [\n    {\n      \"op\": \"c\",\n      \"schema\": {\n        \"owner\": \"DBZUSER\",\n        \"table\": \"ORDERS\",\n        \"obj\": 73406,\n        \"columns\": [\n          {\n            \"name\": \"ORDER_NUMBER\",\n            \"type\": \"number\",\n            \"precision\": -1,\n            \"scale\": -1,\n            \"nullable\": false\n          },\n          {\n            \"name\": \"ORDER_DATE\",\n            \"type\": \"date\",\n            \"nullable\": true\n          },\n          {\n            \"name\": \"PURCHASER\",\n            \"type\": \"number\",\n            \"precision\": -1,\n            \"scale\": -1,\n            \"nullable\": true\n          },\n          {\n            \"name\": \"QUANTITY\",\n            \"type\": \"number\",\n            \"precision\": -1,\n            \"scale\": -1,\n            \"nullable\": true\n          },\n          {\n            \"name\": \"PRODUCT_ID\",\n            \"type\": \"number\",\n            \"precision\": -1,\n            \"scale\": -1,\n            \"nullable\": true\n          }\n        ]\n      },\n      \"num\": 0,\n      \"rid\": \"AAAR6+AAFAAAACGAAA\",\n      \"after\": {\n        \"ORDER_NUMBER\": 10013,\n        \"ORDER_DATE\": 1704067200000000000,\n        \"PURCHASER\": 1003,\n        \"QUANTITY\": 2,\n        \"PRODUCT_ID\": 107\n      }\n    }\n  ]\n}\n</code></pre></p> <p>DDL \u8d1f\u8f7d\uff1a <pre><code>{\n  \"scn\": 2930816,\n  \"tm\": 1753384727000000000,\n  \"c_scn\": 2930820,\n  \"c_idx\": 3,\n  \"xid\": \"0x0008.011.000004c7\",\n  \"db\": \"FREE\",\n  \"payload\": [\n    {\n      \"op\": \"ddl\",\n      \"schema\": {\n        \"owner\": \"DBZUSER\",\n        \"table\": \"TEST_TABLE\",\n        \"obj\": 74234\n      },\n      \"sql\": \"CREATE TABLE test_table (\\n    id NUMBER PRIMARY KEY,\\n    binary_double_col BINARY_DOUBLE,\\n    binary_float_col BINARY_FLOAT,\\n    float_col FLOAT(10),\\n    number_col NUMBER(10,2),\\n    long_col LONG,\\n    date_col DATE,\\n    interval_ds_col INTERVAL DAY TO SECOND,\\n    interval_ym_col INTERVAL YEAR TO MONTH,\\n    timestamp_col TIMESTAMP,\\n    timestamp_tz_col TIMESTAMP WITH TIME ZONE,\\n    timestamp_ltz_col TIMESTAMP WITH LOCAL TIME ZONE,\\n    char_col CHAR(10),\\n    nchar_col NCHAR(10),\\n    nvarchar2_col NVARCHAR2(50),\\n    varchar_col VARCHAR(50),\\n    varchar2_col VARCHAR2(50),\\n    raw_col RAW(100),\\n    bfile_col BFILE,\\n    blob_col BLOB,\\n    clob_col CLOB,\\n    nclob_col NCLOB,\\n    rowid_col ROWID,\\n    urowid_col UROWID\\n)\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#4","title":"4) \u5bf9\u8c61\u6620\u5c04\u5f15\u64ce","text":"<p>\u5bf9\u8c61\u6620\u5c04\u5f15\u64ce\u8d1f\u8d23\u52a0\u8f7d\u548c\u7ef4\u62a4\u6bcf\u4e2a\u6d3b\u52a8\u8fde\u63a5\u5668\u4e0b\u7684\u5bf9\u8c61\u6620\u5c04\u4fe1\u606f\u3002\u8fd9\u4e9b\u6620\u5c04\u4fe1\u606f\u544a\u8bc9 SynchDB \u5728 DDL \u548c DML \u5904\u7406\u8fc7\u7a0b\u4e2d\u5982\u4f55\u5c06\u6e90\u5bf9\u8c61\u6620\u5c04\u5230\u76ee\u6807\u5bf9\u8c61\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cSynchdb \u6ca1\u6709\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\uff0c\u5b83\u5c06\u4f7f\u7528\u9ed8\u8ba4\u6620\u5c04\u89c4\u5219\u6765\u5904\u7406\u6570\u636e\u3002</p> <p>\u4e00\u4e2a\u5bf9\u8c61\u53ef\u4ee5\u5f15\u7528\uff1a * \u8868\u540d\u3002 * \u5217\u540d\u3002 * \u6570\u636e\u7c7b\u578b\u3002 * \u8f6c\u6362\u8868\u8fbe\u5f0f\u3002</p> <p>\u5728\u521b\u5efa\u6620\u5c04\u89c4\u5219\u4e4b\u524d\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>synchdb_add_objmap()</code> \u51fd\u6570\u5c06\u6e90\u8868\u540d\u3001\u5217\u540d\u548c\u6570\u636e\u7c7b\u578b\u6620\u5c04\u5230\u4e0d\u540c\u7684\u76ee\u6807\u8868\u540d\u3001\u5217\u540d\u548c\u6570\u636e\u7c7b\u578b\uff0c\u6240\u6709\u89c4\u5219\u90fd\u53ef\u4ee5\u901a\u8fc7\u67e5\u8be2 <code>synchdb_objmap</code> \u8868\u6765\u67e5\u770b\u3002\u66f4\u591a\u5173\u4e8e\u5bf9\u8c61\u6620\u5c04\u7684\u4fe1\u606f\u8bf7\u53c2\u89c1\u6b64\u5904\u3002\u5728 <code>synchdb_att_view()</code> \u89c6\u56fe\u4e0b\u53ef\u4ee5\u67e5\u770b\u6620\u5c04\u5185\u5bb9\u7684\u6458\u8981\u3002</p> <p>\u201c\u8f6c\u6362\u8868\u8fbe\u5f0f\u201d\u662f\u4e00\u4e2a SQL \u8868\u8fbe\u5f0f\uff0c\u5b83\u5c06\u5728\u6570\u636e\u8f6c\u6362\u5b8c\u6210\u540e\u3001\u6570\u636e\u5e94\u7528\u4e4b\u524d\u8fd0\u884c\uff08\u5982\u679c\u6307\u5b9a\uff09\u3002\u6b64\u8868\u8fbe\u5f0f\u53ef\u4ee5\u662f\u4efb\u4f55\u53ef\u5728 PostgreSQL \u4e2d\u8fd0\u884c\u7684\u8868\u8fbe\u5f0f\uff0c\u4f8b\u5982\u8c03\u7528\u5176\u4ed6 SQL \u51fd\u6570\u6216\u4f7f\u7528\u8fd0\u7b97\u7b26\u3002\u66f4\u591a\u5173\u4e8e\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u7684\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#5","title":"5) \u7edf\u8ba1\u6536\u96c6\u5668","text":"<p>\u7edf\u8ba1\u6536\u96c6\u5668\u8d1f\u8d23\u6536\u96c6 SynchDB \u81ea\u64cd\u4f5c\u5f00\u59cb\u4ee5\u6765\u6570\u636e\u5904\u7406\u7684\u7edf\u8ba1\u4fe1\u606f\u3002\u8fd9\u5305\u62ec DDL \u548c DML \u7684\u6570\u91cf\u3001\u5df2\u5904\u7406\u7684 CREATE\u3001INSERT\u3001UPDATE \u548c DELETE \u64cd\u4f5c\u7684\u6570\u91cf\u3001\u5904\u7406\u7684\u5e73\u5747\u6279\u6b21\u5927\u5c0f\u4ee5\u53ca\u591a\u4e2a\u65f6\u95f4\u6233\uff0c\u8fd9\u4e9b\u65f6\u95f4\u6233\u5206\u522b\u63cf\u8ff0\u4e86\u6570\u636e\u5728\u6e90\u4e2d\u9996\u6b21\u751f\u6210\u7684\u65f6\u95f4\u3001Debezium \u5904\u7406\u6570\u636e\u7684\u65f6\u95f4\u4ee5\u53ca\u6570\u636e\u5728 PostgreSQL \u4e2d\u5e94\u7528\u7684\u65f6\u95f4\u3002\u8fd9\u4e9b\u6307\u6807\u53ef\u4ee5\u5e2e\u52a9\u7528\u6237\u4e86\u89e3 SynchDB \u7684\u5904\u7406\u884c\u4e3a\uff0c\u4ece\u800c\u8c03\u6574\u548c\u4f18\u5316\u8bbe\u7f6e\uff0c\u4ece\u800c\u63d0\u9ad8\u5904\u7406\u6027\u80fd\u3002\u66f4\u591a\u5173\u4e8e\u7edf\u8ba1\u6570\u636e\u7684\u4fe1\u606f\uff0c\u8bf7\u8bbf\u95ee\u6b64\u5904\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#6-ddl","title":"6) DDL \u8f6c\u6362\u5668","text":"<p>DDL \u8f6c\u6362\u5668\u8d1f\u8d23\u5c06\u201cJSON \u89e3\u6790\u5668\u201d\u751f\u6210\u7684 DDL \u6570\u636e\u8f6c\u6362\u4e3a PostgreSQL \u53ef\u4ee5\u7406\u89e3\u7684\u683c\u5f0f\u3002\u5bf9\u4e8e DDL\uff0cSynchDB \u4f9d\u8d56\u4e8e PostgreSQL SPI \u5f15\u64ce\u8fdb\u884c\u5904\u7406\uff0c\u56e0\u6b64\u8f6c\u6362\u7684\u8f93\u51fa\u662f\u666e\u901a\u7684 SQL \u67e5\u8be2\u5b57\u7b26\u4e32\u3002DDL \u8f6c\u6362\u5668\u4f1a\u68c0\u67e5 DDL \u6570\u636e\uff0c\u5e76\u4e0e\u201c\u5bf9\u8c61\u6620\u5c04\u5f15\u64ce\u201d\u534f\u4f5c\uff0c\u4ee5\u6b63\u786e\u8f6c\u6362\u6e90\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u8868\u3001\u5217\u540d\u6216\u6570\u636e\u7c7b\u578b\u6620\u5c04\u3002</p> <p>\u5982\u679c\u6839\u636e\u201c\u5bf9\u8c61\u6620\u5c04\u5f15\u64ce\u201d\uff0c\u540d\u4e3a\u201cemployee\u201d\u7684\u8fdc\u7a0b\u8868\u8981\u5728\u76ee\u6807\u4e2d\u6620\u5c04\u4e3a\u201cstaff\u201d\uff0c\u5219 DDL \u8f6c\u6362\u5668\u8d1f\u8d23\u89e3\u6790\u8fd9\u4e9b\u540d\u79f0\u6620\u5c04\uff0c\u5e76\u76f8\u5e94\u5730\u4e3a SPI \u521b\u5efa SQL \u67e5\u8be2\u3002</p> <p>\u8be5\u8f6c\u6362\u5668\u76ee\u524d\u53ef\u4ee5\u5904\u7406\u4ee5\u4e0b Oracle DDL \u64cd\u4f5c\uff1a</p> <ul> <li>\u521b\u5efa\u8868</li> <li>\u5220\u9664\u8868</li> <li>\u4fee\u6539\u8868</li> <li>\u4fee\u6539\u8868\u6dfb\u52a0\u5217</li> <li>\u4fee\u6539\u8868\u5220\u9664\u5217</li> <li>\u4fee\u6539\u8868\u6dfb\u52a0\u7ea6\u675f</li> <li>\u4fee\u6539\u8868\u5220\u9664\u7ea6\u675f</li> </ul>"},{"location":"zh/architecture/openlog_replicator_event_processor/#_1","title":"\u9650\u5236","text":"<p>Openlog Replicator \u8fde\u63a5\u5668\u4e0d\u652f\u6301\u4ee5\u4e0b\u5728 DDL \u547d\u4ee4\u4e2d\u58f0\u660e\u7684 Oracle \u7279\u6027\uff1a</p> <ul> <li>\u865a\u62df\u5217</li> <li>\u5e26\u7a7a\u683c\u7684\u5f15\u7528\u8868\u540d\u6216\u5217\u540d</li> <li>\u7d22\u5f15\u7ec4\u7ec7\u8868 (IOT)</li> <li><code>CREATE TABLE AS</code> \u5b50\u53e5</li> <li><code>CREATE TYPE</code> \u5b50\u53e5</li> <li><code>CREATE TABLE OF</code> \u5b50\u53e5</li> <li><code>ALTER TABLE MODIFY name DEFAULT</code></li> <li><code>ALTER TABLE MODIFY name NOT NULL</code></li> <li><code>ALTER TABLE MODIFY name NULL</code></li> <li><code>ALTER TABLE MODIFY name SET UNUSED</code></li> <li><code>ALTER TABLE MODIFY name DROP UNUSED COLUMNS</code></li> <li><code>ALTER TABLE RENAME</code></li> </ul> <p>Openlog Replicator \u8fde\u63a5\u5668\u63a5\u53d7\u4f46\u5ffd\u7565\u4ee5\u4e0b\u7ea6\u675f\u5b50\u53e5\uff1a</p> <ul> <li>ENABLE VALIDATE</li> <li>ENABLE NOVALIDATE</li> <li>DISABLE VALIDATE</li> <li>DISABLE NOVALIDATE</li> </ul> <p>\u4ee5\u4e0b\u5185\u5bb9\u5c06\u88ab\u89c6\u4e3a DEFAULT NULL\uff1a</p> <ul> <li>DEFAULT ON NULL 'expr'</li> <li>DEFAULT 'expr'</li> </ul> <p>\u4ee5\u4e0b\u8bed\u53e5\u53ea\u80fd\u63a5\u53d7\u4e00\u7ec4\u5217\u5b9a\u4e49\uff0c\u800c\u4e0d\u80fd\u63a5\u53d7\u591a\u7ec4\u3002</p> <ul> <li><code>ALTER TABLE MODIFY ADD ...</code></li> <li><code>ALTER TABLE MODIFY (ADD ...)</code></li> <li><code>ALTER TABLE MODIFY DROP ...</code> </li> <li><code>ALTER TABLE MODIFY (DROP ...)</code> </li> </ul> <p>&lt;\u6ce8\u610f&gt; \u66f4\u591a\u9650\u5236\u53ef\u80fd\u4f1a\u5728\u6211\u4eec\u53d1\u73b0\u540e\u5728\u6b64\u5904\u66f4\u65b0\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#7-dml","title":"7) DML \u8f6c\u6362\u5668","text":"<p>DML \u8f6c\u6362\u5668\u8d1f\u8d23\u5c06\u201cJSON \u89e3\u6790\u5668\u201d\u751f\u6210\u7684 DML \u6570\u636e\u8f6c\u6362\u4e3a PostgreSQL \u53ef\u4ee5\u7406\u89e3\u7684\u683c\u5f0f\u3002\u5bf9\u4e8e DML\uff0cSynchDB \u4f9d\u8d56 PostgreSQL \u7684\u6267\u884c\u5668 API \u5c06\u6570\u636e\u76f4\u63a5\u5e94\u7528\u4e8e PostgreSQL\uff0c\u56e0\u6b64\u8f6c\u6362\u7684\u8f93\u51fa\u4e3a PostgreSQL \u6267\u884c\u5668\u53ef\u4ee5\u7406\u89e3\u7684 TupleTableSlot (TTS) \u683c\u5f0f\u3002\u4e3a\u4e86\u751f\u6210\u9002\u7528\u4e8e PostgreSQL \u7684\u6b63\u786e TTS\uff0cDML \u8f6c\u6362\u5668\u4f9d\u8d56\u4e8e\uff1a</p> <ul> <li>\u63cf\u8ff0\u6709\u6548\u8f7d\u8377\u6570\u636e\u5982\u4f55\u8868\u793a\u7684\u6a21\u5f0f\u5143\u6570\u636e</li> <li>PostgreSQL \u76ee\u5f55\uff08pg_class \u548c pg_type\uff09\uff0c\u7528\u4e8e\u4e86\u89e3\u8868\u7684\u4fe1\u606f\u3001\u6bcf\u5217\u7684\u6570\u636e\u7c7b\u578b\u548c\u5c5e\u6027\u3002</li> <li>\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\uff0c\u7528\u4e8e\u786e\u5b9a\u662f\u5426\u9700\u8981\u5bf9\u5df2\u5904\u7406\u7684\u6570\u636e\u8fd0\u884c\u989d\u5916\u7684\u8f6c\u6362\u8868\u8fbe\u5f0f</li> <li>\u9700\u8981\u5904\u7406\u7684\u6709\u6548\u8f7d\u8377\u6570\u636e\u672c\u8eab</li> </ul> <p>DML \u8f6c\u6362\u5668\u5305\u542b\u591a\u4e2a\u4f8b\u7a0b\uff0c\u8fd9\u4e9b\u4f8b\u7a0b\u53ef\u4ee5\u5904\u7406\u7279\u5b9a\u7684\u8f93\u5165\u6570\u636e\u7c7b\u578b\u5e76\u751f\u6210\u7279\u5b9a\u7684\u8f93\u51fa\u7c7b\u578b\u3002\u4e3a\u7279\u5b9a\u7684\u8f6c\u6362\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u4f8b\u7a0b\u53ef\u80fd\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u56e0\u4e3a\u67d0\u4e9b\u6570\u636e\u7c7b\u578b\u53ef\u80fd\u662f\u7528\u6237\u5b9a\u4e49\u7684\uff0c\u6216\u8005\u7531 SynchDB \u4e0d\u592a\u4e86\u89e3\u7684\u5176\u4ed6\u6269\u5c55\u521b\u5efa\u3002SynchDB \u5fc5\u987b\u8bbe\u8ba1\u4e3a\u80fd\u591f\u5904\u7406 PostgreSQL \u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u539f\u751f\u548c\u975e\u539f\u751f\u6570\u636e\u7c7b\u578b\u3002</p> <p>\u4f8b\u7a0b\u9009\u62e9\u9996\u5148\u8981\u67e5\u770b PostgreSQL \u4e2d\u521b\u5efa\u7684\u6570\u636e\u7c7b\u578b\uff0c\u8be5\u6570\u636e\u7c7b\u578b\u53ef\u5206\u4e3a\u4e24\u79cd\u7c7b\u578b\uff0c\u6bcf\u79cd\u7c7b\u578b\u7684\u5904\u7406\u6280\u672f\u7565\u6709\u4e0d\u540c\uff1a</p> <ul> <li>\u539f\u751f\u6570\u636e\u7c7b\u578b\u3002</li> <li>\u975e\u539f\u751f\u6570\u636e\u7c7b\u578b\u3002</li> </ul>"},{"location":"zh/architecture/openlog_replicator_event_processor/#_2","title":"\u6570\u636e\u8f6c\u6362","text":"<p>\u8f93\u5165\u6570\u636e\u6309\u4e0a\u8ff0\u903b\u8f91\u5904\u7406\u540e\uff0c\u8f6c\u6362\u5668\u5c06\u68c0\u67e5\u7528\u6237\u662f\u5426\u914d\u7f6e\u4e86\u201c\u8f6c\u6362\u8868\u8fbe\u5f0f\u201d\uff0c\u8be5\u8868\u8fbe\u5f0f\u5e94\u5728\u5e94\u7528\u4e8e PostgreSQL \u4e4b\u524d\u5e94\u7528\u4e8e\u5df2\u5904\u7406\u7684\u6570\u636e\u3002\u8f6c\u6362\u8868\u8fbe\u5f0f\u53ef\u4ee5\u662f\u4efb\u4f55\u53ef\u5728 psql \u63d0\u793a\u7b26\u4e0b\u8fd0\u884c\u7684 PostgreSQL \u8868\u8fbe\u5f0f\u3001\u547d\u4ee4\u6216 SQL \u51fd\u6570\u3002\u5b83\u4f7f\u7528\u201c%d\u201d\u4f5c\u4e3a\u5360\u4f4d\u7b26\uff0c\u5728\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u5c06\u66ff\u6362\u4e3a\u5df2\u5904\u7406\u7684\u6570\u636e\u3002\u4f8b\u5982\uff0c\u8f6c\u6362\u8868\u8fbe\u5f0f\u201c'&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\u201d\u5c06\u5728\u5df2\u5904\u7406\u7684\u5b57\u7b26\u4e32\u6570\u636e\u524d\u6dfb\u52a0\u548c\u540e\u6dfb\u52a0\u5176\u4ed6\u5b57\u7b26\u3002</p> <p>\u56e0\u6b64\uff0c\u5982\u679c\u975e\u539f\u751f\u6570\u636e\u7c7b\u578b\u7684\u7c7b\u522b\u4e3a TYPCATEGORY_USER\uff0c\u800c DML \u8f6c\u6362\u5668\u6ca1\u6709\u5408\u9002\u7684\u4f8b\u7a0b\u6765\u5904\u7406\u6b64\u7c7b\u6570\u636e\uff0c\u56e0\u6b64\u4f1a\u5c06\u5176\u4fdd\u7559\u539f\u6837\u3002\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\u4e00\u4e2a\u8f6c\u6362\u8868\u8fbe\u5f0f\u6765\u8c03\u7528\u81ea\u5b9a\u4e49 SQL \u51fd\u6570\uff0c\u4ee5\u4fbf\u8f6c\u6362\u5668\u77e5\u9053\u5982\u4f55\u6b63\u786e\u5904\u7406\u6570\u636e\u5e76\u751f\u6210\u5408\u9002\u7684\u8f93\u51fa\u3002\u4f8b\u5982\uff0c\u8868\u8fbe\u5f0f\u201cto_my_composite_type('%d')\u201d\u5c06\u8c03\u7528\u7528\u6237\u5b9a\u4e49\u7684 SQL \u51fd\u6570\u201cto_my_composite_type\u201d\uff0c\u5e76\u4ee5\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u3002\u8be5\u8868\u8fbe\u5f0f\u5fc5\u987b\u6709\u8fd4\u56de\u503c\uff0c\u56e0\u4e3a\u5b83\u5c06\u5728\u5e94\u7528\u671f\u95f4\u88ab\u8f93\u5165\u5230 PostgreSQL \u4e2d\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#8","title":"8) \u9519\u8bef\u5904\u7406\u7a0b\u5e8f","text":"<p>\u9519\u8bef\u5904\u7406\u7a0b\u5e8f\u4e3b\u8981\u8d1f\u8d23\u5904\u7406\u6570\u636e\u540c\u6b65\u5404\u4e2a\u9636\u6bb5\u53ef\u80fd\u51fa\u73b0\u7684\u4efb\u4f55\u9519\u8bef\u3002\u683c\u5f0f\u8f6c\u6362\u5668\u652f\u6301\u591a\u79cd\u9519\u8bef\u5904\u7406\u7b56\u7565\uff0c\u53ef\u901a\u8fc7\u201csynchdb.error_handling_strategy\u201d\u53c2\u6570\u8fdb\u884c\u914d\u7f6e\u3002\u8be6\u7ec6\u4fe1\u606f\u8bf7\u53c2\u89c1\u6b64\u5904\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#9-spi","title":"9) SPI \u5ba2\u6237\u7aef","text":"<p>SPI \u5ba2\u6237\u7aef\u7ec4\u4ef6\u4f4d\u4e8e\u590d\u5236\u4ee3\u7406 (Replication Agent) \u4e0b\uff0c\u5145\u5f53 PostgreSQL \u6838\u5fc3\u548c SynchDB \u4e4b\u95f4\u7684\u6865\u6881\u3002\u5b83\u8d1f\u8d23\u4e0e SPI \u670d\u52a1\u5668\u5efa\u7acb\u8fde\u63a5\u3001\u542f\u52a8\u4e8b\u52a1\u3001\u83b7\u53d6\u5feb\u7167\u3001\u6267\u884c\u7531\u201cDDL \u8f6c\u6362\u5668\u201d\u521b\u5efa\u7684 SQL \u67e5\u8be2\u5e76\u9500\u6bc1\u8fde\u63a5\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u8981\u5904\u7406\u7684\u67e5\u8be2\uff0c\u90fd\u4f1a\u521b\u5efa\u548c\u9500\u6bc1 SPI \u8fde\u63a5\uff0c\u8fd9\u770b\u8d77\u6765\u6548\u7387\u4e0d\u9ad8\u3002\u7531\u4e8e SPI \u4ec5\u5728 DDL \u64cd\u4f5c\u671f\u95f4\u4f7f\u7528\uff0c\u800c DDL \u901a\u5e38\u4e0d\u592a\u9891\u7e41\uff0c\u56e0\u6b64\u6027\u80fd\u65b9\u9762\u5e94\u8be5\u4e0d\u9519\u3002</p>"},{"location":"zh/architecture/openlog_replicator_event_processor/#10-api","title":"10) \u6267\u884c\u5668 API","text":"<p>\u4e5f\u9a7b\u7559\u5728\u590d\u5236\u4ee3\u7406\u4e2d\u3002\u6b64\u7ec4\u4ef6\u8d1f\u8d23\u521d\u59cb\u5316\u6267\u884c\u5668\u4e0a\u4e0b\u6587\u3001\u6253\u5f00\u8868\u3001\u83b7\u53d6\u9002\u5f53\u7684\u9501\u3001\u4ece DML \u8f6c\u6362\u5668\u7684\u8f93\u51fa\u521b\u5efa TupleTableSlot (TTS)\u3001\u8c03\u7528\u6267\u884c\u5668 API \u6267\u884c INSERT\u3001UPDATE\u3001DELETE \u64cd\u4f5c\u4ee5\u53ca\u8fdb\u884c\u8d44\u6e90\u6e05\u7406\u3002\u901a\u5e38\uff0c\u8fd9\u662f\u4e00\u79cd\u6bd4 SPI \u66f4\u5feb\u7684\u6570\u636e\u64cd\u4f5c\u65b9\u6cd5\uff0c\u56e0\u4e3a\u5b83\u4e0d\u9700\u8981\u50cf SPI \u90a3\u6837\u89e3\u6790\u8f93\u5165\u67e5\u8be2\u5b57\u7b26\u4e32\u3002</p>"},{"location":"zh/architecture/test_framework/","title":"\u6d4b\u8bd5\u6846\u67b6","text":""},{"location":"zh/getting-started/configuration/","title":"\u914d\u7f6e\u8bf4\u660e","text":"<p>SynchDB \u5728 postgresql.conf \u4e2d\u652f\u6301\u4ee5\u4e0b GUC \u53d8\u91cf\u3002\u8fd9\u4e9b\u662f\u9002\u7528\u4e8e SynchDB \u7ba1\u7406\u7684\u6240\u6709Debezium\u8fde\u63a5\u5668\u7684\u901a\u7528\u53c2\u6570\uff1a</p> GUC \u53d8\u91cf \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 synchdb.naptime integer 100 \u4ece Debezium runner \u5f15\u64ce\u8f6e\u8be2\u6570\u636e\u7684\u65f6\u95f4\u95f4\u9694\uff08\u6beb\u79d2\uff09 synchdb.dml_use_spi boolean false \u662f\u5426\u4f7f\u7528 SPI \u5904\u7406 DML \u64cd\u4f5c synchdb.synchdb_auto_launcher boolean true \u662f\u5426\u81ea\u52a8\u542f\u52a8\u6d3b\u8dc3\u7684 SynchDB \u8fde\u63a5\u5668\u5de5\u4f5c\u8fdb\u7a0b\u3002\u6b64\u9009\u9879\u4ec5\u5728 SynchDB \u88ab\u5305\u542b\u5728 <code>shared_preload_library</code> GUC \u9009\u9879\u4e2d\u65f6\u751f\u6548 synchdb.dbz_batch_size integer 2048 Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u751f\u6210\u7684 SynchDB \u53ef\u5904\u7406\u7684\u6700\u5927\u53d8\u66f4\u4e8b\u4ef6\u6570\u3002\u6b64\u6279\u6b21\u53d8\u66f4\u7531 SynchDB \u5728\u5355\u4e2a\u4e8b\u52a1\u4e2d\u5904\u7406 synchdb.dbz_queue_size integer 8192 Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u7684\u53d8\u66f4\u4e8b\u4ef6\u961f\u5217\u7684\u6700\u5927\u5927\u5c0f\uff08\u4ee5\u53d8\u66f4\u4e8b\u4ef6\u6570\u8861\u91cf\uff09\u3002\u5e94\u5c06\u5176\u8bbe\u7f6e\u4e3a <code>synchdb.dbz_batch_size</code> \u7684\u81f3\u5c11\u4e24\u500d synchdb.dbz_connect_timeout_ms integer 30000 Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u4e0e\u8fdc\u7a0b\u6570\u636e\u5e93\u5efa\u7acb\u521d\u59cb\u8fde\u63a5\u7684\u8d85\u65f6\u503c\uff08\u4ee5\u6beb\u79d2\u4e3a\u5355\u4f4d\uff09 synchdb.dbz_query_timeout_ms integer 600000 Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u5728\u8fdc\u7a0b\u6570\u636e\u5e93\u4e0a\u6267\u884c\u67e5\u8be2\u7684\u8d85\u65f6\u503c\uff08\u4ee5\u6beb\u79d2\u4e3a\u5355\u4f4d\uff09 synchdb.dbz_skipped_oeprations string \u201ct\u201d Debezium \u5728\u5904\u7406\u66f4\u6539\u4e8b\u4ef6\u65f6\u5e94\u8df3\u8fc7\u7684\u64cd\u4f5c\u7684\u9017\u53f7\u5206\u9694\u5217\u8868\u3002 \u201cc\u201d \u8868\u793a\u63d2\u5165\uff0c\u201cu\u201d \u8868\u793a\u66f4\u65b0\uff0c\u201cd\u201d \u8868\u793a\u5220\u9664\uff0c\u201ct\u201d \u8868\u793a\u622a\u65ad synchdb.jvm_max_heap_size integer 1024 \u542f\u52a8\u8fde\u63a5\u5668\u65f6\u5206\u914d\u7ed9 Java \u865a\u62df\u673a (JVM) \u7684\u6700\u5927heap\u5185\u5b58\u5927\u5c0f\uff08\u4ee5 MB \u4e3a\u5355\u4f4d\uff09\u3002 synchdb.dbz_snapshot_thread_num integer 2 Debezium \u5d4c\u5165\u5f0f\u8fde\u63a5\u5668\u5728\u521d\u59cb\u5feb\u7167\u671f\u95f4\u5e94\u4ea7\u751f\u7684\u7ebf\u7a0b\u6570\u3002\u8bf7\u6ce8\u610f\uff0c\u6839\u636e Debezium\uff0c\u591a\u7ebf\u7a0b\u5feb\u7167\u662f\u4e00\u9879\u201c\u5b75\u5316\u529f\u80fd\u201d synchdb.dbz_snapshot_fetch_size integer 0 Debezium \u5d4c\u5165\u5f0f\u8fde\u63a5\u5668\u5728\u521d\u59cb\u5feb\u7167\u671f\u95f4\u5e94\u4e00\u6b21\u83b7\u53d6\u7684\u884c\u6570\u3002\u5c06\u5176\u8bbe\u7f6e\u4e3a 0 \u4ee5\u8ba9\u5f15\u64ce\u81ea\u52a8\u9009\u62e9 synchdb.dbz_snapshot_min_row_to_stream_results integer 0 \u5728\u521d\u59cb\u5feb\u7167\u671f\u95f4\uff0cDebezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u5207\u6362\u5230\u6d41\u6a21\u5f0f\u4e4b\u524d\u8fdc\u7a0b\u8868\u5e94\u5305\u542b\u7684\u6700\u5c0f\u884c\u6570\u3002\u5c06\u5176\u8bbe\u7f6e\u4e3a 0 \u4ee5\u59cb\u7ec8\u5207\u6362\u5230\u6d41\u6a21\u5f0f synchdb.dbz_incremental_snapshot_chunk_size integer 2048 \u5728\u589e\u91cf\u5feb\u7167\u671f\u95f4\uff0cDebezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u4e3a SynchDB \u751f\u6210\u7684\u66f4\u6539\u4e8b\u4ef6\u7684\u6700\u5927\u6570\u91cf synchdb.dbz_incremental_snapshot_watermarking_strategy \u5b57\u7b26\u4e32 \u201cinsert-insert Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u7528\u4e8e\u89e3\u51b3\u589e\u91cf\u5feb\u7167\u671f\u95f4\u6f5c\u5728\u51b2\u7a81\u7684\u6c34\u5370\u7b56\u7565\u3002\u53ef\u80fd\u7684\u503c\u662f\u201cinsert-insert\u201d\u548c\u201cinsert-delete\u201d synchdb.dbz_offset_flush_interval_ms integer 60000 Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u5c06\u504f\u79fb\u6570\u636e\u5237\u65b0\u5230\u78c1\u76d8\u7684\u95f4\u9694\uff08\u4ee5\u6beb\u79d2\u4e3a\u5355\u4f4d\uff09 synchdb.dbz_capture_only_selected_table_ddl boolean true Debezium \u5d4c\u5165\u5f0f\u5f15\u64ce\u662f\u5426\u5e94\u5728\u521d\u59cb\u5feb\u7167\u671f\u95f4\u6355\u83b7\u6240\u6709\u8868\uff08false\uff09\u6216\u9009\u5b9a\u8868\uff08true\uff09\u7684\u6a21\u5f0f synchdb.max_connector_workers integer 30 \u6700\u5927\u7684\u8fde\u63a5\u5668\u540e\u53f0\u8fdb\u7a0b\u6570\u91cf synchdb.error_handling_strategy enum \"exit\" \u914d\u7f6e\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u7684\u9519\u8bef\u5904\u7406\u7b56\u7565\u3002\u53ef\u80fd\u7684\u503c\u6709\u201cexit\u201d\u8868\u793a\u51fa\u9519\u65f6\u9000\u51fa\uff0c\u201cskip\u201d\u8868\u793a\u51fa\u9519\u65f6\u7ee7\u7eed\uff0c\u201cretry\u201d\u8868\u793a\u51fa\u9519\u65f6\u91cd\u8bd5 synchdb.dbz_log_level enum \"warn\" Debezium Runner \u7684\u65e5\u5fd7\u7ea7\u522b\u8bbe\u7f6e\u3002\u53ef\u80fd\u7684\u503c\u6709\u201cdebug\u201d\uff0c\u201cinfo\u201d\uff0c\u201cwarn\u201d\uff0c\u201cerror\u201d\uff0c\u201call\u201d\uff0c\u201cfatal\u201d\uff0c\u201coff\u201d\uff0c\u201ctrace\u201d synchdb.log_change_on_error boolean true \u8fde\u63a5\u5668\u662f\u5426\u5e94\u5728\u53d1\u751f\u9519\u8bef\u65f6\u8bb0\u5f55\u539f\u59cb JSON \u66f4\u6539\u4e8b\u4ef6 synchdb.jvm_max_direct_buffer_size integer 1024 \u5206\u914d\u7528\u4e8e\u4fdd\u5b58 JSON \u66f4\u6539\u4e8b\u4ef6\u7684\u6700\u5927\u76f4\u63a5\u7f13\u51b2\u533a\u5927\u5c0f\uff08\u4ee5 MB \u4e3a\u5355\u4f4d\uff09 synchdb.dbz_logminer_stream_mode enum \"uncommitted\" \u57fa\u65bc Debezium \u7684 Oracle \u9023\u63a5\u5668\u7684\u6d41\u6a21\u5f0f\u3002\u9810\u8a2d\u503c\u70bauncommitted\uff0c\u9019\u8868\u793a\u900f\u904e Debezium \u5f9e Oracle \u4e32\u6d41\u50b3\u8f38\u7684\u6240\u6709\u8b8a\u66f4\u5747\u672a\u63d0\u4ea4\u3002\u9019\u8868\u660e Debezium \u5fc5\u9808\u57f7\u884c\u4e00\u4e9b\u5de5\u4f5c\u4f86\u78ba\u4fdd\u4e8b\u52d9\u548c\u6240\u6709\u76f8\u95dc\u8b8a\u66f4\u7684\u5b8c\u6574\u6027\u3002\u8a2d\u5b9a\u70ba \"committed\" \u6703\u5c07\u9019\u9805\u5de5\u4f5c\u8f49\u79fb\u5230 Oralce \u7aef synchdb.olr_connect_timeout_ms integer 5000 \uff08\u50c5\u5f71\u97ff OLR \u9023\u63a5\u5668\uff09\u9023\u63a5\u5230 OpenLog \u8907\u88fd\u5668\u670d\u52d9\u6642\u7684\u9023\u7dda\u903e\u6642\u6642\u9593\uff08\u4ee5\u6beb\u79d2\u70ba\u55ae\u4f4d\uff09 synchdb.olr_read_timeout_m integer 5000 \uff08\u50c5\u5f71\u97ff OLR \u9023\u63a5\u5668\uff09\u5f9e\u5957\u63a5\u5b57\u8b80\u53d6\u6642\u7684\u8b80\u53d6\u903e\u6642\u6642\u9593\uff08\u4ee5\u6beb\u79d2\u70ba\u55ae\u4f4d\uff09 synchdb.olr_snapshot_engine enum \"debezium\" \uff08\u50c5\u5f71\u97ff OLR \u9023\u63a5\u5668\uff09\u6307\u5b9a\u5e95\u5c64\u5f15\u64ce\u5b8c\u6210\u521d\u59cb\u5feb\u7167\u7a0b\u5e8f\u3002\u53ef\u4ee5\u662f\u201cdebezium\u201d\u6216\u201cfdw\u201d\u3002\u5982\u679c\u9078\u64c7\u201cfdw\u201d\uff0c\u5247\u9700\u8981\u78ba\u4fdd\u5728 synchdb.cdc_start_delay_ms integer 0 \u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\u3001CDC \u6d41\u958b\u59cb\u524d\u7b49\u5f85\u7684\u5ef6\u9072\u6642\u9593\u3002 synchdb.fdw_migrate_with_subtx boolean true \u5728 FDW \u7684\u5feb\u7167\u671f\u9593\uff0c\u662f\u5426\u4f7f\u7528\u5b50\u4ea4\u6613\u9077\u79fb\u8868\u7684\u9078\u9805 synchdb.letter_casing_strategy enum \"lowercase\" synchdb \u61c9\u5982\u4f55\u8655\u7406\u4f86\u81ea\u4e0d\u540c\u6570\u636e\u5e93\u6e90\u7684\u7269\u4ef6\u5b57\u6bcd\u5927\u5c0f\u5beb\u5dee\u7570\u3002\u53ef\u9078\u503c\u70ba\uff1a\"lower\"\uff08\u898f\u7bc4\u5316\u70ba\u5c0f\u5beb\uff09\u3001\"upper\"\uff08\u898f\u7bc4\u5316\u70ba\u5927\u5beb\uff09\u6216 \"asis\"\uff08\u4fdd\u7559\u63a5\u6536\u5230\u7684\u4efb\u4f55\u5b57\u6bcd\u5927\u5c0f\u5beb\uff09\u3002"},{"location":"zh/getting-started/configuration/#_2","title":"\u6280\u672f\u8bf4\u660e","text":"<ul> <li>GUC\uff08Grand Unified Configuration\uff09\u662f PostgreSQL \u4e2d\u7684\u5168\u5c40\u914d\u7f6e\u53c2\u6570</li> <li>\u8fd9\u4e9b\u503c\u9700\u8981\u5728 <code>postgresql.conf</code> \u6587\u4ef6\u4e2d\u8bbe\u7f6e</li> <li>\u4fee\u6539\u914d\u7f6e\u540e\u9700\u8981\u91cd\u542f\u670d\u52a1\u5668\u624d\u80fd\u751f\u6548</li> <li><code>shared_preload_library</code> \u662f\u4e00\u4e2a\u5173\u952e\u7684\u7cfb\u7edf\u914d\u7f6e\uff0c\u5b83\u51b3\u5b9a\u4e86\u542f\u52a8\u65f6\u52a0\u8f7d\u54ea\u4e9b\u5e93\uff0csynchdb \u5fc5\u987b\u653e\u5728\u8fd9\u91cc\u624d\u80fd\u542f\u7528 \u8fde\u63a5\u5668\u81ea\u52a8\u542f\u52a8\u5668</li> </ul>"},{"location":"zh/getting-started/configuration/#_3","title":"\u914d\u7f6e\u793a\u4f8b","text":"<pre><code># postgresql.conf \u914d\u7f6e\u793a\u4f8b\nsynchdb.naptime = 1000                                                  # \u5c06\u7b49\u5f85\u65f6\u95f4\u589e\u52a0\u52301\u79d2\nsynchdb.dml_use_spi = true                                              # \u542f\u7528 SPI \u5904\u7406 DML \u64cd\u4f5c\nsynchdb.synchdb_auto_launcher = true                                    # \u542f\u7528\u81ea\u52a8\u8fde\u63a5\u5668\u542f\u52a8synchdb.dbz_batch_size=4096 # \u6bcf\u4e2a\u6279\u6b21\u6700\u591a\u53ef\u4ee5\u6709 4096 \u4e2a\u66f4\u6539\u4e8b\u4ef6\nsynchdb.dbz_queue_size=8192                                             # Debezium \u5c06\u4f7f\u7528 8192 \u4e2a\u66f4\u6539\u4e8b\u4ef6\u961f\u5217\u5927\u5c0f\nsynchdb.jvm_max_heap_size=2048                                          # \u5206\u914d\u7ed9\u8fde\u63a5\u5668\u7684 2GB \u5806\u5185\u5b58\nsynchdb.dbz_snapshot_fetch_size=0                                       # \u8ba9 Debezium \u786e\u5b9a\u5728\u521d\u59cb\u5feb\u7167\u671f\u95f4\u8981\u83b7\u53d6\u7684\u6700\u4f73\u884c\u6570\nsynchdb.dbz_min_row_to_stream_results=0                                 # \u59cb\u7ec8\u5728\u521d\u59cb\u5feb\u7167\u671f\u95f4\u6d41\u5f0f\u4f20\u8f93\u7ed3\u679c\nsynchdb.dbz_snapshot_thread_num=1                                       # Debezium \u521d\u59cb\u5feb\u7167\u671f\u95f4\u7684\u5355\u4e2a\u7ebf\u7a0b\nsynchdb.dbz_incremental_snapshot_chunk_size=4096                        # \u589e\u91cf\u5feb\u7167\u4ee5 4096 \u4e2a\u6279\u6b21\u751f\u6210\u66f4\u6539\u4e8b\u4ef6max\nsynchdb.dbz_incremental_snapshot_watermarking_strategy='insert_insert'  # \u4f7f\u7528 insert_insert \u6c34\u5370\u7b56\u7565\nsynchdb.dbz_offset_flush_interval_ms=60000                              # \u5982\u679c\u9700\u8981\uff0c\u6bcf\u5206\u949f\u5c06\u504f\u79fb\u6570\u636e\u5237\u65b0\u5230\u78c1\u76d8\nsynchdb.dbz_capture_only_selected_table_ddl=false                       # Debezium \u5c06\u4ec5\u6355\u83b7\u9009\u5b9a\u8868\u7684\u6a21\u5f0f\uff0c\u800c\u4e0d\u662f\u6240\u6709\u8868\nsynchdb.max_connector_workers=false                                     # \u6700\u591a\u5141\u8bb8 10 \u4e2a\u8fde\u63a5\u5668\nsynchdb.error_handling_strategy='retry'                                 # \u8fde\u63a5\u5668\u5e94\u5728\u53d1\u751f\u9519\u8bef\u65f6\u91cd\u8bd5\nsynchdb.dbz_log_leve='error'                                            # Debezium Runner \u5e94\u4ec5\u8bb0\u5f55\u9519\u8bef\u6d88\u606f\nsynchdb.log_change_on_error=true                                        # \u53d1\u751f\u9519\u8bef\u65f6\u8bb0\u5f55 JSON \u66f4\u6539\u4e8b\u4ef6\nsynchdb.cdc_start_delay_ms=30000                                        # \u5feb\u7167\u5b8c\u6210\u5f8c\u7b49\u5f85 30 \u79d2\uff0cCDC \u958b\u59cb\u524d\u7b49\u5f85\nsynchdb.olr_snapshot_engine=\"fdw\"                                       # \u4f7f\u7528\u57fa\u65bc FDW \u7684\u5feb\u7167\u5f15\u64ce\u5b8c\u6210\u5feb\u7167\u904e\u7a0b\nsynchdb.letter_casing_strategy=\"asis\"                                   # \u4fdd\u7559\u539f\u59cb\u6a94\u6848\u4e2d\u6240\u6709\u7269\u4ef6\u5b57\u6bcd\u7684\u5927\u5c0f\u5beb\u3002\n</code></pre>"},{"location":"zh/getting-started/configuration/#_4","title":"\u4f7f\u7528\u5efa\u8bae","text":"<ol> <li> <p>synchdb.naptime</p> <ul> <li>\u8f83\u4f4e\u7684\u503c\uff1a\u66f4\u65b0\u9891\u7387\u66f4\u9ad8\uff0c\u4f46\u7cfb\u7edf\u8d1f\u8f7d\u66f4\u5927</li> <li>\u8f83\u9ad8\u7684\u503c\uff1a\u7cfb\u7edf\u8d1f\u8f7d\u8f83\u4f4e\uff0c\u4f46\u66f4\u65b0\u9891\u7387\u964d\u4f4e</li> <li>\u6839\u636e\u6570\u636e\u5ef6\u8fdf\u8981\u6c42\u8fdb\u884c\u8c03\u6574</li> </ul> </li> <li> <p>synchdb.dml_use_spi</p> <ul> <li>\u9700\u8981\u7279\u5b9a SPI \u96c6\u6210\u65f6\u542f\u7528</li> <li>\u6807\u51c6 DML \u64cd\u4f5c\u4fdd\u6301 <code>false</code></li> </ul> </li> <li> <p>synchdb.synchdb_auto_launcher</p> <ul> <li>\u5efa\u8bae\u4fdd\u6301 <code>true</code> \u4ee5\u5b9e\u73b0connecot\u81ea\u52a8\u542f\u7528\u7ba1\u7406</li> <li>\u4ec5\u5728\u9700\u8981\u624b\u52a8\u63a7\u5236\u8fde\u63a5\u5668\u65f6\u6539\u4e3a <code>false</code></li> </ul> </li> <li> <p>synchdb.dbz_batch_size</p> <ul> <li>\u503c\u8d8a\u4f4e\uff1aJVM \u5185\u5b58\u4f7f\u7528\u91cf\u8d8a\u4f4e\uff0c\u5904\u7406\u53d8\u66f4\u4e8b\u4ef6\u7684\u901f\u5ea6\u8d8a\u6162</li> <li>\u503c\u8d8a\u9ad8\uff1aJVM \u5185\u5b58\u4f7f\u7528\u91cf\u8d8a\u9ad8\uff0c\u5904\u7406\u53d8\u66f4\u4e8b\u4ef6\u7684\u901f\u5ea6\u8d8a\u5feb</li> <li>\u6839\u636e\u8d44\u6e90\u9700\u6c42\u8fdb\u884c\u8c03\u6574</li> </ul> </li> <li> <p>synchdb.dbz_queue_size</p> <ul> <li>\u503c\u8d8a\u4f4e\uff1a\u7528\u4e8e\u4fdd\u5b58\u53d8\u66f4\u4e8b\u4ef6\u7684 Debezium \u961f\u5217\u8d8a\u5c0f</li> <li>\u503c\u8d8a\u9ad8\uff1a\u7528\u4e8e\u4fdd\u5b58\u53d8\u66f4\u4e8b\u4ef6\u7684 Debezium \u961f\u5217\u8d8a\u5927</li> <li>\u9700\u8981\u8bbe\u7f6e\u4e3a <code>synchdb.dbz_batch_size</code> \u7684\u81f3\u5c11\u4e24\u500d</li> </ul> </li> <li> <p>synchdb.jvm_max_heap_size</p> <ul> <li>\u503c\u8d8a\u4f4e\uff1a\u5206\u914d\u7ed9 JVM \u7684\u5806\u5185\u5b58\u8d8a\u5c0f</li> <li>\u503c\u8d8a\u9ad8\uff1a\u5206\u914d\u7ed9 JVM \u7684\u5806\u5185\u5b58\u8d8a\u5927</li> <li>\u6839\u636e\u7cfb\u7edf\u8d44\u6e90\u548c\u5de5\u4f5c\u8d1f\u8f7d\u9700\u6c42\u8fdb\u884c\u8c03\u6574</li> <li>\u5904\u7406\u5927\u91cf\u8868\u65f6\u9700\u6c42\u4f1a\u589e\u52a0</li> </ul> </li> <li> <p>synchdb.dbz_snapshot_fetch_size</p> <ul> <li>\u503c\u8d8a\u4f4e\uff1a\u5feb\u7167\u671f\u95f4\u4ece\u8868\u4e2d\u83b7\u53d6\u7684\u884c\u8d8a\u5c11</li> <li>\u503c\u8d8a\u9ad8\uff1a\u83b7\u53d6\u7684\u884c\u8d8a\u591a\u5feb\u7167\u671f\u95f4\u8981\u4ece\u8868\u4e2d\u83b7\u53d6\u7684\u884c\u6570</li> <li>\u5efa\u8bae\u5c06\u5176\u4fdd\u7559\u4e3a 0\uff0c\u4ee5\u4fbf\u8ba9 Debezium \u627e\u51fa\u6700\u4f73\u503c</li> </ul> </li> <li> <p>synchdb.dbz_min_row_to_stream_results</p> <ul> <li>\u8f83\u4f4e\u7684\u503c\uff1aJVM \u5185\u5b58\u9700\u6c42\u8f83\u5c11\uff0c\u66f4\u6539\u4e8b\u4ef6\u5904\u7406\u8f83\u6162</li> <li>\u8f83\u9ad8\u7684\u503c\uff1aJVM \u5185\u5b58\u9700\u6c42\u8f83\u591a\uff0c\u66f4\u6539\u4e8b\u4ef6\u5904\u7406\u8f83\u5feb</li> <li>\u5efa\u8bae\u5c06\u5176\u4fdd\u7559\u4e3a 0\uff0c\u4ee5\u4fbf\u8ba9 Debezium \u59cb\u7ec8\u4f7f\u7528\u6d41\u6a21\u5f0f\u4ee5\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u91cf</li> </ul> </li> <li> <p>synchdb.dbz_snapshot_thread_num</p> <ul> <li>\u8f83\u4f4e\u7684\u503c\uff1a\u5c06\u6570\u636e\u5bfc\u51fa\u5230 SynchDB \u8fdb\u884c\u5904\u7406\u7684\u901f\u5ea6\u8f83\u6162</li> <li>\u8f83\u9ad8\u7684\u503c\uff1a\u5c06\u6570\u636e\u5bfc\u51fa\u5230 SyncDB \u8fdb\u884c\u5904\u7406\u7684\u901f\u5ea6\u8f83\u5feb</li> <li>\u5efa\u8bae\u5c06\u5176\u8bbe\u7f6e\u4e3a\u76f8\u540c\u7684 CPU \u6838\u5fc3\u6570</li> </ul> </li> <li> <p>synchdb.dbz_incremental_snapshot_chunk_size</p> <ul> <li>\u8f83\u4f4e\u7684\u503c\uff1a\u589e\u91cf\u5feb\u7167\u671f\u95f4\uff0c\u5728\u8f83\u4f4e\u7684 JVM \u5185\u5b58\u4f7f\u7528\u91cf\u4e0b\uff0c\u66f4\u6539\u4e8b\u4ef6\u5904\u7406\u8f83\u6162</li> <li>\u8f83\u9ad8\u7684\u503c\uff1a\u589e\u91cf\u5feb\u7167\u671f\u95f4\uff0c\u5728\u8f83\u9ad8\u7684 JVM \u5185\u5b58\u4f7f\u7528\u91cf\u4e0b\uff0c\u66f4\u6539\u4e8b\u4ef6\u5904\u7406\u8f83\u5feb</li> <li>\u5efa\u8bae\u5c06\u5176\u8bbe\u7f6e\u4e3a\u4e0e <code>synchdb.dbz_batch_size</code> \u76f8\u540c\uff0c\u5e76\u6839\u636e\u8d44\u6e90\u9700\u6c42\u8fdb\u884c\u8c03\u6574</li> </ul> </li> <li> <p>synchdb.dbz_offset_flush_interval_ms</p> <ul> <li>\u8f83\u4f4e\u7684\u503c\uff1a\u66f4\u9891\u7e41\u5730\u66f4\u65b0\u504f\u79fb\u6587\u4ef6\uff0c\u66f4\u591a\u7684 IO\uff0c\u6545\u969c\u6062\u590d\u540e\u91cd\u65b0\u5904\u7406\u7684\u65e7\u6279\u6b21\u8f83\u5c11</li> <li>\u8f83\u9ad8\u7684\u503c\uff1a\u66f4\u4e0d\u9891\u7e41\u5730\u66f4\u65b0\u504f\u79fb\u6587\u4ef6\uff0c\u66f4\u5c11\u7684 IO\uff0c\u6545\u969c\u6062\u590d\u540e\u91cd\u65b0\u5904\u7406\u7684\u65e7\u6279\u6b21\u8f83\u591a</li> <li>\u5efa\u8bae\u5c06\u5176\u8bbe\u7f6e\u4e3a 60000\uff0c\u8fd9\u662f Debezium \u7684\u5efa\u8bae</li> </ul> </li> <li> <p>synchdb.max_connector_workers</p> <ul> <li>\u8f83\u4f4e\u7684\u503c\uff1a\u4e00\u6b21\u53ef\u4ee5\u8fd0\u884c\u7684\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u8d8a\u5c11\uff0c\u5171\u4eab\u5185\u5b58\u9700\u6c42\u8d8a\u5c11</li> <li>\u8f83\u9ad8\u7684\u503c\uff1a\u4e00\u6b21\u53ef\u4ee5\u8fd0\u884c\u7684\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u8d8a\u591a\uff0c\u5171\u4eab\u5185\u5b58\u9700\u6c42\u8d8a\u591a</li> </ul> </li> </ol>"},{"location":"zh/getting-started/configuration/#_5","title":"\u6027\u80fd\u8003\u8651","text":"<ul> <li>\u6839\u636e\u7cfb\u7edf\u8d1f\u8f7d\u548c\u5ef6\u8fdf\u8981\u6c42\u8c03\u6574 <code>synchdb.naptime</code></li> <li>\u8c03\u9ad8 <code>synchdb.dbz_batch_size</code> \u548c <code>synchdb.dbz_queue_size</code> \u4ee5\u589e\u52a0\u5904\u7406\u541e\u5410\u91cf</li> <li>\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u6574 <code>synchdb.jvm_max_heap_size</code></li> <li>\u8868\u6570\u91cf\u8f83\u5c11\uff0810k \u6216\u66f4\u5c11\uff09+ \u6bcf\u4e2a\u8868\u7684\u6570\u636e\u91cf\u9002\u4e2d\u6216\u8f83\u5927\uff1a512MB ~ 1024MB \u5c31\u8db3\u591f\u4e86</li> <li>\u8868\u6570\u91cf\u8f83\u591a\uff08100k \u6216\u66f4\u591a\uff09+ \u6bcf\u4e2a\u8868\u7684\u6570\u636e\u91cf\u9002\u4e2d\uff1a\u8003\u8651\u589e\u52a0\u5230 2048MB \u6216\u4ee5\u4e0a</li> <li>\u5c06 <code>synchdb.dbz_snapshot_fetch_size</code> \u8bbe\u7f6e\u4e3a 0\uff0c\u8ba9 Debezium \u9009\u62e9\u6700\u4f73\u63d0\u53d6\u503c</li> <li>\u5c06 <code>synchdb.dbz_snapshot_thread_num</code> \u8bbe\u7f6e\u4e3a\u4e0e CPU \u6838\u5fc3\u6570\u5339\u914d</li> <li>\u5c06 <code>synchdb.dbz_min_row_to_stream_results</code> \u8bbe\u7f6e\u4e3a 0\uff0c\u4ee5\u59cb\u7ec8\u4f7f\u7528\u6d41\u6a21\u5f0f\u6765\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u91cf</li> </ul>"},{"location":"zh/getting-started/configuration/#_6","title":"\u5e38\u89c1\u4f7f\u7528\u573a\u666f","text":""},{"location":"zh/getting-started/configuration/#_7","title":"\u9ad8\u541e\u5410\u91cf\u7cfb\u7edf","text":"<pre><code>synchdb.naptime = 10            # \u66f4\u5feb\u7684\u8f6e\u8be2\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u66f4\u65b0\nsynchdb.dml_use_spi = false     # \u6807\u51c6 DML \u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\nsynchdb.dbz_batch_size = 16384\nsynchdb.dbz_queue_size = 32768\nsynchdb.jvm_max_heap_size = 2048\nsynchdb.dbz_snapshot_thread_num = 4\nsynchdb.dbz_snapshot_fetch_size = 0\nsynchdb.dbz_min_row_to_stream_results = 0\n</code></pre>"},{"location":"zh/getting-started/configuration/#_8","title":"\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf","text":"<pre><code>synchdb.naptime = 1000          # \u964d\u4f4e\u8f6e\u8be2\u9891\u7387\nsynchdb.dml_use_spi = false     # \u6700\u5c0f\u5316\u989d\u5916\u5f00\u9500\nsynchdb.dbz_batch_size = 1024\nsynchdb.dbz_queue_size = 2048\nsynchdb.jvm_max_heap_size = 512\nsynchdb.dbz_snapshot_thread_num = 1\nsynchdb.dbz_snapshot_fetch_size = 0\nsynchdb.dbz_min_row_to_stream_results = 0\n</code></pre>"},{"location":"zh/getting-started/configuration/#_9","title":"\u5f00\u53d1/\u6d4b\u8bd5\u73af\u5883","text":"<pre><code>synchdb.naptime = 500           # \u9ed8\u8ba4\u8f6e\u8be2\u95f4\u9694\nsynchdb.dml_use_spi = true      # \u542f\u7528\u9ad8\u7ea7\u529f\u80fd\u8fdb\u884c\u6d4b\u8bd5\nsynchdb.dbz_batch_size = 2048\nsynchdb.dbz_queue_size = 4096\nsynchdb.jvm_max_heap_size = 1024\nsynchdb.dbz_snapshot_thread_num = 2\nsynchdb.dbz_snapshot_fetch_size = 0\nsynchdb.dbz_min_row_to_stream_results = 0\n</code></pre>"},{"location":"zh/getting-started/configuration/#_10","title":"\u6545\u969c\u6392\u9664","text":"<ol> <li> <p>CPU \u4f7f\u7528\u7387\u9ad8</p> <ul> <li>\u589e\u52a0 <code>synchdb.naptime</code> \u503c</li> <li>\u68c0\u67e5 DML \u64cd\u4f5c\u6a21\u5f0f</li> <li>\u51cf\u5c11 <code>synchdb.dbz_batch_size</code> \u548c <code>synchdb.dbz_queue_size</code></li> <li>\u589e\u52a0 <code>synchdb.dbz_snapshot_thread_num</code></li> </ul> </li> <li> <p>\u6570\u636e\u5ef6\u8fdf\u95ee\u9898</p> <ul> <li>\u51cf\u5c11 <code>synchdb.naptime</code> \u503c</li> <li>\u589e\u52a0 <code>synchdb.dbz_batch_size</code> \u548c <code>synchdb.dbz_queue_size</code></li> <li>\u68c0\u67e5\u7f51\u7edc\u8fde\u63a5</li> <li>\u589e\u52a0 <code>shared_buffers</code></li> <li>\u5c06\u5de5\u4f5c\u8d1f\u8f7d\u62c6\u5206\u5230\u591a\u4e2a\u8fde\u63a5\u5668\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4e00\u4e2a</li> <li>\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u4ee5\u4ec5\u83b7\u53d6\u6a21\u5f0f\u5e76\u5f00\u59cb CDC\uff0c\u800c\u4e0d\u662f <code>initial</code> \u6a21\u5f0f\uff08\u5728 CDC \u5f00\u59cb\u4e4b\u524d\u6355\u83b7\u6a21\u5f0f\u548c\u521d\u59cb\u6570\u636e\uff09\u3002</li> </ul> </li> <li> <p>\u542f\u52a8\u95ee\u9898</p> <ul> <li>\u9a8c\u8bc1 <code>shared_preload_library</code> \u914d\u7f6e</li> <li>\u68c0\u67e5 <code>synchdb_get_state()</code> \u7684\u9519\u8bef\u6d88\u606f</li> <li>\u68c0\u67e5\u8fde\u63a5\u5668\u5de5\u4f5c\u72b6\u6001</li> </ul> </li> <li> <p>\u5185\u5b58\u4e0d\u8db3\u95ee\u9898</p> <ul> <li>\u589e\u52a0 <code>synchdb.jvm_max_heap_size</code></li> <li>\u589e\u52a0 <code>shared_buffers</code></li> </ul> </li> </ol>"},{"location":"zh/getting-started/configuration/#_11","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li> <p>\u521d\u59cb\u8bbe\u7f6e</p> <ul> <li>\u4ece\u9ed8\u8ba4\u503c\u5f00\u59cb</li> <li>\u76d1\u63a7\u7cfb\u7edf\u6027\u80fd</li> <li>\u6839\u636e\u9700\u6c42\u9010\u6b65\u8c03\u6574</li> </ul> </li> <li> <p>\u751f\u4ea7\u73af\u5883</p> <ul> <li>\u8bb0\u5f55\u6240\u6709\u914d\u7f6e\u66f4\u6539</li> <li>\u5728\u6d4b\u8bd5\u73af\u5883\u4e2d\u5148\u6d4b\u8bd5\u66f4\u6539</li> <li>\u4fdd\u6301\u6b63\u5e38\u5de5\u4f5c\u914d\u7f6e\u7684\u5907\u4efd</li> </ul> </li> <li> <p>\u76d1\u63a7</p> <ul> <li>\u8ddf\u8e2a\u7cfb\u7edf\u8d44\u6e90\u4f7f\u7528\u60c5\u51b5</li> <li>\u76d1\u63a7\u6570\u636e\u540c\u6b65\u5ef6\u8fdf</li> <li>\u8bb0\u5f55\u914d\u7f6e\u66f4\u6539</li> </ul> </li> </ol>"},{"location":"zh/getting-started/configuration/#_12","title":"\u8865\u5145\u8bf4\u660e","text":"<ol> <li> <p>\u6027\u80fd\u4f18\u5316</p> <ul> <li>\u5728\u9ad8\u8d1f\u8f7d\u60c5\u51b5\u4e0b\u9002\u5f53\u589e\u52a0 <code>naptime</code></li> <li>\u9700\u8981\u5b9e\u65f6\u6027\u65f6\u53ef\u4ee5\u964d\u4f4e <code>naptime</code>\uff0c\u4f46\u8981\u6ce8\u610f\u7cfb\u7edf\u8d1f\u8f7d</li> <li>\u5efa\u8bae\u6839\u636e\u5b9e\u9645\u4e1a\u52a1\u573a\u666f\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5</li> </ul> </li> <li> <p>\u5b89\u5168\u8003\u8651</p> <ul> <li>\u5b9a\u671f\u68c0\u67e5\u914d\u7f6e\u6587\u4ef6\u6743\u9650</li> <li>\u8bb0\u5f55\u914d\u7f6e\u66f4\u6539\u65e5\u5fd7</li> <li>\u4fdd\u6301\u914d\u7f6e\u6587\u4ef6\u7684\u5907\u4efd</li> </ul> </li> <li> <p>\u7ef4\u62a4\u5efa\u8bae</p> <ul> <li>\u5b9a\u671f\u68c0\u67e5\u7cfb\u7edf\u65e5\u5fd7</li> <li>\u76d1\u63a7\u8fde\u63a5\u5668\u72b6\u6001</li> <li>\u5236\u5b9a\u914d\u7f6e\u53d8\u66f4\u6d41\u7a0b</li> </ul> </li> </ol>"},{"location":"zh/getting-started/installation/","title":"\u5b89\u88c5","text":""},{"location":"zh/getting-started/installation/#_2","title":"\u4ece\u8f6f\u4ef6\u5305\u5b89\u88c5","text":"<p>\u8bbf\u95ee\u6211\u4eec\u7684\u53d1\u5e03\u9875\u9762 \u4e0b\u8f7d synchdb \u8f6f\u4ef6\u5305\u3002</p>"},{"location":"zh/getting-started/installation/#deb","title":".deb \u5305","text":"<ol> <li> <p>\u4ece\u5b98\u65b9 apt \u5b58\u50a8\u5e93\u5b89\u88c5 PostgreSQL\uff08\u7248\u672c 16 \u4e3a\u4f8b\uff09\uff1a <pre><code>sudo apt install -y postgresql-common\nsudo /usr/share/postgresql-common/pgdg/apt.postgresql.org.sh\nsudo apt install postgresql-16\n</code></pre></p> </li> <li> <p>\u5b89\u88c5 Java \u8fd0\u884c\u65f6\u73af\u5883\uff1a <pre><code>sudo apt install openjdk-17-jre-headless\n</code></pre></p> </li> <li> <p>\u66f4\u65b0\u5171\u4eab\u5e93\u8def\u5f84\uff1a <pre><code>JAVA_PATH=$(which java)\nJRE_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJRE_LIB_PATH=${JRE_HOME_PATH}/lib\necho \"$JRE_LIB_PATH\" | sudo tee /etc/ld.so.conf.d/java.conf\nsudo ldconfig\n</code></pre></p> </li> <li> <p>\u5b89\u88c5 SynchDB\uff1a <pre><code>dpkg -i synchdb-1.1-1.ub22.pg16_x86_64.deb\n</code></pre></p> </li> <li>SynchDB \u5e94\u8be5\u5df2\u51c6\u5907\u5c31\u7eea\u3002\u8bf7\u53c2\u9605 \u5feb\u901f\u5165\u95e8 \u9875\u9762\u5f00\u59cb\u4f7f\u7528</li> </ol>"},{"location":"zh/getting-started/installation/#rpm","title":".rpm \u8f6f\u4ef6\u5305","text":"<ol> <li>\u4ece\u5b98\u65b9 rpm \u4ed3\u5e93\u5b89\u88c5 PostgreSQL\uff08\u7248\u672c 16 \u4e3a\u4f8b\uff09\uff1a \u5176\u4ed6 PostgreSQL \u7248\u672c\u7684\u5b98\u65b9 rpm \u4e0b\u8f7d\u8bf4\u660e\uff0c\u8bf7\u53c2\u8003\u6b64\u5904 (https://www.postgresql.org/download/linux/redhat/) <pre><code>sudo dnf install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-9-x86_64/pgdg-redhat-repo-latest.noarch.rpm\nsudo dnf -qy module disable postgresql\nsudo dnf install -y postgresql16-server postgresql16-contrib\n</code></pre></li> <li> <p>\u5b89\u88c5 Java \u8fd0\u884c\u73af\u5883\uff1a <pre><code>sudo dnf install -y java-17-openjdk\n</code></pre></p> </li> <li> <p>\u66f4\u65b0\u5171\u4eab\u5e93\u8def\u5f84\uff1a <pre><code>JAVA_PATH=$(which java)\nJRE_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJRE_LIB_PATH=${JRE_HOME_PATH}/lib\necho \"$JRE_LIB_PATH\" | sudo tee /etc/ld.so.conf.d/java.conf\nsudo ldconfig\n</code></pre></p> </li> <li> <p>\u5b89\u88c5 SynchDB\uff1a <pre><code>sudo dnf install -y synchdb-1.1-1.el9.pg16.x86_64.rpm\n</code></pre></p> </li> <li>SynchDB \u5e94\u8be5\u5df2\u51c6\u5907\u5c31\u7eea\u3002\u8bf7\u53c2\u9605 \u5feb\u901f\u5165\u95e8 \u9875\u9762\u5f00\u59cb\u4f7f\u7528</li> </ol>"},{"location":"zh/getting-started/installation/#_3","title":"\u4ece\u9884\u7f16\u8bd1\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u5b89\u88c5","text":"<p>\u8bbf\u95ee\u6211\u4eec\u7684\u53d1\u5e03\u9875\u9762 \u4e0b\u8f7d\u9884\u7f16\u8bd1\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002\u6211\u4eec\u76ee\u524d\u652f\u6301\u57fa\u4e8e Debian \u7684 Linux \u7cfb\u7edf\uff08\u5982 Ubuntu\uff09\u7cfb\u7edf\u4e0a\u7684\u9884\u7f16\u8bd1\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002\u5176\u4ed6\u5e73\u53f0\u5c06\u5728\u4e0d\u4e45\u7684\u5c06\u6765\u5f97\u5230\u652f\u6301\u3002SynchDB \u9884\u7f16\u8bd1\u4e8c\u8fdb\u5236\u6587\u4ef6\u9700\u8981\u5148\u5b89\u88c5 PostgreSQL\u3002\u5b83\u6240\u9700\u7684 PostgreSQL \u7248\u672c\u5728\u5305\u540d\u79f0\u4e2d\u63cf\u8ff0\u3002\u4f8b\u5982\uff0c<code>synchdb-1.1-1.ub22.pg16_x86_64.tar.gz</code> \u662f\u5728 Ubuntu 22.04 \u4e0a\u9488\u5bf9 PostgreSQL 16 \u7f16\u8bd1\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002</p>"},{"location":"zh/getting-started/installation/#_4","title":"\u9884\u7f16\u8bd1\u4e8c\u8fdb\u5236\u6587\u4ef6","text":"<ol> <li> <p>\u89e3\u538b\u9884\u7f16\u8bd1\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684 tar.gz \u5305\uff1a <pre><code>tar xzvf synchdb-1.1-1.ub22.pg16_x86_64.tar.gz -C /tmp\n</code></pre></p> </li> <li> <p>\u627e\u51fa\u5f53\u524d PostgreSQL \u7684 lib \u548c share \u76ee\u5f55 <pre><code>LIBDIR=$(pg_config | grep -w LIBDIR | awk -F ' = ' '/LIBDIR/ {print $2}')\nSHAREDIR=$(pg_config | grep -w SHAREDIR | awk -F ' = ' '/SHAREDIR/ {print $2}')\n</code></pre></p> </li> <li> <p>\u5c06\u9884\u7f16\u8bd1\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u590d\u5236\u5230\u76f8\u5e94\u76ee\u5f55\uff1a <pre><code>cp /tmp/synchdb-1.1-1.ub22.pg16_x86_64/usr/lib/postgresql/16/lib/* $LIBDIR\ncp /tmp/synchdb-1.1-1.ub22.pg16_x86_64/usr/share/postgresql/16/extension/* $SHAREDIR\n</code></pre></p> </li> <li> <p>\u5b89\u88c5 Java Runtime Environment\uff1a <pre><code>sudo apt install openjdk-17-jre-headless\n</code></pre></p> </li> <li> <p>\u66f4\u65b0\u5171\u4eab\u5e93\u8def\u5f84\uff1a <pre><code>JAVA_PATH=$(which java)\nJRE_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJRE_LIB_PATH=${JRE_HOME_PATH}/lib\necho \"$JRE_LIB_PATH\" | sudo tee /etc/ld.so.conf.d/java.conf\nsudo ldconfig\n</code></pre></p> </li> <li> <p>SynchDB \u5e94\u8be5\u5df2\u51c6\u5907\u5c31\u7eea\u3002\u8bf7\u53c2\u9605 \u5feb\u901f\u5165\u95e8 \u9875\u9762\u5f00\u59cb\u4f7f\u7528</p> </li> </ol>"},{"location":"zh/getting-started/installation/#_5","title":"\u6e90\u4ee3\u7801\u7f16\u8bd1\u53ca\u5b89\u88c5","text":"<p>\u6b64\u9009\u9879\u8981\u6c42\u60a8\u4ece\u6e90\u4ee3\u7801\u6784\u5efa\u548c\u5b89\u88c5 PostgreSQL \u548c SynchDB\u3002</p>"},{"location":"zh/getting-started/installation/#_6","title":"\u7cfb\u7edf\u8981\u6c42","text":"<p>\u6784\u5efa\u548c\u8fd0\u884cSynchDB\u9700\u8981\u4ee5\u4e0b\u8f6f\u4ef6\u3002\u5217\u51fa\u7684\u7248\u672c\u662f\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u6d4b\u8bd5\u8fc7\u7684\u7248\u672c\u3002\u8f83\u65e7\u7684\u7248\u672c\u53ef\u80fd\u4ecd\u7136\u53ef\u7528\u3002</p> <ul> <li>Java Development Kit 22. \u4e0b\u8f7d\u5730\u5740\uff1a\u70b9\u51fb\u8fd9\u91cc</li> <li>Apache Maven 3.9.8. \u4e0b\u8f7d\u5730\u5740\uff1a\u70b9\u51fb\u8fd9\u91cc</li> <li>PostgreSQL \u6e90\u4ee3\u7801. Git\u514b\u9686\u5730\u5740\uff1a\u70b9\u51fb\u8fd9\u91cc. PostgreSQL\u7f16\u8bd1\u8981\u6c42\u8bf7\u53c2\u8003\u6b64wiki</li> <li>Docker compose 2.28.1 (\u7528\u4e8e\u6d4b\u8bd5). \u53c2\u8003\u5b89\u88c5\u6307\u5357</li> <li>\u57fa\u4e8eUnix\u7684\u64cd\u4f5c\u7cfb\u7edf\uff0c\u5982Ubuntu 22.04\u6216MacOS</li> </ul> <p>Openlog Replicator \u8fde\u63a5\u5668\u652f\u6301\u7684\u989d\u5916\u8981\u6c42\uff08\u5982\u679c\u5728\u6784\u5efa\u8fc7\u7a0b\u4e2d\u542f\u7528\uff09</p> <ul> <li>libprotobuf-c v1.5.2\u3002\u8bf7\u53c2\u9605\u6b64\u5904 \u4ece\u6e90\u4ee3\u7801\u6784\u5efa\u3002</li> </ul> <p>\u5982\u679c\u60a8\u60f3\u4f7f\u7528\u57fa\u65bc FDW \u7684\u5feb\u7167\uff0c\u5247\u9700\u8981\u4ee5\u4e0b\u5167\u5bb9\uff1a</p> <ul> <li>OCI v23.9.0\u3002\u66f4\u591a\u8cc7\u8a0a\u8acb\u53c3\u95b1\u6b64\u8655\u3002</li> <li>oracle_fdw v2.8.0\u3002\u5982\u4f55\u5f9e\u539f\u59cb\u78bc\u5efa\u7f6e\uff1f\u8acb\u53c3\u95b1\u6b64\u8655\u3002</li> </ul>"},{"location":"zh/getting-started/installation/#synchdb-mysqlsql-server-oracle","title":"\u9810\u8a2d SynchDB \u5efa\u7f6e - \u652f\u63f4 MySQL\u3001SQL Server \u548c Oracle \u9023\u63a5\u5668","text":"<p>\u5982\u679c\u60a8\u5df2\u5b89\u88dd PostgreSQL\uff0c\u5247\u53ef\u4ee5\u4f7f\u7528 PGXS \u5efa\u7f6e\u4e26\u5b89\u88dd\u9810\u8a2d SynchDB\u3002\u8acb\u6ce8\u610f\uff0c\u60a8\u7684 PostgreSQL \u5b89\u88dd\u5fc5\u9808\u5305\u542b SynchDB \u6240\u9700\u7684 pgcrypto \u63d2\u4ef6\u3002</p> <pre><code>USE_PGXS=1 make PG_CONFIG=$(which pg_config)\nUSE_PGXS=1 make build_dbz PG_CONFIG=$(which pg_config)\n\nsudo USE_PGXS=1 make PG_CONFIG=$(which pg_config) install\nsudo USE_PGXS=1 make install_dbz PG_CONFIG=$(which pg_config)\n</code></pre>"},{"location":"zh/getting-started/installation/#openlog-replicator-synchdb","title":"\u5efa\u69cb\u652f\u63f4 Openlog Replicator \u9023\u63a5\u5668\u7684 SynchDB","text":"<p>\u8981\u5efa\u7f6e\u652f\u63f4 Openlog Replicator \u9023\u63a5\u5668\u7684 SynchDB\uff0c\u9084\u9700\u8981\u5efa\u7f6e\u4e00\u500b\u984d\u5916\u7684 SynchDB Oracle \u89e3\u6790\u5668\u5143\u4ef6\u3002\u6b64\u5143\u4ef6\u57fa\u65bc IvorySQL \u7684 Oracle \u89e3\u6790\u5668\uff0c\u4e26\u91dd\u5c0d SynchDB \u9032\u884c\u4e86\u4fee\u6539\uff0c\u9700\u8981 PostgreSQL \u5f8c\u7aef\u539f\u59cb\u7a0b\u5f0f\u78bc\u624d\u80fd\u6210\u529f\u5efa\u7f6e\u3002\u4ee5\u4e0b\u662f\u5177\u9ad4\u6b65\u9a5f\uff1a</p>"},{"location":"zh/getting-started/installation/#163","title":"\u51c6\u5907\u6e90\u4ee3\u7801\uff08\u4ee516.3\u4e3a\u4f8b\uff09","text":"<p>\u8907\u88fd PostgreSQL \u539f\u59cb\u78bc\u4e26\u5207\u63db\u5230 16.3 \u7248\u672c\u6a19\u7c64</p> <pre><code>git clone https://github.com/postgres/postgres.git\ncd postgres\ngit checkout REL_16_3\n</code></pre> <p>\u5f9e\u64f4\u5145\u8cc7\u6599\u593e\u5167\u514b\u9686 SynchDB \u539f\u59cb\u78bc</p> <p>\u6ce8\u610f\uff1a\u76ee\u524d\u4f7f\u7528\u5206\u652f (synchdb-devel)[https://github.com/Hornetlabs/synchdb/tree/synchdb-devel] \u9032\u884c\u958b\u767c\u3002</p> <pre><code>cd contrib/\ngit clone https://github.com/Hornetlabs/synchdb.git\n</code></pre>"},{"location":"zh/getting-started/installation/#postgresql","title":"\u7f16\u8bd1\u548c\u5b89\u88c5PostgreSQL","text":"<p>\u60a8\u53ef\u4ee5\u6309\u7167\u6b64\u8655\u4e2d\u6240\u8ff0\u7684\u6a19\u6e96\u5efa\u7f6e\u548c\u5b89\u88dd\u6d41\u7a0b\u5b8c\u6210\u6b64\u64cd\u4f5c\u3002</p> <p>\u8b66\u544a\uff1aSynchDB \u4f9d\u8cf4 pgcrypto \u4f86\u52a0\u5bc6\u548c\u89e3\u5bc6\u654f\u611f\u7684\u5b58\u53d6\u8cc7\u8a0a\u3002\u8acb\u78ba\u4fdd PostgreSQL \u5df2\u5efa\u7f6e\u4e26\u555f\u7528 SSL \u652f\u63f4\u3002</p> <pre><code>cd /home/$USER/postgres\n./configure --with-ssl=openssl --enable-cassert\nmake\nsudo make install\n</code></pre> <p>\u5efa\u7f6e\u6240\u9700\u7684 pgcrypto \u64f4\u5c55</p> <pre><code>cd /home/$USER/postgres/contrib/pgcrypto\nmake\nsudo make install\n</code></pre>"},{"location":"zh/getting-started/installation/#synchdb-openlog-replicator","title":"\u5efa\u7f6e SynchDB \u4e26\u65b0\u589e Openlog Replicator \u9023\u63a5\u5668\u652f\u6301","text":"<pre><code># \u5efa\u7f6e\u4e26\u5b89\u88dd debezium runner\ncd /home/$USER/postgres/contrib/synchdb\nmake build_dbz\nsudo make install_dbz\n\n# \u5efa\u7f6e\u4e26\u5b89\u88dd Oracle \u89e3\u6790\u5668\nmake oracle_parser\nsudo make install_oracle_parser\n\n# \u5efa\u7f6e\u4e26\u5b89\u88dd synchdb\nmake WITH_OLR=1\nsudo make WITH_OLR=1 install\n</code></pre>"},{"location":"zh/getting-started/installation/#linker-javaubuntu","title":"\u914d\u7f6e Linker \u4ee5\u8bbf\u95ee Java\uff08Ubuntu\uff09","text":"<p>\u6700\u540e\uff0c\u6211\u4eec\u8fd8\u9700\u8981\u544a\u8bc9\u7cfb\u7edf\u7684 Linker \u65b0\u6dfb\u52a0\u7684 Java \u5e93 (libjvm.so) \u5728\u7cfb\u7edf\u4e2d\u7684\u4f4d\u7f6e\u3002</p> <p><pre><code># \u52a8\u6001\u8bbe\u7f6e JDK \u8def\u5f84\nJAVA_PATH=$(which java)\nJDK_HOME_PATH=$(readlink -f ${JAVA_PATH} | sed 's:/bin/java::')\nJDK_LIB_PATH=${JDK_HOME_PATH}/lib\n\necho $JDK_LIB_PATH\necho $JDK_LIB_PATH/server\n\nsudo echo \"$JDK_LIB_PATH\" \uff5c sudo tee -a /etc/ld.so.conf.d/x86_64-linux-gnu.conf\nsudo echo \"$JDK_LIB_PATH/server\" | sudo tee -a /etc/ld.so.conf.d/x86_64-linux-gnu.conf\n</code></pre> \u6ce8\u610f\uff0c\u5bf9\u4e8e\u642d\u8f7d M1/M2 \u82af\u7247\u7684 Mac\uff0c\u94fe\u63a5\u5668\u6587\u4ef6\u4f4d\u4e8e /etc/ld.so.conf.d/aarch64-linux-gnu.conf</p> <p>\u8fd0\u884c ldconfig \u91cd\u65b0\u52a0\u8f7d\uff1a <pre><code>sudo ldconfig\n</code></pre></p> <p>\u786e\u4fdd synchdo.so \u6269\u5c55\u53ef\u4ee5\u94fe\u63a5\u5230\u7cfb\u7edf\u4e0a\u7684 libjvm Java \u5e93\uff1a <pre><code>ldd synchdb.so\nlinux-vdso.so.1 (0x00007ffeae35a000)\nlibjvm.so =&gt; /usr/lib/jdk-22.0.1/lib/server/libjvm.so (0x00007fc1276c1000)\nlibc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fc127498000)\nlibdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fc127493000)\nlibpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fc12748e000)\nlibrt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007fc127489000)\nlibm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007fc1273a0000)\n/lib64/ld-linux-x86-64.so.2 (0x00007fc128b81000)\n</code></pre></p> <p>\u5982\u679c SynchDB \u6784\u5efa\u65f6\u652f\u6301 openlog replicator\uff0c\u8bf7\u786e\u4fdd\u5b83\u53ef\u4ee5\u94fe\u63a5\u5230\u4f60\u7cfb\u7edf\u4e0a\u7684 libprotobuf-c \u5e93\uff1a <pre><code>ldd synchdb.so\nlinux-vdso.so.1 (0x00007ffde6ba5000)\nlibjvm.so =&gt; /home/ubuntu/java/jdk-22.0.1/lib/server/libjvm.so (0x00007f3c8e191000)\nlibprotobuf-c.so.1 =&gt; /usr/local/lib/libprotobuf-c.so.1 (0x00007f3c8e186000)\nlibc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3c8df5d000)\nlibdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f3c8df58000)\nlibpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f3c8df53000)\nlibrt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f3c8df4c000)\nlibm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f3c8de65000)\n/lib64/ld-linux-x86-64.so.2 (0x00007f3c8f69e000)\n</code></pre></p>"},{"location":"zh/getting-started/prepare_tests_env/","title":"\u5feb\u901f\u6d4b\u8bd5\u73af\u5883","text":"<p>\u6b64\u5904\u63d0\u5230\u7684\u6b65\u9aa4\u65e8\u5728\u5feb\u901f\u542f\u52a8\u5916\u90e8\u6570\u636e\u5e93\uff0c\u7528\u4e8e Synchdb \u7684\u9a8c\u8bc1\u548c\u529f\u80fd\u6f14\u793a\u3002\u542f\u52a8\u793a\u4f8b\u5f02\u6784\u6570\u636e\u5e93\u6240\u9700\u7684\u6587\u4ef6\u548c\u811a\u672c\u53ef\u4ee5\u5728 SynchDB \u4ee3\u7801\u5e93\u4e2d\u627e\u5230\uff08\u6b64\u5904\uff09(https://github.com/Hornetlabs/synchdb/testenv/)\u3002</p>"},{"location":"zh/getting-started/prepare_tests_env/#mysql","title":"\u51c6\u5907\u4e00\u4e2a\u6837\u672c MySQL \u6570\u636e\u5e93","text":"<p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 docker compose \u542f\u52a8\u4e00\u4e2a\u6837\u672c MySQL \u6570\u636e\u5e93\u8fdb\u884c\u6d4b\u8bd5\u3002\u7528\u6237\u51ed\u8bc1\u5728 <code>synchdb-mysql-test.yaml</code> \u6587\u4ef6\u4e2d\u63cf\u8ff0\u3002</p> <pre><code>docker compose -f synchdb-mysql-test.yaml up -d\n</code></pre> <p>\u4ee5 <code>root</code> \u8eab\u4efd\u767b\u5f55 MySQL\uff0c\u5e76\u6388\u4e88 <code>mysqluser</code> \u7528\u6237\u6267\u884c\u5b9e\u65f6 CDC \u7684\u6743\u9650 <pre><code>mysql -h 127.0.0.1 -u root -p\n\nGRANT replication client on *.* to mysqluser;\nGRANT replication slave  on *.* to mysqluser;\nGRANT RELOAD ON *.* TO 'mysqluser'@'%';\nFLUSH PRIVILEGES;\n</code></pre></p> <p>\u9000\u51fa mysql \u5ba2\u6237\u7aef\u5de5\u5177\uff1a <pre><code>\\q\n</code></pre></p>"},{"location":"zh/getting-started/prepare_tests_env/#sql-server","title":"\u51c6\u5907\u4e00\u4e2a\u6837\u672c SQL Server \u6570\u636e\u5e93","text":"<p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 docker compose \u542f\u52a8\u4e00\u4e2a\u6837\u672c SQL Server \u6570\u636e\u5e93\u8fdb\u884c\u6d4b\u8bd5\u3002\u7528\u6237\u51ed\u8bc1\u5728 <code>synchdb-sqlserver-test.yaml</code> \u6587\u4ef6\u4e2d\u63cf\u8ff0\u3002 <pre><code>docker compose -f synchdb-sqlserver-test.yaml up -d\n</code></pre> \u5982\u679c\u9700\u8981\u542f\u7528 SSL \u8bc1\u4e66\u7684 SQL Server\uff0c\u8bf7\u4f7f\u7528 synchdb-sqlserver-withssl-test.yaml \u6587\u4ef6\u3002</p> <p>\u4f60\u53ef\u80fd\u6ca1\u6709\u5b89\u88c5 SQL Server \u5ba2\u6237\u7aef\u5de5\u5177\uff0c\u4f60\u53ef\u4ee5\u767b\u5f55\u5230 SQL Server \u5bb9\u5668\u6765\u8bbf\u95ee\u5176\u5ba2\u6237\u7aef\u5de5\u5177\u3002</p> <p>\u627e\u51fa SQL Server \u7684\u5bb9\u5668 ID\uff1a <pre><code>id=$(docker ps | grep sqlserver | awk '{print $1}')\n</code></pre></p> <p>\u5c06\u6570\u636e\u5e93\u67b6\u6784\u590d\u5236\u5230 SQL Server \u5bb9\u5668\u4e2d\uff1a <pre><code>docker cp inventory.sql $id:/\n</code></pre></p> <p>\u767b\u5f55\u5230 SQL Server \u5bb9\u5668\uff1a <pre><code>docker exec -it $id bash\n</code></pre></p> <p>\u6839\u636e\u67b6\u6784\u6784\u5efa\u6570\u636e\u5e93\uff1a <pre><code>/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -i /inventory.sql\n</code></pre></p> <p>\u8fd0\u884c\u4e00\u4e9b\u7b80\u5355\u7684\u67e5\u8be2\uff08\u5982\u679c\u4f60\u4f7f\u7528\u7684\u662f\u542f\u7528 SSL \u7684 SQL Server\uff0c\u8bf7\u6dfb\u52a0 -N -C\uff09\uff1a <pre><code>/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -d testDB -Q \"insert into orders(order_date, purchaser, quantity, product_id) values( '2024-01-01', 1003, 2, 107)\"\n\n/opt/mssql-tools/bin/sqlcmd -U sa -P $SA_PASSWORD -d testDB -Q \"select * from orders\"\n</code></pre></p>"},{"location":"zh/getting-started/prepare_tests_env/#oracle","title":"\u51c6\u5907\u4e00\u4e2a\u793a\u4f8b Oracle \u6570\u636e\u5e93","text":"<p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 Oracle \u63d0\u4f9b\u7684\u514d\u8d39 Oracle \u6570\u636e\u5e93 docker \u955c\u50cf\u6765\u6d4b\u8bd5\u548c\u8bc4\u4f30 SynchDB\u3002\u5b83\u9644\u5e26\u4e00\u4e2a\u514d\u8d39\u7684\u5bb9\u5668\u6570\u636e\u5e93 <code>FREE</code> \u548c\u4e00\u4e2a\u53ef\u63d2\u5165\u6570\u636e\u5e93 <code>FREEPDB1</code> <pre><code>docker run -d -p 1521:1521 container-registry.oracle.com/database/free:latest\n</code></pre></p> <p>\u627e\u51fa\u5bb9\u5668 ID \u5e76\u767b\u5f55\uff1a <pre><code>id=$(docker ps | grep oracle | awk '{print $1}')\ndocker exec -it $id bash\n</code></pre></p> <p>\u6309\u7167\u6b64\u5904 \u4e2d\u63cf\u8ff0\u7684\u6b65\u9aa4\u8bbe\u7f6e logminer \u548c logminer \u7528\u6237</p>"},{"location":"zh/getting-started/prepare_tests_env/#ci","title":"\u4f7f\u7528 CI \u811a\u672c\u51c6\u5907\u6d4b\u8bd5\u6570\u636e\u5e93","text":"<p>\u793a\u4f8b MySQL\u3001SQL Server \u548c Oracle \u6570\u636e\u5e93\u4e5f\u53ef\u4ee5\u4f7f\u7528\u4f4d\u4e8e\u6e90\u5b58\u50a8\u5e93\u4e0b <code>ci/</code> \u6587\u4ef6\u5939\u4e2d\u7684\u811a\u672c\u8fdb\u884c\u51c6\u5907\u3002\u8be5\u811a\u672c\u9700\u8981 docker \u548c docker-compose \u624d\u80fd\u8fd0\u884c\uff0c\u5e76\u4e14\u57fa\u672c\u4e0a\u9075\u5faa\u4e0e\u4e0a\u8ff0\u76f8\u540c\u7684\u6b65\u9aa4\u3002</p> <p>\u51c6\u5907 MySQL \u6570\u636e\u5e93\u8fdb\u884c\u6d4b\u8bd5\uff1a <pre><code>DBTYPE=mysql ci/setup-remotebs.sh\n</code></pre></p> <p>\u51c6\u5907 SQL Server \u6570\u636e\u5e93\u8fdb\u884c\u6d4b\u8bd5\uff1a <pre><code>DBTYPE=sqlserver ci/setup-remotebs.sh\n</code></pre></p> <p>\u51c6\u5907 Oracle \u6570\u636e\u5e93\u8fdb\u884c\u6d4b\u8bd5\uff1a <pre><code>DBTYPE=oracle ci/setup-remotebs.sh\n</code></pre></p> <p>\u51c6\u5907 Oracle19c \u6570\u636e\u5e93\u8fdb\u884c\u6d4b\u8bd5\uff1a <pre><code>DBTYPE=ora19c ci/setup-remotebs.sh\n</code></pre></p> <p>\u4f7f\u7528 Openlog Replicator \u51c6\u5907 Oracle19c \u6570\u636e\u5e93\u8fdb\u884c\u6d4b\u8bd5\uff1a <pre><code>DBTYPE=olr OLRVER=1.3.0 ci/setup-remotebs.sh\n</code></pre></p>"},{"location":"zh/getting-started/quick_start/","title":"\u5feb\u901f\u5165\u95e8\u6307\u5357","text":"<p>\u5c1d\u8bd5 SynchDB \u7684\u6700\u5feb\u65b9\u6cd5\u662f\u4f7f\u7528 SynchDB \u53ca\u5176\u914d\u5957\u6e90\uff08MySQL\u3001SQL Server\u3001Oracle \u7b49\uff09\u7684\u9884\u6784\u5efa Docker \u955c\u50cf\u3002\u4f7f\u7528\u4ed3\u5e93\u7684 <code>ezdeploy.sh</code>\uff08\u4ec5\u9650 Linux\uff09\u547d\u4ee4\uff0c\u5b83\u4f1a\u901a\u8fc7\u7b80\u5355\u7684\u4ea4\u4e92\u5f0f\u63d0\u793a\u5f15\u5bfc\u60a8\u542f\u52a8\u6240\u9009\u6e90\u4ee5\u53ca\u53ef\u9009\u7684 Prometheus/Grafana\uff0c\u4ee5\u4fbf\u60a8\u5728\u51e0\u5206\u949f\u5185\u9a8c\u8bc1\u6355\u83b7\u548c\u590d\u5236\u64cd\u4f5c\u3002</p>"},{"location":"zh/getting-started/quick_start/#ezdeploysh","title":"ezdeploy.sh","text":"<p>\u6b64\u5de5\u5177\u53ef\u4ece SynchDB \u6e90\u7801\u4ed3\u5e93 \u6b64\u5904 \u4e0b\u8f7d\u3002\u5b83\u9700\u8981 <code>docker</code> \u548c <code>docker-compose</code>\uff08\u6216 <code>docker compose</code>\uff09\uff0c\u5e76\u4e14\u5fc5\u987b\u5728 Linux \u4e0a\u8fd0\u884c\u3002\u8fd0\u884c\u65f6\u4f1a\u6253\u5370\u90e8\u7f72\u9009\u9879\u5217\u8868\uff1a</p> <pre><code>./ezdeploy.sh\n----------------------------------\n-----&gt; Welcome to ezdeploy! &lt;-----\n----------------------------------\n\nplease select a quick deploy option:\n         1) synchdb only\n         2) synchdb + mysql\n         3) synchdb + sqlserver\n         4) synchdb + oracle23ai\n         5) synchdb + oracle19c\n         6) synchdb + olr(oracle19c)\n         7) synchdb + all source databases\n         8) custom deployment\n         9) deploy monitoring\n        10) teardown deployment\nenter your selection:\n</code></pre> <ul> <li>\u4ec5\u5bf9\u4e8e synchdb \u90e8\u7f72\uff0c\u8bf7\u4f7f\u7528\u9009\u9879 <code>1)</code>\u3002</li> <li>\u5bf9\u4e8e synchdb + 1 \u4e2a\u6e90\u6570\u636e\u5e93\uff0c\u8bf7\u4f7f\u7528\u9009\u9879 <code>2)</code> \u81f3 <code>6)</code>\u3002</li> <li>\u5bf9\u4e8e synchdb + \u6240\u6709\u6e90\u6570\u636e\u5e93\uff0c\u8bf7\u4f7f\u7528\u9009\u9879 <code>7)</code>\u3002</li> <li>\u5bf9\u4e8e synchdb + \u81ea\u5b9a\u4e49\u6e90\u6570\u636e\u5e93\uff0c\u8bf7\u4f7f\u7528\u9009\u9879 <code>8)</code>\u3002</li> <li>\u5bf9\u4e8e prometheus \u548c grafana \u76d1\u63a7\u90e8\u7f72\uff0c\u8bf7\u4f7f\u7528\u9009\u9879 <code>9)</code>\u3002</li> <li>\u8981\u62c6\u9664\u6240\u6709\u90e8\u7f72\uff0c\u8bf7\u4f7f\u7528\u9009\u9879 <code>10)</code>\u3002</li> </ul>"},{"location":"zh/getting-started/quick_start/#_2","title":"\u6d4b\u8bd5\u6e90\u6570\u636e\u5e93\u8bbf\u95ee\u8be6\u60c5","text":"<p>MySQL:</p> <ul> <li>\u6570\u636e\u5e93\uff1ainventory</li> <li>\u6a21\u5f0f\uff1aN/A</li> <li>\u7528\u6237\uff1amysqluser</li> <li>\u5bc6\u7801\uff1amysqlpwd</li> </ul> <p>Sqlserver:</p> <ul> <li>\u6570\u636e\u5e93\uff1atestDB</li> <li>\u6a21\u5f0f\uff1adbo</li> <li>\u7528\u6237\uff1asa</li> <li>\u5bc6\u7801\uff1aPassword!</li> </ul> <p>Oracle23ai:</p> <ul> <li>\u6570\u636e\u5e93\uff1aFREE</li> <li>\u6a21\u5f0f\uff1ac##dbzuser</li> <li>\u7528\u6237\uff1ac##dbzuser</li> <li>\u5bc6\u7801\uff1adbz</li> </ul> <p>Oracle19c:</p> <ul> <li>\u6570\u636e\u5e93\uff1aFREE</li> <li>\u6a21\u5f0f\uff1aDBZUSER</li> <li>\u7528\u6237\uff1aDBZUSER</li> <li>\u5bc6\u7801\uff1adbz</li> </ul> <p>Openlog Replicator (OLR)\uff1a</p> <ul> <li>\u670d\u52a1\u540d\u79f0\uff1aORACLE</li> </ul>"},{"location":"zh/getting-started/quick_start/#psql-synchdb","title":"\u4f7f\u7528 psql \u8bbf\u95ee Synchdb","text":"<p>\u90e8\u7f72\u5b8c\u6210\u540e\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8bbf\u95ee synchdb\uff1a</p> <pre><code>docker exec -it synchdb bash -c \"p\u200b\u200bsql -d postgres\"\n</code></pre> <p>\u8fde\u63a5\u540e\uff0c\u521b\u5efa <code>synchdb</code> \u6269\u5c55\uff1a</p> <pre><code>CREATE EXTENSION synchdb CASCADE;\n</code></pre>"},{"location":"zh/getting-started/quick_start/#_3","title":"\u521b\u5efa\u8fde\u63a5\u5668","text":"<p>\u4ee5\u4e0b\u662f\u4e3a\u6bcf\u79cd\u53d7\u652f\u6301\u7684\u6e90\u6570\u636e\u5e93\u7c7b\u578b\u521b\u5efa\u57fa\u672c\u8fde\u63a5\u5668\u7684\u4e00\u4e9b\u793a\u4f8b\u3002</p> <p>MySQL: <pre><code>SELECT synchdb_add_conninfo('mysqlconn',\n                            'mysql',\n                            3306,\n                            'mysqluser',\n                            'mysqlpwd',\n                            'inventory',\n                            'postgres',\n                            'null',\n                            'null',\n                            'mysql');\n</code></pre></p> <p>Sqlserver: <pre><code>SELECT synchdb_add_conninfo('sqlserverconn',\n                            'sqlserver', \n                            1433,\n                            'sa',\n                            'Password!',\n                            'testDB',\n                            'postgres',\n                            'null',\n                            'null',\n                            'sqlserver');\n</code></pre></p> <p>Oracle23ai: <pre><code>SELECT synchdb_add_conninfo('oracleconn',\n                            'oracle',\n                            1521,\n                            'c##dbzuser',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'oracle');\n</code></pre></p> <p>Oracle19c: <pre><code>SELECT synchdb_add_conninfo('ora19cconn',\n                            'ora19c',\n                            1521,\n                            'DBZUSER',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'oracle');\n</code></pre></p> <p>OLR(Oracle19c): <pre><code>SELECT synchdb_add_conninfo('olrconn',\n                            'ora19c',\n                            1521,\n                            'DBZUSER',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'olr');\n\nSELECT synchdb_add_olr_conninfo('olrconn',\n                                'OpenLogReplicator',\n                                7070,\n                                'ORACLE');\n</code></pre></p> <p>\u67e5\u770b\u5df2\u521b\u5efa\u7684\u8fde\u63a5\u5668\uff1a</p> <pre><code>SELECT * FROM synchdb_conninfo;\n</code></pre> <p>\u6709\u5173\u521b\u5efa\u8fde\u63a5\u5668\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6b64\u5904</p>"},{"location":"zh/getting-started/quick_start/#_4","title":"\u521b\u5efa\u5bf9\u8c61\u6620\u5c04","text":"<p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6e90\u6570\u636e\u5e93\u540d\u79f0\u5c06\u6620\u5c04\u5230\u76ee\u6807\u6570\u636e\u5e93\u4e2d\u7684\u67b6\u6784\u540d\u79f0\u3002\u53ef\u4ee5\u4f7f\u7528\u5bf9\u8c61\u6620\u5c04\u6765\u66f4\u6539\u6b64\u67b6\u6784\u540d\u79f0\u3002\u8ba9\u6211\u4eec\u4ece\u57fa\u4e8e Oracle \u7684\u8fde\u63a5\u5668\u4e2d\u66f4\u6539\u201corders\u201d\u8868\u7684\u76ee\u6807\u67b6\u6784\uff0c\u5176\u4f59\u90e8\u5206\u4fdd\u7559\u9ed8\u8ba4\u503c\u3002</p> <pre><code>SELECT synchdb_add_objmap('oracleconn','table','free.c##dbzuser.orders','oracle23ai.orders');\nSELECT synchdb_add_objmap('ora19cconn','table','free.dbzuser.orders','oracle19c.orders');\nSELECT synchdb_add_objmap('olrconn','table','free.dbzuser.orders','olr.orders');\n</code></pre> <p>\u6709\u5173\u521b\u5efa\u5bf9\u8c61\u6620\u5c04\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904</p>"},{"location":"zh/getting-started/quick_start/#jmx-","title":"\u521b\u5efa JMX \u5bfc\u51fa\u5668 - \u53ef\u9009","text":"<p>\u4ee5\u4e0b\u662f\u4e00\u4e9b\u542f\u7528 JMX \u5bfc\u51fa\u5668\u8fdb\u884c\u76d1\u63a7\u7684\u793a\u4f8b\uff08\u5982\u679c\u5df2\u901a\u8fc7 <code>ezdeploy.sh</code> \u9884\u5148\u90e8\u7f72\u4e86 Prometheus + Grafana\uff09\uff1a</p> <p>MySQL: <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n                            'mysqlconn',\n                            '/home/ubuntu/jmx_prometheus_javaagent-1.3.0.jar',\n                            9404,\n                            '/home/ubuntu/jmxexport.conf');\n</code></pre></p> <p>Sqlserver: <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n                            'sqlserverconn',\n                            '/home/ubuntu/jmx_prometheus_javaagent-1.3.0.jar',\n                            9405,\n                            '/home/ubuntu/jmxexport.conf');\n</code></pre></p> <p>Oracle23ai: <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n                            'oracleconn',\n                            '/home/ubuntu/jmx_prometheus_javaagent-1.3.0.jar',\n                            9406,\n                            '/home/ubuntu/jmxexport.conf');\n</code></pre></p> <p>Oracle19c: <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n                            'ora19cconn',\n                            '/home/ubuntu/jmx_prometheus_javaagent-1.3.0.jar',\n                            9407,\n                            '/home/ubuntu/jmxexport.conf');\n</code></pre></p> <p>\u5173\u4e8e\u521b\u5efa JMX Exporter \u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904</p>"},{"location":"zh/getting-started/quick_start/#_5","title":"\u542f\u52a8\u8fde\u63a5\u5668","text":"<p>MySQL: <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre></p> <p>Sqlserver: <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn');\n</code></pre></p> <p>Oracle23ai: <pre><code>SELECT synchdb_start_engine_bgw('oracleconn');\n</code></pre></p> <p>Oracle19c: <pre><code>SELECT synchdb_start_engine_bgw('ora19cconn');\n</code></pre></p> <p>OLR(Oracle19c): <pre><code>SELECT synchdb_start_engine_bgw('olrconn');\n</code></pre></p> <p>\u6709\u5173\u8fde\u63a5\u5668\u542f\u52a8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904</p>"},{"location":"zh/getting-started/quick_start/#_6","title":"\u68c0\u67e5\u8fde\u63a5\u5668\u8fd0\u884c\u72b6\u6001","text":"<p>\u4f7f\u7528\u201csynchdb_state_view()\u201d\u68c0\u67e5\u6240\u6709\u8fde\u63a5\u5668\u7684\u8fd0\u884c\u72b6\u6001\u3002</p> <pre><code>SELECT * FROM synchdb_state_view;\n</code></pre> <p>\u4ee5\u4e0b\u662f\u8f93\u51fa\u793a\u4f8b\uff1a <pre><code>postgres=# SELECT * FROM synchdb_state_view;\n     name      | connector_type |  pid   |       stage      |  state  |   err    |                                           last_dbz_offset\n---------------+----------------+--------+------------------+---------+----------+------------------------------------------------------------------------------------------------------\n sqlserverconn | sqlserver      | 579820 | initial snapshot | polling | no error | {\"commit_lsn\":\"0000006a:00006608:0003\",\"snapshot\":true,\"snapshot_completed\":false}\n mysqlconn     | mysql          | 579845 | initial snapshot | polling | no error | {\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}\n oracleconn    | oracle         | 580053 | initial snapshot | polling | no error | offset file not flushed yet\n ora19cconn    | oracle         | 593421 | initial snapshot | polling | no error | offset file not flushed yet\n olrconn       | oracle         | 601235 | initial snapshot | polling | no error | offset file not flushed yet\n(5 rows)\n</code></pre></p> <p>\u6709\u5173\u8fd0\u884c\u72b6\u6001\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904\uff0c\u4ee5\u53ca\u8fd0\u884c\u7edf\u8ba1\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u6b64\u5904\u3002</p>"},{"location":"zh/getting-started/quick_start/#_7","title":"\u68c0\u67e5\u521d\u59cb\u5feb\u7167\u4e2d\u7684\u8868\u548c\u6570\u636e","text":"<p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u8fde\u63a5\u5668\u5c06\u6267\u884c\u201c\u521d\u59cb\u201d\u5feb\u7167\uff0c\u4ee5\u6355\u83b7\u8868\u6a21\u5f0f\u548c\u521d\u59cb\u6570\u636e\uff0c\u7136\u540e\u8f6c\u6362\u5e76\u5c06\u5b83\u4eec\u5e94\u7528\u5230\u4e0d\u540c\u201c\u6a21\u5f0f\u201d\u4e0b\u7684 PostgreSQL\u3002\u60a8\u5e94\u8be5\u770b\u5230\u7c7b\u4f3c\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <p>MySQL: <pre><code>\\dt inventory.*\n</code></pre></p> <pre><code>\\dt inventory.*\n               List of relations\n  Schema   |       Name       | Type  | Owner\n-----------+------------------+-------+--------\n inventory | addresses        | table | ubuntu\n inventory | customers        | table | ubuntu\n inventory | geom             | table | ubuntu\n inventory | orders           | table | ubuntu\n inventory | products         | table | ubuntu\n inventory | products_on_hand | table | ubuntu\n(6 rows)\n</code></pre> <p>Sqlserver: <pre><code>\\dt testdb.*\n</code></pre></p> <pre><code>\\dt testdb.*\n             List of relations\n Schema |       Name       | Type  | Owner\n--------+------------------+-------+--------\n testdb | customers        | table | ubuntu\n testdb | orders           | table | ubuntu\n testdb | products         | table | ubuntu\n testdb | products_on_hand | table | ubuntu\n(4 rows)\n</code></pre> <p>Oracle23ai <pre><code>\\dt oracle23ai.*\n</code></pre></p> <pre><code>\\dt oracle23ai.*\n          List of relations\n   Schema   |  Name  | Type  | Owner\n------------+--------+-------+--------\n oracle23ai | orders | table | ubuntu\n(1 row)\n</code></pre> <p>Oracle19c <pre><code>\\dt oracle19c.*\n</code></pre></p> <pre><code>\\dt oracle19c.*\n          List of relations\n  Schema   |  Name  | Type  | Owner\n-----------+--------+-------+--------\n oracle19c | orders | table | ubuntu\n(1 row)\n</code></pre> <p>OLR <pre><code>\\dt olr.*\n</code></pre></p> <pre><code>\\dt olr.*\n        List of relations\n Schema |  Name  | Type  | Owner\n--------+--------+-------+--------\n olr    | orders | table | ubuntu\n(1 row)\n</code></pre>"},{"location":"zh/getting-started/quick_start/#insert-cdc","title":"\u6a21\u62df INSERT \u4e8b\u4ef6\u5e76\u89c2\u5bdf\u53d8\u66f4\u6570\u636e\u6355\u83b7 (CDC)","text":"<p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 <code>docker exec</code> \u4e3a\u6bcf\u79cd\u8fde\u63a5\u5668\u7c7b\u578b\u6a21\u62df\u4e00\u6b21 INSERT \u64cd\u4f5c\uff0c\u5e76\u89c2\u5bdf\u53d8\u66f4\u6570\u636e\u6355\u83b7 (CDC)\u3002</p> <p>MySQL: <pre><code>docker exec -i mysql mysql -D inventory -umysqluser -pmysqlpwd -e \"INSERT INTO orders(order_date, purchaser, quantity, product_id) VALUES ('2025-12-12', 1002, 10000, 102)\"\n</code></pre></p> <pre><code>postgres=# SELECT * from inventory.orders;\n order_number | order_date | purchaser | quantity | product_id\n--------------+------------+-----------+----------+------------\n        10001 | 2016-01-16 |      1001 |        1 |        102\n        10002 | 2016-01-17 |      1002 |        2 |        105\n        10003 | 2016-02-19 |      1002 |        2 |        106\n        10004 | 2016-02-21 |      1003 |        1 |        107\n        10005 | 2025-12-12 |      1002 |    10000 |        102\n(5 rows)\n</code></pre> <p>Sqlserver: <pre><code>docker exec -i sqlserver /opt/mssql-tools18/bin/sqlcmd -U sa -P 'Password!' -d testDB -C -Q \"INSERT INTO orders(order_date, purchaser, quantity, product_id) VALUES ('2025-12-12', 1002, 10000, 102)\"\n</code></pre></p> <pre><code>postgres=# SELECT * from testdb.orders;\n order_number | order_date | purchaser | quantity | product_id\n--------------+------------+-----------+----------+------------\n        10001 | 2016-01-16 |      1001 |        1 |        102\n        10002 | 2016-01-17 |      1002 |        2 |        105\n        10003 | 2016-02-19 |      1002 |        2 |        106\n        10004 | 2016-02-21 |      1003 |        1 |        107\n        10005 | 2025-12-12 |      1002 |    10000 |        102\n(5 rows)\n</code></pre> <p>Oracle23ai: <pre><code>echo -ne \"INSERT INTO orders(order_number, order_date, purchaser, quantity, product_id) VALUES (10005, TO_DATE('2025-12-12', 'YYYY-MM-DD'), 1002, 10000, 102);\\n\" | docker exec -i oracle sqlplus c##dbzuser/dbz@//localhost:1521/FREE\n</code></pre></p> <pre><code>postgres=# SELECT * FROM oracle23ai.orders;\n order_number |     order_date      | purchaser | quantity | product_id\n--------------+---------------------+-----------+----------+------------\n        10001 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10002 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10003 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10004 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10005 | 2025-12-12 00:00:00 |      1002 |    10000 |        102\n(5 rows)\n</code></pre> <p>Oracle19c: <pre><code>echo -ne \"INSERT INTO orders(order_number, order_date, purchaser, quantity, product_id) VALUES (10005, TO_DATE('2025-12-12', 'YYYY-MM-DD'), 1002, 10000, 102);\\n\" | docker exec -i ora19c sqlplus DBZUSER/dbz@//localhost:1521/FREE\n</code></pre></p> <pre><code>postgres=# SELECT * FROM oracle19c.orders;\n order_number |     order_date      | purchaser | quantity | product_id\n--------------+---------------------+-----------+----------+------------\n        10001 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10002 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10003 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10004 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10005 | 2025-12-12 00:00:00 |      1002 |    10000 |        102\n(5 rows)\n</code></pre> <p>OLR: <pre><code>echo -ne \"INSERT INTO orders(order_number, order_date, purchaser, quantity, product_id) VALUES (10005, TO_DATE('2025-12-12', 'YYYY-MM-DD'), 1002, 10000, 102);\\n\" | docker exec -i ora19c sqlplus DBZUSER/dbz@//localhost:1521/FREE\n</code></pre></p> <pre><code>postgres=# SELECT * FROM olr.orders;\n order_number |     order_date      | purchaser | quantity | product_id\n--------------+---------------------+-----------+----------+------------\n        10001 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10002 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10003 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10004 | 2024-01-01 00:00:00 |      1003 |        2 |        107\n        10005 | 2025-12-12 00:00:00 |      1002 |    10000 |        102\n(5 rows)\n</code></pre>"},{"location":"zh/getting-started/quick_start/#grafana-","title":"Grafana \u4e0a\u7684\u8fde\u63a5\u5668\u6307\u6807 - \u53ef\u9009","text":"<p>\u5982\u679c\u60a8\u9009\u62e9\u4f7f\u7528 <code>ezdeploy.sh</code> \u90e8\u7f72\u76d1\u63a7\uff0c\u5e76\u5728\u542f\u52a8\u8fde\u63a5\u5668\u4e4b\u524d\u8c03\u7528\u4e86\u53ef\u9009\u7684 <code>synchdb_add_jmx_exporter_conninfo()</code>\uff0c\u5219\u8fde\u63a5\u5668\u6307\u6807\u5c06\u5728 Grafana \u4e0a\u53ef\u7528\u3002</p> <ul> <li>\u8bbf\u95ee Grafana: http://localhost:3000/</li> <li>\u9ed8\u8ba4\u767b\u5f55\u540d: admin/admin (\u9996\u6b21\u767b\u5f55\u65f6\u9700\u8981\u66f4\u6539\u5bc6\u7801)</li> </ul> <p>\u5bfc\u822a\u5230\u4eea\u8868\u677f\u83dc\u5355\uff1a </p> <p>\u9009\u62e9\u6240\u9700\u6a21\u677f\uff1a</p> <ul> <li>Java \u865a\u62df\u673a - JVM \u8d44\u6e90\u4fe1\u606f</li> <li>SynchDB MySQL \u4eea\u8868\u677f - MySQL \u8fde\u63a5\u5668\u4fe1\u606f</li> <li>SynchDB SQLServer \u4eea\u8868\u677f - SQLServer \u8fde\u63a5\u5668\u4fe1\u606f</li> <li>SynchDB Oracle \u4eea\u8868\u677f - Oracle \u8fde\u63a5\u5668\u4fe1\u606f</li> </ul> <p>\u9009\u62e9\u6240\u9700\u5b9e\u4f8b\uff1a \u6bcf\u4e2a\u542f\u7528 JMX \u5bfc\u51fa\u5668\u7684\u8fde\u63a5\u5668\u90fd\u7ed1\u5b9a\u5230\u4e00\u4e2a\u4e13\u7528\u7aef\u53e3\u53f7\uff0c\u4ee5\u4fbf Prometheus \u53ef\u4ee5\u4ece\u4e2d\u83b7\u53d6\u6570\u636e\u3002\u4f7f\u7528\u5b9e\u4f8b\u4e0b\u62c9\u83dc\u5355\u6309\u7aef\u53e3\u53f7\u9009\u62e9\u8fde\u63a5\u5668\u3002</p> <p></p> <p>Java \u865a\u62df\u673a\u4eea\u8868\u677f\uff1a </p> <p>MySQL \u4eea\u8868\u677f\uff1a </p> <p>SQLServer \u4eea\u8868\u677f\uff1a </p> <p>Oracle \u4eea\u8868\u677f\uff1a </p>"},{"location":"zh/getting-started/quick_start/#_8","title":"\u505c\u6b62\u5e76\u79fb\u9664\u8fde\u63a5\u5668","text":"<p>MySQL: <pre><code>SELECT synchdb_stop_engine_bgw('mysqlconn');\nSELECT synchdb_del_conninfo('mysqlconn');\n</code></pre></p> <p>Sqlserver: <pre><code>SELECT synchdb_stop_engine_bgw('sqlserverconn');\nSELECT synchdb_del_conninfo('sqlserverconn');\n</code></pre></p> <p>Oracle23ai: <pre><code>SELECT synchdb_stop_engine_bgw('oracleconn');\nSELECT synchdb_del_conninfo('oracleconn');\n</code></pre></p> <p>Oracle19c: <pre><code>SELECT synchdb_stop_engine_bgw('ora19cconn');\nSELECT synchdb_del_conninfo('ora19cconn');\n</code></pre></p> <p>OLR(Oracle19c): <pre><code>SELECT synchdb_stop_engine_bgw('olrconn');\nSELECT synchdb_del_conninfo('olrconn');\n</code></pre></p>"},{"location":"zh/getting-started/remote_database_setups/","title":"\u6e90\u6570\u636e\u5e93\u8bbe\u7f6e","text":"<p>\u5728 Synchdb \u53ef\u4ee5\u4e0e\u5916\u90e8\u5f02\u6784\u6570\u636e\u5e93\u4ea4\u4e92\u5e76\u542f\u52a8\u590d\u5236\u4e4b\u524d\uff0c\u9700\u8981\u6839\u636e\u4e0b\u5217\u6d41\u7a0b\u8fdb\u884c\u914d\u7f6e</p>"},{"location":"zh/getting-started/remote_database_setups/#synchdb-mysql","title":"\u4e3a SynchDB \u8bbe\u7f6e MySQL","text":""},{"location":"zh/getting-started/remote_database_setups/#_2","title":"\u521b\u5efa\u7528\u6237","text":"<p>\u521b\u5efa\u7528\u6237 <pre><code>mysql&gt; CREATE USER 'user'@'localhost' IDENTIFIED BY 'password';\n</code></pre></p> <p>\u6388\u4e88\u6240\u9700\u6743\u9650 <pre><code>mysql&gt; GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'user' IDENTIFIED BY 'password';\n</code></pre></p> <p>\u786e\u5b9a\u7528\u6237\u7684\u6743\u9650 <pre><code>mysql&gt; FLUSH PRIVILEGES;\n</code></pre></p>"},{"location":"zh/getting-started/remote_database_setups/#binlog","title":"\u542f\u7528 binlog","text":"<p>\u68c0\u67e5 binlog \u662f\u5426\u542f\u7528 <pre><code>// for MySQL 5.x\nmysql&gt; SELECT variable_value as \"BINARY LOGGING STATUS (log-bin) ::\"\nFROM information_schema.global_variables WHERE variable_name='log_bin';\n\n// for MySQL 8.x\nmysql&gt; SELECT variable_value as \"BINARY LOGGING STATUS (log-bin) ::\"\nFROM performance_schema.global_variables WHERE variable_name='log_bin';\n</code></pre></p> <p>\u5982\u679c binlog \u5904\u4e8e\u201cOFF\u201d\u72b6\u6001\uff0c\u5219\u5c06\u4ee5\u4e0b\u5c5e\u6027\u6dfb\u52a0\u5230\u914d\u7f6e\u6587\u4ef6\u4e2d <pre><code>server-id                   = 223344\nlog_bin                     = mysql-bin\nbinlog_format               = ROW\nbinlog_row_image            = FULL\nbinlog_expire_logs_seconds  = 864000\n</code></pre></p> <p>\u518d\u6b21\u68c0\u67e5binlog\u72b6\u6001 <pre><code>// for MySQL 5.x\nmysql&gt; SELECT variable_value as \"BINARY LOGGING STATUS (log-bin) ::\"\nFROM information_schema.global_variables WHERE variable_name='log_bin';\n\n// for MySQL 8.x\nmysql&gt; SELECT variable_value as \"BINARY LOGGING STATUS (log-bin) ::\"\nFROM performance_schema.global_variables WHERE variable_name='log_bin';\n</code></pre></p>"},{"location":"zh/getting-started/remote_database_setups/#gtid","title":"\u542f\u7528 GTID\uff08\u53ef\u9009\uff09","text":"<p>\u5168\u5c40\u4e8b\u52a1\u6807\u8bc6\u7b26 (GTID) \u552f\u4e00\u5730\u6807\u8bc6\u96c6\u7fa4\u5185\u670d\u52a1\u5668\u4e0a\u53d1\u751f\u7684\u4e8b\u52a1\u3002\u867d\u7136 SynchDB \u8fde\u63a5\u5668\u4e0d\u5f3a\u5236\u9700\u8981\uff0c\u4f46\u4f7f\u7528 GTID \u53ef\u4ee5\u7b80\u5316\u590d\u5236\uff0c\u5e76\u4f7f\u60a8\u80fd\u591f\u66f4\u8f7b\u677e\u5730\u786e\u8ba4\u4e3b\u670d\u52a1\u5668\u548c\u526f\u672c\u670d\u52a1\u5668\u662f\u5426\u4e00\u81f4\u3002</p> <p>\u542f\u7528 <code>gtid_mode</code> <pre><code>mysql&gt; gtid_mode=ON\n</code></pre></p> <p>\u542f\u7528 <code>enforce_gtid_consistency</code> <pre><code>mysql&gt; enforce_gtid_consistency=ON\n</code></pre></p> <p>\u786e\u8ba4\u66f4\u6539 <pre><code>mysql&gt; show global variables like '%GTID%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| enforce_gtid_consistency | ON    |\n| gtid_mode                | ON    |\n+--------------------------+-------+\n</code></pre></p>"},{"location":"zh/getting-started/remote_database_setups/#_3","title":"\u914d\u7f6e\u4f1a\u8bdd\u8d85\u65f6","text":"<p>\u5f53\u4e3a\u5927\u578b\u6570\u636e\u5e93\u5236\u5904\u7406 initial snapshot\u65f6\uff0c\u60a8\u5efa\u7acb\u7684\u8fde\u63a5\u53ef\u80fd\u4f1a\u5728\u8bfb\u53d6\u8868\u65f6\u8d85\u65f6\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7\u5728 MySQL \u914d\u7f6e\u6587\u4ef6\u4e2d\u914d\u7f6e<code>interactive_timeout</code>\u548c<code>wait_timeout</code>\u6765\u9632\u6b62\u6b64\u884c\u4e3a\u3002</p> <p>\u914d\u7f6e <code>interactive_timeout:</code> <pre><code>mysql&gt; interactive_timeout=&lt;duration in seconds&gt;\n</code></pre></p> <p>\u914d\u7f6e <code>wait_timeout</code> <pre><code>mysql&gt; wait_timeout=&lt;duration in seconds&gt;\n</code></pre></p>"},{"location":"zh/getting-started/remote_database_setups/#_4","title":"\u542f\u7528\u67e5\u8be2\u65e5\u5fd7\u4e8b\u4ef6","text":"<p>\u60a8\u53ef\u80fd\u5e0c\u671b\u67e5\u770b\u6bcf\u4e2a\u4e8c\u8fdb\u5236\u65e5\u5fd7\u4e8b\u4ef6\u7684\u539f\u59cb SQL \u8bed\u53e5\u3002\u5728 MySQL \u914d\u7f6e\u6587\u4ef6\u4e2d\u542f\u7528<code>binlog_rows_query_log_events</code>\u9009\u9879\u5141\u8bb8\u60a8\u6267\u884c\u6b64\u64cd\u4f5c\u3002\u76ee\u524d SynchDB \u4e0d\u4f1a\u4ee5\u4efb\u4f55\u65b9\u5f0f\u5904\u7406\u6216\u89e3\u6790\u539f\u59cb SQL \u8bed\u53e5\uff0c\u5373\u4f7f\u5b83\u4eec\u5305\u542b\u5728 binlog \u5185\u3002\u8fd9\u4e9b\u4ec5\u4f9b\u53c2\u8003/\u8c03\u8bd5</p> <p>\u542f\u7528 <code>binlog_rows_query_log_events</code> <pre><code>mysql&gt; binlog_rows_query_log_events=ON\n</code></pre></p>"},{"location":"zh/getting-started/remote_database_setups/#binlog_1","title":"\u9a8c\u8bc1 Binlog \u884c\u503c\u9009\u9879","text":"<p>\u9a8c\u8bc1\u6570\u636e\u5e93\u4e2d <code>binlog_row_value_options</code> \u53d8\u91cf\u7684\u8bbe\u7f6e\u3002\u8981\u4f7f\u8fde\u63a5\u5668\u80fd\u591f\u4f7f\u7528 UPDATE \u4e8b\u4ef6\uff0c\u5fc5\u987b\u5c06\u6b64\u53d8\u91cf\u8bbe\u7f6e\u4e3a\u9664 <code>PARTIAL_JSON</code> \u4ee5\u5916\u7684\u503c\u3002</p> <p>check current variable value <pre><code>mysql&gt; show global variables where variable_name = 'binlog_row_value_options';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| binlog_row_value_options |       |\n+--------------------------+-------+\n</code></pre></p> <p>\u5982\u679c\u53d8\u91cf\u7684\u503c\u4e3a\u201cPARTIAL_JSON\u201d\uff0c\u8bf7\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u53d6\u6d88\u8bbe\u7f6e\u5b83 <pre><code>mysql&gt; set @@global.binlog_row_value_options=\"\" ;\n</code></pre></p>"},{"location":"zh/getting-started/remote_database_setups/#synchdb-sqlserver","title":"\u4e3a SynchDB \u8bbe\u7f6e SQLServer","text":""},{"location":"zh/getting-started/remote_database_setups/#sqlserver-cdc","title":"\u5728 SQLServer \u6570\u636e\u5e93\u4e0a\u542f\u7528 CDC","text":"<p>\u5728\u4e3a\u8868\u542f\u7528 CDC \u4e4b\u524d\uff0c\u5fc5\u987b\u5148\u4e3a SQL Server \u6570\u636e\u5e93\u542f\u7528\u5b83\u3002SQLServer \u7ba1\u7406\u5458\u901a\u8fc7\u8fd0\u884c\u7cfb\u7edf\u5b58\u50a8\u8fc7\u7a0b\u6765\u542f\u7528 CDC\u3002\u53ef\u4ee5\u4f7f\u7528 SQL Server Management Studio \u6216 Transact-SQL \u6765\u8fd0\u884c\u7cfb\u7edf\u5b58\u50a8\u8fc7\u7a0b\u3002</p> <pre><code>USE MyDB\nGO\nEXEC sys.sp_cdc_enable_db\nGO\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#sqlserver-cdc_1","title":"\u5728 SQLServer \u8868\u4e0a\u542f\u7528 CDC","text":"<p>SQLServer \u7ba1\u7406\u5458\u5fc5\u987b\u5728\u60a8\u5e0c\u671b SynchDB \u6355\u83b7\u7684\u6e90\u8868\u4e0a\u542f\u7528\u53d8\u66f4\u6570\u636e\u6355\u83b7\u3002\u6570\u636e\u5e93\u5fc5\u987b\u5df2\u542f\u7528 CDC\u3002\u8981\u5728\u8868\u4e0a\u542f\u7528 CDC\uff0cSQLServer \u7ba1\u7406\u5458\u9700\u8981\u4e3a\u8868\u8fd0\u884c\u5b58\u50a8\u8fc7\u7a0b\u201csys.sp_cdc_enable_table\u201d\u3002\u5fc5\u987b\u4e3a\u8981\u6355\u83b7\u7684\u6bcf\u4e2a\u8868\u542f\u7528 SQL Server CDC\u3002</p> <p>\u4e3a SynchDB \u542f\u7528 3 \u4e2a\u8868<code>customer</code>\u3001<code>district</code> \u548c <code>history</code> \u4ee5\u8fdb\u884c\u6355\u83b7\uff1a</p> <pre><code>USE MyDB\nGO\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'customer', @role_name = NULL, @supports_net_changes = 0;\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'district', @role_name = NULL, @supports_net_changes = 0;\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'history', @role_name = NULL, @supports_net_changes = 0;\nGO\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#cdc","title":"\u9a8c\u8bc1\u7528\u6237\u5bf9 CDC \u8868\u7684\u6743\u9650","text":"<p>SQLServer \u7ba1\u7406\u5458\u53ef\u4ee5\u8fd0\u884c\u7cfb\u7edf\u5b58\u50a8\u8fc7\u7a0b\u6765\u67e5\u8be2\u6570\u636e\u5e93\u6216\u8868\u4ee5\u68c0\u7d22\u5176 CDC \u914d\u7f6e\u4fe1\u606f\u3002</p> <p>\u4ee5\u4e0b\u67e5\u8be2\u8fd4\u56de\u6570\u636e\u5e93\u4e2d\u542f\u7528 CDC \u7684\u6bcf\u4e2a\u8868\u7684\u914d\u7f6e\u4fe1\u606f\uff0c\u5176\u4e2d\u5305\u542b\u8c03\u7528\u8005\u6709\u6743\u8bbf\u95ee\u7684\u66f4\u6539\u6570\u636e\u3002\u5982\u679c\u7ed3\u679c\u4e3a\u7a7a\uff0c\u8bf7\u9a8c\u8bc1\u7528\u6237\u662f\u5426\u6709\u6743\u8bbf\u95ee\u6355\u83b7\u5b9e\u4f8b\u548c CDC \u8868\u3002</p> <pre><code>USE MyDB;\nGO\nEXEC sys.sp_cdc_help_change_data_capture\nGO\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#cdc_1","title":"\u5f53\u542f\u7528 CDC \u65f6\u8868\u67b6\u6784\u53d1\u751f\u66f4\u6539","text":"<p>\u5982\u679c\u67d0\u4e2a\u8868\u5df2\u6dfb\u52a0\u5230 CDC \u6355\u83b7\u5217\u8868\u5e76\u5df2\u88ab SynchDB \u6355\u83b7\uff0c\u5219\u9700\u8981\u5c06 SQLServer \u4e0a\u6b64\u8868\u53d1\u751f\u7684\u4efb\u4f55\u67b6\u6784\u66f4\u6539\u91cd\u65b0\u6dfb\u52a0\u56de CDC \u6355\u83b7\u5217\u8868\uff0c\u4ee5\u5411 SynchDB \u751f\u6210\u6b63\u786e\u7684 DDL ALTER TABLE \u4e8b\u4ef6\u3002\u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 DDL \u590d\u5236 \u9875\u9762\u3002</p>"},{"location":"zh/getting-started/remote_database_setups/#synchdb-oracle","title":"\u4e3a SynchDB \u8bbe\u7f6e Oracle","text":"<p>\u4ee5\u4e0b\u793a\u4f8b\u57fa\u4e8e\u5bb9\u5668\u6570\u636e\u5e93 <code>FREE</code> \u548c\u53ef\u63d2\u62d4\u6570\u636e\u5e93 <code>FREEPDB1</code>:</p>"},{"location":"zh/getting-started/remote_database_setups/#sys","title":"\u4e3a Sys \u7528\u6237\u8bbe\u7f6e\u5bc6\u7801","text":"<pre><code>sqlplus / as sysdba\n    Alter user sys identified by oracle;\nExit\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#_5","title":"\u914d\u7f6e\u65e5\u5fd7\u6316\u6398\u5668","text":"<pre><code>sqlplus /nolog\n\n    CONNECT sys/oracle as sysdba;\n    alter system set db_recovery_file_dest_size = 10G;\n    alter system set db_recovery_file_dest = '/opt/oracle/oradata/recovery_area' scope=spfile;\n    shutdown immediate;\n    startup mount;\n    alter database archivelog;\n    alter database open;\n    archive log list;\nexit\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#logminer","title":"\u521b\u5efa logminer \u7528\u6237","text":"<pre><code>sqlplus sys/oracle@//localhost:1521/FREE as sysdba\n\n    ALTER DATABASE ADD SUPPLEMENTAL LOG DATA;\n    ALTER PROFILE DEFAULT LIMIT FAILED_LOGIN_ATTEMPTS UNLIMITED;\n    exit;\n\nsqlplus sys/oracle@//localhost:1521/FREE as sysdba\n\n    CREATE TABLESPACE LOGMINER_TBS DATAFILE '/opt/oracle/oradata/FREE/logminer_tbs.dbf' SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;\n    exit;\n\nsqlplus sys/oracle@//localhost:1521/FREEPDB1 as sysdba\n\n    CREATE TABLESPACE LOGMINER_TBS DATAFILE '/opt/oracle/oradata/FREE/FREEPDB1/logminer_tbs.dbf' SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;\n    exit;\n\nsqlplus sys/oracle@//localhost:1521/FREE as sysdba\n\n    CREATE USER c##dbzuser IDENTIFIED BY dbz DEFAULT TABLESPACE LOGMINER_TBS QUOTA UNLIMITED ON LOGMINER_TBS CONTAINER=ALL;\n\n    GRANT CREATE SESSION TO c##dbzuser CONTAINER=ALL;\n    GRANT SET CONTAINER TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$DATABASE TO c##dbzuser CONTAINER=ALL;\n    GRANT FLASHBACK ANY TABLE TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ANY TABLE TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT_CATALOG_ROLE TO c##dbzuser CONTAINER=ALL;\n    GRANT EXECUTE_CATALOG_ROLE TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ANY TRANSACTION TO c##dbzuser CONTAINER=ALL;\n    GRANT LOGMINING TO c##dbzuser CONTAINER=ALL;\n\n    GRANT SELECT ANY DICTIONARY TO c##dbzuser CONTAINER=ALL;\n\n    GRANT CREATE TABLE TO c##dbzuser CONTAINER=ALL;\n    GRANT LOCK ANY TABLE TO c##dbzuser CONTAINER=ALL;\n    GRANT CREATE SEQUENCE TO c##dbzuser CONTAINER=ALL;\n\n    GRANT EXECUTE ON DBMS_LOGMNR TO c##dbzuser CONTAINER=ALL;\n    GRANT EXECUTE ON DBMS_LOGMNR_D TO c##dbzuser CONTAINER=ALL;\n\n    GRANT SELECT ON V_$LOG TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$LOG_HISTORY TO c##dbzuser CONTAINER=ALL;\n\n    GRANT SELECT ON V_$LOGMNR_LOGS TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$LOGMNR_CONTENTS TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$LOGMNR_PARAMETERS TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$LOGFILE TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$ARCHIVED_LOG TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$ARCHIVE_DEST_STATUS TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$TRANSACTION TO c##dbzuser CONTAINER=ALL; \n    GRANT SELECT ON V_$MYSTAT TO c##dbzuser CONTAINER=ALL;\n    GRANT SELECT ON V_$STATNAME TO c##dbzuser CONTAINER=ALL; \n\n    GRANT EXECUTE ON DBMS_WORKLOAD_REPOSITORY TO C##DBZUSER;\n    GRANT SELECT ON DBA_HIST_SNAPSHOT TO C##DBZUSER;\n    GRANT EXECUTE ON DBMS_WORKLOAD_REPOSITORY TO PUBLIC;\n\n\n    Exit\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#_6","title":"\u4e3a\u6307\u5b9a\u6355\u83b7\u8868\u542f\u7528\u8865\u5145\u65e5\u5fd7\u6570\u636e","text":"<p>\u9700\u8981\u5728\u6bcf\u4e2a\u88ab\u6355\u83b7\u7684\u8868\u8fd0\u884c\u6b64\u914d\u7f6e\uff0c\u4ee5\u4fbf\u6b63\u786e\u5904\u7406 UPDATE \u548c DELETE \u64cd\u4f5c\u3002</p> <pre><code>ALTER TABLE customer ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;\nALTER TABLE products ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;\n... etc\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#openlog-replicator-oracle","title":"Openlog Replicator \u652f\u6301\u7684\u5176\u4ed6 Oracle \u8bbe\u7f6e","text":"<p>Openlog Replicator \u9700\u8981\u989d\u5916\u6743\u9650\u624d\u80fd\u6d41\u5f0f\u4f20\u8f93 Oracle \u66f4\u6539\uff1a</p> <pre><code>GRANT SELECT, FLASHBACK ON SYS.CCOL$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.CDEF$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.COL$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.DEFERRED_STG$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.ECOL$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.LOB$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.LOBCOMPPART$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.LOBFRAG$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.OBJ$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TAB$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TABCOMPART$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TABPART$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TABSUBPART$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.TS$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON SYS.USER$ TO DBZUSER;\nGRANT SELECT, FLASHBACK ON XDB.XDB$TTSET TO DBZUSER;\nGRANT FLASHBACK ANY TABLE TO DBZUSER;\nGRANT SELECT ON SYS.V_$ARCHIVED_LOG TO DBZUSER;\nGRANT SELECT ON SYS.V_$DATABASE TO DBZUSER;\nGRANT SELECT ON SYS.V_$DATABASE_INCARNATION TO DBZUSER;\nGRANT SELECT ON SYS.V_$LOG TO DBZUSER;\nGRANT SELECT ON SYS.V_$LOGFILE TO DBZUSER;\nGRANT SELECT ON SYS.V_$PARAMETER TO DBZUSER;\nGRANT SELECT ON SYS.V_$STANDBY_LOG TO DBZUSER;\nGRANT SELECT ON SYS.V_$TRANSPORTABLE_PLATFORM TO DBZUSER;\nDECLARE\n    CURSOR C1 IS SELECT TOKSUF FROM XDB.XDB$TTSET;\n    CMD VARCHAR2(2000);\nBEGIN\n    FOR C IN C1 LOOP\n        CMD := 'GRANT SELECT, FLASHBACK ON XDB.X$NM' || C.TOKSUF || ' TO DBZUSER';\n        EXECUTE IMMEDIATE CMD;\n        CMD := 'GRANT SELECT, FLASHBACK ON XDB.X$QN' || C.TOKSUF || ' TO DBZUSER';\n        EXECUTE IMMEDIATE CMD;\n        CMD := 'GRANT SELECT, FLASHBACK ON XDB.X$PT' || C.TOKSUF || ' TO DBZUSER';\n        EXECUTE IMMEDIATE CMD;\n    END LOOP;\nEND;\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#synchdb-postgres","title":"\u8a2d\u5b9a SynchDB \u7684 Postgres \u9023\u63a5\u5668","text":"<p>\u9700\u8981\u914d\u7f6e PostgreSQL \u4f3a\u670d\u5668\uff0c\u4f7f\u5176\u7528\u4f5c SynchDB \u7684\u8cc7\u6599\u5eab\u4f86\u6e90\u3002</p>"},{"location":"zh/getting-started/remote_database_setups/#guc","title":"GUC \u8a2d\u5b9a","text":"<pre><code>wal_level = logical\nmax_wal_senders = &lt;&lt; \u53ef\u80fd\u9700\u8981\u6839\u64da\u60a8\u7684\u9700\u6c42\u9032\u884c\u8abf\u6574 - \u9810\u8a2d\u503c\u70ba 10 &gt;&gt;\nmax_replication_slots = &lt;&lt; \u53ef\u80fd\u9700\u8981\u6839\u64da\u60a8\u7684\u9700\u6c42\u9032\u884c\u8abf\u6574 - \u9810\u8a2d\u503c\u70ba 10 &gt;&gt;\nwal_writer_delay = &lt;&lt; \u5982\u679c `synchronous_commit` \u7684\u503c\u4e0d\u662f \u201con\u201d\uff0c\u5efa\u8b70\u8a2d\u5b9a\u70ba 10ms\u3002\u9810\u8a2d\u503c\u70ba 200ms &gt;&gt;\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#_7","title":"\u6b0a\u9650\u8a2d\u5b9a","text":"<p>\u5efa\u7acb\u4e00\u500b\u5177\u6709\u8907\u88fd\u6b0a\u9650\u7684\u65b0\u4f7f\u7528\u8005\uff1a</p> <pre><code>CREATE ROLE &lt;name&gt; REPLICATION LOGIN;\n</code></pre> <p>SynchDB \u5f9e\u70ba PostgreSQL \u4f86\u6e90\u8868\u5efa\u7acb\u7684\u767c\u5e03\u4e2d\u53d6\u5f97\u4f86\u6e90\u8868\u7684\u8b8a\u66f4\u4e8b\u4ef6\u6d41\u3002\u767c\u5e03\u5305\u542b\u5f9e\u4e00\u500b\u6216\u591a\u500b\u8868\u7522\u751f\u7684\u7d93\u904e\u7be9\u9078\u7684\u8b8a\u66f4\u4e8b\u4ef6\u96c6\u3002\u6bcf\u500b\u767c\u5e03\u4e2d\u7684\u6578\u64da\u90fd\u6839\u64da\u767c\u5e03\u898f\u7bc4\u9032\u884c\u904e\u6ffe\u3002\u898f\u683c\u53ef\u4ee5\u7531 PostgreSQL \u8cc7\u6599\u5eab\u7ba1\u7406\u54e1\u6216 Debezium \u9023\u63a5\u5668\u5efa\u7acb\u3002\u70ba\u4e86\u5141\u8a31 SynchDB Postgres \u9023\u63a5\u5668\u5efa\u7acb\u767c\u5e03\u4e26\u6307\u5b9a\u8981\u8907\u88fd\u5230\u5176\u4e2d\u7684\u6578\u64da\uff0c\u9023\u63a5\u5668\u5fc5\u9808\u4ee5\u8cc7\u6599\u5eab\u4e2d\u7684\u7279\u5b9a\u6b0a\u9650\u904b\u884c\u3002</p> <p>\u6709\u5e7e\u7a2e\u65b9\u6cd5\u53ef\u4ee5\u78ba\u5b9a\u5982\u4f55\u5efa\u7acb\u767c\u5e03\u3002\u901a\u5e38\uff0c\u6700\u597d\u5728\u8a2d\u5b9a\u9023\u63a5\u5668\u4e4b\u524d\uff0c\u70ba\u8981\u6355\u7372\u7684\u8868\u624b\u52d5\u5efa\u7acb\u767c\u5e03\u3002\u4f46\u662f\uff0c\u60a8\u53ef\u4ee5\u8a2d\u5b9a\u74b0\u5883\uff0c\u4f7f SynchDB \u81ea\u52d5\u5efa\u7acb\u767c\u5e03\u4e26\u6307\u5b9a\u8981\u65b0\u589e\u5230\u5176\u4e2d\u7684\u8cc7\u6599\u3002</p> <p>SynchDB \u4f7f\u7528\u5305\u542b\u6e05\u55ae\u5c6c\u6027\uff08\u7576\u4f7f\u7528 <code>synchdb_add_conninfo</code> \u5efa\u7acb\u9023\u63a5\u5668\u6642\uff09\u4f86\u6307\u5b9a\u5982\u4f55\u5c07\u8cc7\u6599\u63d2\u5165\u5230\u767c\u5e03\u4e2d\u3002</p> <p>\u8981\u4f7f SynchDB \u5efa\u7acb PostgreSQL \u767c\u5e03\uff0c\u5b83\u5fc5\u9808\u4ee5\u5177\u6709\u4ee5\u4e0b\u6b0a\u9650\u7684\u4f7f\u7528\u8005\u8eab\u5206\u57f7\u884c\uff1a</p> <ul> <li>\u8cc7\u6599\u5eab\u4e2d\u7684\u8907\u88fd\u6b0a\u9650\uff0c\u7528\u65bc\u5c07\u8868\u683c\u65b0\u589e\u81f3\u767c\u5e03\u3002</li> <li>\u8cc7\u6599\u5eab\u7684 CREATE \u6b0a\u9650\uff0c\u7528\u65bc\u65b0\u589e\u767c\u5e03\u3002</li> <li>\u9700\u8981\u5c0d\u9336\u64c1\u6709 SELECT \u6b0a\u9650\u624d\u80fd\u8907\u88fd\u521d\u59cb\u8868\u8cc7\u6599\u3002\u8868\u6240\u6709\u8005\u81ea\u52d5\u64c1\u6709\u5c0d\u9336\u7684 SELECT \u6b0a\u9650\u3002</li> </ul> <p>\u82e5\u8981\u5c07\u8868\u683c\u65b0\u589e\u81f3\u767c\u5e03\u4e2d\uff0c\u4f7f\u7528\u8005\u5fc5\u9808\u662f\u8a72\u8868\u683c\u7684\u64c1\u6709\u8005\u3002\u4f46\u7531\u65bc\u4f86\u6e90\u8868\u5df2\u5b58\u5728\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u7a2e\u6a5f\u5236\u8207\u539f\u59cb\u6240\u6709\u8005\u5171\u4eab\u6240\u6709\u6b0a\u3002\u82e5\u8981\u555f\u7528\u5171\u4eab\u6240\u6709\u6b0a\uff0c\u60a8\u53ef\u4ee5\u5efa\u7acb PostgreSQL \u8907\u88fd\u7fa4\u7d44\uff0c\u7136\u5f8c\u5c07\u73fe\u6709\u8868\u683c\u64c1\u6709\u8005\u548c\u8907\u88fd\u4f7f\u7528\u8005\u65b0\u589e\u81f3\u8a72\u7fa4\u7d44\u3002</p> <p>\u6b65\u9a5f\uff1a</p> <ul> <li>\u5efa\u7acb\u8907\u88fd\u7d44\u3002</li> </ul> <pre><code>CREATE ROLE &lt;replication_group&gt;;\n</code></pre> <ul> <li>\u5c07\u8868\u683c\u7684\u539f\u59cb\u64c1\u6709\u8005\u65b0\u589e\u81f3\u8a72\u7fa4\u7d44\u3002</li> </ul> <pre><code>GRANT REPLICATION_GROUP TO &lt;original_owner&gt;;\n</code></pre> <ul> <li>\u5c07 Debezium \u8907\u88fd\u4f7f\u7528\u8005\u65b0\u589e\u81f3\u8a72\u7fa4\u7d44\u3002</li> </ul> <pre><code>GRANT REPLICATION_GROUP TO &lt;replication_user&gt;;\n</code></pre> <ul> <li>\u5c07\u8868\u683c\u7684\u6240\u6709\u6b0a\u8f49\u79fb\u7d66 \u3002 <pre><code>ALTER TABLE &lt;table_name&gt; OWNER TO REPLICATION_GROUP;\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#pg_hba","title":"pg_hba \u8a2d\u5b9a","text":"<p>\u8981\u4f7f Debezium \u80fd\u5920\u8907\u88fd PostgreSQL \u6578\u64da\uff0c\u60a8\u5fc5\u9808\u914d\u7f6e\u8cc7\u6599\u5eab\u4ee5\u5141\u8a31\u8207\u57f7\u884c PostgreSQL \u9023\u63a5\u5668\u7684\u4e3b\u6a5f\u9032\u884c\u8907\u88fd\u3002\u82e5\u8981\u6307\u5b9a\u5141\u8a31\u8207\u8cc7\u6599\u5eab\u8907\u88fd\u7684\u7528\u6236\u7aef\uff0c\u8acb\u5728 PostgreSQL \u57fa\u65bc\u4e3b\u6a5f\u7684\u9a57\u8b49\u6a94\u6848 <code>pg_hba.conf</code> \u65b0\u589e\u689d\u76ee\u3002\u6709\u95dc pg_hba.conf \u6587\u4ef6\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8acb\u53c3\u95b1 PostgreSQL \u6587\u4ef6\u3002</p> <pre><code>local replication &lt;youruser&gt; trust\nhost replication &lt;youruser&gt; 127.0.0.1/32 trust\nhost replication &lt;youruser&gt; ::1/128 trust\n</code></pre>"},{"location":"zh/getting-started/remote_database_setups/#ddl-lsn","title":"\u5b89\u88dd DDL \u89f8\u767c\u5668\u548c\u81ea\u8a02 LSN \u8996\u5716","text":"<p>\u82e5\u8981\u5c07\u4f7f\u7528\u8005\u8868 DDL \u908f\u8f2f\u8907\u88fd\u5230 SynchDB\uff0c\u60a8\u5fc5\u9808\u5728\u4f86\u6e90 PostgreSQL \u8cc7\u6599\u5eab\u4e2d\u5b89\u88dd DDL \u89f8\u767c\u5668\u3002\u6b64\u5916\uff0c\u60a8\u9084\u9700\u8981\u5efa\u7acb\u81ea\u8a02\u8996\u5716\uff0c\u8a72\u8996\u5716\u6703\u50b3\u56de\u4f86\u6e90\u8cc7\u6599\u5eab\u4e2d\u7684\u76ee\u524d LSN\uff0c\u4ee5\u4fbf SynchDB \u53ef\u4ee5\u5728\u5feb\u7167\u904e\u7a0b\u4e2d\u900f\u904e FDW \u6aa2\u7d22\u5b83\u3002</p> <p>SynchDB \u539f\u59cb\u78bc\u5eab\u5305\u542b\u4e00\u500b\u7528\u65bc\u8a2d\u5b9a\u7684 SQL \u8173\u672c\u548c\u4e00\u500b\u7528\u65bc\u6e05\u7406\u7684\u8173\u672c\u3002\u8acb\u78ba\u4fdd\u5728\u4f86\u6e90 PostgreSQL \u8cc7\u6599\u5eab\u4e2d\u904b\u884c\u5b83\u5011\uff1a</p> <p>\u901a\u8fc7 psql \u6703\u8a71\u5b89\u88dd DDL \u89f8\u767c\u5668\u51fd\u6578\uff1a</p> <pre><code>psql -U &lt;user&gt; -d &lt;database&gt; &lt; postgres-connector-src-ddl-setup.sql\n</code></pre> <p>\u901a\u8fc7 psql \u6703\u8a71\u6e05\u7406 DDL \u89f8\u767c\u5668\u51fd\u6578\uff1a</p> <pre><code>psql -U &lt;user&gt; -d &lt;database&gt; &lt; postgres-connector-src-ddl-teardown.sql\n</code></pre> <p>\u5982\u679c\u60a8\u4e0d\u9700\u8981 DDL \u8907\u88fd\uff0c\u5247\u7121\u9700\u5728\u4f86\u6e90\u8cc7\u6599\u5eab\u5b89\u88dd\u6b64 DDL \u89f8\u767c\u5668\u51fd\u6578\u3002\u4f46\u662f\uff0c\u5982\u679c\u60a8\u60f3\u8981\u5c0d\u4f86\u6e90\u8cc7\u6599\u5eab\uff08\u76ee\u524d\u8868\u683c + \u8cc7\u6599\uff09\u9032\u884c\u76ee\u524d\u5feb\u7167\uff0c\u5247\u9700\u8981\u76ee\u524d LSN \u8996\u5716\u3002\u60a8\u7121\u9700\u8f09\u5165\u4e0a\u8ff0 SQL \u8173\u672c\uff0c\u5373\u53ef\u5c07\u5176\u65b0\u589e\u81f3\u4f86\u6e90\u8cc7\u6599\u5eab\u3002\u8acb\u78ba\u4fdd\u6b64\u8996\u5716\u662f\u5728 <code>public</code> \u6a21\u5f0f\u4e0b\u5efa\u7acb\u7684\u3002</p> <pre><code>CREATE VIEW synchdb_wal_lsn AS SELECT pg_current_wal_lsn()::pg_lsn AS wal_lsn;\n</code></pre>"},{"location":"zh/monitoring/attr_view/","title":"\u5c5e\u6027\u89c6\u56fe","text":""},{"location":"zh/monitoring/attr_view/#_2","title":"\u67e5\u770b\u8fde\u63a5\u5668\u7ba1\u7406\u7684\u5c5e\u6027","text":"<p>\u8fde\u63a5\u5668\u5b8c\u6210\u521d\u59cb\u8868\u5feb\u7167\u540e\uff0c\u6e90\u8868\u3001\u5217\u548c\u6570\u636e\u7c7b\u578b\u5c06\u6839\u636e\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u5728 PostgreSQL \u7aef\u8fdb\u884c\u8f6c\u6362\u548c\u521b\u5efa\u3002SynchDB \u63d0\u4f9b\u4e86\u4e00\u4e2a\u89c6\u56fe\uff0c\u53ef\u5e76\u6392\u663e\u793a\u8fde\u63a5\u5668\u7684\u6570\u636e\u7c7b\u578b\u3001\u540d\u79f0\u6620\u5c04\u4ee5\u53ca\u6e90\u8868\u548c\u76ee\u6807\u8868\u4e4b\u95f4\u7684\u8f6c\u6362\u89c4\u5219\u5173\u7cfb\u3002</p> <p>\u6b64\u89c6\u56fe\u4ec5\u4f9b\u53c2\u8003\uff0c\u65e8\u5728\u5411\u7528\u6237\u663e\u793a\u8fde\u63a5\u5668\u5f53\u524d\u6b63\u5728\u8ddf\u8e2a\u7684\u8868\u7684\u5217\u8868\u4ee5\u53ca\u6bcf\u4e2a\u8868/\u5217\u4f7f\u7528\u7684\u6620\u5c04/\u8f6c\u6362\u89c4\u5219\u3002</p> <pre><code>SELECT * FROM synchdb_att_view();\n</code></pre> <p>\u8fd4\u56de\u5b57\u6bb5\uff1a</p> \u5b57\u6bb5 \u63cf\u8ff0 \u7c7b\u578b <code>name</code> \u8fde\u63a5\u5668\u6807\u8bc6\u7b26 \u6587\u672c <code>attnum</code> \u5c5e\u6027\u7f16\u53f7 \u6574\u6570 <code>ext_tbname</code> \u8fdc\u7a0b\u663e\u793a\u7684\u8868\u540d \u6587\u672c <code>pg_tbname</code> PostgreSQL \u4e2d\u7684\u6620\u5c04\u8868\u540d \u6587\u672c <code>ext_attname</code> \u8fdc\u7a0b\u663e\u793a\u7684\u5217\u540d \u6587\u672c <code>pg_attname</code> PostgreSQL \u4e2d\u6620\u5c04\u7684\u5217\u540d \u6587\u672c <code>ext_atttypename</code> \u8fdc\u7a0b\u663e\u793a\u7684\u6570\u636e\u7c7b\u578b \u6587\u672c <code>pg_atttypename</code> PostgreSQL \u4e2d\u6620\u5c04\u7684\u6570\u636e\u7c7b\u578b \u6587\u672c <code>transform</code> \u8f6c\u6362\u8868\u8fbe\u5f0f \u6587\u672c <p>\u793a\u4f8b\u8f93\u51fa</p> <pre><code>SELECT * from synchdb_att_view;\n   name    | type  | attnum |         ext_tbname         |         pg_tbname          | ext_attname | pg_attname  | ext_atttypename | pg_atttypename |         transform\n-----------+-------+--------+----------------------------+----------------------------+-------------+-------------+-----------------+----------------+----------------------------\n mysqlconn | mysql |      1 | inventory.addresses        | inventory.addresses        | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.addresses        | inventory.addresses        | customer_id | customer_id | INT             | int4           |\n mysqlconn | mysql |      3 | inventory.addresses        | inventory.addresses        | street      | street      | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.addresses        | inventory.addresses        | city        | city        | VARCHAR         | varchar        |\n mysqlconn | mysql |      5 | inventory.addresses        | inventory.addresses        | state       | state       | VARCHAR         | varchar        |\n mysqlconn | mysql |      6 | inventory.addresses        | inventory.addresses        | zip         | zip         | VARCHAR         | varchar        |\n mysqlconn | mysql |      7 | inventory.addresses        | inventory.addresses        | type        | type        | ENUM            | text           |\n mysqlconn | mysql |      1 | inventory.customers        | schema1.people             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.customers        | schema1.people             | first_name  | first_name  | VARCHAR         | varchar        |\n mysqlconn | mysql |      3 | inventory.customers        | schema1.people             | last_name   | family_name | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.customers        | schema1.people             | email       | contact     | VARCHAR         | varchar        |\n mysqlconn | mysql |      1 | inventory.geom             | inventory.geom             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.geom             | inventory.geom             | g           | g           | GEOMETRY        | geometry       |\n mysqlconn | mysql |      3 | inventory.geom             | inventory.geom             | h           | h           | GEOMETRY        | text           |\n mysqlconn | mysql |      1 | inventory.products         | public.stuff               | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products         | public.stuff               | name        | name        | VARCHAR         | varchar        | '&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\n mysqlconn | mysql |      3 | inventory.products         | public.stuff               | description | description | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.products         | public.stuff               | weight      | weight      | FLOAT           | float4         |\n mysqlconn | mysql |      1 | inventory.products_on_hand | inventory.products_on_hand | product_id  | product_id  | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products_on_hand | inventory.products_on_hand | quantity    | quantity    | INT             | int8           |\n</code></pre>"},{"location":"zh/monitoring/jmx_exporter/#jmx-exporter_1","title":"\u4ec0\u4e48\u662f JMX Exporter","text":"<p>JMX Exporter\uff08\u4e5f\u79f0\u4e3a JMX Prometheus Java Agent\uff09\u662f\u4e00\u4e2a Java \u4ee3\u7406\uff0c\u5b83\u4ee5 Prometheus \u53ef\u4ee5\u6293\u53d6\u548c\u76d1\u63a7\u7684\u683c\u5f0f\u516c\u5f00 Java \u5e94\u7528\u7a0b\u5e8f\u7684 JMX \u6307\u6807\u3002\u5b83\u662f\u7531 Prometheus \u793e\u533a\u521b\u5efa\u7684\u4e00\u6b3e\u5de5\u5177\uff0c\u652f\u6301\u4ee5\u4e0b\u529f\u80fd\uff1a</p> <ul> <li>\u8bbf\u95ee JVM \u5185\u90e8\u6307\u6807\uff08\u4f8b\u5982\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\u3001\u7ebf\u7a0b\u6570\u3001GC \u7edf\u8ba1\u4fe1\u606f\u7b49\uff09</li> <li>\u901a\u8fc7 MBean \u516c\u5f00\u81ea\u5b9a\u4e49\u5e94\u7528\u7a0b\u5e8f\u6307\u6807</li> <li>\u901a\u8fc7 HTTP \u7aef\u70b9\u5bfc\u51fa\u8fd9\u4e9b\u6307\u6807\uff08\u4f8b\u5982 http://localhost:9404/metrics\uff09</li> <li>\u5c06 Java \u5e94\u7528\u7a0b\u5e8f\uff08\u4f8b\u5982 Kafka\u3001Cassandra \u6216\u60a8\u81ea\u5df1\u7684\u5e94\u7528\u7a0b\u5e8f\uff09\u96c6\u6210\u5230 Prometheus \u76d1\u63a7\u8bbe\u7f6e\u4e2d</li> </ul> <p>\u6b64\u5de5\u5177\u53ef\u89e3\u9501\u57fa\u4e8e Prometheus + Graphana \u7684 SynchDB \u8fde\u63a5\u5668\u76d1\u63a7\u529f\u80fd</p> <p></p>"},{"location":"zh/monitoring/jmx_exporter/#jmx","title":"\u83b7\u53d6 JMX \u5bfc\u51fa\u5668","text":"<p>\u9884\u7f16\u8bd1\u7684 JMX \u5bfc\u51fa\u5668 (.jar) \u53ef\u5728\u5b98\u65b9 JMX \u5bfc\u51fa\u5668\u53d1\u5e03\u9875\u9762 \u83b7\u53d6\u3002\u6211\u4eec\u611f\u5174\u8da3\u7684\u662f\u201cjmx_prometheus_javaagent\u201d\u5de5\u5177\uff0c\u4f8b\u5982\uff1a</p> <pre><code>jmx_prometheus_javaagent-1.3.0.jar\n</code></pre> <p>\u8bf7\u5c06\u5176\u4e0b\u8f7d\u5230\u8fd0\u884c SynchDB \u8fde\u63a5\u5668\u7684\u540c\u4e00\u53f0\u673a\u5668\u4e0a\u3002</p>"},{"location":"zh/monitoring/jmx_exporter/#jmx_1","title":"\u7f16\u5199 JMX \u5bfc\u51fa\u5668\u914d\u7f6e\u6587\u4ef6","text":"<p>JMX \u5bfc\u51fa\u5668\u9700\u8981\u4e00\u4e2a\u914d\u7f6e\u6587\u4ef6\u6765\u5b9a\u4e49\u66b4\u9732\u6307\u6807\u7684\u884c\u4e3a\u3002\u4ee5\u4e0b\u662f\u4e00\u4e2a\u57fa\u672c\u7684\u914d\u7f6e\u6a21\u677f\uff0c\u53ef\u5e2e\u52a9\u60a8\u5165\u95e8\u3002</p> <pre><code>startDelaySeconds: 0\nssl: false\nlowercaseOutputName: true\nlowercaseOutputLabelNames: true\n\nrules:\n  - pattern: \".*\"\n</code></pre> <p>\u6709\u5173\u66f4\u591a\u9ad8\u7ea7\u914d\u7f6e\u53c2\u6570\u53ca\u5176\u4f7f\u7528\u65b9\u6cd5\uff0c\u8bf7\u53c2\u9605\u5b98\u65b9 prometheus \u6587\u6863\u3002</p>"},{"location":"zh/monitoring/jmx_exporter/#jmx-synchdb","title":"\u5c06 JMX \u5bfc\u51fa\u5668\u914d\u7f6e\u5230 SynchDB \u8fde\u63a5\u5668","text":"<p>synchdb_add_jmx_exporter_conninfo() \u548c synchdb_del_jmx_exporter_conninfo() \u51fd\u6570\u7528\u4e8e\u5411\u73b0\u6709\u8fde\u63a5\u5668\u6dfb\u52a0\u6216\u5220\u9664 JMX \u5bfc\u51fa\u5668\u914d\u7f6e\u3002\u8fd9\u652f\u6301\u901a\u8fc7 Prometheus \u548c Graphana \u7b49\u5de5\u5177\u8fdb\u884c\u8fd0\u884c\u65f6\u76d1\u63a7\u548c\u8bca\u65ad\u3002</p> <p>\u51fd\u6570\u7b7e\u540d</p> <pre><code>synchdb_add_jmx_exporter_conninfo(\n    name TEXT,\n    exporter_jar_path TEXT,\n    exporter_port INTEGER,\n    config_file_path TEXT\n);\n\nsynchdb_del_jmx_exporter_conninfo(\n    name text\n)\n</code></pre> Parameter Type Description <code>connector_name</code> <code>TEXT</code> Name of the existing connector you want to attach the JMX Exporter to. <code>exporter_jar_path</code> <code>TEXT</code> Absolute path to the <code>jmx_prometheus_javaagent.jar</code> file. <code>exporter_port</code> <code>INT</code> Port on which the JMX Exporter HTTP server will expose metrics (e.g. 9404). <code>config_file_path</code> <code>TEXT</code> Path to the JMX Exporter's YAML configuration file we defined above. <pre><code>SELECT synchdb_add_jmx_exporter_conninfo(\n    'mysqlconn',    -- existing connector name\n    '/path/to/jmx_exporter/jar',        -- path to JMX exporter java agent jar\n    9404,           -- JMX exporter running port\n    '/path/to/jmx/conf');       -- path to JMX exporter conf file\n</code></pre>"},{"location":"zh/monitoring/jmx_exporter/#http","title":"\u901a\u8fc7 HTTP \u83b7\u53d6\u6307\u6807","text":"<p>\u5f53\u8fde\u63a5\u5668\u4f7f\u7528 JMX \u5bfc\u51fa\u5668\u8bbe\u7f6e\u542f\u52a8\u65f6\uff0c\u5b83\u5c06\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u516c\u5f00\u6307\u6807\uff1a</p> <pre><code>http://&lt;host&gt;:9404/metrics\n</code></pre> <p>\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u6d4b\u8bd5\uff1a <pre><code>curl http://&lt;host&gt;:9404/metrics\n\n# HELP debezium_mysql_connector_metrics_binlogposition debezium.mysql:name=null,type=connector-metrics,attribute=BinlogPosition\n# TYPE debezium_mysql_connector_metrics_binlogposition untyped\ndebezium_mysql_connector_metrics_binlogposition{context=\"streaming\",server=\"synchdb-connector\"} 1500.0\n# HELP debezium_mysql_connector_metrics_changesapplied debezium.mysql:name=null,type=connector-metrics,attribute=ChangesApplied\n# TYPE debezium_mysql_connector_metrics_changesapplied untyped\ndebezium_mysql_connector_metrics_changesapplied{context=\"schema-history\",server=\"synchdb-connector\"} 39.0\n# HELP debezium_mysql_connector_metrics_changesrecovered debezium.mysql:name=null,type=connector-metrics,attribute=ChangesRecovered\n# TYPE debezium_mysql_connector_metrics_changesrecovered untyped\ndebezium_mysql_connector_metrics_changesrecovered{context=\"schema-history\",server=\"synchdb-connector\"} 26.0\n# HELP debezium_mysql_connector_metrics_connected debezium.mysql:name=null,type=connector-metrics,attribute=Connected\n# TYPE debezium_mysql_connector_metrics_connected untyped\ndebezium_mysql_connector_metrics_connected{context=\"streaming\",server=\"synchdb-connector\"} 1.0\n\n...\n...\n...\n</code></pre></p>"},{"location":"zh/monitoring/jmx_exporter/#prometheus-graphana","title":"Prometheus \u548c Graphana","text":"<p>\u4e00\u65e6\u6211\u4eec\u786e\u8ba4\u53ef\u4ee5\u901a\u8fc7 HTTP \u83b7\u53d6\u6307\u6807\uff0c\u5c31\u53ef\u4ee5\u5c06\u6b64\u7aef\u70b9\u914d\u7f6e\u5230 Prometheus \u7cfb\u7edf\uff0c\u5e76\u8ba9\u5176\u201c\u6293\u53d6\u201d\u6240\u6709\u6307\u6807\u3002\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5728 graphana \u4e2d\u521b\u5efa\u4e00\u4e2a Prometheus \u6570\u636e\u6e90\uff0c\u5e76\u4f7f\u7528\u5b83\u521b\u5efa\u4e00\u4e2a\u4eea\u8868\u677f\u3002\u8bf7\u53c2\u9605 Prometheus \u548c graphana \u6559\u7a0b \u4e86\u89e3\u5982\u4f55\u64cd\u4f5c\u3002</p> <p>\u4e3a\u4e86\u5feb\u901f\u6d4b\u8bd5\uff0c\u60a8\u8fd8\u53ef\u4ee5\u4f7f\u7528 <code>ezdeploy</code> \u5de5\u5177\u5feb\u901f\u90e8\u7f72 prometheus \u548c grafana\uff0c\u5e76\u4f7f\u7528 Synchdb \u5185\u7f6e\u7684\u4eea\u8868\u677f\u6a21\u677f\u3002\u6709\u5173\u6a21\u5f0f\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 \u5feb\u901f\u5165\u95e8\u6307\u5357\u3002</p>"},{"location":"zh/monitoring/jmx_monitor/","title":"JMX MBEAN \u76d1\u63a7","text":""},{"location":"zh/monitoring/jmx_monitor/#jmxjava","title":"JMX\uff08Java \u7ba1\u7406\u6269\u5c55\uff09","text":"<p>JMX\uff0c\u5373 Java \u7ba1\u7406\u6269\u5c55\uff0c\u662f\u4e00\u79cd Java \u6280\u672f\uff0c\u63d0\u4f9b\u7528\u4e8e\u7ba1\u7406\u548c\u76d1\u63a7\u5e94\u7528\u7a0b\u5e8f\u3001\u7cfb\u7edf\u5bf9\u8c61\u3001\u8bbe\u5907\u548c\u9762\u5411\u670d\u52a1\u7684\u7f51\u7edc\u7684\u5de5\u5177\u3002\u5b83\u5141\u8bb8\u5f00\u53d1\u4eba\u5458\u516c\u5f00\u5e94\u7528\u7a0b\u5e8f\u4fe1\u606f\uff0c\u5e76\u5141\u8bb8\u5916\u90e8\u5de5\u5177\u8bbf\u95ee\u548c\u4ea4\u4e92\u8fd9\u4e9b\u4fe1\u606f\uff0c\u4ee5\u8fdb\u884c\u76d1\u63a7\u548c\u7ba1\u7406\u3002</p>"},{"location":"zh/monitoring/jmx_monitor/#debezium-jmx-mbean","title":"Debezium \u7684 JMX MBean","text":"<p>Debezium \u8fde\u63a5\u5668\u901a\u8fc7\u8fde\u63a5\u5668\u7684 MBean \u540d\u79f0\uff08MBean \u6807\u7b7e\u7b49\u4e8e\u8fde\u63a5\u5668\u540d\u79f0\uff09\u516c\u5f00\u6307\u6807\u3002\u8fd9\u4e9b\u6307\u6807\u7279\u5b9a\u4e8e\u6bcf\u4e2a\u8fde\u63a5\u5668\u5b9e\u4f8b\uff0c\u63d0\u4f9b\u6709\u5173\u8fde\u63a5\u5668\u5feb\u7167\u3001\u6d41\u5f0f\u4f20\u8f93\u548c\u6a21\u5f0f\u5386\u53f2\u8bb0\u5f55\u8fdb\u7a0b\u884c\u4e3a\u7684\u6570\u636e\u3002</p>"},{"location":"zh/monitoring/jmx_monitor/#synchdb_add_jmx_conninfo-jmx-synchdb_del_jmx_conninfo","title":"\u4f7f\u7528 synchdb_add_jmx_conninfo() \u5728\u8fde\u63a5\u5668\u4e0a\u542f\u7528 JMX\uff0c\u6216\u4f7f\u7528 synchdb_del_jmx_conninfo() \u7981\u7528","text":"<p>synchdb_add_jmx_conninfo() \u548c synchdb_del_jmx_conninfo() \u51fd\u6570\u7528\u4e8e\u5411\u73b0\u6709\u8fde\u63a5\u5668\u6dfb\u52a0\u6216\u5220\u9664 JMX \u76d1\u63a7\u914d\u7f6e\u3002\u8fd9\u5141\u8bb8\u901a\u8fc7 JConsole \u7b49\u5de5\u5177\u8fdb\u884c\u8fd0\u884c\u65f6\u76d1\u63a7\u548c\u8bca\u65ad\u3002</p> <p>\u51fd\u6570\u7b7e\u540d</p> <pre><code>synchdb_add_jmx_conninfo(\n    name text,\n    jmx_listenaddr text,\n    jmx_port integer,\n    jmx_rmiserveraddr text,\n    jmx_rmiport integer,\n    jmx_auth boolean,\n    jmx_auth_passwdfile text,\n    jmx_auth_accessfile text,\n    jmx_ssl boolean,\n    jmx_ssl_keystore text,\n    jmx_ssl_keystore_pass text,\n    jmx_ssl_truststore text,\n    jmx_ssl_truststore_pass text\n)\n\nsynchdb_del_jmx_conninfo(\n    name text\n)\n</code></pre> \u53c2\u6570 \u63cf\u8ff0 <code>name</code> (\u6587\u672c)\u8981\u6dfb\u52a0 JMX \u914d\u7f6e\u7684\u73b0\u6709\u8fde\u63a5\u5668\u7684\u540d\u79f0\u3002\u5fc5\u987b\u5df2\u5b58\u5728\u4e8e <code>synchdb_conninfo</code> \u4e2d\u3002 <code>jmx_listenaddr</code> (\u6587\u672c)JVM \u5c06\u5728\u5176\u4e0a\u4fa6\u542c JMX \u8fde\u63a5\u7684 IP \u5730\u5740\u3002\u4f7f\u7528 <code>'0.0.0.0'</code> \u4fa6\u542c\u6240\u6709\u7f51\u7edc\u63a5\u53e3\uff0c\u6216\u6307\u5b9a\u7279\u5b9a IP\u3002 <code>jmx_port</code> (\u6574\u6570)JMX \u901a\u4fe1\u7684\u672c\u5730\u7aef\u53e3\uff08\u7528\u4e8e\u5ba2\u6237\u7aef\u53d1\u73b0\uff09\u3002\u5fc5\u987b\u5904\u4e8e\u6253\u5f00\u72b6\u6001\u4e14\u672a\u4f7f\u7528\u3002 <code>jmx_rmiserveraddr</code> (\u6587\u672c)\u8fdc\u7a0b JMX \u5ba2\u6237\u7aef\uff08\u4f8b\u5982 JConsole\uff09\u7528\u4e8e\u8fde\u63a5 JVM \u7684\u516c\u5171/\u5916\u90e8 IP \u5730\u5740\u3002\u901a\u5e38\u8bbe\u7f6e\u4e3a\u4e3b\u673a\u7684\u5916\u90e8 IP\u3002 <code>jmx_rmiport</code> (\u6574\u6570)\u7528\u4e8e\u5b9e\u9645 JMX \u5bf9\u8c61\u901a\u4fe1\u7684 RMI \u670d\u52a1\u5668\u7aef\u53e3\u3002\u6b64\u7aef\u53e3\u4e5f\u5fc5\u987b\u5728\u9632\u706b\u5899\u548c\u7f51\u7edc\u8bbe\u7f6e\u4e2d\u6253\u5f00\u3002\u901a\u5e38\u4e0e <code>jmx_port</code> \u76f8\u540c\u3002 <code>jmx_auth</code> (\u5e03\u5c14\u503c)\u662f\u5426\u542f\u7528 JMX \u8eab\u4efd\u9a8c\u8bc1\uff1f\u5982\u679c\u4e3a <code>true</code>\uff0c\u5ba2\u6237\u7aef\u5fc5\u987b\u63d0\u4f9b\u5b58\u50a8\u5728\u4ee5\u4e0b\u6587\u4ef6\u4e2d\u7684\u7528\u6237\u540d/\u5bc6\u7801\u3002 <code>jmx_auth_passwdfile</code> (\u6587\u672c)\u7528\u4e8e JMX \u8eab\u4efd\u9a8c\u8bc1\u7684\u5bc6\u7801\u6587\u4ef6\u7684\u8def\u5f84\u3002\u5982\u679c\u4e0d\u4f7f\u7528\u8eab\u4efd\u9a8c\u8bc1\uff0c\u8bf7\u4f20\u9012 <code>'null'</code>\u3002 <code>jmx_auth_accessfile</code> (text)\u5b9a\u4e49\u89d2\u8272\uff08\u4f8b\u5982 <code>monitor</code>\u3001<code>control</code>\uff09\u7684\u8bbf\u95ee\u63a7\u5236\u6587\u4ef6\u7684\u8def\u5f84\u3002\u4ec5\u5728\u542f\u7528\u8eab\u4efd\u9a8c\u8bc1\u65f6\u624d\u9700\u8981\u3002\u5982\u679c\u4e0d\u4f7f\u7528\u8eab\u4efd\u9a8c\u8bc1\uff0c\u8bf7\u4f20\u9012 <code>'null'</code> <code>jmx_ssl</code> (boolean)\u662f\u5426\u4e3a JMX \u8fde\u63a5\u542f\u7528 SSL \u52a0\u5bc6\uff1f\u8bbe\u7f6e\u4e3a <code>true</code> \u4ee5\u786e\u4fdd\u901a\u4fe1\u5b89\u5168\u3002 <code>jmx_ssl_keystore</code> (text)\u5305\u542b\u670d\u52a1\u5668\u79c1\u94a5\u548c\u8bc1\u4e66\u7684\u5bc6\u94a5\u5e93\u6587\u4ef6\uff08JKS \u683c\u5f0f\uff09\u7684\u8def\u5f84\u3002\u5982\u679c <code>jmx_ssl = true</code>\uff0c\u5219\u4e3a\u5fc5\u586b\u9879\u3002 <code>jmx_ssl_keystore_pass</code> (text)\u5bc6\u94a5\u5e93\u6587\u4ef6\u7684\u5bc6\u7801\u3002 <code>jmx_ssl_truststore</code> (text)\u4fdd\u5b58\u53d7\u4fe1\u4efb CA \u8bc1\u4e66\u7684\u4fe1\u4efb\u5e93 (JKS) \u7684\u8def\u5f84\u3002\u5982\u679c\u914d\u7f6e\u4e86\u53cc\u5411 TLS\uff0c\u5219\u7528\u4e8e\u9a8c\u8bc1\u5ba2\u6237\u7aef\u8eab\u4efd\u3002 <code>jmx_ssl_truststore_pass</code> (\u6587\u672c)\u4fe1\u4efb\u5e93\u6587\u4ef6\u7684\u5bc6\u7801\u3002"},{"location":"zh/monitoring/jmx_monitor/#jmx","title":"JMX \u8eab\u4efd\u9a8c\u8bc1\u7684\u5bc6\u7801\u548c\u8bbf\u95ee\u6587\u4ef6","text":"<p>\u5728 JVM \u914d\u7f6e\u4e2d\u542f\u7528 JMX \u8eab\u4efd\u9a8c\u8bc1\uff08\u5373\u8bbe\u7f6e jmx_auth = true\uff09\u65f6\uff0c\u60a8\u5fc5\u987b\u63d0\u4f9b\u4e24\u4e2a\u6587\u4ef6\uff1a</p>"},{"location":"zh/monitoring/jmx_monitor/#_1","title":"\u5bc6\u7801\u6587\u4ef6\uff1a","text":"<p>\u6b64\u6587\u4ef6\u5b58\u50a8\u6709\u6548\u7684 JMX \u7528\u6237\u540d\u53ca\u5176\u5bf9\u5e94\u7684\u5bc6\u7801\u3002</p> <p>\u683c\u5f0f\uff1a</p> <pre><code># Format: username password\n&lt;username&gt; &lt;password&gt;\n</code></pre> <p>\u4f8b\u5b50\uff1a</p> <pre><code>monitorRole mySecretPassword\ncontrolRole anotherSecretPassword\n</code></pre>"},{"location":"zh/monitoring/jmx_monitor/#_2","title":"\u8bbf\u95ee\u6587\u4ef6\uff1a","text":"<p>\u6b64\u6587\u4ef6\u5b9a\u4e49\u4e86\u6bcf\u4e2a\u7528\u6237\u53ef\u4ee5\u901a\u8fc7 JMX \u6267\u884c\u7684\u64cd\u4f5c\u3002\u53ef\u80fd\u7684\u8bbf\u95ee\u7ea7\u522b\uff1a</p> <ul> <li>readonly \u2013 \u53ef\u4ee5\u67e5\u770b MBean\uff0c\u4f46\u4e0d\u80fd\u4fee\u6539\u3002</li> <li>readwrite \u2013 \u53ef\u4ee5\u67e5\u770b\u548c\u4fee\u6539 MBean\u3002</li> </ul> <p>\u683c\u5f0f\uff1a <pre><code># \u683c\u5f0f\uff1a\u7528\u6237\u540d \u8bbf\u95ee\u7ea7\u522b\n&lt;\u7528\u6237\u540d&gt; &lt;\u8bbf\u95ee\u6743\u9650&gt;\n</code></pre></p> <p>\u793a\u4f8b\uff1a <pre><code>monitorRole readonly\ncontrolRole readwrite\n</code></pre></p>"},{"location":"zh/monitoring/jmx_monitor/#_3","title":"\u6587\u4ef6\u6743\u9650\uff1a","text":"<p>\u786e\u4fdd\u4e24\u4e2a\u6587\u4ef6\u5747\u5f52\u8fd0\u884c JVM \u7684\u7528\u6237\u6240\u6709\uff0c\u4e14\u5177\u6709\u53d7\u9650\u7684\u6743\u9650\uff1a</p> <pre><code>chmod 600 jmxpwd.file jmxacc.file\nchown youruser:youruser jmxpwd.file jmxacc.file\n</code></pre>"},{"location":"zh/monitoring/jmx_monitor/#synchdb_add_jmx_conninfo","title":"synchdb_add_jmx_conninfo \u793a\u4f8b","text":"<p>\u542f\u7528\u65e0\u9700\u8eab\u4efd\u9a8c\u8bc1\u548c SSL \u7684 JMX MBean\uff1a</p> <pre><code>SELECT synchdb_add_jmx_conninfo(\n    'mysqlconn',    -- existing connector name\n    '0.0.0.0',      -- JMX listen address\n    9010,           -- JMX listen port\n    '10.55.13.17',  -- JMX RMI server address - for remote client connect\n    9010,           -- JMX RMI server port - for remoet client connect\n    false,          -- use authentication?\n    'null',         -- password file for authentication\n    'null',         -- access file for authentication\n    false,          -- use SSL?\n    'null',         -- SSL keystore path\n    'null',         -- SSL keystore password\n    'null',         -- SSL trust store\n    'null');        -- SSL trust store password\n</code></pre> <p>\u542f\u7528\u5e26\u6709\u8eab\u4efd\u9a8c\u8bc1\u7684 JMX MBean</p> <pre><code>SELECT synchdb_add_jmx_conninfo(\n    'mysqlconn',    -- existing connector name\n    '0.0.0.0',      -- JMX listen address\n    9010,           -- JMX listen port\n    '10.55.13.17',  -- JMX RMI server address - for remote client connect\n    9010,           -- JMX RMI server port - for remoet client connect\n    true,           -- use authentication?\n    '/path/to/passwd.file',         -- password file for authentication\n    '/path/to/access.file',         -- access file for authentication\n    false,          -- use SSL?\n    'null',         -- SSL keystore path\n    'null',         -- SSL keystore password\n    'null',         -- SSL trust store\n    'null');        -- SSL trust store password\n</code></pre> <p>\u542f\u7528\u5e26\u6709\u8eab\u4efd\u9a8c\u8bc1\u548c SSL \u7684 JMX MBean\uff0c\u65e0\u9700 SSL \u5ba2\u6237\u7aef\u9a8c\u8bc1</p> <pre><code>SELECT synchdb_add_jmx_conninfo(\n    'mysqlconn',    -- existing connector name\n    '0.0.0.0',      -- JMX listen address\n    9010,           -- JMX listen port\n    '10.55.13.17',  -- JMX RMI server address - for remote client connect\n    9010,           -- JMX RMI server port - for remoet client connect\n    true,           -- use authentication?\n    '/path/to/passwd.file',         -- password file for authentication\n    '/path/to/access.file',         -- access file for authentication\n    true,           -- use SSL?\n    '/path/to/keystore',            -- SSL keystore path\n    'keystorepass',         -- SSL keystore password\n    'null',         -- SSL trust store\n    'null');        -- SSL trust store password\n</code></pre> <p>\u542f\u7528\u5177\u6709\u8eab\u4efd\u9a8c\u8bc1\u548c SSL + SSL \u5ba2\u6237\u7aef\u9a8c\u8bc1\u7684 JMX MBean</p> <pre><code>SELECT synchdb_add_jmx_conninfo(\n    'mysqlconn',    -- existing connector name\n    '0.0.0.0',      -- JMX listen address\n    9010,           -- JMX listen port\n    '10.55.13.17',  -- JMX RMI server address - for remote client connect\n    9010,           -- JMX RMI server port - for remoet client connect\n    true,           -- use authentication?\n    '/path/to/passwd.file',         -- password file for authentication\n    '/path/to/access.file',         -- access file for authentication\n    true,           -- use SSL?\n    '/path/to/keystore',            -- SSL keystore path\n    'keystorepass',         -- SSL keystore password\n    '/path/to/truststore',          -- SSL trust store\n    'truststorepass');      -- SSL trust store password\n</code></pre>"},{"location":"zh/monitoring/jmx_monitor/#jconsole-jmx","title":"\u4f7f\u7528 jconsole \u53ef\u89c6\u5316 JMX \u6307\u6807","text":"<p>\u5f53\u542f\u52a8\u4e00\u4e2a\u914d\u7f6e\u4e86 JMX \u7684\u8fde\u63a5\u5668\u65f6\uff0cJMX \u670d\u52a1\u5c06\u5728\u6307\u5b9a\u7684\u7aef\u53e3\u53f7\u4e0a\u8fd0\u884c\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 Java \u53d1\u884c\u7248\u81ea\u5e26\u7684 jconsole \u8fde\u63a5\u5230 JMX \u670d\u52a1\u5668\u3002\u53ef\u4ee5\u901a\u8fc7 JVM\uff08\u8fde\u63a5\u5668\u5de5\u4f5c\u8fdb\u7a0b\uff09PID \u6216 IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u8fdb\u884c\u672c\u5730\u8fde\u63a5\u3002\u5982\u679c\u542f\u7528\u4e86\u8eab\u4efd\u9a8c\u8bc1\uff0c\u5219\u8fd8\u9700\u8981\u7528\u6237\u540d\u548c\u5bc6\u7801\u3002\u5982\u679c\u4e0d\u4f7f\u7528\u8eab\u4efd\u9a8c\u8bc1\uff0c\u5219\u8fd9\u4e9b\u53ef\u4ee5\u7559\u7a7a\u3002</p> <p></p> <p>\u8fde\u63a5\u6210\u529f\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u67e5\u770b JVM \u8fd0\u884c\u6307\u6807\u7684\u6240\u6709\u8be6\u7ec6\u4fe1\u606f\uff0c\u4f8b\u5982 CPU\u3001\u5185\u5b58\u3001\u7c7b\u5229\u7528\u7387\u3001\u7ebf\u7a0b\u6570\u7b49\u3002</p> <p> </p>"},{"location":"zh/monitoring/jmx_monitor/#debezium-jmx-mbean_1","title":"\u53ef\u89c6\u5316 Debezium JMX MBean","text":"<p>\u6700\u540e\u4e00\u4e2a\u9009\u9879\u5361\u662f MBean\uff0c\u5176\u4e2d\u5305\u542b Debezium \u9488\u5bf9\u67b6\u6784\u5386\u53f2\u8bb0\u5f55\u3001\u5feb\u7167\u548c\u6d41\u5f0f\u4f20\u8f93\u9636\u6bb5\u7684\u7279\u5b9a\u6307\u6807\u3002</p> <p> </p> <p>\u6839\u636e\u8fde\u63a5\u5668\u7c7b\u578b\uff0cMBean \u6307\u6807\u53ef\u80fd\u4f1a\u6709\u6240\u4e0d\u540c\u3002\u6709\u5173\u6355\u83b7\u6307\u6807\u5217\u8868\uff0c\u8bf7\u53c2\u9605 Debezium \u8fde\u63a5\u5668\u6587\u6863\uff1a</p> <ul> <li>MySQL \u7684 MBean</li> <li>SQL Server \u7684 MBean</li> <li>Oracle \u7684 MBean</li> </ul>"},{"location":"zh/monitoring/jvm_mem/","title":"JVM \u5185\u5b58\u4f7f\u7528\u60c5\u51b5","text":""},{"location":"zh/monitoring/jvm_mem/#jvm_1","title":"\u8f6c\u50a8 JVM \u5185\u5b58\u4f7f\u7528\u60c5\u51b5","text":"<p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5b9e\u7528\u51fd\u6570 <code>synchdb_log_jvm_meminfo</code> \u5c06\u5f53\u524d JVM \u7684\u5806\u5185\u5b58\u548c\u975e\u5806\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\u8f6c\u50a8\u5230\u65e5\u5fd7\u6587\u4ef6\u4e2d\u3002\u8fd9\u7eaf\u7cb9\u662f\u63d0\u4f9b\u4fe1\u606f\uff0c\u65e8\u5728\u8ba9\u7528\u6237\u4e86\u89e3\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\uff0c\u8fd9\u5bf9\u4e8e\u4e3a\u8fde\u63a5\u5668\u7684 JVM \u914d\u7f6e\u5408\u9002\u7684\u6700\u5927\u5806\u5185\u5b58\u503c\u53ef\u80fd\u5f88\u91cd\u8981\u3002 <pre><code>SELECT synchdb_log_jvm_meminfo('mysqlconn');\n</code></pre></p> <p>\u68c0\u67e5 PostgreSQL \u65e5\u5fd7\u6587\u4ef6\uff1a <pre><code>2024-12-09 14:34:21.910 PST [25491] LOG:  Requesting memdump for mysqlconn connector\n2024-12-09 14:34:21 WARN  DebeziumRunner:297 - Heap Memory:\n2024-12-09 14:34:21 WARN  DebeziumRunner:298 -   Used: 19272600 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:299 -   Committed: 67108864 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:300 -   Max: 2147483648 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:302 - Non-Heap Memory:\n2024-12-09 14:34:21 WARN  DebeziumRunner:303 -   Used: 42198864 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:304 -   Committed: 45023232 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:305 -   Max: -1 bytes\n</code></pre></p>"},{"location":"zh/monitoring/state_view/","title":"\u8fde\u63a5\u5668\u8fd0\u884c\u72b6\u6001","text":""},{"location":"zh/monitoring/state_view/#_2","title":"\u68c0\u67e5\u8fde\u63a5\u5668\u8fd0\u884c\u72b6\u6001","text":"<p>\u4f7f\u7528 <code>synchdb_state_view()</code> \u68c0\u67e5\u6240\u6709\u8fde\u63a5\u5668\u7684\u8fd0\u884c\u72b6\u6001\u3002</p> <p>\u8bf7\u53c2\u9605\u4ee5\u4e0b\u793a\u4f8b\u8f93\u51fa\uff1a <pre><code>postgres=# select * from synchdb_state_view;\n     name      | connector_type |  pid   |        stage        |  state  |   err    |                                           last_dbz_offset\n---------------+----------------+--------+---------------------+---------+----------+------------------------------------------------------------------------------------------------------\n sqlserverconn | sqlserver      | 579820 | change data capture | polling | no error | {\"commit_lsn\":\"0000006a:00006608:0003\",\"snapshot\":true,\"snapshot_completed\":false}\n mysqlconn     | mysql          | 579845 | change data capture | polling | no error | {\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}\n oracleconn    | oracle         | 580053 | change data capture | polling | no error | offset file not flushed yet\n(3 rows)\n</code></pre></p> <p>\u5217\u8be6\u60c5\uff1a</p> \u5b57\u6bb5 \u63cf\u8ff0 name \u7531 <code>synchdb_add_conninfo()</code> \u521b\u5efa\u7684\u5173\u8054\u8fde\u63a5\u5668\u4fe1\u606f\u540d\u79f0 connector_type \u8fde\u63a5\u5668\u7c7b\u578b\uff08mysql\u3001oracle\u3001sqlserver \u7b49\uff09 pid \u8fde\u63a5\u5668\u5de5\u4f5c\u8fdb\u7a0b\u7684 PID stage \u8fde\u63a5\u5668\u7684\u9636\u6bb5\u3002\u89c1\u4e0b\u6587\u3002 state \u8fde\u63a5\u5668\u7684\u72b6\u6001\u3002\u89c1\u4e0b\u6587\u3002 err \u5de5\u4f5c\u8fdb\u7a0b\u9047\u5230\u7684\u6700\u540e\u4e00\u4e2a\u53ef\u80fd\u5bfc\u81f4\u5176\u9000\u51fa\u7684\u9519\u8bef\u6d88\u606f\u3002\u6b64\u9519\u8bef\u53ef\u80fd\u6e90\u4e8e PostgreSQL \u5904\u7406\u66f4\u6539\u65f6\uff0c\u4e5f\u53ef\u80fd\u6e90\u4e8e Debezium \u8fd0\u884c\u5f15\u64ce\u8bbf\u95ee\u5f02\u6784\u6570\u636e\u5e93\u6570\u636e\u65f6\u3002 last_dbz_offset synchdb \u6355\u83b7\u7684\u6700\u540e\u4e00\u4e2a Debezium \u504f\u79fb\u91cf\u3002\u8bf7\u6ce8\u610f\uff0c\u8fd9\u53ef\u80fd\u65e0\u6cd5\u53cd\u6620\u8fde\u63a5\u5668\u5f15\u64ce\u7684\u5f53\u524d\u5b9e\u65f6\u504f\u79fb\u91cf\u503c\u3002\u76f8\u53cd\uff0c\u5b83\u663e\u793a\u4e3a\u4e00\u4e2a\u68c0\u67e5\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636e\u9700\u8981\u4ece\u6b64\u504f\u79fb\u91cf\u70b9\u91cd\u65b0\u542f\u52a8\u3002 <p>\u53ef\u80fd\u7684\u72b6\u6001\uff1a</p> <ul> <li>\ud83d\udd34 <code>stopped</code> - \u975e\u6d3b\u52a8</li> <li>\ud83d\udfe1 <code>initializing</code> - \u6b63\u5728\u542f\u52a8</li> <li>\ud83d\udfe0 <code>paused</code> - \u6682\u65f6\u505c\u6b62</li> <li>\ud83d\udfe2 <code>syncing</code> - \u6b63\u5728\u4e3b\u52a8\u8f6e\u8be2</li> <li>\ud83d\udd35 <code>parsing</code> - \u6b63\u5728\u5904\u7406\u4e8b\u4ef6</li> <li>\ud83d\udfe3 <code>converting</code> - \u6b63\u5728\u8f6c\u6362\u6570\u636e</li> <li>\u26aa <code>executing</code> - \u6b63\u5728\u5e94\u7528\u66f4\u6539</li> <li>\ud83d\udfe4 <code>updating offset</code> - \u6b63\u5728\u66f4\u65b0\u68c0\u67e5\u70b9</li> <li>\ud83d\udfe8 <code>restarting</code> - \u6b63\u5728\u91cd\u65b0\u521d\u59cb\u5316</li> <li>\u26aa <code>dumping memory</code> - JVM \u6b63\u5728\u51c6\u5907\u5c06\u5185\u5b58\u4fe1\u606f\u8f6c\u50a8\u5230\u65e5\u5fd7\u6587\u4ef6</li> <li>\u26ab <code>unknown</code> - \u4e0d\u786e\u5b9a\u72b6\u6001</li> </ul> <p>\u53ef\u80fd\u7684\u72b6\u6001\uff1a</p> <ul> <li><code>initial snapping</code> - \u8fde\u63a5\u5668\u6b63\u5728\u6267\u884c\u521d\u59cb\u5feb\u7167\uff08\u6784\u5efa\u8868\u7ed3\u6784\u4ee5\u53ca\u53ef\u9009\u7684\u521d\u59cb\u6570\u636e\uff09</li> <li><code>change data capture</code> - \u8fde\u63a5\u5668\u6b63\u5728\u6d41\u5f0f\u4f20\u8f93\u540e\u7eed\u8868\u66f4\u6539 (CDC)</li> <li><code>schema sync</code> - \u8fde\u63a5\u5668\u4ec5\u590d\u5236\u8868\u67b6\u6784\uff08\u65e0\u6570\u636e\uff09</li> </ul>"},{"location":"zh/monitoring/stats_view/","title":"\u9023\u63a5\u5668\u7d71\u8a08\u8a0a\u606f","text":""},{"location":"zh/monitoring/stats_view/#_2","title":"\u6aa2\u67e5\u9023\u63a5\u5668\u904b\u884c\u7d71\u8a08\u4fe1\u606f","text":"<p>SynchDB \u6703\u8a18\u9304\u6bcf\u500b\u9023\u63a5\u5668\u7684\u7d71\u8a08\u4fe1\u606f\u3002\u9019\u4e9b\u7d71\u8a08\u4fe1\u606f\u8207 Debezium \u6216 JVM \u57fa\u65bc JMX \u7684\u7d71\u8a08\u4e0d\u540c\uff0c\u5118\u7ba1\u5b83\u5011\u53ef\u80fd\u5177\u6709\u76f8\u4f3c\u6216\u91cd\u758a\u7684\u53c3\u6578\u3002</p> <p>\u7d71\u8a08\u4fe1\u606f\u5206\u70ba\u4e09\u985e\uff1a</p> <ul> <li>\u5e38\u898f\u7d71\u8a08\u4fe1\u606f</li> <li>\u5feb\u7167\u7d71\u8a08\u8a0a\u606f</li> <li>CDC \u7d71\u8a08\u4fe1\u606f</li> </ul> <p>\u8acb\u6ce8\u610f\uff0c\u9019\u4e9b\u7d71\u8a08\u4fe1\u606f\u4e0d\u662f\u6301\u4e45\u5316\u7684\uff0c\u5728 PostgreSQL \u91cd\u65b0\u555f\u52d5\u5f8c\u6703\u907a\u5931/\u91cd\u7f6e\u3002</p>"},{"location":"zh/monitoring/stats_view/#_3","title":"\u5e38\u898f\u7d71\u8a08\u4fe1\u606f","text":"<p>\u900f\u904e synchdb_genstats \u8996\u5716\u53d6\u5f97\uff1a <pre><code>select * from synchdb_genstats;\n\n  name   | bad_events | total_events | batches_done | average_batch_size | first_src_ts  |  first_pg_ts  |  last_src_ts  |  last_pg_ts\n---------+------------+--------------+--------------+--------------------+---------------+---------------+---------------+---------------\n olrconn |        191 |          453 |           14 |                 32 | 1761170446000 | 1761170450120 | 1761170448000 | 1761170450120\n(1 row)\n</code></pre></p> <p>\u5217\u8a73\u60c5\uff1a</p> \u5b57\u6bb5 \u63cf\u8ff0 \u540d\u7a31 \u7531 <code>synchdb_add_conninfo()</code> \u5efa\u7acb\u7684\u95dc\u806f\u9023\u63a5\u5668\u8cc7\u8a0a\u540d\u7a31 bad_events \u5ffd\u7565\u7684\u932f\u8aa4\u4e8b\u4ef6\u6578\u91cf\uff08\u4f8b\u5982\u7a7a\u4e8b\u4ef6\u3001\u4e0d\u652f\u63f4\u7684 DDL \u4e8b\u4ef6\u7b49\uff09 total_events \u5df2\u8655\u7406\u7684\u4e8b\u4ef6\u7e3d\u6578\uff08\u5305\u62ec bad_events\uff09 batches_done \u5df2\u5b8c\u6210\u7684\u6279\u6b21\u6578 average_batch_size \u5e73\u5747\u6279\u6b21\u5927\u5c0f (total_events / batches_done) first_src_ts \u6700\u5f8c\u4e00\u500b\u6279\u6b21\u7684\u7b2c\u4e00\u500b\u4e8b\u4ef6\u5728\u5916\u90e8\u8cc7\u6599\u5eab\u7522\u751f\u7684\u6642\u9593\u6233\u8a18\uff08\u4ee5\u6beb\u79d2\u70ba\u55ae\u4f4d\uff09 first_pg_ts \u6700\u5f8c\u4e00\u500b\u6279\u6b21\u7684\u7b2c\u4e00\u500b\u4e8b\u4ef6\u61c9\u7528\u5230 PostgreSQL \u7684\u6642\u9593\u6233\uff08\u4ee5\u6beb\u79d2\u70ba\u55ae\u4f4d\uff09 last_src_ts \u6700\u5f8c\u4e00\u500b\u6279\u6b21\u7684\u6700\u5f8c\u4e00\u500b\u4e8b\u4ef6\u5728\u5916\u90e8\u8cc7\u6599\u5eab\u7522\u751f\u7684\u6642\u9593\u6233\u8a18\uff08\u4ee5\u6beb\u79d2\u70ba\u55ae\u4f4d\uff09 last_pg_ts \u6700\u5f8c\u4e00\u500b\u6279\u6b21\u7684\u6700\u5f8c\u4e00\u500b\u4e8b\u4ef6\u61c9\u7528\u5230 PostgreSQL \u7684\u6642\u9593\u6233\uff08\u4ee5\u6beb\u79d2\u70ba\u55ae\u4f4d\uff09"},{"location":"zh/monitoring/stats_view/#_4","title":"\u5feb\u7167\u7d71\u8a08\u4fe1\u606f","text":"<p>\u900f\u904e synchdb_snapstats \u8996\u5716\u53d6\u5f97\uff1a <pre><code>select * from synchdb_snapstats;\n\n  name   | tables |  rows  | snapshot_begin_ts | snapshot_end_ts\n---------+--------+--------+-------------------+-----------------\n olrconn |      2 | 100032 |     1761160017191 |   1761160033250\n(1 row)\n</code></pre></p> <p>\u5217\u8a73\u60c5\uff1a</p> \u5b57\u6bb5 \u63cf\u8ff0 \u540d\u7a31 \u7531 <code>synchdb_add_conninfo()</code> \u5efa\u7acb\u7684\u95dc\u806f\u9023\u63a5\u5668\u8cc7\u8a0a\u540d\u7a31 \u8868 \u5feb\u7167\u904e\u7a0b\u4e2d\u9077\u79fb\u7684\u8868\u683c\u6a21\u5f0f\u6578\u91cf \u884c \u5feb\u7167\u904e\u7a0b\u4e2d\u9077\u79fb\u7684\u884c\u6578 \u5feb\u7167\u958b\u59cb\u6642\u9593 \u5feb\u7167\u958b\u59cb\u6642\u9593\u7684\u6642\u9593\u6233\u8a18\uff08\u4ee5\u6beb\u79d2\u70ba\u55ae\u4f4d\uff09 \u5feb\u7167\u7d50\u675f\u6642\u9593 \u5feb\u7167\u7d50\u675f\u6642\u9593\u7684\u6642\u9593\u6233\u8a18\uff08\u4ee5\u6beb\u79d2\u70ba\u55ae\u4f4d\uff09"},{"location":"zh/monitoring/stats_view/#cdc","title":"CDC \u7d71\u8a08\u4fe1\u606f","text":"<p>\u900f\u904e synchdb_cdcstats \u8996\u5716\u53d6\u5f97\uff1a <pre><code>select * from synchdb_cdcstats;\n\n  name   | ddls | dmls | creates | updates | deletes | txs | truncates\n---------+------+------+---------+---------+---------+-----+-----------\n olrconn |  161 |  124 |      10 |      47 |      67 | 562 |         0\n(1 row)\n</code></pre></p> <p>\u5217\u8a73\u60c5\uff1a</p> \u5b57\u6bb5 \u63cf\u8ff0 name \u7531 <code>synchdb_add_conninfo()</code> \u5efa\u7acb\u7684\u95dc\u806f\u9023\u63a5\u5668\u8cc7\u8a0a\u540d\u7a31 ddls \u5df2\u5b8c\u6210\u7684 DDL \u904b\u7b97\u5143 dmls \u5df2\u5b8c\u6210\u7684 DML \u904b\u7b97\u5143 creates CDC \u968e\u6bb5\u5b8c\u6210\u7684 CREATES \u4e8b\u4ef6\u6578 updates CDC \u968e\u6bb5\u5b8c\u6210\u7684 UPDATES \u4e8b\u4ef6\u6578 deletes CDC \u968e\u6bb5\u5b8c\u6210\u7684 DELETES \u4e8b\u4ef6\u6578 txs \u8655\u7406\u7684\u4e8b\u52d9\u4e8b\u4ef6\u6578\uff0c\u4f8b\u5982 begin \u548c commit truncates \u8655\u7406\u7684 truncate \u4e8b\u4ef6\u6578"},{"location":"zh/monitoring/stats_view/#synchdb_reset_stats","title":"synchdb_reset_stats","text":"<p>\u7528\u9014\uff1a\u91cd\u7f6e\u6307\u5b9a\u9023\u63a5\u5668\u540d\u7a31\u7684\u6240\u6709\u7d71\u8a08\u4fe1\u606f</p> <pre><code>SELECT synchdb_reset_stats('olrconn');\n</code></pre>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#synchdb-mysql","title":"\u4e3a SynchDB \u51c6\u5907 MySQL \u6570\u636e\u5e93","text":"<p>\u5728\u4f7f\u7528 SynchDB \u4ece MySQL \u590d\u5236\u4e4b\u524d\uff0c\u9700\u8981\u6309\u7167\u6b64\u5904 \u6982\u8ff0\u7684\u6b65\u9aa4\u914d\u7f6e MySQL</p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#mysql","title":"\u521b\u5efa MySQL \u8fde\u63a5\u5668","text":"<p>\u521b\u5efa\u4e00\u4e2a\u8fde\u63a5\u5668\uff0c\u8be5\u8fde\u63a5\u5668\u6307\u5411 MySQL \u4e2d <code>inventory</code> \u6570\u636e\u5e93\u4e0b\u7684\u6240\u6709\u8868\u3002 <pre><code>SELECT synchdb_add_conninfo(\n'mysqlconn', '127.0.0.1', 3306, 'mysqluser',\n'mysqlpwd', 'inventory', 'postgres',\n'null', 'null', 'mysql');\n</code></pre></p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#_1","title":"\u521d\u59cb\u5feb\u7167","text":"<p>SynchDB \u4e2d\u7684\u300c\u521d\u59cb\u5feb\u7167\u300d\uff08\u6216\u8868\u5feb\u7167\uff09\u662f\u6307\u8907\u88fd\u6240\u6709\u6307\u5b9a\u8868\u7684\u8868\u7d50\u69cb\u548c\u521d\u59cb\u8cc7\u6599\u3002\u9019\u985e\u4f3c\u65bc PostgreSQL \u908f\u8f2f\u8907\u88fd\u4e2d\u7684\u300c\u8868\u540c\u6b65\u300d\u3002\u7576\u4f7f\u7528\u9810\u8a2d\u7684 <code>initial</code> \u6a21\u5f0f\u555f\u52d5\u9023\u63a5\u5668\u6642\uff0c\u5b83\u6703\u5728\u9032\u5165\u8b8a\u66f4\u8cc7\u6599\u64f7\u53d6 (CDC) \u968e\u6bb5\u4e4b\u524d\u81ea\u52d5\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u53ef\u4ee5\u4f7f\u7528 <code>never</code> \u6a21\u5f0f\u5b8c\u5168\u7701\u7565\u6b64\u6b65\u9a5f\uff0c\u6216\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u90e8\u5206\u7701\u7565\u6b64\u6b65\u9a5f\u3002\u6709\u95dc\u6240\u6709\u5feb\u7167\u9078\u9805\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c\u9023\u63a5\u5668\u5728\u5f8c\u7e8c\u91cd\u65b0\u555f\u52d5\u6642\u4e0d\u6703\u518d\u6b21\u57f7\u884c\u6b64\u64cd\u4f5c\uff0c\u800c\u662f\u76f4\u63a5\u5f9e\u4e0a\u6b21\u672a\u5b8c\u6210\u7684\u504f\u79fb\u91cf\u8655\u6062\u5fa9 CDC\u3002\u6b64\u884c\u70ba\u7531 Debezium \u5f15\u64ce\u7ba1\u7406\u7684\u5143\u8cc7\u6599\u6a94\u6848\u63a7\u5236\u3002\u6709\u95dc\u5143\u8cc7\u6599\u6a94\u6848\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#_2","title":"\u4e0d\u540c\u7684\u9023\u63a5\u5668\u555f\u52d5\u6a21\u5f0f","text":""},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#cdc","title":"\u521d\u59cb\u5feb\u7167 + CDC","text":"<p>\u4f7f\u7528 <code>initial</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u5bf9\u6240\u6709\u6307\u5b9a\u8868\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a\u6240\u6709\u8868\uff09\u6267\u884c\u521d\u59cb\u5feb\u7167\u3002\u5b8c\u6210\u540e\uff0c\u53d8\u66f4\u6570\u636e\u6355\u83b7 (CDC) \u8fdb\u7a0b\u5c06\u5f00\u59cb\u6d41\u5f0f\u4f20\u8f93\u65b0\u7684\u53d8\u66f4\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'initial');\n\n\u6216\n\nSELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre> <p>The stage of this connector should be in <code>initial snapshot</code> the first time it runs: <pre><code>postgres=# select * from synchdb_state_view;\n    name    | connector_type |  pid   |      stage       |  state  |   err    |                      last_dbz_offs\net\n------------+----------------+--------+------------------+---------+----------+-----------------------------------\n-------------------------\n mysqlconn  | mysql          | 522195 | initial snapshot | polling | no error | {\"ts_sec\":1750375008,\"file\":\"mysql\n-bin.000003\",\"pos\":1500}\n</code></pre></p> <p>A new schema called <code>inventory</code> will be created and all tables streamed by the connector will be replicated under that schema. <pre><code>postgres=# set search_path=inventory;\nSET\npostgres=# \\d\n                    List of relations\n  Schema   |          Name           |   Type   | Owner\n-----------+-------------------------+----------+--------\n inventory | addresses               | table    | ubuntu\n inventory | addresses_id_seq        | sequence | ubuntu\n inventory | customers               | table    | ubuntu\n inventory | customers_id_seq        | sequence | ubuntu\n inventory | geom                    | table    | ubuntu\n inventory | geom_id_seq             | sequence | ubuntu\n inventory | orders                  | table    | ubuntu\n inventory | orders_order_number_seq | sequence | ubuntu\n inventory | products                | table    | ubuntu\n inventory | products_id_seq         | sequence | ubuntu\n inventory | products_on_hand        | table    | ubuntu\n</code></pre></p> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u540e\uff0c\u5982\u679c\u81f3\u5c11\u6709\u4e00\u6761\u540e\u7eed\u66f4\u6539\u88ab\u63a5\u6536\u5e76\u5904\u7406\uff0c\u8fde\u63a5\u5668\u9636\u6bb5\u5c06\u4ece\u201c\u521d\u59cb\u5feb\u7167\u201d\u5207\u6362\u4e3a\u201c\u53d8\u66f4\u6570\u636e\u6355\u83b7\u201d\u3002 <pre><code>postgres=# select * from synchdb_state_view;\n    name    | connector_type |  pid   |        stage        |  state  |   err    |                      last_dbz_o\nffset\n------------+----------------+--------+---------------------+---------+----------+--------------------------------\n----------------------------\n mysqlconn  | mysql          | 522195 | change data capture | polling | no error | {\"ts_sec\":1750375008,\"file\":\"my\nsql-bin.000003\",\"pos\":1500}\n</code></pre></p> <p>\u8fd9\u610f\u5473\u7740\u8fde\u63a5\u5668\u73b0\u5728\u6b63\u5728\u6d41\u5f0f\u4f20\u8f93\u6307\u5b9a\u8868\u7684\u65b0\u66f4\u6539\u3002\u4ee5\u201c\u521d\u59cb\u201d\u6a21\u5f0f\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4ece\u4e0a\u6b21\u6210\u529f\u70b9\u5f00\u59cb\u7ee7\u7eed\u590d\u5236\uff0c\u5e76\u4e14\u4e0d\u4f1a\u91cd\u65b0\u8fd0\u884c\u521d\u59cb\u5feb\u7167\u3002</p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#cdc_1","title":"\u4ec5\u521d\u59cb\u5feb\u7167\uff0c\u65e0 CDC","text":"<p>\u4f7f\u7528 <code>initial_only</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4ec5\u5bf9\u6240\u6709\u6307\u5b9a\u8868\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a\u5168\u90e8\uff09\u6267\u884c\u521d\u59cb\u5feb\u7167\uff0c\u4e4b\u540e\u5c06\u4e0d\u518d\u6267\u884c CDC\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'initial_only');\n</code></pre> <p>\u8fde\u63a5\u5668\u4f3c\u4e4e\u4ecd\u5728\u201c\u8f6e\u8be2\u201d\u5176\u4ed6\u8fde\u63a5\u5668\uff0c\u4f46\u4e0d\u4f1a\u6355\u83b7\u4efb\u4f55\u66f4\u6539\uff0c\u56e0\u4e3a Debzium \u5185\u90e8\u5df2\u505c\u6b62 CDC\u3002\u60a8\u53ef\u4ee5\u9009\u62e9\u5173\u95ed\u5b83\u3002\u5728 <code>initial_only</code> \u6a21\u5f0f\u4e0b\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u4e0d\u4f1a\u91cd\u5efa\u8868\uff0c\u56e0\u4e3a\u5b83\u4eec\u5df2\u7ecf\u6784\u5efa\u597d\u4e86\u3002</p> <pre><code>postgres=# select * from synchdb_state_view;\n    name    | connector_type |  pid   |      stage       |  state  |   err    |       last_dbz_offset\n------------+----------------+--------+------------------+---------+----------+-----------------------------\n mysqlconn  | mysql          | 522330 | initial snapshot | polling | no error | offset file not flushed yet\n</code></pre>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#cdc_2","title":"\u4ec5\u6355\u83b7\u8868\u6a21\u5f0f + CDC","text":"<p>\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4ec5\u6267\u884c\u6a21\u5f0f\u6355\u83b7\uff0c\u5728 PostgreSQL \u4e2d\u6784\u5efa\u76f8\u5e94\u7684\u8868\uff0c\u5e76\u4e14\u4e0d\u4f1a\u590d\u5236\u73b0\u6709\u8868\u6570\u636e\uff08\u8df3\u8fc7\u521d\u59cb\u5feb\u7167\uff09\u3002\u6a21\u5f0f\u6355\u83b7\u5b8c\u6210\u540e\uff0c\u8fde\u63a5\u5668\u5c06\u8fdb\u5165 CDC \u6a21\u5f0f\uff0c\u5e76\u5f00\u59cb\u6355\u83b7\u5bf9\u8868\u7684\u540e\u7eed\u66f4\u6539\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'no_data');\n</code></pre> <p>\u5728 <code>no_data</code> \u6a21\u5f0f\u4e0b\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4e0d\u4f1a\u518d\u6b21\u91cd\u5efa\u6a21\u5f0f\uff0c\u5e76\u4e14\u5b83\u5c06\u4ece\u4e0a\u6b21\u6210\u529f\u70b9\u6062\u590d CDC\u3002</p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#cdc_3","title":"\u4ec5 CDC","text":"<p>\u4f7f\u7528 <code>never</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u5b8c\u5168\u8df3\u8fc7\u6a21\u5f0f\u6355\u83b7\u548c\u521d\u59cb\u5feb\u7167\uff0c\u5e76\u8fdb\u5165 CDC \u6a21\u5f0f\u4ee5\u6355\u83b7\u540e\u7eed\u66f4\u6539\u3002\u8bf7\u6ce8\u610f\uff0c\u8fde\u63a5\u5668\u8981\u6c42\u5728\u4ee5 <code>never</code> \u6a21\u5f0f\u542f\u52a8\u4e4b\u524d\uff0c\u6240\u6709\u6355\u83b7\u8868\u90fd\u5df2\u5728 PostgreSQL \u4e2d\u521b\u5efa\u3002\u5982\u679c\u8868\u4e0d\u5b58\u5728\uff0c\u8fde\u63a5\u5668\u5728\u5c1d\u8bd5\u5c06 CDC \u66f4\u6539\u5e94\u7528\u4e8e\u4e0d\u5b58\u5728\u7684\u8868\u65f6\u5c06\u9047\u5230\u9519\u8bef\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'never');\n</code></pre> <p>\u4ee5\u201cnever\u201d\u6a21\u5f0f\u91cd\u542f\u8fde\u63a5\u5668\u5c06\u4ece\u4e0a\u6b21\u6210\u529f\u70b9\u5f00\u59cb\u6062\u590d CDC\u3002</p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#cdc_4","title":"\u59cb\u7ec8\u6267\u884c\u521d\u59cb\u5feb\u7167 + CDC","text":"<p>\u4f7f\u7528 <code>always</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u59cb\u7ec8\u6355\u83b7\u6355\u83b7\u8868\u7684\u6a21\u5f0f\uff0c\u59cb\u7ec8\u91cd\u505a\u521d\u59cb\u5feb\u7167\uff0c\u7136\u540e\u8f6c\u5230 CDC\u3002\u8fd9\u7c7b\u4f3c\u4e8e\u91cd\u7f6e\u6309\u94ae\uff0c\u56e0\u4e3a\u4f7f\u7528\u6b64\u6a21\u5f0f\u5c06\u91cd\u5efa\u6240\u6709\u5185\u5bb9\u3002\u8bf7\u8c28\u614e\u4f7f\u7528\uff0c\u5c24\u5176\u662f\u5728\u6355\u83b7\u5927\u91cf\u8868\u65f6\uff0c\u8fd9\u53ef\u80fd\u9700\u8981\u5f88\u957f\u65f6\u95f4\u624d\u80fd\u5b8c\u6210\u3002\u91cd\u5efa\u540e\uff0cCDC \u5c06\u6062\u590d\u6b63\u5e38\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre> <p>\u4f46\u662f\uff0c\u53ef\u4ee5\u4f7f\u7528\u8fde\u63a5\u5668\u7684 <code>snapshottable</code> \u9009\u9879\u9009\u62e9\u90e8\u5206\u8868\u6765\u91cd\u505a\u521d\u59cb\u5feb\u7167\u3002\u7b26\u5408 <code>snapshottable</code> \u4e2d\u6761\u4ef6\u7684\u8868\u5c06\u91cd\u505a\u521d\u59cb\u5feb\u7167\uff0c\u5426\u5219\u5c06\u8df3\u8fc7\u5176\u521d\u59cb\u5feb\u7167\u3002\u5982\u679c <code>snapshottable</code> \u4e3a null \u6216\u4e3a\u7a7a\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u8fde\u63a5\u5668 <code>table</code> \u9009\u9879\u4e2d\u6307\u5b9a\u7684\u6240\u6709\u8868\u90fd\u5c06\u5728 <code>always</code> \u6a21\u5f0f\u4e0b\u91cd\u505a\u521d\u59cb\u5feb\u7167\u3002</p> <p>\u6b64\u793a\u4f8b\u4f7f\u8fde\u63a5\u5668\u4ec5\u91cd\u505a <code>inventory.customers</code> \u8868\u7684\u521d\u59cb\u5feb\u7167\u3002\u6240\u6709\u5176\u4ed6\u8868\u7684\u5feb\u7167\u5c06\u88ab\u8df3\u8fc7\u3002 <pre><code>UPDATE synchdb_conninfo\nSET data = jsonb_set(data, '{snapshottable}', '\"inventory.customers\"')\nWHERE name = 'mysqlconn';\n</code></pre></p> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u540e\uff0cCDC \u5c06\u5f00\u59cb\u3002\u5728 <code>always</code> \u6a21\u5f0f\u4e0b\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\u3002</p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#mysql_1","title":"MySQL \u9023\u63a5\u5668\u7684\u53ef\u7528\u5feb\u7167\u6a21\u5f0f","text":"<ul> <li>initial (default)</li> <li>initial_only</li> <li>no_data</li> <li>never</li> <li>always</li> <li>schemasync</li> </ul>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#schemasync","title":"\u4f7f\u7528 schemasync \u6a21\u5f0f\u9810\u89bd\u4f86\u6e90\u8868\u548c\u76ee\u6a19\u8868\u95dc\u4fc2","text":"<p>\u5728\u5617\u8a66\u5c0d\u7576\u524d\u8868\u548c\u8cc7\u6599\uff08\u53ef\u80fd\u975e\u5e38\u9f90\u5927\uff09\u9032\u884c\u521d\u59cb\u5feb\u7167\u4e4b\u524d\uff0c\u53ef\u4ee5\u5728\u5be6\u969b\u8cc7\u6599\u9077\u79fb\u4e4b\u524d\u300c\u9810\u89bd\u300d\u4f86\u6e90\u8868\u548c\u76ee\u6a19\u8868\u4e4b\u9593\u7684\u6240\u6709\u8868\u548c\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u3002\u9019\u6a23\uff0c\u60a8\u5c31\u6709\u6a5f\u6703\u5728\u5be6\u969b\u9077\u79fb\u4e4b\u524d\u4fee\u6539\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u6216\u7269\u4ef6\u540d\u7a31\u3002\u9019\u53ef\u4ee5\u900f\u904e\u7279\u6b8a\u7684\u300cschemasync\u300d\u521d\u59cb\u5feb\u7167\u6a21\u5f0f\u4f86\u5be6\u73fe\u3002\u6709\u95dc\u8a73\u7d30\u7bc4\u4f8b\uff0c\u8acb\u53c3\u95b1\u5bf9\u8c61\u6620\u5c04\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#_3","title":"\u9078\u64c7\u6027\u8868\u540c\u6b65","text":""},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#_4","title":"\u9078\u64c7\u6240\u9700\u8868\u4e26\u9996\u6b21\u555f\u52d5\u540c\u6b65","text":"<p>\u8868\u683c\u9078\u64c7\u5728\u9023\u63a5\u5668\u5efa\u7acb\u968e\u6bb5\u900f\u904e <code>synchdb_add_conninfo()</code> \u51fd\u6578\u5b8c\u6210\uff0c\u8a72\u51fd\u6578\u7528\u65bc\u6307\u5b9a\u8981\u5f9e\u4e2d\u8907\u88fd\u7684\u8868\u5217\u8868\uff08\u4ee5\u5b8c\u5168\u9650\u5b9a\u540d\u7a31 (FQN) \u8868\u793a\uff0c\u4e26\u4ee5\u9017\u865f\u5206\u9694\uff09\u3002</p> <p>\u4f8b\u5982\uff0c\u4ee5\u4e0b\u547d\u4ee4\u5efa\u7acb\u4e00\u500b\u9023\u63a5\u5668\uff0c\u8a72\u9023\u63a5\u5668\u50c5\u5f9e\u9060\u7aef MySQL \u8cc7\u6599\u5eab\u8907\u88fd <code>inventory.orders</code> \u548c <code>inventory.products</code> \u8868\u4e2d\u7684\u8b8a\u66f4\u3002 <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', \n    '127.0.0.1', \n    3306, \n    'mysqluser', \n    'mysqlpwd', \n    'inventory', \n    'null', \n    'inventory.orders,inventory.products', \n    'null', \n    'mysql'\n);\n</code></pre></p> <p>\u9996\u6b21\u555f\u52d5\u6b64\u9023\u63a5\u5668\u6642\uff0c\u5c07\u89f8\u767c\u57f7\u884c\u521d\u59cb\u5feb\u7167\uff0c\u4e26\u8907\u88fd\u9078\u5b9a\u7684 2 \u500b\u8868\u7684\u67b6\u69cb\u548c\u8cc7\u6599\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#_5","title":"\u9a57\u8b49\u9023\u63a5\u5668\u72c0\u614b\u548c\u8868\u683c","text":"<p>\u6aa2\u67e5\u9023\u63a5\u5668\u72c0\u614b\u548c\u65b0\u8868\u683c\uff1a</p> <pre><code>postgres=# Select name, state, err from synchdb_state_view;\n     name      |  state  |   err\n---------------+---------+----------\n mysqlconn     | polling | no error\n(1 row)\n\npostgres=# \\dt inventory.*\n            List of tables\n  Schema   |   Name   | Type  | Owner\n-----------+----------+-------+--------\n inventory | orders   | table | ubuntu\n inventory | products | table | ubuntu\n</code></pre> <p>\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c<code>mysqlconn</code> \u9023\u63a5\u5668\u5c07\u7e7c\u7e8c\u64f7\u53d6 <code>inventory.orders</code> \u548c <code>inventory.products</code> \u8868\u7684\u5f8c\u7e8c\u8b8a\u66f4\u3002</p>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#_6","title":"\u904b\u884c\u6642\u52a0\u5165\u66f4\u591a\u8981\u8907\u88fd\u7684\u8868","text":"<p>\u4e0a\u4e00\u7bc0\u4e2d\u7684 <code>mysqlconn</code> \u5df2\u5b8c\u6210\u521d\u59cb\u5feb\u7167\u4e26\u53d6\u5f97\u4e86\u6240\u9078\u8868\u683c\u7684\u8868\u683c\u7d50\u69cb\u3002\u5982\u679c\u6211\u5011\u60f3\u8981\u65b0\u589e\u66f4\u591a\u8981\u8907\u88fd\u7684\u8868\uff0c\u5247\u9700\u8981\u901a\u77e5 Debezium \u5f15\u64ce\u66f4\u65b0\u4e86\u8868\u7d50\u69cb\uff0c\u4e26\u518d\u6b21\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u5177\u9ad4\u64cd\u4f5c\u5982\u4e0b\uff1a</p> <ol> <li> <p>\u66f4\u65b0 <code>synchdb_conninfo</code> \u8868\u4ee5\u5305\u542b\u5176\u4ed6\u8868\u3002</p> </li> <li> <p>\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u5011\u5c07 <code>inventory.customers</code> \u8868\u52a0\u5165\u540c\u6b65\u6e05\u55ae\uff1a <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"inventory.orders,inventory.products,inventory.customers\"') \nWHERE name = 'mysqlconn';\n</code></pre></p> </li> <li>\u914d\u7f6e\u5feb\u7167\u8868\u53c3\u6578\uff0c\u4f7f\u5176\u53ea\u5305\u542b\u65b0\u8868 <code>inventory.customers</code>\uff0c\u9019\u6a23 SynchDB \u5c31\u4e0d\u6703\u5617\u8a66\u91cd\u5efa\u5df2\u7d93\u5b8c\u6210\u5feb\u7167\u7684 2 \u500b\u8868\u3002 <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{snapshottable}', '\"inventory.customers\"') \nWHERE name = 'mysqlconn';\n</code></pre></li> <li>\u5c07\u5feb\u7167\u6a21\u5f0f\u8a2d\u70ba\u201c\u59cb\u7d42\u201d\uff0c\u7136\u5f8c\u91cd\u65b0\u555f\u52d5\u9023\u63a5\u5668\uff0c\u4ee5\u57f7\u884c\u53e6\u4e00\u6b21\u521d\u59cb\u5feb\u7167\uff1a <pre><code>SELECT synchdb_restart_connector('mysqlconn', 'always');\n</code></pre> \u9019\u6a23\u4e00\u4f86\uff0cDebezium \u5c31\u53ea\u80fd\u5c0d\u65b0\u8868 <code>inventory.customers</code> \u9032\u884c\u5feb\u7167\uff0c\u800c\u820a\u8868 <code>inventory.orders</code> \u548c <code>inventory.products</code> \u5247\u4fdd\u6301\u4e0d\u8b8a\u3002\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c\u6240\u6709\u8868\u683c\u7684 CDC \u64cd\u4f5c\u5c07\u6703\u6062\u5fa9\u3002</li> </ol>"},{"location":"zh/tutorial/mysql_cdc_to_postgresql/#_7","title":"\u9a57\u8b49\u66f4\u65b0\u5f8c\u7684\u8868\u683c","text":"<p>\u73fe\u5728\uff0c\u6211\u5011\u53ef\u4ee5\u518d\u6b21\u6aa2\u67e5\u8868\u683c\uff1a <pre><code>postgres=# \\dt inventory.*\n             List of tables\n  Schema   |   Name    | Type  | Owner\n-----------+-----------+-------+--------\n inventory | customers | table | ubuntu\n inventory | orders    | table | ubuntu\n inventory | products  | table | ubuntu\n</code></pre></p>"},{"location":"zh/tutorial/object_mapping_workflow/","title":"\u5bf9\u8c61\u6620\u5c04\u5de5\u4f5c\u6d41\u7a0b","text":"<p>SynchDB \u5177\u6709\u9ed8\u8ba4\u540d\u79f0\u548c\u6570\u636e\u7c7b\u578b\u6620\u5c04\u89c4\u5219\u6765\u5904\u7406\u4f20\u5165\u7684\u66f4\u6539\u4e8b\u4ef6\u3002\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u9ed8\u8ba4\u89c4\u5219\u90fd\u53ef\u4ee5\u6b63\u5e38\u5de5\u4f5c\u3002\u4f46\u662f\uff0c\u5982\u679c\u60a8\u6709\u7279\u5b9a\u7684\u8f6c\u6362\u8981\u6c42\uff0c\u6216\u8005\u9ed8\u8ba4\u89c4\u5219\u4e0d\u9002\u5408\u60a8\uff0c\u5219\u53ef\u4ee5\u5c06\u81ea\u5df1\u7684\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u914d\u7f6e\u5230\u7279\u5b9a\u8fde\u63a5\u5668\u3002\u8bf7\u6309\u7167\u4ee5\u4e0b\u5de5\u4f5c\u6d41\u7a0b\u67e5\u770b\u548c\u8c03\u6574\u4efb\u4f55\u7279\u5b9a\u7684\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u3002</p>"},{"location":"zh/tutorial/object_mapping_workflow/#schemasync","title":"\u521b\u5efa\u8fde\u63a5\u5668\u5e76\u4ee5 <code>schemasync</code> \u6a21\u5f0f\u542f\u52a8\u5b83","text":"<p><code>schemasync</code> \u662f\u4e00\u79cd\u7279\u6b8a\u6a21\u5f0f\uff0c\u5b83\u4f7f\u8fde\u63a5\u5668\u8fde\u63a5\u5230\u8fdc\u7a0b\u6570\u636e\u5e93\u5e76\u5c1d\u8bd5\u4ec5\u540c\u6b65\u6307\u5b9a\u8868\u7684\u67b6\u6784\u3002\u5b8c\u6210\u6b64\u64cd\u4f5c\u540e\uff0c\u8fde\u63a5\u5668\u5c06\u5904\u4e8e <code>\u6682\u505c</code> \u72b6\u6001\uff0c\u7528\u6237\u53ef\u4ee5\u67e5\u770b\u4f7f\u7528\u9ed8\u8ba4\u89c4\u5219\u521b\u5efa\u7684\u6240\u6709\u8868\u548c\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u5728\u9700\u8981\u65f6\u8fdb\u884c\u66f4\u6539\u3002</p> <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn',\n    '127.0.0.1',\n    3306,\n    'mysqluser',\n    'mysqlpwd',\n    'inventory',\n    'null',\n    'null',\n    'mysql');\n\nSELECT synchdb_start_engine_bgw('mysqlconn', 'schemasync');\n</code></pre>"},{"location":"zh/tutorial/object_mapping_workflow/#_2","title":"\u786e\u4fdd\u8fde\u63a5\u5668\u5904\u4e8e\u6682\u505c\u72b6\u6001","text":"<pre><code>SELECT name, connector_type, pid, stage, state FROM synchdb_state_view;\n     name      | connector_type |  pid   |    stage    |  state\n---------------+----------------+--------+-------------+---------\n mysqlconn     | mysql          | 579845 | schema sync | polling\n</code></pre>"},{"location":"zh/tutorial/object_mapping_workflow/#_3","title":"\u67e5\u770b\u9ed8\u8ba4\u521b\u5efa\u7684\u8868\u7684\u6620\u5c04\u89c4\u5219","text":"<pre><code>postgres=# select * from synchdb_att_view;\n   name    | type  | attnum |         ext_tbname         |         pg_tbname          | ext_attname | pg_attname  | ext_atttypename | pg_atttypename | transform\n-----------+-------+--------+----------------------------+----------------------------+-------------+-------------+-----------------+----------------+-----------\n mysqlconn | mysql |      1 | inventory.addresses        | inventory.addresses        | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.addresses        | inventory.addresses        | customer_id | customer_id | INT             | int4           |\n mysqlconn | mysql |      3 | inventory.addresses        | inventory.addresses        | street      | street      | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.addresses        | inventory.addresses        | city        | city        | VARCHAR         | varchar        |\n mysqlconn | mysql |      5 | inventory.addresses        | inventory.addresses        | state       | state       | VARCHAR         | varchar        |\n mysqlconn | mysql |      6 | inventory.addresses        | inventory.addresses        | zip         | zip         | VARCHAR         | varchar        |\n mysqlconn | mysql |      7 | inventory.addresses        | inventory.addresses        | type        | type        | ENUM            | text           |\n mysqlconn | mysql |      1 | inventory.customers        | inventory.customers        | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.customers        | inventory.customers        | first_name  | first_name  | VARCHAR         | varchar        |\n mysqlconn | mysql |      3 | inventory.customers        | inventory.customers        | last_name   | last_name   | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.customers        | inventory.customers        | email       | email       | VARCHAR         | varchar        |\n mysqlconn | mysql |      1 | inventory.geom             | inventory.geom             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.geom             | inventory.geom             | g           | g           | GEOMETRY        | text           |\n mysqlconn | mysql |      3 | inventory.geom             | inventory.geom             | h           | h           | GEOMETRY        | text           |\n mysqlconn | mysql |      1 | inventory.products         | inventory.products         | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products         | inventory.products         | name        | name        | VARCHAR         | varchar        |\n mysqlconn | mysql |      3 | inventory.products         | inventory.products         | description | description | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.products         | inventory.products         | weight      | weight      | FLOAT           | float4         |\n mysqlconn | mysql |      1 | inventory.products_on_hand | inventory.products_on_hand | product_id  | product_id  | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products_on_hand | inventory.products_on_hand | quantity    | quantity    | INT             | int4           |\n(20 rows)\n</code></pre>"},{"location":"zh/tutorial/object_mapping_workflow/#_4","title":"\u5b9a\u4e49\u81ea\u5b9a\u4e49\u6620\u5c04\u89c4\u5219","text":"<p>\u7528\u6237\u53ef\u4ee5\u4f7f\u7528<code>synchdb_add_objmap</code>\u51fd\u6570\u521b\u5efa\u81ea\u5b9a\u4e49\u6620\u5c04\u89c4\u5219\u3002\u5b83\u53ef\u7528\u4e8e\u6620\u5c04\u8868\u540d\u3001\u5217\u540d\u3001\u6570\u636e\u7c7b\u578b\u5e76\u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u8868\u8fbe\u5f0f\u89c4\u5219</p> <pre><code>SELECT synchdb_add_objmap('mysqlconn','table','inventory.products','stuff');\nSELECT synchdb_add_objmap('mysqlconn','table','inventory.customers','schema1.people');\nSELECT synchdb_add_objmap('mysqlconn','column','inventory.customers.last_name','family_name');\nSELECT synchdb_add_objmap('mysqlconn','column','inventory.customers.email','contact');\nSELECT synchdb_add_objmap('mysqlconn','datatype','inventory.geom.g','geometry|0');\nSELECT synchdb_add_objmap('mysqlconn','datatype','inventory.orders.quantity','bigint|0');\nSELECT synchdb_add_objmap('mysqlconn','transform','inventory.products.name','''&gt;&gt;&gt;&gt;&gt;'' || ''%d'' || ''&lt;&lt;&lt;&lt;&lt;''');\n</code></pre>"},{"location":"zh/tutorial/object_mapping_workflow/#_5","title":"\u5ba1\u67e5\u8fc4\u4eca\u4e3a\u6b62\u521b\u5efa\u7684\u6240\u6709\u5bf9\u8c61\u6620\u5c04\u89c4\u5219","text":"<pre><code>postgres=# select * from synchdb_objmap;\n   name    |  objtype  | enabled |            srcobj             |           dstobj\n-----------+-----------+---------+-------------------------------+----------------------------\n mysqlconn | table     | t       | inventory.products            | stuff\n mysqlconn | column    | t       | inventory.customers.last_name | family_name\n mysqlconn | column    | t       | inventory.customers.email     | contact\n mysqlconn | table     | t       | inventory.customers           | schema1.people\n mysqlconn | transform | t       | inventory.products.name       | '&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\n mysqlconn | datatype  | t       | inventory.geom.g              | geometry|0\n mysqlconn | datatype  | t       | inventory.orders.quantity     | bigint|0\n(7 rows)\n</code></pre>"},{"location":"zh/tutorial/object_mapping_workflow/#_6","title":"\u91cd\u65b0\u52a0\u8f7d\u5bf9\u8c61\u6620\u5c04\u89c4\u5219","text":"<p>\u4e00\u65e6\u5b9a\u4e49\u4e86\u6240\u6709\u81ea\u5b9a\u4e49\u89c4\u5219\uff0c\u6211\u4eec\u5c31\u9700\u8981\u5411\u8fde\u63a5\u5668\u53d1\u51fa\u4fe1\u53f7\u6765\u52a0\u8f7d\u5b83\u4eec\u3002\u8fd9\u5c06\u5bfc\u81f4\u8fde\u63a5\u5668\u8bfb\u53d6\u5e76\u5e94\u7528\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u3002\u5982\u679c\u5b83\u53d1\u73b0\u5f53\u524d PostgreSQL \u503c\u4e0e\u5bf9\u8c61\u6620\u5c04\u503c\u4e4b\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u5b83\u5c06\u5c1d\u8bd5\u66f4\u6b63\u6620\u5c04\u3002</p> <pre><code>SELECT synchdb_reload_objmap('mysqlconn');\n</code></pre>"},{"location":"zh/tutorial/object_mapping_workflow/#synchdb_att_view","title":"\u518d\u6b21\u68c0\u67e5 <code>synchdb_att_view</code> \u662f\u5426\u6709\u53d8\u5316","text":"<pre><code>SELECT * from synchdb_att_view;\n   name    | type  | attnum |         ext_tbname         |         pg_tbname          | ext_attname | pg_attname  | ext_atttypename | pg_atttypename |         transform\n-----------+-------+--------+----------------------------+----------------------------+-------------+-------------+-----------------+----------------+----------------------------\n mysqlconn | mysql |      1 | inventory.addresses        | inventory.addresses        | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.addresses        | inventory.addresses        | customer_id | customer_id | INT             | int4           |\n mysqlconn | mysql |      3 | inventory.addresses        | inventory.addresses        | street      | street      | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.addresses        | inventory.addresses        | city        | city        | VARCHAR         | varchar        |\n mysqlconn | mysql |      5 | inventory.addresses        | inventory.addresses        | state       | state       | VARCHAR         | varchar        |\n mysqlconn | mysql |      6 | inventory.addresses        | inventory.addresses        | zip         | zip         | VARCHAR         | varchar        |\n mysqlconn | mysql |      7 | inventory.addresses        | inventory.addresses        | type        | type        | ENUM            | text           |\n mysqlconn | mysql |      1 | inventory.customers        | schema1.people             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.customers        | schema1.people             | first_name  | first_name  | VARCHAR         | varchar        |\n mysqlconn | mysql |      3 | inventory.customers        | schema1.people             | last_name   | family_name | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.customers        | schema1.people             | email       | contact     | VARCHAR         | varchar        |\n mysqlconn | mysql |      1 | inventory.geom             | inventory.geom             | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.geom             | inventory.geom             | g           | g           | GEOMETRY        | geometry           |\n mysqlconn | mysql |      3 | inventory.geom             | inventory.geom             | h           | h           | GEOMETRY        | text           |\n mysqlconn | mysql |      1 | inventory.products         | public.stuff               | id          | id          | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products         | public.stuff               | name        | name        | VARCHAR         | varchar        | '&gt;&gt;&gt;&gt;&gt;' || '%d' || '&lt;&lt;&lt;&lt;&lt;'\n mysqlconn | mysql |      3 | inventory.products         | public.stuff               | description | description | VARCHAR         | varchar        |\n mysqlconn | mysql |      4 | inventory.products         | public.stuff               | weight      | weight      | FLOAT           | float4         |\n mysqlconn | mysql |      1 | inventory.products_on_hand | inventory.products_on_hand | product_id  | product_id  | INT             | int4           |\n mysqlconn | mysql |      2 | inventory.products_on_hand | inventory.products_on_hand | quantity    | quantity    | INT             | int8           |\n</code></pre>"},{"location":"zh/tutorial/object_mapping_workflow/#_7","title":"\u6062\u590d\u8fde\u63a5\u5668\u6216\u91cd\u505a\u6574\u4e2a\u5feb\u7167","text":"<p>\u4e00\u65e6\u786e\u8ba4\u5bf9\u8c61\u6620\u5c04\u6b63\u786e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u6062\u590d\u8fde\u63a5\u5668\u3002\u8bf7\u6ce8\u610f\uff0c\u6062\u590d\u53ea\u4f1a\u7ee7\u7eed\u6d41\u5f0f\u4f20\u8f93\u65b0\u7684\u8868\u66f4\u6539\u3002\u4e0d\u4f1a\u590d\u5236\u8868\u7684\u73b0\u6709\u6570\u636e\u3002 <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p> <p>\u8981\u6355\u83b7\u8868\u7684\u73b0\u6709\u6570\u636e\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u4f7f\u7528\u65b0\u7684\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u91cd\u505a\u6574\u4e2a\u5feb\u7167\uff1a <pre><code>SELECT synchdb_restart_connector('mysqlconn', 'always');\n</code></pre></p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#synchdb-oracle","title":"\u4e3a SynchDB \u51c6\u5907 Oracle \u6570\u636e\u5e93","text":"<p>\u5728\u4f7f\u7528 SynchDB \u4ece Oracle \u590d\u5236\u4e4b\u524d\uff0c\u9700\u8981\u6309\u7167\u6b64\u5904 \u6982\u8ff0\u7684\u6b65\u9aa4\u914d\u7f6e Oracle\u3002</p> <p>\u8bf7\u786e\u4fdd SynchDB \u9700\u8981\u590d\u5236\u7684\u6bcf\u4e2a\u8868\u7684\u6240\u6709\u5217\u90fd\u542f\u7528\u4e86\u8865\u5145\u65e5\u5fd7\u6570\u636e\u3002\u8fd9\u662f SynchDB \u6b63\u786e\u5904\u7406\u66f4\u65b0\u548c\u5220\u9664\u64cd\u4f5c\u6240\u5fc5\u9700\u7684\u3002</p> <p>\u4f8b\u5982\uff0c\u4ee5\u4e0b\u547d\u4ee4\u4e3a\u201ccustomer\u201d\u548c\u201cproducts\u201d\u8868\u7684\u6240\u6709\u5217\u542f\u7528\u4e86\u8865\u5145\u65e5\u5fd7\u6570\u636e\u3002\u8bf7\u6839\u636e\u9700\u8981\u6dfb\u52a0\u66f4\u591a\u8868\u3002</p> <pre><code>ALTER TABLE customer ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;\nALTER TABLE products ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;\n... etc\n</code></pre>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#oracle","title":"\u521b\u5efa Oracle \u8fde\u63a5\u5668","text":"<p>\u521b\u5efa\u4e00\u4e2a\u8fde\u63a5\u5668\uff0c\u6307\u5411 Oracle \u4e2d <code>FREE</code> \u6570\u636e\u5e93\u548c <code>DBZUSER</code> schema \u4e0b\u7684\u6240\u6709\u8868\u3002 <pre><code>SELECT\nsynchdb_add_conninfo(\n'oracleconn','127.0.0.1',1521,\n'DBZUSER','dbz','FREE','DBZUSER',\n'null','null','oracle');\n</code></pre></p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#_1","title":"\u521d\u59cb\u5feb\u7167","text":"<p>SynchDB \u4e2d\u7684\u300c\u521d\u59cb\u5feb\u7167\u300d\uff08\u6216\u8868\u5feb\u7167\uff09\u662f\u6307\u8907\u88fd\u6240\u6709\u6307\u5b9a\u8868\u7684\u8868\u7d50\u69cb\u548c\u521d\u59cb\u8cc7\u6599\u3002\u9019\u985e\u4f3c\u65bc PostgreSQL \u908f\u8f2f\u8907\u88fd\u4e2d\u7684\u300c\u8868\u540c\u6b65\u300d\u3002\u7576\u4f7f\u7528\u9810\u8a2d\u7684 <code>initial</code> \u6a21\u5f0f\u555f\u52d5\u9023\u63a5\u5668\u6642\uff0c\u5b83\u6703\u5728\u9032\u5165\u8b8a\u66f4\u8cc7\u6599\u64f7\u53d6 (CDC) \u968e\u6bb5\u4e4b\u524d\u81ea\u52d5\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u53ef\u4ee5\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u90e8\u5206\u7701\u7565\u6b64\u6b65\u9a5f\u3002\u6709\u95dc\u6240\u6709\u5feb\u7167\u9078\u9805\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c\u9023\u63a5\u5668\u5728\u5f8c\u7e8c\u91cd\u65b0\u555f\u52d5\u6642\u4e0d\u6703\u518d\u6b21\u57f7\u884c\u6b64\u64cd\u4f5c\uff0c\u800c\u662f\u76f4\u63a5\u5f9e\u4e0a\u6b21\u672a\u5b8c\u6210\u7684\u504f\u79fb\u91cf\u8655\u6062\u5fa9 CDC\u3002\u6b64\u884c\u70ba\u7531 Debezium \u5f15\u64ce\u7ba1\u7406\u7684\u5143\u8cc7\u6599\u6a94\u6848\u63a7\u5236\u3002\u6709\u95dc\u5143\u8cc7\u6599\u6a94\u6848\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#_2","title":"\u4e0d\u540c\u7684\u9023\u63a5\u5668\u555f\u52d5\u6a21\u5f0f","text":""},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#cdc","title":"\u521d\u59cb\u5feb\u7167 + CDC","text":"<p>\u4f7f\u7528 <code>initial</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u5bf9\u6240\u6709\u6307\u5b9a\u8868\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a\u5168\u90e8\uff09\u6267\u884c\u521d\u59cb\u5feb\u7167\u3002\u5b8c\u6210\u540e\uff0c\u53d8\u66f4\u6570\u636e\u6355\u83b7 (CDC) \u8fdb\u7a0b\u5c06\u5f00\u59cb\u6d41\u5f0f\u4f20\u8f93\u65b0\u7684\u53d8\u66f4\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn', 'initial');\n\n\u6216\n\nSELECT synchdb_start_engine_bgw('oracleconn');\n</code></pre> <p>\u6b64\u8fde\u63a5\u5668\u9996\u6b21\u8fd0\u884c\u65f6\uff0c\u5176\u9636\u6bb5\u5e94\u5904\u4e8e <code>initial snapper</code> \u72b6\u6001\uff1a <pre><code>postgres=# select * from synchdb_state_view where name='oracleconn';\n    name    | connector_type |  pid   |      stage       |  state  |   err    |       last_dbz_offset\n------------+----------------+--------+------------------+---------+----------+-----------------------------\n oracleconn | oracle         | 528146 | initial snapshot | polling | no error | offset file not flushed yet\n(1 row)\n</code></pre></p> <p>\u5c06\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a\u201cinventory\u201d\u7684\u65b0\u6a21\u5f0f\uff0c\u5e76\u4e14\u8fde\u63a5\u5668\u6d41\u5f0f\u4f20\u8f93\u7684\u6240\u6709\u8868\u90fd\u5c06\u5728\u8be5\u6a21\u5f0f\u4e0b\u590d\u5236\u3002 <pre><code>postgres=# set search_path=free;\nSET\npostgres=# \\d\n              List of relations\n Schema |        Name        | Type  | Owner\n--------+--------------------+-------+--------\n free   | orders             | table | ubuntu\n</code></pre> \u521d\u59cb\u5feb\u7167\u5b8c\u6210\u540e\uff0c\u5982\u679c\u81f3\u5c11\u63a5\u6536\u5e76\u5904\u7406\u4e86\u4e00\u4e2a\u540e\u7eed\u66f4\u6539\uff0c\u5219\u8fde\u63a5\u5668\u9636\u6bb5\u5e94\u4ece\u201c\u521d\u59cb\u5feb\u7167\u201d\u66f4\u6539\u4e3a\u201c\u66f4\u6539\u6570\u636e\u6355\u83b7\u201d\u3002 <pre><code>postgres=# select * from synchdb_state_view where name='oracleconn';\n    name    | connector_type |  pid   |        stage        |  state  |   err    |\n    last_dbz_offset\n------------+----------------+--------+---------------------+---------+----------+-------------------------------\n-------------------------------------------------------\n oracleconn | oracle         | 528414 | change data capture | polling | no error | {\"commit_scn\":\"3118146:1:02001\nf00c0020000\",\"snapshot_scn\":\"3081987\",\"scn\":\"3118125\"}\n</code></pre> \u8fd9\u610f\u5473\u7740\u8fde\u63a5\u5668\u73b0\u5728\u6b63\u5728\u6d41\u5f0f\u4f20\u8f93\u6307\u5b9a\u8868\u7684\u65b0\u66f4\u6539\u3002\u4ee5\u201cinitial\u201d\u6a21\u5f0f\u91cd\u542f\u8fde\u63a5\u5668\u5c06\u4ece\u4e0a\u6b21\u6210\u529f\u70b9\u5f00\u59cb\u7ee7\u7eed\u590d\u5236\uff0c\u5e76\u4e14\u4e0d\u4f1a\u91cd\u65b0\u8fd0\u884c\u521d\u59cb\u5feb\u7167\u3002</p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#cdc_1","title":"\u4ec5\u521d\u59cb\u5feb\u7167\uff0c\u65e0CDC","text":"<p>\u4f7f\u7528\u201cinitial_only\u201d\u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4ec5\u5bf9\u6240\u6709\u6307\u5b9a\u8868\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a\u6240\u6709\u8868\uff09\u6267\u884c\u521d\u59cb\u5feb\u7167\uff0c\u4e4b\u540e\u5c06\u4e0d\u518d\u6267\u884cCDC\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn', 'initial_only');\n</code></pre> <p>\u8fde\u63a5\u5668\u4ecd\u7136\u4f1a\u663e\u793a\u6b63\u5728\u201c\u8f6e\u8be2\u201d\uff0c\u4f46\u7531\u4e8eDebzium\u5185\u90e8\u5df2\u505c\u6b62CDC\uff0c\u56e0\u6b64\u4e0d\u4f1a\u6355\u83b7\u4efb\u4f55\u66f4\u6539\u3002\u60a8\u53ef\u4ee5\u9009\u62e9\u5173\u95ed\u5b83\u3002\u4ee5\u201cinitial_only\u201d\u6a21\u5f0f\u91cd\u542f\u8fde\u63a5\u5668\u4e0d\u4f1a\u91cd\u5efa\u8868\uff0c\u56e0\u4e3a\u5b83\u4eec\u5df2\u7ecf\u6784\u5efa\u597d\u4e86\u3002</p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#cdc_2","title":"\u4ec5\u6355\u83b7\u8868\u6a21\u5f0f + CDC","text":"<p>\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4ec5\u6267\u884c\u6a21\u5f0f\u6355\u83b7\uff0c\u5728 PostgreSQL \u4e2d\u6784\u5efa\u76f8\u5e94\u7684\u8868\uff0c\u5e76\u4e14\u4e0d\u4f1a\u590d\u5236\u73b0\u6709\u8868\u6570\u636e\uff08\u8df3\u8fc7\u521d\u59cb\u5feb\u7167\uff09\u3002\u6a21\u5f0f\u6355\u83b7\u5b8c\u6210\u540e\uff0c\u8fde\u63a5\u5668\u5c06\u8fdb\u5165 CDC \u6a21\u5f0f\uff0c\u5e76\u5f00\u59cb\u6355\u83b7\u5bf9\u8868\u7684\u540e\u7eed\u66f4\u6539\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn', 'no_data');\n</code></pre> <p>\u5728 <code>no_data</code> \u6a21\u5f0f\u4e0b\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4e0d\u4f1a\u518d\u6b21\u91cd\u5efa\u6a21\u5f0f\uff0c\u5e76\u4e14\u5b83\u5c06\u4ece\u4e0a\u6b21\u6210\u529f\u70b9\u6062\u590d CDC\u3002</p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#cdc_3","title":"\u59cb\u7ec8\u6267\u884c\u521d\u59cb\u5feb\u7167 + CDC","text":"<p>\u4f7f\u7528 <code>always</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u59cb\u7ec8\u6355\u83b7\u6355\u83b7\u8868\u7684\u6a21\u5f0f\uff0c\u59cb\u7ec8\u91cd\u505a\u521d\u59cb\u5feb\u7167\uff0c\u7136\u540e\u8f6c\u5230 CDC\u3002\u8fd9\u7c7b\u4f3c\u4e8e\u91cd\u7f6e\u6309\u94ae\uff0c\u56e0\u4e3a\u4f7f\u7528\u6b64\u6a21\u5f0f\u5c06\u91cd\u5efa\u6240\u6709\u5185\u5bb9\u3002\u8bf7\u8c28\u614e\u4f7f\u7528\u6b64\u6a21\u5f0f\uff0c\u5c24\u5176\u662f\u5728\u6355\u83b7\u5927\u91cf\u8868\u65f6\uff0c\u8fd9\u53ef\u80fd\u9700\u8981\u5f88\u957f\u65f6\u95f4\u624d\u80fd\u5b8c\u6210\u3002\u91cd\u5efa\u540e\uff0cCDC \u5c06\u6062\u590d\u6b63\u5e38\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn', 'always');\n</code></pre> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u540e\uff0c\u6301\u7eed\u6570\u636e\u6355\u83b7 (CDC) \u5c06\u5f00\u59cb\u3002\u5728 <code>always</code> \u6a21\u5f0f\u4e0b\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\u3002</p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#oracle_1","title":"Oracle \u9023\u63a5\u5668\u7684\u53ef\u7528\u5feb\u7167\u6a21\u5f0f","text":"<ul> <li>initial (default)</li> <li>initial_only</li> <li>no_data</li> <li>always</li> <li>schemasync</li> </ul>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#schemasync","title":"\u4f7f\u7528 schemasync \u6a21\u5f0f\u9810\u89bd\u4f86\u6e90\u8868\u548c\u76ee\u6a19\u8868\u95dc\u4fc2","text":"<p>\u5728\u5617\u8a66\u5c0d\u7576\u524d\u8868\u548c\u8cc7\u6599\uff08\u53ef\u80fd\u975e\u5e38\u9f90\u5927\uff09\u9032\u884c\u521d\u59cb\u5feb\u7167\u4e4b\u524d\uff0c\u53ef\u4ee5\u5728\u5be6\u969b\u8cc7\u6599\u9077\u79fb\u4e4b\u524d\u300c\u9810\u89bd\u300d\u4f86\u6e90\u8868\u548c\u76ee\u6a19\u8868\u4e4b\u9593\u7684\u6240\u6709\u8868\u548c\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u3002\u9019\u6a23\uff0c\u60a8\u5c31\u6709\u6a5f\u6703\u5728\u5be6\u969b\u9077\u79fb\u4e4b\u524d\u4fee\u6539\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u6216\u7269\u4ef6\u540d\u7a31\u3002\u9019\u53ef\u4ee5\u900f\u904e\u7279\u6b8a\u7684\u300cschemasync\u300d\u521d\u59cb\u5feb\u7167\u6a21\u5f0f\u4f86\u5be6\u73fe\u3002\u6709\u95dc\u8a73\u7d30\u7bc4\u4f8b\uff0c\u8acb\u53c3\u95b1\u5bf9\u8c61\u6620\u5c04\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#_3","title":"\u9078\u64c7\u6027\u8868\u540c\u6b65","text":""},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#_4","title":"\u9078\u64c7\u6240\u9700\u8868\u4e26\u9996\u6b21\u555f\u52d5\u540c\u6b65","text":"<p>\u8868\u683c\u9078\u64c7\u5728\u9023\u63a5\u5668\u5efa\u7acb\u968e\u6bb5\u900f\u904e <code>synchdb_add_conninfo()</code> \u51fd\u6578\u5b8c\u6210\uff0c\u8a72\u51fd\u6578\u7528\u65bc\u6307\u5b9a\u8981\u5f9e\u4e2d\u8907\u88fd\u7684\u8868\u5217\u8868\uff08\u4ee5\u5b8c\u5168\u9650\u5b9a\u540d\u7a31 (FQN) \u8868\u793a\uff0c\u4e26\u4ee5\u9017\u865f\u5206\u9694\uff09\u3002</p> <p>\u4f8b\u5982\uff0c\u4ee5\u4e0b\u547d\u4ee4\u5efa\u7acb\u4e00\u500b\u9023\u63a5\u5668\uff0c\u8a72\u9023\u63a5\u5668\u50c5\u5f9e\u9060\u7aef MySQL \u8cc7\u6599\u5eab\u8907\u88fd <code>inventory.orders</code> \u548c <code>inventory.products</code> \u8868\u4e2d\u7684\u8b8a\u66f4\u3002 <pre><code>SELECT synchdb_add_conninfo(\n    'oracleconn', \n    '127.0.0.1', \n    1521, \n    'DBZUSER', \n    'dbz', \n    'FREE', \n    'DBZUSER', \n    'DBZUSER.ORDERS', \n    'null', \n    'oracle'\n);\n</code></pre></p> <p>\u9996\u6b21\u555f\u52d5\u6b64\u9023\u63a5\u5668\u6642\uff0c\u5c07\u89f8\u767c\u57f7\u884c\u521d\u59cb\u5feb\u7167\uff0c\u4e26\u8907\u88fd\u9078\u5b9a\u7684\u8868\u7684\u67b6\u69cb\u548c\u8cc7\u6599\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('oracleconn');\n</code></pre>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#_5","title":"\u9a57\u8b49\u9023\u63a5\u5668\u72c0\u614b\u548c\u8868\u683c","text":"<p>\u6aa2\u67e5\u9023\u63a5\u5668\u72c0\u614b\u548c\u65b0\u8868\u683c\uff1a <pre><code>postgres=# Select name, state, err from synchdb_state_view;\n    name    |  state  |   err\n------------+---------+----------\n oracleconn | polling | no error\n\npostgres=# \\dt free.*\n          List of tables\n Schema |  Name  | Type  | Owner\n--------+--------+-------+--------\n free   | orders | table | ubuntu\n</code></pre></p> <p>\u9810\u8a2d\u60c5\u6cc1\u4e0b\uff0c\u4f86\u6e90\u8cc7\u6599\u5eab\u540d\u7a31\u6703\u5c0d\u61c9\u5230\u76ee\u6a19\u8cc7\u6599\u5eab\u7684\u6a21\u5f0f\uff0c\u4e26\u4e14\u5b57\u6bcd\u5927\u5c0f\u5beb\u7b56\u7565\u70ba\u5c0f\u5beb\uff0c\u56e0\u6b64 <code>FREE.ORDERS</code> \u5728 PostgreSQL \u4e2d\u6703\u8b8a\u6210 <code>free.orders</code>\u3002\u8868\u5b8c\u6210\u521d\u59cb\u5feb\u7167\u5f8c\uff0c\u9023\u63a5\u5668\u5c07\u555f\u52d5 CDC \u4ee5\u4e32\u6d41\u50b3\u8f38\u9019\u4e9b\u8868\u7684\u5f8c\u7e8c\u8b8a\u66f4\u3002</p>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#_6","title":"\u904b\u884c\u6642\u52a0\u5165\u66f4\u591a\u8981\u8907\u88fd\u7684\u8868","text":"<p>\u4e0a\u4e00\u7bc0\u4e2d\u7684 <code>oracleconn</code> \u5df2\u5b8c\u6210\u521d\u59cb\u5feb\u7167\u4e26\u53d6\u5f97\u4e86\u6240\u9078\u8868\u683c\u7684\u8868\u683c\u6a21\u5f0f\u3002\u5982\u679c\u6211\u5011\u60f3\u8981\u65b0\u589e\u66f4\u591a\u8981\u8907\u88fd\u7684\u8868\uff0c\u5247\u9700\u8981\u901a\u77e5 Debezium \u5f15\u64ce\u66f4\u65b0\u5f8c\u7684\u8868\u683c\u90e8\u5206\uff0c\u4e26\u518d\u6b21\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u5177\u9ad4\u64cd\u4f5c\u5982\u4e0b\uff1a</p> <ol> <li> <p>\u66f4\u65b0 <code>synchdb_conninfo</code> \u8868\u4ee5\u5305\u542b\u5176\u4ed6\u8868\u3002</p> </li> <li> <p>\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u5011\u5c07 <code>DBZUSER.CUSTOMERS</code> \u8868\u52a0\u5165\u540c\u6b65\u6e05\u55ae\uff1a <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"DBZUSER.ORDERS,DBZUSER.CUSTOMERS\"') \nWHERE name = 'oracleconn';\n</code></pre></p> </li> <li>\u5c07\u5feb\u7167\u6a21\u5f0f\u8a2d\u70ba\u201c\u59cb\u7d42\u201d\uff0c\u7136\u5f8c\u91cd\u65b0\u555f\u52d5\u9023\u63a5\u5668\uff0c\u4ee5\u57f7\u884c\u53e6\u4e00\u6b21\u521d\u59cb\u5feb\u7167\uff1a <pre><code>DROP table free.orders;\nSELECT synchdb_restart_connector('oracleconn', 'always');\n</code></pre> \u9019\u8feb\u4f7f Debezium \u5728\u9032\u884c CDC \u4e32\u6d41\u4e4b\u524d\uff0c\u91cd\u65b0\u5efa\u7acb\u6240\u6709\u8868\u683c\u7684\u5feb\u7167\uff0c\u5305\u62ec\u73fe\u6709\u7684 <code>free.orders</code> \u8868\u548c\u65b0\u7684 <code>free.customers</code> \u8868\u3002\u9019\u610f\u5473\u8457\uff0c\u8981\u65b0\u589e\u8868\uff0c\u5fc5\u9808\u522a\u9664\u73fe\u6709\u8868\uff08\u4ee5\u9632\u6b62\u91cd\u8907\u8868\u548c\u4e3b\u9375\u932f\u8aa4\uff09\uff0c\u4e26\u91cd\u65b0\u5efa\u7acb\u6574\u500b\u521d\u59cb\u5feb\u7167\u3002\u9019\u76f8\u7576\u5197\u9918\uff0cDebezium \u5efa\u8b70\u4f7f\u7528\u589e\u91cf\u5feb\u7167\u4f86\u65b0\u589e\u8cc7\u6599\u8868\uff0c\u800c\u7121\u9700\u91cd\u65b0\u5efa\u7acb\u5feb\u7167\u3002\u4e00\u65e6\u6211\u5011\u5c07\u589e\u91cf\u5feb\u7167\u652f\u63f4\u65b0\u589e\u81f3 SynchDB\uff0c\u6211\u5011\u5c07\u66f4\u65b0\u6b64\u6d41\u7a0b\u3002</li> </ol>"},{"location":"zh/tutorial/oracle_cdc_to_postgresql/#_7","title":"\u9a57\u8b49\u66f4\u65b0\u5f8c\u7684\u8868\u683c","text":"<p>\u73fe\u5728\uff0c\u6211\u5011\u53ef\u4ee5\u518d\u6b21\u6aa2\u67e5\u6211\u5011\u7684\u8868\uff1a <pre><code>postgres=# \\dt free.*\n          List of tables\n Schema      |  Name  | Type  | Owner\n-------------+--------+-------+--------\n free        | orders | table | ubuntu\n customers   | orders | table | ubuntu\n</code></pre></p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#synchdb-postgresql","title":"\u70ba SynchDB \u6e96\u5099 PostgreSQL \u8cc7\u6599\u5eab","text":"<p>\u5728\u4f7f\u7528 SynchDB \u5f9e PostgreSQL \u8907\u88fd\u8cc7\u6599\u4e4b\u524d\uff0c\u9700\u8981\u6309\u7167\u6b64\u8655\u4e2d\u6982\u8ff0\u7684\u6b65\u9a5f\u8a2d\u5b9a PostgreSQL \u4f3a\u670d\u5668\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#postgresql","title":"\u5efa\u7acb PostgreSQL \u9023\u63a5\u5668","text":"<p>\u5efa\u7acb\u4e00\u500b\u9023\u63a5\u5668\uff0c\u8a72\u9023\u63a5\u5668\u6307\u5411\u8cc7\u6599\u5eab <code>postgres</code> \u548c\u6a21\u5f0f <code>public</code> \u4e0b\u7684\u6240\u6709\u8cc7\u6599\u8868\u3002</p> <pre><code>SELECT \n  synchdb_add_conninfo(\n    'pgconn', '127.0.0.1', 5432, \n    'myuser', 'mypass', 'postgres', 'public', \n    'null', 'null', 'postgres');\n</code></pre>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#_1","title":"\u521d\u59cb\u5feb\u7167","text":"<p>SynchDB \u4e2d\u7684\u300c\u521d\u59cb\u5feb\u7167\u300d\uff08\u6216\u8868\u5feb\u7167\uff09\u662f\u6307\u8907\u88fd\u6240\u6709\u6307\u5b9a\u8cc7\u6599\u8868\u7684\u8868\u7d50\u69cb\u53ca\u5176\u521d\u59cb\u8cc7\u6599\u3002\u9019\u985e\u4f3c\u65bc PostgreSQL \u908f\u8f2f\u8907\u88fd\u4e2d\u7684\u300c\u8868\u540c\u6b65\u300d\u3002\u7576\u4f7f\u7528\u9810\u8a2d\u7684 <code>initial</code> \u6a21\u5f0f\u555f\u52d5\u9023\u63a5\u5668\u6642\uff0c\u5b83\u6703\u5728\u9032\u5165\u8b8a\u66f4\u8cc7\u6599\u64f7\u53d6 (CDC) \u968e\u6bb5\u4e4b\u524d\u81ea\u52d5\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u53ef\u4ee5\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u90e8\u5206\u7701\u7565\u6b64\u6b65\u9a5f\u3002\u6709\u95dc\u6240\u6709\u5feb\u7167\u9078\u9805\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c\u9023\u63a5\u5668\u5728\u5f8c\u7e8c\u91cd\u65b0\u555f\u52d5\u6642\u4e0d\u6703\u518d\u6b21\u57f7\u884c\u521d\u59cb\u5feb\u7167\uff0c\u800c\u662f\u76f4\u63a5\u5f9e\u4e0a\u6b21\u672a\u5b8c\u6210\u7684\u504f\u79fb\u91cf\u8655\u6062\u5fa9 CDC\u3002\u6b64\u884c\u70ba\u7531 Debezium \u5f15\u64ce\u7ba1\u7406\u7684\u5143\u8cc7\u6599\u6a94\u6848\u63a7\u5236\u3002\u6709\u95dc\u5143\u8cc7\u6599\u6a94\u6848\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p> <p>PostgreSQL \u9023\u63a5\u5668\u7684\u521d\u59cb\u5feb\u7167\u7565\u6709\u4e0d\u540c\u3002\u8207\u5176\u4ed6\u9023\u63a5\u5668\u4e0d\u540c\uff0cDebezium \u5f15\u64ce\u4e0d\u6703\u5efa\u69cb\u521d\u59cb\u8868\u7d50\u69cb\u3002\u9019\u662f\u56e0\u70ba PostgreSQL \u4e0d\u6703\u660e\u78ba\u5730\u767c\u51fa DDL WAL \u4e8b\u4ef6\u3002 PostgreSQL \u7684\u539f\u751f\u908f\u8f2f\u8907\u88fd\u4e5f\u5b58\u5728\u8457\u540c\u6a23\u7684\u554f\u984c\u3002\u4f7f\u7528\u8005\u5fc5\u9808\u5728\u555f\u52d5\u908f\u8f2f\u8907\u88fd\u4e4b\u524d\u9810\u5148\u5728\u76ee\u6a19\u8cc7\u6599\u5eab\u5efa\u7acb\u8868\u683c\u6a21\u5f0f\u3002\u56e0\u6b64\uff0c\u9996\u6b21\u555f\u52d5\u57fa\u65bc Debezium \u7684 PostgreSQL \u9023\u63a5\u5668\u6642\uff0c\u5b83\u6703\u5047\u5b9a\u60a8\u5df2\u7d93\u5efa\u7acb\u4e86\u6307\u5b9a\u7684\u8868\u6a21\u5f0f\u53ca\u5176\u521d\u59cb\u6578\u64da\uff0c\u4e26\u7acb\u5373\u9032\u5165 CDC \u6d41\u6a21\u5f0f\uff0c\u800c\u7121\u9700\u5be6\u969b\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002</p> <p>\u53ef\u4ee5\u900f\u904e\u57fa\u65bc FDW \u7684\u521d\u59cb\u5feb\u7167\u4f86\u89e3\u6c7a\u6b64\u554f\u984c\u3002\u8a72\u5feb\u7167\u4f7f\u7528 <code>postgres_fdw</code> \u5efa\u7acb\u521d\u59cb\u8868\u6a21\u5f0f\u548c\u6578\u64da\uff0c\u7136\u5f8c\u518d\u900f\u904e Debezium \u5207\u63db\u5230 CDC \u6d41\u6a21\u5f0f\u3002\u82e5\u8981\u4f7f\u7528\u6b64\u529f\u80fd\uff0c\u60a8\u5fc5\u9808\u5728\u555f\u52d5\u9023\u63a5\u5668\u4e4b\u524d\u5c07 <code>synchdb.olr_snapshot_engine</code> \u8a2d\u5b9a\u70ba <code>fdw</code>\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#_2","title":"\u4e0d\u540c\u7684\u9023\u63a5\u5668\u555f\u52d5\u6a21\u5f0f","text":""},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#cdc","title":"\u521d\u59cb\u5feb\u7167 + CDC","text":"<p>\u4f7f\u7528 <code>synchdb.olr_snapshot_engine = 'debezium'</code>\uff1a</p> <p>\u60a8\u9700\u8981\u5728\u76ee\u6a19\u8cc7\u6599\u5eab\u5efa\u7acb\u521d\u59cb\u8868\u6a21\u5f0f\u548c\u8cc7\u6599\u3002 Debezium \u4e0d\u6703\u5275\u5efa\u5b83\u5011\u3002</p> <p>\u4f7f\u7528 synchdb.olr_snapshot_engine = 'fdw' \u6642\uff1a</p> <p>\u4ee5 <code>initial</code> \u6a21\u5f0f\u555f\u52d5\u9023\u63a5\u5668\u5c07\u5c0d\u6240\u6709\u6307\u5b9a\u7684\u8868\u57f7\u884c\u521d\u59cb\u5feb\u7167\uff08\u900f\u904e postgres_fdw\uff09\u3002\u5b8c\u6210\u5f8c\uff0c\u8b8a\u66f4\u8cc7\u6599\u64f7\u53d6 (CDC) \u6d41\u7a0b\u5c07\u958b\u59cb\u4e32\u6d41\u65b0\u8b8a\u66f4\uff08\u900f\u904e Debezium\uff09\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('pgconn', 'initial');\n\nor \n\nSELECT synchdb_start_engine_bgw('pgconn');\n</code></pre> <p>\u6b64\u9023\u63a5\u5668\u9996\u6b21\u904b\u4f5c\u6642\uff0c\u5176\u72c0\u614b\u61c9\u70ba\u300c\u521d\u59cb\u5feb\u7167\u300d\uff1a</p> <pre><code>postgres=# select * from synchdb_state_view where name='oracleconn';\n  name  | connector_type |  pid   |      stage       |  state  |   err    |       last_dbz_offset\n--------+----------------+--------+------------------+---------+----------+-----------------------------\n pgconn | postgres       | 528746 | initial snapshot | polling | no error | offset file not flushed yet\n</code></pre> <p>\u5c07\u5efa\u7acb\u4e00\u500b\u540d\u70ba\u300cpostgres\u300d\u7684\u65b0\u6a21\u5f0f\uff0c\u9023\u63a5\u5668\u50b3\u8f38\u7684\u6240\u6709\u8868\u90fd\u5c07\u5728\u8a72\u6a21\u5f0f\u4e0b\u9032\u884c\u8907\u88fd\u3002</p> <pre><code>postgres=# set search_path=postgres;\nSET\npostgres=# \\d\n              List of relations\n  Schema  |        Name        | Type  | Owner\n----------+--------------------+-------+--------\n postgres | orders             | table | ubuntu\n</code></pre> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c\u4e26\u4e14\u81f3\u5c11\u6536\u5230\u4e26\u8655\u7406\u4e86\u4e00\u500b\u5f8c\u7e8c\u66f4\u6539\uff0c\u9023\u63a5\u5668\u968e\u6bb5\u61c9\u5f9e\u201c\u521d\u59cb\u5feb\u7167\u201d\u66f4\u6539\u70ba\u201c\u8b8a\u66f4\u8cc7\u6599\u64f7\u53d6\u201d\u3002</p> <pre><code>postgres=# select * from synchdb_state_view where name='pgconn';\n  name  | connector_type |   pid   |        stage        |  state  |   err    |\n       last_dbz_offset\n--------+----------------+---------+---------------------+---------+----------+-----------------------------------\n-----------------------------------------------------------------\n pgconn | postgres       | 1604388 | change data capture | polling | no error | {\"lsn_proc\":37396384,\"messageType\"\n:\"INSERT\",\"lsn\":37396384,\"txId\":1015,\"ts_usec\":1767740340957961}\n</code></pre> <p>\u9019\u610f\u5473\u8457\u9023\u63a5\u5668\u73fe\u5728\u6b63\u5728\u4e32\u6d41\u6307\u5b9a\u8868\u7684\u65b0\u8b8a\u66f4\u3002\u4ee5 <code>initial</code> \u6a21\u5f0f\u91cd\u65b0\u555f\u52d5\u9023\u63a5\u5668\u5c07\u5f9e\u4e0a\u6b21\u6210\u529f\u8907\u88fd\u9ede\u958b\u59cb\u7e7c\u7e8c\u8907\u88fd\uff0c\u4e26\u4e14\u4e0d\u6703\u91cd\u65b0\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#cdc_1","title":"\u50c5\u521d\u59cb\u5feb\u7167\uff0c\u4e0d\u57f7\u884c CDC","text":"<p>\u4f7f\u7528 synchdb.olr_snapshot_engine = 'debezium' \u6642\uff1a</p> <p>\u60a8\u9700\u8981\u5728\u76ee\u6a19\u8cc7\u6599\u5eab\u4e2d\u5efa\u7acb\u521d\u59cb\u8868\u67b6\u69cb\u548c\u8cc7\u6599\u3002 Debezium \u4e0d\u6703\u5275\u5efa\u5b83\u5011\u3002</p> <p>\u4f7f\u7528 synchdb.olr_snapshot_engine = 'fdw' \u6642\uff1a</p> <p>\u4f7f\u7528 <code>initial_only</code> \u6a21\u5f0f\u555f\u52d5\u9023\u63a5\u5668\u5c07\u50c5\u5c0d\u6240\u6709\u6307\u5b9a\u8cc7\u6599\u8868\uff08\u5728\u672c\u4f8b\u4e2d\u70ba\u6240\u6709\u8cc7\u6599\u8868\uff09\u57f7\u884c\u521d\u59cb\u5feb\u7167\uff0c\u4e14\u4e4b\u5f8c\u4e0d\u6703\u57f7\u884c CDC\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('pgconn', 'initial_only');\n</code></pre> <p>\u9023\u63a5\u5668\u770b\u8d77\u4f86\u4ecd\u7136\u5728\u8f2a\u8a62\uff0c\u4f46\u7531\u65bc Debzium \u5167\u90e8\u5df2\u505c\u6b62 CDC\uff0c\u56e0\u6b64\u4e0d\u6703\u6355\u7372\u4efb\u4f55\u66f4\u6539\u3002\u60a8\u53ef\u4ee5\u9078\u64c7\u5c07\u5176\u95dc\u9589\u3002\u4ee5 <code>initial_only</code> \u6a21\u5f0f\u91cd\u65b0\u555f\u52d5\u9023\u63a5\u5668\u4e0d\u6703\u91cd\u5efa\u8868\uff0c\u56e0\u70ba\u5b83\u5011\u5df2\u7d93\u5efa\u7acb\u5b8c\u6210\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#cdc_2","title":"\u50c5\u6355\u7372\u8868\u67b6\u69cb + CDC","text":"<p>\u4f7f\u7528 synchdb.olr_snapshot_engine = 'debezium' \u6642\uff1a</p> <p>\u60a8\u9700\u8981\u5728\u76ee\u6a19\u8cc7\u6599\u5eab\u4e2d\u5efa\u7acb\u521d\u59cb\u8868\u67b6\u69cb\u548c\u8cc7\u6599\u3002 Debezium \u4e0d\u6703\u5275\u5efa\u5b83\u5011\u3002</p> <p>\u4f7f\u7528 synchdb.olr_snapshot_engine = 'fdw' \u6642\uff1a</p> <p>\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u555f\u52d5\u9023\u63a5\u5668\u5c07\u50c5\u57f7\u884c\u67b6\u69cb\u6355\u7372\uff0c\u4e26\u5728 PostgreSQL \u4e2d\u5efa\u7acb\u76f8\u61c9\u7684\u8868\uff0c\u800c\u4e0d\u6703\u8907\u88fd\u73fe\u6709\u8868\u8cc7\u6599\uff08\u8df3\u904e\u521d\u59cb\u5feb\u7167\uff09\u3002\u67b6\u69cb\u64f7\u53d6\u5b8c\u6210\u5f8c\uff0c\u9023\u63a5\u5668\u5c07\u9032\u5165 CDC \u6a21\u5f0f\uff0c\u4e26\u958b\u59cb\u64f7\u53d6\u5f8c\u7e8c\u8868\u8b8a\u66f4\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('pgconn', 'no_data');\n</code></pre> <p>\u4ee5 <code>no_data</code> \u6a21\u5f0f\u91cd\u65b0\u555f\u52d5\u9023\u63a5\u5668\u4e0d\u6703\u91cd\u65b0\u91cd\u5efa\u6a21\u5f0f\uff0c\u800c\u662f\u5f9e\u4e0a\u6b21\u6210\u529f\u9ede\u6062\u5fa9 CDC\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#cdc_3","title":"\u59cb\u7d42\u57f7\u884c\u521d\u59cb\u5feb\u7167 + CDC","text":"<p>\u4f7f\u7528 synchdb.olr_snapshot_engine = 'debezium' \u6642\uff1a</p> <p>\u60a8\u9700\u8981\u5728\u76ee\u6a19\u8cc7\u6599\u5eab\u4e2d\u5efa\u7acb\u521d\u59cb\u8868\u6a21\u5f0f\u548c\u8cc7\u6599\u3002 Debezium \u4e0d\u6703\u5275\u5efa\u5b83\u5011\u3002</p> <p>\u4f7f\u7528 synchdb.olr_snapshot_engine = 'fdw' \u6642\uff1a</p> <p>\u4f7f\u7528 <code>always</code> \u6a21\u5f0f\u555f\u52d5\u9023\u63a5\u5668\u5c07\u59cb\u7d42\u64f7\u53d6\u64f7\u53d6\u8868\u7684\u6a21\u5f0f\uff0c\u59cb\u7d42\u91cd\u65b0\u57f7\u884c\u521d\u59cb\u5feb\u7167\uff0c\u7136\u5f8c\u9032\u884c CDC\u3002\u9019\u985e\u4f3c\u65bc\u91cd\u7f6e\u6309\u9215\uff0c\u56e0\u70ba\u4f7f\u7528\u6b64\u6a21\u5f0f\u5c07\u91cd\u5efa\u6240\u6709\u5167\u5bb9\u3002\u8acb\u8b39\u614e\u4f7f\u7528\u6b64\u6a21\u5f0f\uff0c\u5c24\u5176\u662f\u5728\u6355\u7372\u5927\u91cf\u8868\u6642\uff0c\u9019\u53ef\u80fd\u9700\u8981\u5f88\u9577\u6642\u9593\u624d\u80fd\u5b8c\u6210\u3002\u91cd\u5efa\u5b8c\u6210\u5f8c\uff0cCDC \u5c07\u7167\u5e38\u6062\u5fa9\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('pgconn', 'always');\n</code></pre> <p>\u4f46\u662f\uff0c\u53ef\u4ee5\u4f7f\u7528\u9023\u63a5\u5668\u7684 <code>snapshottable</code> \u9078\u9805\u4f86\u9078\u64c7\u90e8\u5206\u9336\u91cd\u65b0\u5efa\u7acb\u521d\u59cb\u5feb\u7167\u3002\u7b26\u5408 <code>snapshottable</code> \u4e2d\u689d\u4ef6\u7684\u8868\u5c07\u91cd\u65b0\u5efa\u7acb\u521d\u59cb\u5feb\u7167\uff1b\u5426\u5247\uff0c\u5c07\u8df3\u904e\u5176\u521d\u59cb\u5feb\u7167\u3002\u5982\u679c <code>snapshottable</code> \u70ba\u7a7a\uff0c\u5247\u9810\u8a2d\u60c5\u6cc1\u4e0b\uff0c\u9023\u63a5\u5668\u7684 <code>table</code> \u9078\u9805\u4e2d\u6307\u5b9a\u7684\u6240\u6709\u8868\u90fd\u6703\u4ee5 <code>always</code> \u6a21\u5f0f\u91cd\u65b0\u5efa\u7acb\u521d\u59cb\u5feb\u7167\u3002</p> <p>\u6b64\u7bc4\u4f8b\u50c5\u4f7f\u9023\u63a5\u5668\u91cd\u65b0\u5efa\u7acb <code>inventory.customers</code> \u8868\u7684\u521d\u59cb\u5feb\u7167\u3002\u6240\u6709\u5176\u4ed6\u8868\u7684\u5feb\u7167\u90fd\u5c07\u88ab\u8df3\u904e\u3002</p> <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{snapshottable}', '\"public.customers\"') \nWHERE name = 'pgconn';\n</code></pre> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\uff0cCDC \u5c07\u958b\u59cb\u904b\u884c\u3002\u4ee5 <code>always</code> \u6a21\u5f0f\u91cd\u65b0\u555f\u52d5\u9023\u63a5\u5668\u5c07\u91cd\u8907\u4e0a\u8ff0\u904e\u7a0b\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#postgres","title":"Postgres \u9023\u63a5\u5668\u7684\u53ef\u7528\u5feb\u7167\u6a21\u5f0f","text":"<ul> <li>initial\uff08\u9810\u8a2d\uff09</li> <li>initial_only</li> <li>no_data</li> <li>always</li> <li>schemasync</li> </ul>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#schemasync","title":"\u4f7f\u7528 schemasync \u6a21\u5f0f\u9810\u89bd\u4f86\u6e90\u8868\u548c\u76ee\u6a19\u8868\u95dc\u4fc2","text":"<p>\u5728\u5617\u8a66\u5c0d\u7576\u524d\u8868\u548c\u8cc7\u6599\uff08\u53ef\u80fd\u975e\u5e38\u9f90\u5927\uff09\u9032\u884c\u521d\u59cb\u5feb\u7167\u4e4b\u524d\uff0c\u53ef\u4ee5\u5728\u5be6\u969b\u8cc7\u6599\u9077\u79fb\u4e4b\u524d\u300c\u9810\u89bd\u300d\u4f86\u6e90\u8868\u548c\u76ee\u6a19\u8868\u4e4b\u9593\u7684\u6240\u6709\u8868\u548c\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u3002\u9019\u4f7f\u60a8\u53ef\u4ee5\u5728\u5be6\u969b\u9077\u79fb\u4e4b\u524d\u4fee\u6539\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u6216\u7269\u4ef6\u540d\u7a31\u3002\u9019\u53ef\u4ee5\u900f\u904e\u7279\u6b8a\u7684\u300cschemasync\u300d\u521d\u59cb\u5feb\u7167\u6a21\u5f0f\u4f86\u5be6\u73fe\u3002\u6709\u95dc\u8a73\u7d30\u7bc4\u4f8b\uff0c\u8acb\u53c3\u95b1\u7269\u4ef6\u5c0d\u6620\u5de5\u4f5c\u6d41\u7a0b\u3002</p> <p>\u8acb\u6ce8\u610f\uff0c\u60a8\u5fc5\u9808\u5c07 <code>synchdb.olr_snapshot_engine</code> \u8a2d\u5b9a\u70ba 'fdw' \u624d\u80fd\u4f7f\u7528 <code>schemasync</code> \u6a21\u5f0f\u9810\u89bd\u8868\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#_3","title":"\u9078\u64c7\u6027\u8868\u540c\u6b65","text":""},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#_4","title":"\u9078\u64c7\u6240\u9700\u8868\u4e26\u9996\u6b21\u555f\u52d5","text":"<p>\u8868\u683c\u9078\u64c7\u5728\u9023\u63a5\u5668\u5efa\u7acb\u968e\u6bb5\u900f\u904e <code>synchdb_add_conninfo()</code> \u51fd\u6578\u5b8c\u6210\uff0c\u8a72\u51fd\u6578\u7528\u65bc\u6307\u5b9a\u8981\u5f9e\u4e2d\u8907\u88fd\u7684\u8868\u5217\u8868\uff08\u4ee5\u5b8c\u5168\u9650\u5b9a\u540d\u7a31 (FQN) \u8868\u793a\uff0c\u4e26\u4ee5\u9017\u865f\u5206\u9694\uff09\u3002</p> <p>\u4f8b\u5982\uff0c\u4ee5\u4e0b\u547d\u4ee4\u5efa\u7acb\u4e00\u500b\u9023\u63a5\u5668\uff0c\u8a72\u9023\u63a5\u5668\u50c5\u8907\u88fd\u9060\u7aef PostgreSQL \u8cc7\u6599\u5eab\u4e2d <code>public.orders</code> \u8868\u7684\u8b8a\u66f4\u3002 <pre><code>SELECT synchdb_add_conninfo(\n    'pgconn', \n    '127.0.0.1', \n    5433, \n    'pguser', \n    'pgpass', \n    'postgres', \n    'public', \n    'public.orders', \n    'null', \n    'postgres'\n);\n</code></pre></p> <p>\u9996\u6b21\u555f\u52d5\u6b64\u9023\u63a5\u5668\u6642\uff0c\u5c07\u89f8\u767c\u57f7\u884c\u521d\u59cb\u5feb\u7167\uff0c\u4e26\u8907\u88fd\u6240\u9078\u8868\u7684\u67b6\u69cb\u548c\u8cc7\u6599\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#_5","title":"\u9a57\u8b49\u9023\u63a5\u5668\u72c0\u614b\u548c\u8868\u683c","text":"<p>\u6aa2\u67e5\u9023\u63a5\u5668\u72c0\u614b\u548c\u65b0\u8868\u683c\uff1a <pre><code>postgres=# Select name, state, err from synchdb_state_view;\n  name  |  state  |   err\n--------+---------+----------\n pgconn | polling | no error\n\n\npostgres=# \\dt postgres.*\n           List of tables\n  Schema  |  Name  | Type  | Owner\n----------+--------+-------+--------\n postgres | orders | table | pguser\n</code></pre></p> <p>\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c\u9023\u63a5\u5668\u5c07\u7e7c\u7e8c\u64f7\u53d6\u8868\u683c\u7684\u5f8c\u7e8c\u8b8a\u66f4\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#_6","title":"\u904b\u884c\u6642\u52a0\u5165\u66f4\u591a\u8981\u8907\u88fd\u7684\u8868","text":"<p>\u4e0a\u4e00\u7bc0\u4e2d\u7684 <code>mysqlconn</code> \u5df2\u5b8c\u6210\u521d\u59cb\u5feb\u7167\u4e26\u53d6\u5f97\u4e86\u6240\u9078\u8868\u683c\u7684\u8868\u683c\u7d50\u69cb\u3002\u5982\u679c\u6211\u5011\u60f3\u8981\u65b0\u589e\u66f4\u591a\u8981\u8907\u88fd\u7684\u8868\uff0c\u5247\u9700\u8981\u901a\u77e5 Debezium \u5f15\u64ce\u66f4\u65b0\u4e86\u8868\u7d50\u69cb\uff0c\u4e26\u518d\u6b21\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u5177\u9ad4\u64cd\u4f5c\u5982\u4e0b\uff1a</p> <ol> <li>\u66f4\u65b0 <code>synchdb_conninfo</code> \u8868\u4ee5\u5305\u542b\u5176\u4ed6\u8868\u3002</li> <li>\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u5011\u5c07 <code>inventory.customers</code> \u8868\u52a0\u5165\u540c\u6b65\u6e05\u55ae\uff1a <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"public.orders,public.customers\"') \nWHERE name = 'pgconn';\n</code></pre></li> <li>\u914d\u7f6e\u5feb\u7167\u8868\u53c3\u6578\uff0c\u4f7f\u5176\u53ea\u5305\u542b\u65b0\u8868 <code>inventory.customers</code>\uff0c\u9019\u6a23 SynchDB \u5c31\u4e0d\u6703\u5617\u8a66\u91cd\u5efa\u5df2\u7d93\u5b8c\u6210\u5feb\u7167\u7684 2 \u500b\u8868\u3002 <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{snapshottable}', '\"public.customers\"') \nWHERE name = 'pgconn';\n</code></pre></li> <li>\u5c07\u5feb\u7167\u6a21\u5f0f\u8a2d\u70ba\u201c\u59cb\u7d42\u201d\uff0c\u7136\u5f8c\u91cd\u65b0\u555f\u52d5\u9023\u63a5\u5668\uff0c\u4ee5\u57f7\u884c\u53e6\u4e00\u6b21\u521d\u59cb\u5feb\u7167\uff1a <pre><code>SELECT synchdb_stop_engine_bgw('pgconn');\nSELECT synchdb_start_engine_bgw('pgconn', 'always');\n</code></pre></li> </ol> <p>&lt;&lt;\u91cd\u8981\u63d0\u793a&gt;&gt; \u8acb\u6ce8\u610f\uff0c\u6b64\u8655\u6211\u5011\u4e0d\u4f7f\u7528 <code>synchdb_restart_connector</code> \u4f86\u91cd\u555f\u9023\u63a5\u5668\uff0c\u56e0\u70ba\u8a72\u51fd\u6578\u4e3b\u8981\u7528\u65bc\u4ee5\u4e0d\u540c\u7684\u5feb\u7167\u6a21\u5f0f\u91cd\u65b0\u555f\u52d5 Debezium \u5f15\u64ce\u3002\u7531\u65bc Postgres \u9023\u63a5\u5668\u4f7f\u7528 FDW \u800c\u975e Debezium \u4f86\u5efa\u7acb\u521d\u59cb\u8868\uff0c\u56e0\u6b64\u6211\u5011\u5fc5\u9808\u660e\u78ba\u5730\u57f7\u884c <code>stop engine</code>\uff0c\u7136\u5f8c\u518d\u547c\u53eb <code>start engine</code> \u4f86\u89f8\u767c FDW \u4f8b\u7a0b\u518d\u6b21\u904b\u884c\u3002</p>"},{"location":"zh/tutorial/postgresql_cdc_to_postgresql/#_7","title":"\u9a57\u8b49\u66f4\u65b0\u5f8c\u7684\u8868\u683c","text":"<p>\u73fe\u5728\uff0c\u6211\u5011\u53ef\u4ee5\u518d\u6b21\u6aa2\u67e5\u6211\u5011\u7684\u8868\uff1a <pre><code>postgres=# \\dt inventory.*\n             List of tables\n  Schema   |   Name    | Type  | Owner\n-----------+-----------+-------+--------\n inventory | customers | table | ubuntu\n inventory | orders    | table | ubuntu\n inventory | products  | table | ubuntu\n</code></pre></p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#synchdb-sql-server","title":"\u4e3a SynchDB \u51c6\u5907 SQL Server \u6570\u636e\u5e93","text":"<p>\u5728\u4f7f\u7528 SynchDB \u4ece SQL Server \u8fdb\u884c\u590d\u5236\u4e4b\u524d\uff0c\u9700\u8981\u6309\u7167\u6b64\u5904 \u6982\u8ff0\u7684\u6b65\u9aa4\u914d\u7f6e SQL Server\u3002</p> <p>\u8bf7\u786e\u4fdd\u6240\u9700\u7684\u8868\u5df2\u5728 SQL Server \u4e2d\u542f\u7528\u4e3a CDC \u8868\u3002\u60a8\u53ef\u4ee5\u5728 SQL Server \u5ba2\u6237\u7aef\u4e0a\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff0c\u4e3a\u201cdbo.customer\u201d\u3001\u201cdbo.district\u201d\u548c\u201cdbo.history\u201d\u542f\u7528 CDC\u3002\u60a8\u5c06\u6839\u636e\u9700\u8981\u7ee7\u7eed\u6dfb\u52a0\u65b0\u8868\u3002</p> <pre><code>USE testDB\nGO\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'customer', @role_name = NULL, @supports_net_changes = 0;\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'district', @role_name = NULL, @supports_net_changes = 0;\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'history', @role_name = NULL, @supports_net_changes = 0;\nGO\n</code></pre>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#_1","title":"\u521d\u59cb\u5feb\u7167","text":"<p>SynchDB \u4e2d\u7684\u300c\u521d\u59cb\u5feb\u7167\u300d\uff08\u6216\u8868\u5feb\u7167\uff09\u662f\u6307\u8907\u88fd\u6240\u6709\u6307\u5b9a\u8868\u7684\u8868\u7d50\u69cb\u548c\u521d\u59cb\u8cc7\u6599\u3002\u9019\u985e\u4f3c\u65bc PostgreSQL \u908f\u8f2f\u8907\u88fd\u4e2d\u7684\u300c\u8868\u540c\u6b65\u300d\u3002\u7576\u4f7f\u7528\u9810\u8a2d\u7684 <code>initial</code> \u6a21\u5f0f\u555f\u52d5\u9023\u63a5\u5668\u6642\uff0c\u5b83\u6703\u5728\u9032\u5165\u8b8a\u66f4\u8cc7\u6599\u64f7\u53d6 (CDC) \u968e\u6bb5\u4e4b\u524d\u81ea\u52d5\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u53ef\u4ee5\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u90e8\u5206\u7701\u7565\u6b64\u6b65\u9a5f\u3002\u6709\u95dc\u6240\u6709\u5feb\u7167\u9078\u9805\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c\u9023\u63a5\u5668\u5728\u5f8c\u7e8c\u91cd\u65b0\u555f\u52d5\u6642\u4e0d\u6703\u518d\u6b21\u57f7\u884c\u6b64\u64cd\u4f5c\uff0c\u800c\u662f\u76f4\u63a5\u5f9e\u4e0a\u6b21\u672a\u5b8c\u6210\u7684\u504f\u79fb\u91cf\u8655\u6062\u5fa9 CDC\u3002\u6b64\u884c\u70ba\u7531 Debezium \u5f15\u64ce\u7ba1\u7406\u7684\u5143\u8cc7\u6599\u6a94\u6848\u63a7\u5236\u3002\u6709\u95dc\u5143\u8cc7\u6599\u6a94\u6848\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#_2","title":"\u4e0d\u540c\u7684\u9023\u63a5\u5668\u555f\u52d5\u6a21\u5f0f","text":""},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#sql-server","title":"\u521b\u5efa SQL Server \u8fde\u63a5\u5668","text":"<p>\u521b\u5efa\u4e00\u4e2a\u8fde\u63a5\u5668\uff0c\u8be5\u8fde\u63a5\u5668\u6307\u5411 SQL Server \u4e2d <code>testDB</code> \u6570\u636e\u5e93\u4e0b\u7684\u6240\u6709\u8868\u3002 <pre><code>SELECT\nsynchdb_add_conninfo(\n'sqlserverconn', '127.0.0.1', 1433,\n'sa', 'Password!', 'testDB', 'postgres',\n'null', 'null', 'sqlserver');\n</code></pre></p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#cdc","title":"\u521d\u59cb\u5feb\u7167 + \u53d8\u66f4\u6570\u636e\u6355\u83b7 (CDC)","text":"<p>\u4f7f\u7528 <code>initial</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u5bf9\u6240\u6709\u6307\u5b9a\u7684\u8868\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a\u6240\u6709\u8868\uff09\u6267\u884c\u521d\u59cb\u5feb\u7167\u3002\u5b8c\u6210\u540e\uff0c\u53d8\u66f4\u6570\u636e\u6355\u83b7 (CDC) \u8fc7\u7a0b\u5c06\u5f00\u59cb\u6d41\u5f0f\u4f20\u8f93\u65b0\u7684\u53d8\u66f4\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn', 'initial');\n\n\u6216\n\nSELECT synchdb_start_engine_bgw('sqlserverconn');\n</code></pre> <p>\u6b64\u8fde\u63a5\u5668\u9996\u6b21\u8fd0\u884c\u65f6\uff0c\u5176\u9636\u6bb5\u5e94\u5904\u4e8e\u201c\u521d\u59cb\u5feb\u7167\u201d\u72b6\u6001\uff1a <pre><code>postgres=# select * from synchdb_state_view where name='sqlserverconn';\n     name      | connector_type |  pid   |      stage       |  state  |   err    |       last_dbz_offset\n---------------+----------------+--------+------------------+---------+----------+-----------------------------\n sqlserverconn | sqlserver      | 526003 | initial snapshot | polling | no error | offset file not flushed yet\n(1 row)\n</code></pre></p> <p>\u5c06\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a\u201ctestdb\u201d\u7684\u65b0\u6a21\u5f0f\uff0c\u5e76\u4e14\u8fde\u63a5\u5668\u6d41\u5f0f\u4f20\u8f93\u7684\u6240\u6709\u8868\u90fd\u5c06\u5728\u8be5\u6a21\u5f0f\u4e0b\u590d\u5236\u3002 <pre><code>postgres=# set search_path=public,testdb;\nSET\npostgres=# \\d\n                  List of relations\n Schema |          Name           |   Type   | Owner\n--------+-------------------------+----------+--------\n public | synchdb_att_view        | view     | ubuntu\n public | synchdb_attribute       | table    | ubuntu\n public | synchdb_conninfo        | table    | ubuntu\n public | synchdb_objmap          | table    | ubuntu\n public | synchdb_state_view      | view     | ubuntu\n public | synchdb_stats_view      | view     | ubuntu\n testdb | customers               | table    | ubuntu\n testdb | customers_id_seq        | sequence | ubuntu\n testdb | orders                  | table    | ubuntu\n testdb | orders_order_number_seq | sequence | ubuntu\n testdb | products                | table    | ubuntu\n testdb | products_id_seq         | sequence | ubuntu\n testdb | products_on_hand        | table    | ubuntu\n(13 rows)\n</code></pre></p> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u540e\uff0c\u5982\u679c\u81f3\u5c11\u63a5\u6536\u5e76\u5904\u7406\u4e86\u4e00\u4e2a\u540e\u7eed\u66f4\u6539\uff0c\u5219\u8fde\u63a5\u5668\u9636\u6bb5\u5e94\u4ece\u201c\u521d\u59cb\u5feb\u7167\u201d\u66f4\u6539\u4e3a\u201c\u66f4\u6539\u6570\u636e\u6355\u83b7\u201d\u3002 <pre><code>postgres=# select * from synchdb_state_view where name='sqlserverconn';\n     name      | connector_type |  pid   |        stage        |  state  |   err    |\n             last_dbz_offset\n---------------+----------------+--------+---------------------+---------+----------+-----------------------------\n----------------------------------------------------------------------\n sqlserverconn | sqlserver      | 526290 | change data capture | polling | no error | {\"event_serial_no\":1,\"commit\n_lsn\":\"0000002b:000004d8:0004\",\"change_lsn\":\"0000002b:000004d8:0003\"}\n(1 row\n</code></pre> \u8fd9\u610f\u5473\u7740\u8fde\u63a5\u5668\u73b0\u5728\u6b63\u5728\u6d41\u5f0f\u4f20\u8f93\u6307\u5b9a\u8868\u7684\u65b0\u66f4\u6539\u3002\u4ee5\u201cinitial\u201d\u6a21\u5f0f\u91cd\u542f\u8fde\u63a5\u5668\u5c06\u4ece\u4e0a\u6b21\u6210\u529f\u70b9\u5f00\u59cb\u7ee7\u7eed\u590d\u5236\uff0c\u5e76\u4e14\u4e0d\u4f1a\u91cd\u65b0\u8fd0\u884c\u521d\u59cb\u5feb\u7167\u3002</p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#cdc_1","title":"\u4ec5\u521d\u59cb\u5feb\u7167\uff0c\u65e0CDC","text":"<p>\u4f7f\u7528\u201cinitial_only\u201d\u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4ec5\u5bf9\u6240\u6709\u6307\u5b9a\u8868\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a\u6240\u6709\u8868\uff09\u6267\u884c\u521d\u59cb\u5feb\u7167\uff0c\u4e4b\u540e\u5c06\u4e0d\u518d\u6267\u884cCDC\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn', 'initial_only');\n</code></pre> <p>\u8fde\u63a5\u5668\u4ecd\u7136\u4f1a\u663e\u793a\u6b63\u5728\u201c\u8f6e\u8be2\u201d\uff0c\u4f46\u7531\u4e8eDebzium\u5185\u90e8\u5df2\u505c\u6b62CDC\uff0c\u56e0\u6b64\u4e0d\u4f1a\u6355\u83b7\u4efb\u4f55\u66f4\u6539\u3002\u60a8\u53ef\u4ee5\u9009\u62e9\u5173\u95ed\u5b83\u3002\u4ee5\u201cinitial_only\u201d\u6a21\u5f0f\u91cd\u542f\u8fde\u63a5\u5668\u4e0d\u4f1a\u91cd\u5efa\u8868\uff0c\u56e0\u4e3a\u5b83\u4eec\u5df2\u7ecf\u6784\u5efa\u597d\u4e86\u3002</p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#cdc_2","title":"\u4ec5\u6355\u83b7\u8868\u6a21\u5f0f + CDC","text":"<p>\u4f7f\u7528 <code>no_data</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4ec5\u6267\u884c\u6a21\u5f0f\u6355\u83b7\uff0c\u5728 PostgreSQL \u4e2d\u6784\u5efa\u76f8\u5e94\u7684\u8868\uff0c\u5e76\u4e14\u4e0d\u4f1a\u590d\u5236\u73b0\u6709\u8868\u6570\u636e\uff08\u8df3\u8fc7\u521d\u59cb\u5feb\u7167\uff09\u3002\u6a21\u5f0f\u6355\u83b7\u5b8c\u6210\u540e\uff0c\u8fde\u63a5\u5668\u5c06\u8fdb\u5165 CDC \u6a21\u5f0f\uff0c\u5e76\u5f00\u59cb\u6355\u83b7\u5bf9\u8868\u7684\u540e\u7eed\u66f4\u6539\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn', 'no_data');\n</code></pre> <p>\u5728 <code>no_data</code> \u6a21\u5f0f\u4e0b\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u4e0d\u4f1a\u518d\u6b21\u91cd\u5efa\u6a21\u5f0f\uff0c\u5e76\u4e14\u5b83\u5c06\u4ece\u4e0a\u6b21\u6210\u529f\u70b9\u6062\u590d CDC\u3002</p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#cdc_3","title":"\u59cb\u7ec8\u6267\u884c\u521d\u59cb\u5feb\u7167 + CDC","text":"<p>\u4f7f\u7528 <code>always</code> \u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u59cb\u7ec8\u6355\u83b7\u6355\u83b7\u8868\u7684\u6a21\u5f0f\uff0c\u59cb\u7ec8\u91cd\u505a\u521d\u59cb\u5feb\u7167\uff0c\u7136\u540e\u8f6c\u5230 CDC\u3002\u8fd9\u7c7b\u4f3c\u4e8e\u91cd\u7f6e\u6309\u94ae\uff0c\u56e0\u4e3a\u4f7f\u7528\u6b64\u6a21\u5f0f\u5c06\u91cd\u5efa\u6240\u6709\u5185\u5bb9\u3002\u8bf7\u8c28\u614e\u4f7f\u7528\u6b64\u6a21\u5f0f\uff0c\u5c24\u5176\u662f\u5728\u6355\u83b7\u5927\u91cf\u8868\u65f6\uff0c\u8fd9\u53ef\u80fd\u9700\u8981\u5f88\u957f\u65f6\u95f4\u624d\u80fd\u5b8c\u6210\u3002\u91cd\u5efa\u540e\uff0cCDC \u5c06\u6062\u590d\u6b63\u5e38\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn', 'always');\n</code></pre> <p>\u4f46\u662f\uff0c\u53ef\u4ee5\u4f7f\u7528\u8fde\u63a5\u5668\u7684 <code>snapshottable</code> \u9009\u9879\u9009\u62e9\u90e8\u5206\u8868\u6765\u91cd\u505a\u521d\u59cb\u5feb\u7167\u3002\u7b26\u5408 <code>snapshottable</code> \u4e2d\u6761\u4ef6\u7684\u8868\u5c06\u91cd\u505a\u521d\u59cb\u5feb\u7167\uff0c\u5426\u5219\u5c06\u8df3\u8fc7\u5176\u521d\u59cb\u5feb\u7167\u3002\u5982\u679c <code>snapshottable</code> \u4e3a null \u6216\u4e3a\u7a7a\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u8fde\u63a5\u5668\u7684 <code>table</code> \u9009\u9879\u4e2d\u6307\u5b9a\u7684\u6240\u6709\u8868\u5c06\u5728 <code>always</code> \u6a21\u5f0f\u4e0b\u91cd\u505a\u521d\u59cb\u5feb\u7167\u3002</p> <p>\u6b64\u793a\u4f8b\u4f7f\u8fde\u63a5\u5668\u4ec5\u91cd\u505a <code>inventory.customers</code> \u8868\u7684\u521d\u59cb\u5feb\u7167\u3002\u6240\u6709\u5176\u4ed6\u8868\u7684\u5feb\u7167\u5c06\u88ab\u8df3\u8fc7\u3002 <pre><code>UPDATE synchdb_conninfo\nSET data = jsonb_set(data, '{snapshottable}', '\"inventory.customers\"')\nWHERE name = 'sqlserverconn';\n</code></pre></p> <p>\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u540e\uff0cCDC \u5c06\u5f00\u59cb\u3002\u5728 <code>always</code> \u6a21\u5f0f\u4e0b\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u5c06\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\u3002</p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#sql-server_1","title":"SQL Server \u9023\u63a5\u5668\u7684\u53ef\u7528\u5feb\u7167\u6a21\u5f0f","text":"<ul> <li>initial (default)</li> <li>initial_only</li> <li>no_data</li> <li>always</li> <li>schemasync</li> </ul>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#schemasync","title":"\u4f7f\u7528 schemasync \u6a21\u5f0f\u9810\u89bd\u4f86\u6e90\u8868\u548c\u76ee\u6a19\u8868\u95dc\u4fc2","text":"<p>\u5728\u5617\u8a66\u5c0d\u7576\u524d\u8868\u548c\u8cc7\u6599\uff08\u53ef\u80fd\u975e\u5e38\u9f90\u5927\uff09\u9032\u884c\u521d\u59cb\u5feb\u7167\u4e4b\u524d\uff0c\u53ef\u4ee5\u5728\u5be6\u969b\u8cc7\u6599\u9077\u79fb\u4e4b\u524d\u300c\u9810\u89bd\u300d\u4f86\u6e90\u8868\u548c\u76ee\u6a19\u8868\u4e4b\u9593\u7684\u6240\u6709\u8868\u548c\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u3002\u9019\u6a23\uff0c\u60a8\u5c31\u6709\u6a5f\u6703\u5728\u5be6\u969b\u9077\u79fb\u4e4b\u524d\u4fee\u6539\u8cc7\u6599\u985e\u578b\u5c0d\u61c9\u6216\u7269\u4ef6\u540d\u7a31\u3002\u9019\u53ef\u4ee5\u900f\u904e\u7279\u6b8a\u7684\u300cschemasync\u300d\u521d\u59cb\u5feb\u7167\u6a21\u5f0f\u4f86\u5be6\u73fe\u3002\u6709\u95dc\u8a73\u7d30\u7bc4\u4f8b\uff0c\u8acb\u53c3\u95b1\u5bf9\u8c61\u6620\u5c04\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#_3","title":"\u9078\u64c7\u6027\u8868\u540c\u6b65","text":""},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#_4","title":"\u9078\u64c7\u6240\u9700\u8868\u4e26\u9996\u6b21\u555f\u52d5","text":"<p>\u8868\u683c\u9078\u64c7\u5728\u9023\u63a5\u5668\u5efa\u7acb\u968e\u6bb5\u900f\u904e <code>synchdb_add_conninfo()</code> \u51fd\u6578\u5b8c\u6210\uff0c\u8a72\u51fd\u6578\u7528\u65bc\u6307\u5b9a\u8981\u5f9e\u4e2d\u8907\u88fd\u7684\u8868\u5217\u8868\uff08\u4ee5\u5b8c\u5168\u9650\u5b9a\u540d\u7a31 (FQN) \u8868\u793a\uff0c\u4e26\u4ee5\u9017\u865f\u5206\u9694\uff09\u3002</p> <p>\u4f8b\u5982\uff0c\u4ee5\u4e0b\u547d\u4ee4\u5efa\u7acb\u4e00\u500b\u9023\u63a5\u5668\uff0c\u8a72\u9023\u63a5\u5668\u50c5\u8907\u88fd\u9060\u7aef SQL Server \u8cc7\u6599\u5eab\u4e2d <code>dbo.orders</code> \u8cc7\u6599\u8868\u7684\u8b8a\u66f4\u3002 <pre><code>SELECT synchdb_add_conninfo(\n    'sqlserverconn', \n    '127.0.0.1', \n    1433, \n    'sa', \n    'Password!', \n    'testDB', \n    'dbo', \n    'dbo.orders,dbo.products',\n    'null', \n    'sqlserver'\n);\n</code></pre></p> <p>\u9996\u6b21\u555f\u52d5\u6b64\u9023\u63a5\u5668\u6642\uff0c\u5c07\u89f8\u767c\u57f7\u884c\u521d\u59cb\u5feb\u7167\uff0c\u4e26\u8907\u88fd\u9078\u5b9a\u7684 2 \u500b\u8868\u7684\u67b6\u69cb\u548c\u8cc7\u6599\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('sqlserverconn');\n</code></pre>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#_5","title":"\u9a57\u8b49\u9023\u63a5\u5668\u72c0\u614b\u548c\u8868\u683c","text":"<p>\u6aa2\u67e5\u9023\u63a5\u5668\u72c0\u614b\u548c\u65b0\u8868\u683c\uff1a <pre><code>postgres=# Select name, state, err from synchdb_state_view;\n     name      |  state  |   err\n---------------+---------+----------\n sqlserverconn | polling | no error\n\npostgres=# \\dt testdb.*\n           List of tables\n Schema |   Name   | Type  | Owner\n--------+----------+-------+--------\n testdb | orders   | table | ubuntu\n testdb | products | table | ubuntu\n</code></pre></p> <p>\u9810\u8a2d\u60c5\u6cc1\u4e0b\uff0c\u4f86\u6e90\u8cc7\u6599\u5eab\u540d\u7a31\u6703\u5c0d\u61c9\u5230\u76ee\u6a19\u8cc7\u6599\u5eab\u7684\u6a21\u5f0f\uff0c\u56e0\u6b64 <code>dbo.orders</code> \u5728 PostgreSQL \u4e2d\u6703\u8b8a\u6210 <code>testdb.orders</code>\u3002\u8868\u5b8c\u6210\u521d\u59cb\u5feb\u7167\u5f8c\uff0c\u9023\u63a5\u5668\u5c07\u555f\u52d5 CDC \u4ee5\u4e32\u6d41\u50b3\u8f38\u9019\u4e9b\u8868\u7684\u5f8c\u7e8c\u8b8a\u66f4\u3002</p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#_6","title":"\u904b\u884c\u6642\u52a0\u5165\u66f4\u591a\u8981\u8907\u88fd\u7684\u8868","text":"<p>\u5982\u679c\u6211\u5011\u60f3\u8981\u65b0\u589e\u66f4\u591a\u8981\u8907\u88fd\u7684\u8868\uff0c\u9700\u8981\u901a\u77e5 Debezium \u5f15\u64ce\u66f4\u65b0\u4e86\u8868\u683c\u90e8\u5206\uff0c\u4e26\u91cd\u200b\u200b\u65b0\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u5177\u9ad4\u64cd\u4f5c\u5982\u4e0b\uff1a</p> <ol> <li> <p>\u66f4\u65b0 <code>synchdb_conninfo</code> \u8868\uff0c\u4f7f\u5176\u5305\u542b\u5176\u4ed6\u8868\u683c\u3002</p> </li> <li> <p>\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u5011\u5c07 <code>dbo.customers</code> \u8868\u52a0\u5165\u540c\u6b65\u6e05\u55ae\uff1a <pre><code>UPDATE synchdb_conninfo \nSET data = jsonb_set(data, '{table}', '\"dbo.orders,dbo.products,dbo.customers\"') \nWHERE name = 'sqlserverconn';\n</code></pre></p> </li> <li>\u5c07\u5feb\u7167\u6a21\u5f0f\u8a2d\u70ba\u201c\u59cb\u7d42\u201d\uff0c\u7136\u5f8c\u91cd\u65b0\u555f\u52d5\u9023\u63a5\u5668\uff0c\u4ee5\u57f7\u884c\u53e6\u4e00\u6b21\u521d\u59cb\u5feb\u7167\uff1a <pre><code>DROP table testdb.orders, testdb.products;\nSELECT synchdb_restart_connector('sqlserverconn', 'always');\n</code></pre></li> </ol> <p>\u9019\u8feb\u4f7f Debezium \u91cd\u65b0\u5efa\u7acb\u6240\u6709\u8868\u7684\u5feb\u7167\uff0c\u5305\u62ec\u820a\u8868 <code>dbo.orders</code> \u548c <code>dbo.products</code>\uff0c\u4ee5\u53ca\u5728\u9032\u884c CDC \u4e32\u6d41\u50b3\u8f38\u4e4b\u524d\u5efa\u7acb\u7684\u65b0\u8868\u3002\u9019\u610f\u5473\u8457\uff0c\u8981\u65b0\u589e\u7b2c\u4e09\u500b\u8868\uff0c\u5fc5\u9808\u522a\u9664\u73fe\u6709\u8868\uff08\u4ee5\u9632\u6b62\u91cd\u8907\u8868\u548c\u4e3b\u9375\u932f\u8aa4\uff09\uff0c\u4e26\u91cd\u65b0\u5efa\u7acb\u6574\u500b\u521d\u59cb\u5feb\u7167\u3002\u9019\u76f8\u7576\u5197\u9918\uff0cDebezium \u5efa\u8b70\u4f7f\u7528\u589e\u91cf\u5feb\u7167\u4f86\u65b0\u589e\u8cc7\u6599\u8868\uff0c\u800c\u7121\u9700\u91cd\u65b0\u5efa\u7acb\u5feb\u7167\u3002\u4e00\u65e6\u6211\u5011\u5c07\u589e\u91cf\u5feb\u7167\u652f\u63f4\u65b0\u589e\u81f3 SynchDB\uff0c\u6211\u5011\u5c07\u66f4\u65b0\u6b64\u904e\u7a0b\u3002</p>"},{"location":"zh/tutorial/sqlserver_cdc_to_postgresql/#_7","title":"\u9a57\u8b49\u66f4\u65b0\u5f8c\u7684\u8868\u683c","text":"<p>\u73fe\u5728\uff0c\u6211\u5011\u53ef\u4ee5\u518d\u6b21\u6aa2\u67e5\u6211\u5011\u7684\u8868\uff1a <pre><code>postgres=# \\dt \"testDB\".*\n           List of tables\n Schema |   Name    | Type  | Owner\n--------+-----------+-------+--------\n testDB | customers | table | ubuntu\n testDB | orders    | table | ubuntu\n testDB | products  | table | ubuntu\n</code></pre></p>"},{"location":"zh/user-guide/configure_error_strategies/","title":"\u914d\u7f6e\u9519\u8bef\u5904\u7406\u7b56\u7565","text":""},{"location":"zh/user-guide/configure_error_strategies/#_2","title":"\u914d\u7f6e\u9519\u8bef\u5904\u7406\u7b56\u7565","text":"<p>\u5728\u521d\u59cb\u5feb\u7167\u6216 CDC \u671f\u95f4\uff0c\u53ef\u80fd\u4f1a\u53d1\u751f\u8bf8\u5982\u4e3b\u952e\u51b2\u7a81\u3001\u6570\u636e\u65e0\u6548\u7b49\u9519\u8bef\uff0cSynchDB \u9700\u8981\u77e5\u9053\u5982\u4f55\u5904\u7406\u8fd9\u4e9b\u9519\u8bef\u3002\u5bf9\u4e8e Synchdb \u5904\u7406\u8fc7\u7a0b\u4e2d\u6216\u5e94\u7528\u5230 PostgreSQL \u8fc7\u7a0b\u4e2d\u53d1\u751f\u7684\u9519\u8bef\uff0c\u53ef\u4ee5\u901a\u8fc7\u914d\u7f6e\u53c2\u6570\u201csynchdb.error_handling_strategy\u201d\u4f7f\u7528\u591a\u79cd\u7b56\u7565\u6765\u5904\u7406\u5b83\u4eec\u3002</p> <p>\u8bf7\u6ce8\u610f\uff0c\u4ee5\u4e0b\u63d0\u5230\u7684\u9519\u8bef\u7b56\u7565\u4ec5\u5728\u9519\u8bef\u6e90\u81ea\u6216\u68c0\u6d4b\u5230 C \u7aef\u53d8\u66f4\u4e8b\u4ef6\u5904\u7406\u8fc7\u7a0b\u4e2d\u65f6\u624d\u4f1a\u6267\u884c\u3002\u5982\u679c\u9519\u8bef\u6e90\u81ea Java \u7aef\u7684 Debezium Runner\uff0c\u4f8b\u5982\u8fde\u63a5\u95ee\u9898\u6216\u4e0e\u8fdc\u7a0b\u6570\u636e\u5e93\u7684\u8fde\u63a5\u95ee\u9898\uff0c\u5219\u4e0a\u8ff0\u7b56\u7565\u5c06\u4e0d\u4f1a\u6267\u884c\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cDebezium Runner \u7684\u9519\u8bef\u6d88\u606f\u5c06\u4f20\u64ad\u5230 C \u7aef\u7684 SynchDB\uff0c\u5e76\u663e\u793a\u5728 <code>synchdb_state_view()</code> \u4e2d\uff0c\u8fde\u63a5\u5668\u5c06\u9000\u51fa\u3002</p>"},{"location":"zh/user-guide/configure_error_strategies/#exit","title":"exit (\u9ed8\u8ba4)","text":"<p>\u8fd9\u662f\u9ed8\u8ba4\u7684\u9519\u8bef\u7b56\u7565\uff0c\u5f53\u53d1\u751f\u9519\u8bef\u65f6\uff0c\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u4f1a\u9000\u51fa\u3002\u5f53\u524d\u6b63\u5728\u5904\u7406\u7684\u5bfc\u81f4\u9519\u8bef\u7684\u6279\u6b21\u5c06\u4e0d\u4f1a\u88ab\u6807\u8bb0\u4e3a\u5df2\u5b8c\u6210\uff0c\u5e76\u4e14\u4e0d\u4f1a\u63d0\u4ea4\u540c\u4e00\u6279\u6b21\u4e2d\u5df2\u6210\u529f\u5b8c\u6210\u7684\u66f4\u6539\u4e8b\u4ef6\u3002\u7528\u6237\u5e94\u68c0\u67e5\u201csynchdb_state_view()\u201d\u6216\u65e5\u5fd7\u6587\u4ef6\u4e2d\u8fd4\u56de\u7684\u9519\u8bef\u6d88\u606f\u4ee5\u89e3\u51b3\u9519\u8bef\u3002\u5f53\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u91cd\u65b0\u542f\u52a8\u65f6\uff0c\u8fde\u63a5\u5668\u5c06\u81ea\u52a8\u91cd\u8bd5\u4e4b\u524d\u5931\u8d25\u7684\u540c\u4e00\u6279\u3002</p>"},{"location":"zh/user-guide/configure_error_strategies/#retry","title":"retry","text":"<p>\u6b64\u7b56\u7565\u4e3a\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u6dfb\u52a0\u4e86 5 \u79d2\u7684\u201crestart_time\u201d\uff0c\u8fd9\u4f1a\u5bfc\u81f4 PostgreSQL \u7684 bgworker \u5f15\u64ce\u5728\u5de5\u4f5c\u5668\u9000\u51fa\u65f6\u6bcf 5 \u79d2\u81ea\u52a8\u542f\u52a8\u4e00\u6b21\u5de5\u4f5c\u5668\u3002\u8fd9\u610f\u5473\u7740\u5f53\u53d1\u751f\u9519\u8bef\u65f6\uff0c\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u4ecd\u5c06\u9000\u51fa\uff0c\u4f46\u4e0e\u4e0a\u9762\u7684 <code>exit</code> \u7b56\u7565\u4e0d\u540c\uff0c\u5b83\u5c06\u7531 bgworker \u5f15\u64ce\u81ea\u52a8\u91cd\u65b0\u542f\u52a8\uff0c\u540e\u8005\u5c06\u5728\u5931\u8d25\u7684\u540c\u4e00\u6279\u6b21\u4e0a\u91cd\u8bd5\u3002\u5b83\u5c06\u7ee7\u7eed\u9000\u51fa\u5e76\u91cd\u65b0\u542f\u52a8\uff0c\u76f4\u5230\u9519\u8bef\u5f97\u5230\u89e3\u51b3\u3002</p>"},{"location":"zh/user-guide/configure_error_strategies/#skip","title":"skip","text":"<p>\u987e\u540d\u601d\u4e49\uff0c\u5f53\u5904\u4e8e <code>skip</code> \u9519\u8bef\u7b56\u7565\u4e2d\u65f6\uff0c\u8fde\u63a5\u5668\u5de5\u4f5c\u5668\u9047\u5230\u7684\u4efb\u4f55\u9519\u8bef\u90fd\u4e0d\u4f1a\u5bfc\u81f4\u5de5\u4f5c\u5668\u9000\u51fa\uff0c\u4f46\u662f\u9519\u8bef\u6d88\u606f\u4ecd\u5c06\u5199\u5165\u65e5\u5fd7\u6216 <code>synchdb_state_view()</code>\uff0c\u4f46\u8fde\u63a5\u5668\u672c\u8eab\u5c06\u5ffd\u7565\u9519\u8bef\u5e76\u7ee7\u7eed\u5904\u7406\u4e0b\u4e00\u4e2a\u66f4\u6539\u4e8b\u4ef6\u751a\u81f3\u4e0b\u4e00\u4e2a\u6279\u6b21\u3002</p>"},{"location":"zh/user-guide/configure_error_strategies/#_3","title":"\u67e5\u770b\u8fde\u63a5\u5668\u7684\u6700\u540e\u4e00\u4e2a\u9519\u8bef\u6d88\u606f","text":"<p>\u5982\u4e0a\u6240\u8ff0\uff0c\u6e90\u81ea Java \u7aef\u7684 Debezium Runner \u6216 C \u7aef\u7684 SynchDB \u7684\u9519\u8bef\u5c06\u4f1a\u4f20\u64ad\u5e76\u663e\u793a\u5728 <code>synchdb_state_view()</code> \u4e2d\u3002\u4f8b\u5982\uff1a</p> <pre><code>select name, pid, err from synchdb_state_view;\n\n   name    | pid |                                                                                                          err\n-----------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n mysqlconn |  -1 | Connector configuration is not valid. Unable to connect: Communications link failure  The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n(1 row)\n</code></pre> <p>\u5982\u679c\u5728\u5904\u7406 JSON \u4e8b\u4ef6\u65f6\u53d1\u751f\u9519\u8bef\uff0c\u5e76\u4e14 GUC \u53c2\u6570 <code>synchdb.log_change_on_error</code> \u8bbe\u7f6e\u4e3a true\uff0cSynchDB \u8fd8\u4f1a\u5728 PostgreSQL \u65e5\u5fd7\u6587\u4ef6\u4e2d\u8f93\u51fa\u5bfc\u81f4\u9519\u8bef\u7684 JSON \u53d8\u5316\u4e8b\u4ef6\uff0c\u4ee5\u4fbf\u8fdb\u884c\u6545\u969c\u6392\u9664\u3002</p>"},{"location":"zh/user-guide/configure_infinispan/","title":"\u914d\u7f6e Infinispan \u7684 Oracle \u8fde\u63a5\u5668","text":""},{"location":"zh/user-guide/configure_infinispan/#_1","title":"\u6982\u8ff0","text":"<p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cDebezium \u7684 Oracle \u8fde\u63a5\u5668\u4f7f\u7528 JVM \u5806\u7f13\u5b58\u4f20\u5165\u7684\u53d8\u66f4\u4e8b\u4ef6\uff0c\u7136\u540e\u518d\u5c06\u5b83\u4eec\u4f20\u9012\u7ed9 SynchDB \u8fdb\u884c\u5904\u7406\u3002\u6700\u5927\u5806\u5927\u5c0f\u901a\u8fc7 <code>synchdb.jvm_max_heap_size</code> GUC \u63a7\u5236\u3002\u5f53 JVM \u5806\u5185\u5b58\u4e0d\u8db3\u65f6\uff08\u5c24\u5176\u662f\u5728\u5904\u7406\u5927\u578b\u4e8b\u52a1\u6216\u5305\u542b\u5927\u91cf\u5217\u7684\u6a21\u5f0f\u65f6\uff09\uff0c\u8fde\u63a5\u5668\u53ef\u80fd\u4f1a\u51fa\u73b0 OutOfMemoryError \u9519\u8bef\uff0c\u8fd9\u4f7f\u5f97\u5806\u5927\u5c0f\u8c03\u6574\u6210\u4e3a\u4e00\u9879\u5173\u952e\u7684\u8c03\u4f18\u6311\u6218\u3002</p> <p>\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0cDebezium \u53ef\u4ee5\u914d\u7f6e\u4f7f\u7528 Infinispan \u4f5c\u4e3a\u5176\u7f13\u5b58\u5c42\u3002Infinispan \u652f\u6301 JVM \u5806\u548c\u5806\u5916\uff08\u76f4\u63a5\u5185\u5b58\uff09\u7684\u5185\u5b58\u5b58\u50a8\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u5927\u7684\u7075\u6d3b\u6027\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u652f\u6301\u949d\u5316\u529f\u80fd\uff0c\u5141\u8bb8\u5728\u8fbe\u5230\u5185\u5b58\u9650\u5236\u65f6\u5c06\u591a\u4f59\u7684\u6570\u636e\u6ea2\u51fa\u5230\u78c1\u76d8\u3002\u8fd9\u4f7f\u5f97\u5b83\u5728\u9ad8\u8d1f\u8f7d\u4e0b\u66f4\u5177\u5f39\u6027\uff0c\u5e76\u786e\u4fdd\u80fd\u591f\u4f18\u96c5\u5730\u5904\u7406\u5927\u578b\u4e8b\u52a1\u6216\u6a21\u5f0f\u53d8\u66f4\uff0c\u800c\u4e0d\u4f1a\u8017\u5c3d\u5185\u5b58\u3002</p>"},{"location":"zh/user-guide/configure_infinispan/#synchdb_add_infinispan","title":"<code>synchdb_add_infinispan()</code>","text":"<p>\u7b7e\u540d\uff1a</p> <pre><code>synchdb_add_infinispan(\n    connectorName NAME,         -- \u8fde\u63a5\u5668\u540d\u79f0\n    memoryType NAME,            -- \u5185\u5b58\u7c7b\u578b\uff0c\u53ef\u4ee5\u662f\u201c\u5806\u201d\u6216\u201c\u975e\u5806\u201d\n    memorySize INT              -- \u9884\u7559\u4e3a\u7f13\u5b58\u7684\u5185\u5b58\u5927\u5c0f\uff08\u4ee5 MB \u4e3a\u5355\u4f4d\uff09\n)\n</code></pre> <p>\u4e3a\u7ed9\u5b9a\u7684\u8fde\u63a5\u5668\u6ce8\u518c\u4e00\u4e2a\u7531 Infinispan \u652f\u6301\u7684\u7f13\u5b58\u914d\u7f6e\u3002\u8fd9\u5141\u8bb8\u8fde\u63a5\u5668\u4f7f\u7528 Infinispan \u7f13\u51b2\u66f4\u6539\u4e8b\u4ef6\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u5806\u548c\u5806\u5916\u5185\u5b58\u5206\u914d\u4ee5\u53ca\u6ea2\u51fa\u5230\u78c1\u76d8\uff08\u949d\u5316\uff09\u3002</p> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u5982\u679c\u5728\u5f53\u524d\u6b63\u5728\u8fd0\u884c\u7684\u8fde\u63a5\u5668\u4e0a\u8c03\u7528\uff0c\u5219\u8be5\u8bbe\u7f6e\u5c06\u5728\u4e0b\u6b21\u91cd\u542f\u65f6\u751f\u6548\u3002</li> <li>\u5982\u679c\u8fde\u63a5\u5668\u5df2\u5b58\u5728 Infinispan \u7f13\u5b58\uff0c\u5b83\u5c06\u88ab\u66ff\u6362\u3002</li> <li>memoryType='off_heap' \u4f7f\u7528\u672c\u673a\uff08\u76f4\u63a5\uff09\u5185\u5b58\uff0c\u4e0d\u53d7 JVM \u5806\u9650\u5236\uff0c\u4f46\u5e94\u8c28\u614e\u8c03\u6574\u5927\u5c0f\u3002</li> <li>\u5f53\u5185\u5b58\u586b\u6ee1\u65f6\uff0c\u7f13\u5b58\u5c06\u81ea\u52a8\u652f\u6301\u949d\u5316\u5230\u78c1\u76d8\u3002</li> </ul> <p>\u793a\u4f8b\uff1a <pre><code>SELECT synchdb_add_infinispan('oracleconn', 'off_heap', 2048);\n</code></pre></p>"},{"location":"zh/user-guide/configure_infinispan/#synchdb_del_infinispan","title":"<code>synchdb_del_infinispan()</code>","text":"<p>\u7b7e\u540d\uff1a</p> <pre><code>synchdb_add_infinispan(\n    connectorName NAME          -- \u8fde\u63a5\u5668\u540d\u79f0\n)\n</code></pre> <p>\u5220\u9664\u6307\u5b9a\u8fde\u63a5\u5668\u7684 Infinispan \u7f13\u5b58\u914d\u7f6e\u53ca\u5176\u76f8\u5173\u7684\u78c1\u76d8\u5143\u6570\u636e\u3002\u6b64\u64cd\u4f5c\u5c06\u5220\u9664\uff1a</p> <ul> <li>\u6240\u6709\u7f13\u5b58\u6587\u4ef6</li> <li>\u6240\u6709\u949d\u5316\uff08\u6ea2\u51fa\u5230\u78c1\u76d8\uff09\u72b6\u6001</li> <li>\u76f8\u5173\u7684 Infinispan \u914d\u7f6e</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u6b64\u51fd\u6570\u53ea\u80fd\u5728\u8fde\u63a5\u5668\u505c\u6b62\u65f6\u6267\u884c\u3002</li> <li>\u5728\u8fde\u63a5\u5668\u5904\u4e8e\u6d3b\u52a8\u72b6\u6001\u65f6\u5c1d\u8bd5\u8fd0\u884c\u6b64\u51fd\u6570\u5c06\u5bfc\u81f4\u9519\u8bef\u3002</li> <li>\u6c38\u4e45\u7981\u7528\u6216\u91cd\u65b0\u914d\u7f6e\u8fde\u63a5\u5668\u7684\u7f13\u5b58\u540e\u7aef\u540e\uff0c\u4f7f\u7528\u6b64\u547d\u4ee4\u8fdb\u884c\u6e05\u7406\u3002</li> </ul> <p>Example: <pre><code>SELECT synchdb_del_infinispan('oracleconn');\n</code></pre></p>"},{"location":"zh/user-guide/configure_infinispan/#_2","title":"<code>\u949d\u5316</code>","text":"<p>\u949d\u5316\u7b80\u5355\u6765\u8bf4\u5c31\u662f\uff0c\u5982\u679c\u7f13\u5b58\u5df2\u6ee1\uff0cinfinispan \u4f1a\u5f39\u51fa\u5e76\u5c06\u6570\u636e\u5199\u5165\u78c1\u76d8\u3002\u53ea\u8981\u5185\u5b58\u4e2d\u6709\u8db3\u591f\u7684\u7a7a\u95f4\u6765\u4fdd\u5b58\u66f4\u6539\u4e8b\u4ef6\uff0c\u5c31\u4e0d\u4f1a\u53d1\u751f\u78c1\u76d8\u5199\u5165\u3002\u6570\u636e\u5c06\u5199\u5165 <code>$PGDATA/pg_synchdb/ispn_[\u8fde\u63a5\u5668\u540d\u79f0]_[\u76ee\u6807\u6570\u636e\u5e93\u540d\u79f0]</code></p>"},{"location":"zh/user-guide/configure_infinispan/#infinispan-oracle-sql","title":"\u7528\u4e8e\u6d4b\u8bd5 Infinispan \u5927\u578b\u4e8b\u52a1\u7684 Oracle SQL \u793a\u4f8b","text":"<p>\u5728 Oracle \u4e2d\u521b\u5efa\u6d4b\u8bd5\u8868\uff1a</p> <pre><code>CREATE TABLE big_tx_test (\n    id       NUMBER PRIMARY KEY,\n    payload  VARCHAR2(4000),\n    created  DATE DEFAULT SYSDATE\n);\n</code></pre> <p>\u521b\u5efa\u4e00\u4e2a\u76f8\u5bf9\u8f83\u5927\u7684\u4ea4\u6613\uff1a <pre><code>BEGIN\n  FOR i IN 1..100000 LOOP\n    INSERT INTO big_tx_test (id, payload)\n    VALUES (i, RPAD('x', 4000, 'x'));\n  END LOOP;\n  COMMIT;\nEND;\n/\n</code></pre></p> <p>\u5927\u4e8b\u52a1\u4e0b\u7684\u884c\u4e3a</p> <p>\u672a\u8bbe\u7f6e infinispan + \u4f4e JVM heap size (128)</p> <ul> <li>\u2192 \u5c06\u53d1\u751f OutOfMemory \u9519\u8bef</li> </ul> <p>\u4f4e JVM heap size (128) + \u9ad8 infinispan heap size (2048)</p> <ul> <li>\u2192 \u5927\u578b\u4e8b\u52a1\u6210\u529f\u5904\u7406</li> </ul> <p>\u4f4e JVM heap size (128) + \u4f4e infinispan heap size (128)</p> <ul> <li>\u2192 \u5c06\u53d1\u751f\u949d\u5316</li> <li>\u2192 <code>ispn_[\u8fde\u63a5\u5668\u540d\u79f0]_[\u76ee\u6807\u6570\u636e\u5e93\u540d\u79f0]</code> \u5927\u5c0f\u5728\u5904\u7406\u8fc7\u7a0b\u4e2d\u4f1a\u589e\u52a0\uff0c\u5927\u578b\u4e8b\u52a1\u5904\u7406\u5b8c\u6210\u540e\u4f1a\u51cf\u5c0f</li> <li>\u2192 \u5927\u578b\u4e8b\u52a1\u5df2\u6210\u529f\u5904\u7406\uff0c\u4f46\u901f\u5ea6\u8f83\u6162\u3002</li> </ul> <p>\u4f4e JVM heap size (128) + \u9ad8 infinispan heap size (2048)</p> <ul> <li>\u2192 \u5c06\u53d1\u751f OutOfMemory \u9519\u8bef</li> <li>\u2192 \u8bf7\u52ff\u5c06 infinispan \u914d\u7f6e heap size \u8d85\u8fc7 JVM \u6700\u5927 heap \u5185\u5b58</li> </ul> <p>\u8f83\u4f4e\u7684 JVM heap size (128) + \u8f83\u4f4e\u7684 infinispan heap size (64)</p> <ul> <li>\u2192 \u5c06\u53d1\u751f\u949d\u5316</li> <li>\u2192 <code>ispn_[\u8fde\u63a5\u5668\u540d\u79f0]_[\u76ee\u6807\u6570\u636e\u5e93\u540d\u79f0]</code> \u7684\u5927\u5c0f\u5c06\u5728\u5904\u7406\u8fc7\u7a0b\u4e2d\u589e\u52a0\uff0c\u5e76\u5728\u5927\u578b\u4e8b\u52a1\u5904\u7406\u5b8c\u6210\u540e\u51cf\u5c0f\u3002</li> <li>\u2192 \u4e0d\u5efa\u8bae\u4f7f\u7528\uff0c\u56e0\u4e3a infinispan \u53ef\u80fd\u4f1a\u5360\u7528\u4e00\u534a\u7684 JVM heap\uff0c\u800c\u5269\u4f59\u7a7a\u95f4\u53ef\u80fd\u4e0d\u8db3\u4ee5\u7528\u4e8e\u5176\u4ed6 Debezium \u64cd\u4f5c\u3002</li> </ul> <p>\u4f4e JVM heap size (128) + \u76f8\u540c\u7684 infinispan heap size (128)</p> <ul> <li>\u2192 \u4e0d\u5efa\u8bae\u4f7f\u7528\uff0c\u56e0\u4e3a infinispan \u53ef\u80fd\u4f1a\u5360\u7528\u6240\u6709 JVM \u5806\u7a7a\u95f4\uff0c\u6700\u7ec8\u5bfc\u81f4 OutOfMemory \u9519\u8bef\u3002</li> </ul> <p>\u9ad8 JVM heap size (2048) + \u4f4e infinispan heap size (128)</p> <ul> <li>\u2192 \u5c06\u53d1\u751f\u949d\u5316\u3002</li> <li>\u2192 <code>ispn_[\u8fde\u63a5\u5668\u540d\u79f0]_[\u76ee\u6807\u6570\u636e\u5e93\u540d\u79f0]</code> \u7684\u5927\u5c0f\u5728\u5904\u7406\u8fc7\u7a0b\u4e2d\u4f1a\u589e\u52a0\uff0c\u5e76\u5728\u5927\u578b\u4e8b\u52a1\u5904\u7406\u5b8c\u6210\u540e\u51cf\u5c0f\u3002</li> <li>\u2192 \u5927\u578b\u4e8b\u52a1\u5904\u7406\u6210\u529f\u3002</li> <li>\u2192 \u6548\u7387\u4f4e\u4e0b - \u56e0\u4e3a\u53ea\u6709\u4e00\u5c0f\u90e8\u5206 JVM heap \u7a7a\u95f4\u7528\u4f5c\u7f13\u5b58 + \u4e0d\u5fc5\u8981\u7684\u949d\u5316\u3002</li> </ul>"},{"location":"zh/user-guide/configure_olr/","title":"\u4e3a Oracle \u914d\u7f6e Openlog Replicator","text":""},{"location":"zh/user-guide/configure_olr/#_1","title":"\u6982\u8ff0","text":"<p>\u9664\u4e86\u57fa\u4e8e LogMiner \u7684 Oracle \u590d\u5236\u529f\u80fd\u5916\uff0cSynchDB \u8fd8\u652f\u6301\u4f7f\u7528 Openlog Replicator (OLR) \u4ece Oracle \u6570\u636e\u5e93\u8fdb\u884c\u6d41\u5f0f\u4f20\u8f93\u3002SynchDB \u652f\u6301\u4e24\u79cd\u7c7b\u578b\u7684 Openlog Replicator\uff1a</p> <ol> <li>\u57fa\u4e8e Debezium \u7684 Openlog Replicator</li> <li>\u539f\u751f Openlog Replicator\uff08\u4e0d\u901a\u8fc7 Debezium\uff09- BETA \u7248</li> </ol> <p>\u8fd9\u4e24\u79cd Openlog Replicator \u90fd\u9700\u8981\u6839\u636e\u4ee5\u4e0b\u8bbe\u7f6e\u793a\u4f8b\u8fdb\u884c\u914d\u7f6e\uff0c\u5e76\u5728 SynchDB \u8fdb\u884c\u6d41\u5f0f\u4f20\u8f93\u4e4b\u524d\u8fde\u63a5\u5230 Oracle\u3002</p>"},{"location":"zh/user-guide/configure_olr/#_2","title":"\u8981\u6c42","text":"<ul> <li>Openlog Replicator \u7248\u672c\uff1a<code>1.3.0</code>\uff08\u5df2\u9a8c\u8bc1\u4e0e Debezium 2.7.x \u7684\u517c\u5bb9\u6027\uff09</li> <li>\u5177\u6709\u53ef\u4f9b OLR \u8bbf\u95ee\u7684\u91cd\u505a\u65e5\u5fd7\u7684 Oracle \u5b9e\u4f8b</li> <li>\u5fc5\u987b\u4e3a OLR \u6388\u4e88\u989d\u5916\u6743\u9650\u3002\u6709\u5173\u5177\u4f53\u7684\u6743\u9650\u8981\u6c42\uff0c\u8bf7\u53c2\u9605\u6b64\u5904\u3002</li> <li>Openlog Replicator \u5fc5\u987b\u5df2\u914d\u7f6e\u5e76\u6b63\u5728\u8fd0\u884c</li> <li>SynchDB \u4e2d\u73b0\u6709\u7684 Oracle \u8fde\u63a5\u5668\uff08\u4f7f\u7528 <code>synchdb_add_conninfo()</code> \u521b\u5efa\uff09</li> </ul> <p>\u6709\u5173\u901a\u8fc7 Docker \u90e8\u7f72 Openlog Replicator \u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6b64\u5916\u90e8\u6307\u5357\u3002</p>"},{"location":"zh/user-guide/configure_olr/#openlog-replicator","title":"Openlog Replicator \u914d\u7f6e\u793a\u4f8b","text":"<p>SynchDB \u7684 OLR \u652f\u6301\u57fa\u4e8e\u4ee5\u4e0b\u914d\u7f6e\u793a\u4f8b\u6784\u5efa\u3002</p> <p>Version 1.3.0 <pre><code>{\n  \"version\": \"1.3.0\",\n  \"source\": [\n    {\n      \"alias\": \"SOURCE\",\n      \"name\": \"ORACLE\",\n      \"reader\": {\n        \"type\": \"online\",\n        \"user\": \"DBZUSER\",\n        \"password\": \"dbz\",\n        \"server\": \"//ora19c:1521/FREE\"\n      },\n      \"format\": {\n        \"type\": \"json\",\n        \"column\": 2,\n        \"db\": 3,\n        \"interval-dts\": 9,\n        \"interval-ytm\": 4,\n        \"message\": 2,\n        \"rid\": 1,\n        \"schema\": 7,\n        \"timestamp-all\": 1,\n        \"scn-all\": 1\n      },\n      \"memory\": {\n        \"min-mb\": 64,\n        \"max-mb\": 1024\n      },\n      \"filter\": {\n        \"table\": [\n          {\"owner\": \"DBZUSER\", \"table\": \".*\"}\n        ]\n      },\n      \"flags\": 32\n    }\n  ],\n  \"target\": [\n    {\n      \"alias\": \"SYNCHDB\",\n      \"source\": \"SOURCE\",\n      \"writer\": {\n        \"type\": \"network\",\n        \"uri\": \"0.0.0.0:7070\"\n      }\n    }\n  ]\n}\n</code></pre></p> <p>Version 1.8.5 <pre><code>{\n  \"version\": \"1.8.5\",\n  \"source\": [\n    {\n      \"alias\": \"SOURCE\",\n      \"name\": \"ORACLE\",\n      \"reader\": {\n        \"type\": \"online\",\n        \"user\": \"DBZUSER\",\n        \"password\": \"dbz\",\n        \"server\": \"//ora19c:1521/FREE\"\n      },\n      \"format\": {\n        \"type\": \"json\",\n        \"column\": 2,\n        \"db\": 3,\n        \"interval-dts\": 9,\n        \"interval-ytm\": 4,\n        \"message\": 2,\n        \"rid\": 1,\n        \"schema\": 7,\n        \"timestamp-all\": 1,\n        \"scn-type\": 1\n      },\n      \"memory\": {\n        \"min-mb\": 64,\n        \"max-mb\": 1024,\n        \"swap-path\": \"/opt/OpenLogReplicator/olrswap\"\n      },\n      \"filter\": {\n        \"table\": [\n          {\"owner\": \"DBZUSER\", \"table\": \".*\"}\n        ]\n      },\n      \"flags\": 32\n    }\n  ],\n  \"target\": [\n    {\n      \"alias\": \"DEBEZIUM\",\n      \"source\": \"SOURCE\",\n      \"writer\": {\n        \"type\": \"network\",\n        \"uri\": \"0.0.0.0:7070\"\n      }\n    }\n  ]\n}\n</code></pre></p> <p>\u8bf7\u6ce8\u610f\u4ee5\u4e0b\u51e0\u70b9\uff1a</p> <ul> <li>\"source\".\"name\": \"ORACLE\" -&gt; \u901a\u8fc7 <code>synchdb_add_olr_conninfo()</code> \u5b9a\u4e49 OLR \u53c2\u6570\u65f6\uff0c\u6b64\u5b57\u6bb5\u5e94\u4e0e <code>olr_source</code> \u503c\u5339\u914d\uff08\u89c1\u4e0b\u6587\uff09</li> <li>\"source\".\"reader\".\"user\" -&gt; \u901a\u8fc7 <code>synchdb_add_conninfo()</code> \u521b\u5efa\u8fde\u63a5\u5668\u65f6\uff0c\u6b64\u5b57\u6bb5\u5e94\u4e0e <code>username</code> \u503c\u5339\u914d</li> <li>\"source\".\"reader\".\"password\" -&gt; \u901a\u8fc7 <code>synchdb_add_conninfo()</code> \u521b\u5efa\u8fde\u63a5\u5668\u65f6\uff0c\u6b64\u5b57\u6bb5\u5e94\u4e0e <code>password</code> \u503c\u5339\u914d</li> <li>\"source\".\"reader\".\"server\" -&gt; \u901a\u8fc7 <code>synchdb_add_conninfo()</code> \u521b\u5efa\u8fde\u63a5\u5668\u65f6\uff0c\u6b64\u5b57\u6bb5\u5e94\u5305\u542b <code>hostname</code>\u3001<code>port</code> \u548c <code>source database</code> \u7684\u503c</li> <li>\"source\".\"filter\".\"table\":[] -&gt; \u8fd9\u4f1a\u8fc7\u6ee4 Openlog Replicator \u6355\u83b7\u7684\u53d8\u66f4\u4e8b\u4ef6\u3002&lt;&lt;&lt;\u91cd\u8981&gt;&gt;&gt;\uff1a\u8fd9\u662f\u76ee\u524d\u4ece Oracle \u8fc7\u6ee4\u53d8\u66f4\u4e8b\u4ef6\u7684\u552f\u4e00\u65b9\u6cd5\uff0c\u56e0\u4e3a SynchDB \u4e2d\u7684 OLR \u5b9e\u73b0\u76ee\u524d\u4e0d\u8fdb\u884c\u4efb\u4f55\u8fc7\u6ee4\u3002\uff08\u901a\u8fc7 <code>synchdb_add_conninfo()</code> \u521b\u5efa\u8fde\u63a5\u5668\u65f6\uff0c<code>table</code> \u548c <code>snapshot table</code> \u7684\u503c\u4f1a\u88ab\u5ffd\u7565\u3002\uff09</li> <li>\"format\":{} -&gt; \u57fa\u4e8e Debezium \u6216\u539f\u751f Openlog Replicator \u8fde\u63a5\u5668\u63d0\u53d6\u7684\u7279\u5b9a Paylod \u683c\u5f0f\u3002\u8bf7\u6309\u7167\u6307\u5b9a\u7684\u65b9\u5f0f\u4f7f\u7528\u8fd9\u4e9b\u503c\u3002</li> <li>\u201cmemory\u201d.\u201cswap-path\u201d -&gt; \u8fd9\u544a\u8bc9 OLR \u5728\u5185\u5b58\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\u5c06\u4ea4\u6362\u6587\u4ef6\u5199\u5165\u54ea\u91cc\u3002</li> <li>\"target\".[0]..\"writer\".\"type\": -&gt; \u5fc5\u987b\u6307\u5b9a <code>network</code>\uff0c\u56e0\u4e3a Debezium \u548c\u539f\u751f Openlog Replicator \u8fde\u63a5\u5668\u90fd\u901a\u8fc7\u7f51\u7edc\u4e0e Openlog Replicator \u901a\u4fe1\u3002</li> <li>\"target\".[0]..\"writer\".\"uri\": -&gt; \u8fd9\u662f Openlog Replicator \u76d1\u542c\u7684\u7ed1\u5b9a\u4e3b\u673a\u548c\u7aef\u53e3\uff0cSynchDB \u5e94\u8be5\u80fd\u591f\u5728\u901a\u8fc7 <code>synchdb_add_olr_conninfo()</code> \u5b9a\u4e49 OLR \u53c2\u6570\u65f6\u901a\u8fc7 <code>olr_host</code> \u548c <code>olr_port</code> \u8bbf\u95ee\u8be5\u4e3b\u673a\u548c\u7aef\u53e3\u3002</li> </ul>"},{"location":"zh/user-guide/configure_olr/#synchdb_add_conninfo","title":"<code>synchdb_add_conninfo()</code>","text":"<p>\u8981\u521b\u5efa\u539f\u751f OLR \u8fde\u63a5\u5668\uff08\u4f7f\u7528 <code>type</code> = 'olr'\uff09\uff1a</p> <pre><code>SELECT synchdb_add_conninfo('olrconn',\n                            'ora19c',\n                            1521,\n                            'DBZUSER',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'oracle');\n</code></pre> <p>\u8981\u521b\u5efa\u57fa\u4e8e Debezium \u7684 OLR \u8fde\u63a5\u5668\uff08\u4f7f\u7528 <code>type</code> = 'oracle'\uff09\uff1a</p> <pre><code>SELECT synchdb_add_conninfo('olrconn',\n                            'ora19c',\n                            1521,\n                            'DBZUSER',\n                            'dbz',\n                            'FREE',\n                            'postgres',\n                            'null',\n                            'null',\n                            'olr');\n</code></pre> <p>&lt;&lt;&lt;\u91cd\u8981&gt;&gt;&gt; SynchDB \u5fc5\u987b\u4f7f\u7528\u6807\u5fd7 (WITH_OLR=1) \u8fdb\u884c\u7f16\u8bd1\u548c\u6784\u5efa\uff0c\u4ee5\u652f\u6301\u672c\u673a openlog \u590d\u5236\u5668\u8fde\u63a5\u5668\u3002</p> <p>\u66f4\u591a\u5173\u4e8e\u521b\u5efa\u8fde\u63a5\u5668\u7684\u4fe1\u606f\uff0c\u8bf7\u8bbf\u95ee\u6b64\u5904</p>"},{"location":"zh/user-guide/configure_olr/#synchdb_add_olr_conninfo","title":"<code>synchdb_add_olr_conninfo()</code>","text":"<p>\u521b\u5efa\u8fde\u63a5\u5668\u540e\uff0c\u7528\u6237\u53ef\u4ee5\u4e3a\u73b0\u6709\u7684 Oracle \u8fde\u63a5\u5668\u6ce8\u518c\u4e00\u4e2a Openlog Replicator \u7aef\u70b9\u3002 </p> <p>\u7b7e\u540d\uff1a</p> <pre><code>synchdb_add_olr_conninfo(\n    conn_name TEXT, -- \u8fde\u63a5\u5668\u540d\u79f0\n    olr_host TEXT, -- OLR \u5b9e\u4f8b\u7684\u4e3b\u673a\u540d\u6216 IP\n    olr_port INT, -- OLR \u516c\u5f00\u7684\u7aef\u53e3\u53f7\uff08\u901a\u5e38\u4e3a 7070\uff09\n    olr_source TEXT -- OLR \u4e2d\u914d\u7f6e\u7684 Oracle \u6e90\u540d\u79f0\n)\n</code></pre> <p>\u793a\u4f8b\uff1a</p> <p>\u8fd9\u5c06\u6307\u793a SynchDB \u4f7f\u7528 Oracle \u6e90\u6807\u8bc6\u7b26 ORACLE\uff0c\u4ece\u8fd0\u884c\u4e8e olrhost:7070 \u7684 Openlog Replicator \u5b9e\u4f8b\u6d41\u5f0f\u4f20\u8f93\u8fde\u63a5\u5668 <code>olrconn</code> \u7684\u53d8\u66f4\u3002\u8c03\u7528 <code>synchdb_start_engine_bgw</code> \u542f\u52a8\u6b64\u8fde\u63a5\u5668\u3002</p> <pre><code>SELECT synchdb_add_olr_conninfo('olrconn', 'olrhost', 7070, 'ORACLE');\n</code></pre>"},{"location":"zh/user-guide/configure_olr/#synchdb_del_olr_conninfo","title":"synchdb_del_olr_conninfo","text":"<p>\u5220\u9664\u7279\u5b9a\u8fde\u63a5\u5668\u7684 OLR \u914d\u7f6e\uff0c\u5c06\u5176\u6062\u590d\u4e3a\u4f7f\u7528 LogMiner\u3002</p> <p>\u7b7e\u540d\uff1a</p> <pre><code>synchdb_del_olr_conninfo(conn_name TEXT)\n</code></pre> <p>\u793a\u4f8b\uff1a</p> <p>\u6b64\u547d\u4ee4\u7981\u7528 oracleconn \u7684 OLR \u4f7f\u7528\u3002\u4f7f\u7528 <code>synchdb_start_engine_bgw</code> \u542f\u52a8\u8fde\u63a5\u5668\u5c06\u56de\u9000\u5230\u9ed8\u8ba4\u7684\u65e5\u5fd7\u6316\u6398\u7b56\u7565\uff08\u57fa\u4e8e Debezium \u7684 OLR \u8fde\u63a5\u5668\uff09\u3002\u5982\u679c\u4f7f\u7528\u539f\u751f Openlog Replicator \u8fde\u63a5\u5668\uff0c\u7f3a\u5c11 OLR \u914d\u7f6e\u5c06\u5bfc\u81f4\u8fde\u63a5\u5668\u542f\u52a8\u65f6\u51fa\u9519\u3002</p> <pre><code>SELECT synchdb_del_olr_conninfo('olrconn');\n</code></pre>"},{"location":"zh/user-guide/configure_olr/#debezium-openlog-replicator","title":"\u57fa\u4e8e Debezium \u7684 Openlog Replicator \u8fde\u63a5\u5668\u7684\u884c\u4e3a\u8bf4\u660e","text":"<ul> <li>\u5f53 LogMiner \u548c OLR \u914d\u7f6e\u90fd\u5b58\u5728\u65f6\uff0cSynchDB \u9ed8\u8ba4\u4f7f\u7528 Openlog Replicator \u8fdb\u884c\u53d8\u66f4\u6355\u83b7\u3002</li> <li>\u5982\u679c OLR \u914d\u7f6e\u7f3a\u5931\uff0cSynchDB \u5c06\u4f7f\u7528\u65e5\u5fd7\u6316\u6398\u7b56\u7565\u6765\u6d41\u5f0f\u4f20\u8f93\u53d8\u66f4\u3002</li> <li>\u4fee\u6539 OLR \u914d\u7f6e\u540e\uff0c\u9700\u8981\u91cd\u65b0\u542f\u52a8\u8fde\u63a5\u5668\u3002</li> </ul>"},{"location":"zh/user-guide/configure_olr/#openlog-replicator_1","title":"\u539f\u751f\u7684 Openlog Replicator \u8fde\u63a5\u5668\u7684\u884c\u4e3a\u8bf4\u660e","text":"<ul> <li>\u76ee\u524d\u4e3a BETA \u7248\u672c\u3002</li> <li>SynchDB \u7ba1\u7406\u4e0e Openlog Replicator \u7684\u8fde\u63a5\uff0c\u5e76\u5728\u4e0d\u4f7f\u7528 Debezium \u7684\u60c5\u51b5\u4e0b\u6d41\u5f0f\u4f20\u8f93\u53d8\u66f4\u3002</li> <li>\u9700\u8981 OLR \u914d\u7f6e\uff0c\u5426\u5219\u8fde\u63a5\u5668\u542f\u52a8\u65f6\u4f1a\u51fa\u9519\u3002</li> <li>\u4f9d\u8d56 Debezium \u7684 Oracle \u8fde\u63a5\u5668\u5b8c\u6210\u521d\u59cb\u5feb\u7167\uff0c\u5e76\u5728\u5b8c\u6210\u540e\u5173\u95ed\uff0c\u540e\u7eed\u7684 CDC \u7531 SynchDB \u5185\u90e8\u9488\u5bf9 Openlog Replicator \u539f\u751f\u5b8c\u6210\u3002</li> <li>\u4f9d\u8d56 IvorySQL \u7684 Oracle \u89e3\u6790\u5668\u6765\u5904\u7406 DDL \u4e8b\u4ef6\u3002\u5728\u4f7f\u7528\u539f\u751f openlog replicator \u8fde\u63a5\u5668\u4e4b\u524d\uff0c\u5fc5\u987b\u5148\u7f16\u8bd1\u5e76\u5b89\u88c5\u5b83\u3002</li> <li>\u8bbf\u95ee\u6b64\u5904 \u4e86\u89e3\u6709\u5173 Openlog Replicator \u7684\u66f4\u591a\u4fe1\u606f\u3002</li> </ul>"},{"location":"zh/user-guide/configure_snapshot_engine/","title":"\u8a2d\u5b9a\u5feb\u7167\u5f15\u64ce","text":""},{"location":"zh/user-guide/configure_snapshot_engine/#cdc","title":"\u521d\u59cb\u5feb\u7167\u8207\u8b8a\u66f4\u8cc7\u6599\u64f7\u53d6 (CDC)","text":"<p>\u521d\u59cb\u5feb\u7167\u662f\u6307\u5c07\u8868\u683c\u7d50\u69cb\u548c\u521d\u59cb\u8cc7\u6599\u5f9e\u9060\u7aef\u8cc7\u6599\u5eab\u9077\u79fb\u5230 SynchDB \u7684\u904e\u7a0b\u3002\u5c0d\u65bc\u5927\u591a\u6578\u9023\u63a5\u5668\u985e\u578b\uff0c\u6b64\u64cd\u4f5c\u50c5\u5728\u9996\u6b21\u555f\u52d5\u9023\u63a5\u5668\u6642\u900f\u904e\u5d4c\u5165\u5f0f Debezium \u904b\u884c\u5668\u57f7\u884c\u4e00\u6b21\uff0c\u56e0\u70ba\u53ea\u6709 Debezium \u5f15\u64ce\u624d\u80fd\u57f7\u884c\u521d\u59cb\u5feb\u7167\u3002\u521d\u59cb\u5feb\u7167\u5b8c\u6210\u5f8c\uff0c\u8b8a\u66f4\u8cc7\u6599\u64f7\u53d6\u5c07\u958b\u59cb\u5c07\u5373\u6642\u8b8a\u66f4\u4e32\u6d41\u50b3\u8f38\u5230 SynchDB\u3002 \u300c\u5feb\u7167\u6a21\u5f0f\u300d\u53ef\u4ee5\u9032\u4e00\u6b65\u63a7\u5236\u521d\u59cb\u5feb\u7167\u548c CDC \u7684\u884c\u70ba\u3002\u66f4\u591a\u4fe1\u606f\uff0c\u8acb\u53c3\u95b1\u6b64\u8655\u3002</p> <p>\u9664\u4e86\u57fa\u65bc Debezium \u7684\u521d\u59cb\u5feb\u7167\uff08\u7576\u8868\u6578\u91cf\u773e\u591a\u6642\u53ef\u80fd\u6703\u5f88\u6162\uff09\u4e4b\u5916\uff0cSynchdB \u9084\u63d0\u4f9b\u4e86\u53e6\u4e00\u500b\u57fa\u65bc FDW \u7684\u539f\u751f\u521d\u59cb\u5feb\u7167\u5f15\u64ce\u3002\u76ee\u524d\uff0c\u53ea\u6709\u539f\u751f Openlog Replicator (OLR) \u9023\u63a5\u5668\u652f\u63f4\u57fa\u65bc FDW \u7684\u5feb\u7167\u3002\u6240\u6709\u5176\u4ed6\u9023\u63a5\u5668\u4ecd\u7136\u4f9d\u8cf4 Debezium \u4f86\u57f7\u884c\u5feb\u7167\u3002</p>"},{"location":"zh/user-guide/configure_snapshot_engine/#fdw","title":"\u57fa\u65bc FDW \u7684\u521d\u59cb\u5feb\u7167","text":"<ul> <li>\u5728 <code>postgresql.conf</code> \u4e2d\u5c07 \"synchdb.olr_snapshot_engine\" \u8a2d\u70ba \"fdw\" \u5373\u53ef\u555f\u7528\u3002</li> <li>\u555f\u52d5\u9700\u8981\u5feb\u7167\u7684 OLR \u9023\u63a5\u5668\uff0c\u4e26\u8a2d\u5b9a\u70ba\u5feb\u7167\u6a21\u5f0f\u3002\u4f8b\u5982\uff1a</li> </ul> <pre><code>SELECT synchdb_start_engine_bgw('olrconn', 'no_data');\n\n-- \u6216\nSELECT synchdb_start_engine_bgw('olrconn', 'always');\n\n-- \u6216\nSELECT synchdb_start_engine_bgw('olrconn', 'schemasync');\n</code></pre>"},{"location":"zh/user-guide/configure_snapshot_engine/#oracle_fdw","title":"\u7f16\u8bd1\u4e26\u5b89\u88dd oracle_fdw","text":"<p>\u5982\u679c\u9078\u64c7 \"fdw\" \u4f5c\u70ba\u5feb\u7167\u5f15\u64ce\uff0c\u60a8\u9700\u8981\u78ba\u4fdd\u76f8\u61c9\u7684\u5916\u90e8\u8cc7\u6599\u5305\u88dd\u5668\u5df2\u5b89\u88dd\u6216\u53ef\u7528\u65bc synchdb\u3002\u4ee5\u4e0b\u662f\u5f9e\u539f\u59cb\u78bc\u5efa\u7f6e\u4e26\u5b89\u88dd oracle_fdw \u7684\u7c21\u8981\u6b65\u9a5f\u4f9b\u60a8\u53c3\u8003\u3002</p>"},{"location":"zh/user-guide/configure_snapshot_engine/#oci","title":"\u5b89\u88dd OCI","text":"<p>\u5efa\u7f6e\u548c\u904b\u884c oracle_fdw \u9700\u8981 OCI\u3002\u5728\u6b64\u7bc4\u4f8b\u4e2d\uff0c\u6211\u4f7f\u7528\u7684\u662f 23.9.0 \u7248\u672c\uff1a</p> <pre><code># \u53d6\u5f97\u9810\u7de8\u8b6f\u8edf\u9ad4\u5305\uff1a\nwget https://download.oracle.com/otn_software/linux/instantclient/2390000/instantclient-basic-linux.x64-23.9.0.25.07.zip\nwget https://download.oracle.com/otn_software/linux/instantclient/2390000/instantclient-sdk-linux.x64-23.9.0.25.07.zip\n\n# \u89e3\u58d3\u7e2e\uff1a\u9078\u64c7\u300cY\u300d\u4ee5\u8986\u5beb\u5143\u8cc7\u6599\u6587\u4ef6\nunzip instantclient-basic-linux.x64-23.9.0.25.07.zip\nunzip instantclient-sdk-linux.x64-23.9.0.25.07.zip\n</code></pre> <p>\u66f4\u65b0\u74b0\u5883\u8b8a\u91cf\uff0c\u4ee5\u4fbf\u7cfb\u7d71\u77e5\u9053\u5728\u54ea\u88e1\u627e\u5230 OCI \u982d\u6a94\u548c\u5eab\u3002</p> <pre><code>export OCI_HOME=/home/$USER/instantclient_23_9\nexport OCI_LIB_DIR=$OCI_HOME\nexport OCI_INC_DIR=$OCI_HOME/sdk/include\nexport LD_LIBRARY_PATH=$OCI_HOME:${LD_LIBRARY_PATH}\nexport PATH=$OCI_HOME:$PATH\n</code></pre> <p>\u60a8\u53ef\u4ee5\u5c07\u4e0a\u8ff0\u547d\u4ee4\u65b0\u589e\u81f3 <code>~/.bashrc</code> \u7684\u672b\u5c3e\uff0c\u4ee5\u4fbf\u6bcf\u6b21\u767b\u5165\u7cfb\u7d71\u6642\u81ea\u52d5\u8a2d\u5b9a PATH\u3002</p> <p>\u60a8\u4e5f\u53ef\u4ee5\u5c07 $OCI_HOME \u65b0\u589e\u81f3 <code>/etc/ld.so.conf.d/x86_64-linux-gnu.conf</code>\uff08\u4ee5 Ubuntu \u70ba\u4f8b\uff09\uff0c\u4f5c\u70ba\u5c0b\u627e\u5171\u7528\u7a0b\u5f0f\u5eab\u7684\u65b0\u8def\u5f91\u3002</p> <p>\u60a8\u61c9\u8a72\u57f7\u884c ldconfig \u547d\u4ee4\uff0c\u4ee5\u4fbf\u9023\u7d50\u5668\u77e5\u9053\u5728\u54ea\u88e1\u627e\u5230\u5171\u7528\u7a0b\u5f0f\u5eab\uff1a</p>"},{"location":"zh/user-guide/configure_snapshot_engine/#oracle_fdw-280","title":"\u5efa\u7f6e oracle_fdw 2.8.0","text":"<pre><code>git clone https://github.com/laurenz/oracle_fdw.git --branch ORACLE_FDW_2_8_0\n</code></pre> <p>\u900f\u904e\u8abf\u6574 Makefile \u4e2d\u7684\u4ee5\u4e0b\u5169\u884c\uff0c\u78ba\u4fdd oracle_fdw \u7684 Makefile \u80fd\u5920\u627e\u5230 OCI \u5305\u542b\u6a94\u6848\u548c\u51fd\u5f0f\u5eab\uff1a</p> <pre><code>FIND_INCLUDE := $(wildcard /usr/include/oracle/*/client64 /usr/include/oracle/*/client /home/$USER/instantclient_23_9/sdk/include)\nFIND_LIBDIRS := $(wildcard /usr/lib/oracle/*/client64/lib /usr/lib/oracle/*/client/lib /home/$USER/instantclient_23_9)\n</code></pre> <p>\u5efa\u7f6e\u4e26\u5b89\u88dd oracle_fdw\uff1a</p> <pre><code>make PG_CONFIG=/usr/local/pgsql/bin/pg_config\nsudo make install PG_CONFIG=/usr/local/pgsql/bin/pg_config\n</code></pre> <p>Oralce_fdw \u5df2\u6e96\u5099\u5c31\u7dd2\u3002</p> <p>&lt;&lt;\u91cd\u8981&gt;&gt; \u5728\u4f7f\u7528\u57fa\u65bc FDW \u7684\u521d\u59cb\u5feb\u7167\u4e4b\u524d\uff0c\u60a8\u7121\u9700\u57f7\u884c\u201cCREATE EXTENSION oracle_fdw\u201d\uff0c\u4e5f\u7121\u9700\u57f7\u884c\u201cCREATE SERVER\u201d\u6216\u201cCREATE USER MAPPING\u201d\u3002 SynchDB \u5728\u57f7\u884c\u5feb\u7167\u6642\u6703\u8655\u7406\u6240\u6709\u9019\u4e9b\u64cd\u4f5c\u3002</p>"},{"location":"zh/user-guide/connector_auto_launcher/","title":"\u81ea\u52a8\u542f\u52a8\u5668","text":""},{"location":"zh/user-guide/connector_auto_launcher/#synchdb","title":"\u542f\u7528 SynchDB \u81ea\u52a8\u542f\u52a8\u5668","text":"<p>\u5f53\u5bf9\u7279\u5b9a <code>connector name</code> \u6267\u884c <code>synchdb_start_engine_bgw()</code> \u65f6\uff0c\u8fde\u63a5\u5de5\u4f5c\u8fdb\u7a0b\u5c06\u5177\u5907\u81ea\u52a8\u542f\u52a8\u8d44\u683c\u3002\u540c\u6837\uff0c\u5f53\u6267\u884c <code>synchdb_stop_engine_bgw()</code> \u65f6\uff0c\u5c06\u53d6\u6d88\u6b64\u8d44\u683c\u3002</p> <p>\u542f\u7528\u81ea\u52a8\u8fde\u63a5\u5668\u542f\u52a8\u5668\u9700\u8981\uff1a</p> <ul> <li>\u5728 postgresql.conf \u4e2d\u5c06 <code>synchdb</code> \u6dfb\u52a0\u5230 <code>shared_preload_libraries</code> GUC \u9009\u9879</li> <li>\u5728 postgresql.conf \u4e2d\u5c06\u65b0\u7684 GUC \u9009\u9879 <code>synchdb.synchdb_auto_launcher</code> \u8bbe\u7f6e\u4e3a true</li> <li>\u91cd\u542f PostgreSQL \u670d\u52a1\u5668\u4f7f\u66f4\u6539\u751f\u6548</li> </ul> <p>\u793a\u4f8b\uff1a <pre><code>shared_preload_libraries = 'synchdb'\nsynchdb.synchdb_auto_launcher = true\n</code></pre></p> <p>\u5728\u542f\u52a8\u65f6\uff0cSynchDB \u6269\u5c55\u5c06\u5f88\u65e9\u88ab\u9884\u52a0\u8f7d\u3002\u5f53 <code>synchdb.synchdb_auto_launcher</code> \u8bbe\u7f6e\u4e3a true \u65f6\uff0cSynchDB \u5c06\u4ea7\u751f\u4e00\u4e2a <code>synchdb_auto_launcher</code> \u540e\u53f0\u5de5\u4f5c\u8fdb\u7a0b\uff0c\u8be5\u8fdb\u7a0b\u5c06\u68c0\u7d22 <code>synchdb_conninfo</code> \u8868\u4e2d\u6807\u8bb0\u4e3a <code>active</code> \u7684\u6240\u6709\u8fde\u63a5\u4fe1\u606f\uff08<code>isactive</code> \u6807\u5fd7\u8bbe\u7f6e\u4e3a <code>true</code>\uff09\u3002\u7136\u540e\uff0c\u5b83\u5c06\u4ee5\u4e0e\u8c03\u7528 <code>synchdb_start_engine_bgw()</code> \u76f8\u540c\u7684\u65b9\u5f0f\u81ea\u52a8\u542f\u52a8\u5b83\u4eec\u4f5c\u4e3a\u5355\u72ec\u7684\u540e\u53f0\u5de5\u4f5c\u8fdb\u7a0b\u3002\u4e4b\u540e <code>synchdb_auto_launcher</code> \u5c06\u9000\u51fa\u3002</p>"},{"location":"zh/user-guide/connector_auto_launcher/#_2","title":"\u5df2\u77e5\u95ee\u9898","text":"<p><code>synchdb_auto_launcher</code> \u5de5\u4f5c\u8fdb\u7a0b\u5c06\u767b\u5f55\u5230\u9ed8\u8ba4\u7684 <code>postgres</code> \u6570\u636e\u5e93\uff0c\u5e76\u5c1d\u8bd5\u4ece <code>synchdb_conninfo</code> \u8868\u4e2d\u67e5\u627e\u6d3b\u52a8\u8fde\u63a5\u5668\u3002\u5982\u679c SynchDB \u5b89\u88c5\u5728\u975e\u9ed8\u8ba4\u6570\u636e\u5e93\u4e2d\uff0c\u5219 <code>synchdb_auto_launcher</code> \u5c06\u65e0\u6cd5\u627e\u5230\u8be5\u8868\uff0c\u56e0\u6b64\u65e0\u6cd5\u81ea\u52a8\u542f\u52a8\u8fde\u63a5\u5668\u5de5\u4f5c\u8fdb\u7a0b\u3002\u5c06\u6765\uff0c\u6211\u4eec\u5c06\u4f7f <code>synchdb_auto_launcher</code> \u68c0\u67e5\u6240\u6709\u6570\u636e\u5e93\uff0c\u5e76\u6839\u636e\u6bcf\u4e2a\u6570\u636e\u5e93\u7684 <code>synchdb_conninfo</code> \u8868\u81ea\u52a8\u542f\u52a8\u8fde\u63a5\u5668\u5de5\u4f5c\u8fdb\u7a0b\u3002</p> <p>\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\u548c\u66f4\u65b0\uff0c\u8bf7\u67e5\u770b[Issue #71] \u3002</p>"},{"location":"zh/user-guide/create_a_connector/","title":"\u521b\u5efa\u8fde\u63a5\u5668","text":""},{"location":"zh/user-guide/create_a_connector/#_2","title":"\u521b\u5efa\u8fde\u63a5\u5668","text":"<p>\u8fde\u63a5\u5668\u4ee3\u8868\u4e0e\u7279\u5b9a\u6e90\u6570\u636e\u5e93\u7684\u8fde\u63a5\uff0c\u590d\u5236\u4e00\u7ec4\u8868\u5e76\u5e94\u7528\u4e8e PostgreSQL\u3002\u5982\u679c\u60a8\u6709\u591a\u4e2a\u9700\u8981\u590d\u5236\u7684\u6e90\u6570\u636e\u5e93\uff0c\u5219\u9700\u8981\u591a\u4e2a\u8fde\u63a5\u5668\uff08\u6bcf\u4e2a\u8fde\u63a5\u5668\u4e00\u4e2a\uff09\u3002\u4e5f\u53ef\u4ee5\u521b\u5efa\u591a\u4e2a\u8fde\u63a5\u5230\u540c\u4e00\u6e90\u6570\u636e\u5e93\u4f46\u590d\u5236\u4e0d\u540c\u8868\u96c6\u7684\u8fde\u63a5\u5668\u3002</p> <p>\u53ef\u4ee5\u4f7f\u7528\u5b9e\u7528 SQL \u51fd\u6570 <code>synchdb_add_conninfo()</code> \u521b\u5efa\u8fde\u63a5\u5668\u3002</p> <p>synchdb_add_conninfo \u63a5\u53d7\u4ee5\u4e0b\u53c2\u6570\uff1a</p> argumet description name \u8868\u793a\u6b64\u8fde\u63a5\u5668\u4fe1\u606f\u7684\u552f\u4e00\u6807\u8bc6\u7b26 hostname \u5f02\u6784\u6570\u636e\u5e93\u7684 IP \u5730\u5740\u6216\u4e3b\u673a\u540d\u3002 port \u8fde\u63a5\u5230\u5f02\u6784\u6570\u636e\u5e93\u7684\u7aef\u53e3\u53f7\u3002 username \u7528\u4e8e\u4e0e\u5f02\u6784\u6570\u636e\u5e93\u8fdb\u884c\u8eab\u4efd\u9a8c\u8bc1\u7684\u7528\u6237\u540d\u3002 password \u7528\u4e8e\u9a8c\u8bc1\u7528\u6237\u540d\u7684\u5bc6\u7801 \u6e90\u6570\u636e\u5e93 \u8fd9\u662f\u6211\u4eec\u8981\u4ece\u4e2d\u590d\u5236\u66f4\u6539\u7684\u5f02\u6784\u6570\u636e\u5e93\u4e2d\u7684\u6e90\u6570\u636e\u5e93\u7684\u540d\u79f0\u3002 \u76ee\u6807\u6570\u636e\u5e93 \uff08\u5df2\u5f03\u7528\uff09\u59cb\u7ec8\u9ed8\u8ba4\u4f7f\u7528\u4e0e synchDB \u5b89\u88c5\u4f4d\u7f6e\u76f8\u540c\u7684\u6570\u636e\u5e93 \u8868 \uff08\u53ef\u9009\uff09- \u4ee5 <code>[database].[table]</code> \u6216 <code>[database].[schema].[table]</code> \u7684\u5f62\u5f0f\u8868\u793a\uff0c\u8be5\u53c2\u6570\u5fc5\u987b\u5b58\u5728\u4e8e\u5f02\u6784\u6570\u636e\u5e93\u4e2d\uff0c\u56e0\u6b64\u5f15\u64ce\u5c06\u4ec5\u590d\u5236\u6307\u5b9a\u7684\u8868\u3002\u5982\u679c\u7559\u7a7a\uff0c\u5219\u590d\u5236\u6240\u6709\u8868\u3002\u6216\u8005\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>file:</code> \u524d\u7f00\u6307\u5b9a\u8868\u5217\u8868\u6587\u4ef6 \u5feb\u7167\u8868 \uff08\u53ef\u9009\uff09- \u4ee5 <code>[database].[table]</code> \u6216 <code>[database].[schema].[table]</code> \u7684\u5f62\u5f0f\u8868\u793a\uff0c\u8be5\u53c2\u6570\u5fc5\u987b\u5b58\u5728\u4e8e\u4e0a\u8ff0 <code>table</code> \u8bbe\u7f6e\u4e2d\uff0c\u56e0\u6b64\u5f15\u64ce\u4ec5\u5728\u5feb\u7167\u6a21\u5f0f\u8bbe\u7f6e\u4e3a <code>always</code> \u65f6\u624d\u4f1a\u91cd\u5efa\u8fd9\u4e9b\u8868\u7684\u5feb\u7167\u3002\u5982\u679c\u7559\u7a7a\u6216\u4e3a null\uff0c\u5219\u5f53\u5feb\u7167\u6a21\u5f0f\u8bbe\u7f6e\u4e3a <code>always</code> \u65f6\uff0c\u5c06\u91cd\u5efa\u4e0a\u8ff0 <code>table</code> \u8bbe\u7f6e\u4e2d\u6307\u5b9a\u7684\u6240\u6709\u8868\u3002\u6216\u8005\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>file:</code> \u524d\u7f00\u6307\u5b9a\u5feb\u7167\u8868\u5217\u8868\u6587\u4ef6 \u8fde\u63a5\u5668 \u8981\u4f7f\u7528\u7684\u8fde\u63a5\u5668\u7c7b\u578b\uff08\u5982\u4e0b\uff09\u3002 <p>&lt;&lt;\u6ce8\u610f&gt;&gt; \u5982\u679c\u9023\u63a5\u5668\u985e\u578b\u70ba\u201colr\u201d\uff0cSynchDB \u4ecd\u5c07\u4f7f\u7528 Debezium \u57f7\u884c\u521d\u59cb\u5feb\u7167\uff0c\u521d\u59cb\u5feb\u7167\u5305\u542b\u201ctable\u201d\u548c\u201csnapshot table\u201d\u53c3\u6578\u4e2d\u6307\u5b9a\u7684\u8868\u548c\u5feb\u7167\u8868\u3002\u5b8c\u6210\u5f8c\uff0cSynchDB \u5c07\u9023\u63a5\u5230 Openlog Replicator \u9032\u884c\u8907\u88fd\uff0c\u800c\u4e0d\u6703\u904e\u6ffe\u300ctable\u300d\u53c3\u6578\u4e2d\u6307\u5b9a\u7684\u6240\u9700\u8868\u3002\u8868\u904e\u6ffe\u662f\u5728 Openlog Replicator \u7684\u914d\u7f6e\u4e2d\u5b8c\u6210\u7684\u3002\u56e0\u6b64\uff0c\u8acb\u78ba\u4fdd Openlog Replicator \u548c SynchDB \u9023\u63a5\u5668\u7684\u300ctable\u300d\u904e\u6ffe\u53c3\u6578\u914d\u7f6e\u4e00\u81f4\uff0c\u4ee5\u907f\u514d\u6f5b\u5728\u7684\u5dee\u7570\u3002</p>"},{"location":"zh/user-guide/create_a_connector/#_3","title":"\u8fde\u63a5\u5668\u7c7b\u578b","text":"<p>SynchDb \u652f\u6301\u4ee5\u4e0b\u8fde\u63a5\u5668\u7c7b\u578b\uff1a</p> <ul> <li>mysql -&gt; MySQL \u6570\u636e\u5e93</li> <li>sqlserver -&gt; Microsoft SQL Server \u6570\u636e\u5e93</li> <li>oracle -&gt; Oracle \u6570\u636e\u5e93</li> <li>olr -&gt; \u539f\u751f Openlog Replicator (BETA)</li> </ul>"},{"location":"zh/user-guide/create_a_connector/#_4","title":"\u68c0\u67e5\u5df2\u521b\u5efa\u7684\u8fde\u63a5\u5668","text":"<p>\u5df2\u521b\u5efa\u7684\u8fde\u63a5\u5668\u663e\u793a\u5728 <code>synchdb_conninfo</code> \u8868\u4e2d\u3002\u6211\u4eec\u53ef\u4ee5\u67e5\u770b\u5176\u5185\u5bb9\u5e76\u6839\u636e\u9700\u8981\u8fdb\u884c\u4fee\u6539\u3002\u8bf7\u6ce8\u610f\uff0c\u7528\u6237\u51ed\u8bc1\u7684\u5bc6\u7801\u7531 pgcrypto \u4f7f\u7528\u53ea\u6709 synchdb \u77e5\u9053\u7684\u5bc6\u94a5\u52a0\u5bc6\u3002\u56e0\u6b64\uff0c\u8bf7\u52ff\u76f4\u63a5\u4fee\u6539\u5bc6\u7801\u5b57\u6bb5\uff0c\u56e0\u4e3a\u5982\u679c\u88ab\u7be1\u6539\uff0c\u53ef\u80fd\u4f1a\u88ab\u9519\u8bef\u89e3\u5bc6\u3002\u4ee5\u4e0b\u662f\u793a\u4f8b\u8f93\u51fa\uff1a</p> <pre><code>postgres=# \\x\nExpanded display is on.\n\npostgres=# select * from synchdb_conninfo;\n-[ RECORD 1 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nname     | sqlserverconn\nisactive | t\ndata     | {\"pwd\": \"\\\\xc30d0407030245ca4a983b6304c079d23a0191c6dabc1683e4f66fc538db65b9ab2788257762438961f8201e6bcefafa60460fbf441e55d844e7f27b31745f04e7251c0123a159540676c4\", \"port\": 1433, \"user\": \"sa\", \"dstdb\": \"postgres\", \"srcdb\": \"testDB\", \"table\": \"null\", \"hostname\": \"192.168.1.86\", \"connector\": \"sqlserver\"}\n-[ RECORD 2 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nname     | mysqlconn\nisactive | t\ndata     | {\"pwd\": \"\\\\xc30d04070302986aff858065e96b62d23901b418a1f0bfdf874ea9143ec096cd648a1588090ee840de58fb6ba5a04c6430d8fe7f7d466b70a930597d48b8d31e736e77032cb34c86354e\", \"port\": 3306, \"user\": \"mysqluser\", \"dstdb\": \"postgres\", \"srcdb\": \"inventory\", \"table\": \"null\", \"hostname\": \"192.168.1.86\", \"connector\": \"mysql\"}\n-[ RECORD 3 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nname     | oracleconn\nisactive | t\ndata     | {\"pwd\": \"\\\\xc30d04070302e3baf1293d0d553066d234014f6fc52e6eea425884b1f65f1955bf504b85062dfe538ca2e22bfd6db9916662406fc45a3a530b7bf43ce4cfaa2b049a1c9af8\", \"port\": 1528, \"user\": \"c##dbzuser\", \"dstdb\": \"postgres\", \"srcdb\": \"FREE\", \"table\": \"null\", \"hostname\": \"192.168.1.86\", \"connector\": \"oracle\"}\n</code></pre> <p>&lt;&lt;&lt;\u91cd\u8981&gt;&gt;&gt; \u672c\u673a Openlog Replicator \u8fde\u63a5\u5668\u5f53\u524d\u4e0d\u652f\u6301\u901a\u8fc7\u201ctable\u201d\u548c\u201csnapshot table\u201d\u53c2\u6570\u6307\u5b9a\u767d\u540d\u5355\u8868\uff0c\u56e0\u6b64\u4ee5\u4e0b\u90e8\u5206\u4e0d\u9002\u7528\u4e8e\u672c\u673a Openlog Replicator \u8fde\u63a5\u5668\u3002</p>"},{"location":"zh/user-guide/create_a_connector/#_5","title":"\u4f7f\u7528\u8868\u5217\u8868\u6587\u4ef6\u6307\u5b9a\u8868","text":"<p>\u5982\u679c\u8981\u590d\u5236\u5927\u91cf\u8868\uff0c\u53ef\u4ee5\u4f7f\u7528\u8868\u5217\u8868\u6587\u4ef6\u6765\u6307\u5b9a\u8868\u3002\u8be5\u5217\u8868\u5fc5\u987b\u91c7\u7528 JSON \u683c\u5f0f\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>{\n    \"table_list\":\n    [\n        \"mydb.myschema.mytable1\",\n        \"mydb.myschema.mytable2\",\n        ...\n        ...\n    ],\n    \"snapshot_table_list\":\n    [\n        \"mydb.myschema.mytable1\",\n        \"mydb.myschema.mytable2\",\n        ...\n        ...\n    ]\n}\n</code></pre> <p>SynchDB \u901a\u8fc7\u540d\u79f0\u67e5\u627e\u4ee5\u4e0b\u5173\u952e JSON \u6570\u7ec4\uff1a * <code>table_list</code> \u662f\u4e00\u4e2a JSON \u6570\u7ec4\uff0c\u5305\u542b\u4ee5\u5b57\u7b26\u4e32\u5f62\u5f0f\u8868\u793a\u7684\u5f85\u590d\u5236\u8868\u3002\u5f53 <code>table</code> \u53c2\u6570\u4ee5\u524d\u7f00 <code>file:</code> \u5f00\u5934\uff0c\u540e\u8ddf\u6587\u4ef6\u8def\u5f84\u65f6\uff0c\u6b64\u53c2\u6570\u4e3a\u5fc5\u586b\u9879\u3002 * <code>snapshot_table_list</code> \u4e5f\u662f\u4e00\u4e2a JSON \u6570\u7ec4\uff0c\u5305\u542b\u8981\u6267\u884c\u5feb\u7167\u7684\u8868\u3002\u5f53 <code>snapshot table</code> \u53c2\u6570\u4ee5\u524d\u7f00 <code>file:</code> \u5f00\u5934\uff0c\u540e\u8ddf\u6587\u4ef6\u8def\u5f84\u65f6\uff0c\u6b64\u53c2\u6570\u4e3a\u5fc5\u586b\u9879\u3002</p> <p>\u6587\u4ef6\u8def\u5f84\u53ef\u4ee5\u662f\u76f8\u5bf9\u4e8e PostgreSQL \u6570\u636e\u76ee\u5f55\u7684\u76f8\u5bf9\u8def\u5f84\uff0c\u4e5f\u53ef\u4ee5\u662f\u7edd\u5bf9\u8def\u5f84\u3002</p>"},{"location":"zh/user-guide/create_a_connector/#_6","title":"\u4f55\u65f6\u6307\u5b9a\u5feb\u7167\u8868\u5217\u8868\uff1f","text":"<p>\u901a\u5e38\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06 <code>snapshot table list</code> \u53c2\u6570\u7559\u7a7a\u6216\u4fdd\u7559\u4e3a <code>null</code>\uff0c\u540e\u8005\u9ed8\u8ba4\u4e0e <code>table</code> \u53c2\u6570\u7684\u503c\u76f8\u540c\u3002\u8fd9\u610f\u5473\u7740 SynchDB \u5c06\u5728\u9700\u8981\u65f6\u5bf9 <code>table</code> \u53c2\u6570\u4e2d\u6307\u5b9a\u7684\u6240\u6709\u8868\u6267\u884c\u521d\u59cb\u5feb\u7167\uff08\u590d\u5236\u67b6\u6784\u5e76\u590d\u5236\u521d\u59cb\u6570\u636e\uff09\u3002\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u80fd\u53ea\u5e0c\u671b\u5bf9\u201c\u8868\u201d\u7684\u5b50\u96c6\u6267\u884c\u521d\u59cb\u5feb\u7167\u3002\u5982\u679c\u662f\u8fd9\u79cd\u60c5\u51b5\uff0c\u6211\u4eec\u53ef\u4ee5\u8bbe\u7f6e\u4e0d\u540c\u7684\u201c\u5feb\u7167\u8868\u5217\u8868\u201d\uff0c\u6307\u793a SynchDB \u4ec5\u91cd\u5efa\u6307\u5b9a\u7684\u8868\u5feb\u7167\u3002</p>"},{"location":"zh/user-guide/create_a_connector/#_7","title":"\u793a\u4f8b\uff1a\u4e3a\u6bcf\u4e2a\u652f\u6301\u7684\u6e90\u6570\u636e\u5e93\u521b\u5efa\u4e00\u4e2a\u8fde\u63a5\u5668\u4ee5\u590d\u5236\u6240\u6709\u8868","text":"<ol> <li> <p>\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a\u201cmysqlconn\u201d\u7684 MySQL \u8fde\u63a5\u5668\uff0c\u5c06 MySQL \u4e2d\u201cinventory\u201d\u4e0b\u7684\u6240\u6709\u8868\u590d\u5236\u5230 PostgreSQL \u4e2d\u76ee\u6807\u6570\u636e\u5e93\u201cpostgres\u201d\uff1a <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'postgres', \n    'null', 'null', 'mysql');\n</code></pre></p> </li> <li> <p>\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a\u201csqlserverconn\u201d\u7684SQLServer\u8fde\u63a5\u5668\uff0c\u5c06\u201ctestDB\u201d\u4e0b\u7684\u6240\u6709\u8868\u590d\u5236\u5230PostgreSQL\u4e2d\u7684\u76ee\u6807\u6570\u636e\u5e93\u201cpostgres\u201d\uff1a <pre><code>SELECT \n  synchdb_add_conninfo(\n    'sqlserverconn', '127.0.0.1', 1433, \n    'sa', 'Password!', 'testDB', 'postgres', \n    'null', 'null', 'sqlserver');\n</code></pre></p> </li> <li> <p>\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a\u201coracleconn\u201d\u7684 Oracle \u8fde\u63a5\u5668\uff0c\u5c06\u201cFREE\u201d\u4e0b\u7684\u6240\u6709\u8868\u590d\u5236\u5230 PostgreSQL \u4e2d\u7684\u76ee\u6807\u6570\u636e\u5e93\u201cpostgres\u201d\uff1a <pre><code>SELECT \n  synchdb_add_conninfo(\n    'oracleconn', '127.0.0.1', 1521, \n    'c##dbzuser', 'dbz', 'FREE', 'postgres', \n    'null', 'null', 'oracle');\n</code></pre></p> </li> </ol>"},{"location":"zh/user-guide/create_a_connector/#_8","title":"\u793a\u4f8b\uff1a\u521b\u5efa\u8fde\u63a5\u5668\u4ee5\u590d\u5236\u6307\u5b9a\u7684\u8868","text":"<p>\u8bf7\u6ce8\u610f\uff0c\u8868\u5fc5\u987b\u4f7f\u7528\u5b8c\u5168\u9650\u5b9a\u540d\u79f0\uff08\u4f8b\u5982\u201c[database].[table]\u201d\u6216\u201c[database].[schema].[table]\u201d\uff09\u6307\u5b9a\uff0c\u5e76\u4e14\u5fc5\u987b\u5b58\u5728\u4e8e\u6e90\u6570\u636e\u5e93\u4e2d\u3002</p> <p>\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a\u201cmysqlconn\u201d\u7684 MySQL \u8fde\u63a5\u5668\uff0c\u5c06 MySQL \u4e2d\u201cinventory\u201d\u4e0b\u7684\u201corders\u201d\u548c\u201ccustomers\u201d\u8868\u590d\u5236\u5230 PostgreSQL \u4e2d\u7684\u76ee\u6807\u6570\u636e\u5e93\u201cpostgres\u201d\uff1a <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'postgres', \n    'inventory.orders,inventory.customers', 'null', 'mysql');\n</code></pre></p>"},{"location":"zh/user-guide/create_a_connector/#_9","title":"\u793a\u4f8b\uff1a\u521b\u5efa\u8fde\u63a5\u5668\u4ee5\u4f7f\u7528\u6587\u4ef6\u590d\u5236\u6307\u5b9a\u7684\u8868","text":"<p>\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a\u201cmysqlconn\u201d\u7684 MySQL \u8fde\u63a5\u5668\uff0c\u5c06 MySQL \u4e2d\u201cinventory\u201d\u4e0b\u8868\u6587\u4ef6\u4e2d\u6307\u5b9a\u7684\u8868\u590d\u5236\u5230 PostgreSQL \u4e2d\u7684\u76ee\u6807\u6570\u636e\u5e93\u201cpostgres\u201d\uff1a <pre><code>SELECT synchdb_add_conninfo(\n    'mysqlconn', '127.0.0.1', 3306, 'mysqluser', \n    'mysqlpwd', 'inventory', 'postgres', \n    'file:/path/to/mytablefile.json', 'file:/path/to/mytablefile.json', 'mysql');\n</code></pre></p> <p>\u5176\u4e2d <code>/path/to/mytablefile.json</code> \u53ef\u4ee5\u662f\uff1a <pre><code>{\n    \"table_list\":\n    [\n        \"inventory.orders\",\n        \"inventory.customers\"\n    ],\n    \"snapshot_table_list\":\n    [\n        \"inventory.orders\",\n        \"inventory.customers\"\n    ]\n}\n</code></pre></p>"},{"location":"zh/user-guide/default_datatype_mapping/","title":"\u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u6620\u5c04","text":"<p>\u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u6620\u5c04\u662f\u5728SynchDB\u5185\u90e8\u6784\u5efa\u7684\u54c8\u5e0c\u8868\uff0c\u5305\u542b\uff1a * \u952e\uff1a{\u6570\u636e\u7c7b\u578b\uff0c\u81ea\u52a8\u589e\u91cf} * \u503c\uff1a{\u6570\u636e\u7c7b\u578b\uff0c\u5927\u5c0f}</p> <p>\u5176\u4e2d\uff1a * \u6570\u636e\u7c7b\u578b\uff1a\u6570\u636e\u7c7b\u578b\u7684\u5b57\u7b26\u4e32\u8868\u793a\uff0c\u5982INT\u3001TEXT\u3001NUMERIC * \u81ea\u52a8\u589e\u91cf\uff1a\u8868\u793a\u6570\u636e\u7c7b\u578b\u662f\u5426\u5177\u6709\u81ea\u52a8\u589e\u91cf\u5c5e\u6027\u7684\u6807\u5fd7 * \u5927\u5c0f\uff1a\u8f6c\u6362\u540e\u7684\u5927\u5c0f\u503c\u3002-1\uff1a\u65e0\u53d8\u5316\uff0c0\uff1a\u672a\u6307\u5b9a\u5927\u5c0f</p> <p>\u53ef\u4ee5\u901a\u8fc7\u5b9a\u4e49\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u6765\u8986\u76d6\u9ed8\u8ba4\u7684\u6570\u636e\u7c7b\u578b\u6620\u5c04\u5173\u7cfb\u3002\u66f4\u591a\u4fe1\u606f\u8bf7\u53c2\u89c1\u8f6c\u6362\u89c4\u5219\u6587\u4ef6\u3002</p>"},{"location":"zh/user-guide/default_datatype_mapping/#mysql","title":"MySQL \u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u6620\u5c04","text":"<pre><code>DatatypeHashEntry mysql_defaultTypeMappings[] =\n{\n    {{\"int\", true}, \"serial\", 0},\n    {{\"bigint\", true}, \"bigserial\", 0},\n    {{\"smallint\", true}, \"smallserial\", 0},\n    {{\"mediumint\", true}, \"serial\", 0},\n    {{\"enum\", false}, \"text\", 0},\n    {{\"set\", false}, \"text\", 0},\n    {{\"bigint\", false}, \"bigint\", 0},\n    {{\"bigint unsigned\", false}, \"numeric\", -1},\n    {{\"numeric unsigned\", false}, \"numeric\", -1},\n    {{\"dec\", false}, \"decimal\", -1},\n    {{\"dec unsigned\", false}, \"decimal\", -1},\n    {{\"decimal unsigned\", false}, \"decimal\", -1},\n    {{\"fixed\", false}, \"decimal\", -1},\n    {{\"fixed unsigned\", false}, \"decimal\", -1},\n    {{\"bit(1)\", false}, \"boolean\", 0},\n    {{\"bit\", false}, \"bit\", -1},\n    {{\"bool\", false}, \"boolean\", -1},\n    {{\"double\", false}, \"double precision\", 0},\n    {{\"double precision\", false}, \"double precision\", 0},\n    {{\"double precision unsigned\", false}, \"double precision\", 0},\n    {{\"double unsigned\", false}, \"double precision\", 0},\n    {{\"real\", false}, \"real\", 0},\n    {{\"real unsigned\", false}, \"real\", 0},\n    {{\"float\", false}, \"real\", 0},\n    {{\"float unsigned\", false}, \"real\", 0},\n    {{\"int\", false}, \"int\", 0},\n    {{\"int unsigned\", false}, \"bigint\", 0},\n    {{\"integer\", false}, \"int\", 0},\n    {{\"integer unsigned\", false}, \"bigint\", 0},\n    {{\"mediumint\", false}, \"int\", 0},\n    {{\"mediumint unsigned\", false}, \"int\", 0},\n    {{\"year\", false}, \"int\", 0},\n    {{\"smallint\", false}, \"smallint\", 0},\n    {{\"smallint unsigned\", false}, \"int\", 0},\n    {{\"tinyint\", false}, \"smallint\", 0},\n    {{\"tinyint unsigned\", false}, \"smallint\", 0},\n    {{\"datetime\", false}, \"timestamp\", -1},\n    {{\"timestamp\", false}, \"timestamptz\", -1},\n    {{\"binary\", false}, \"bytea\", 0},\n    {{\"varbinary\", false}, \"bytea\", 0},\n    {{\"blob\", false}, \"bytea\", 0},\n    {{\"mediumblob\", false}, \"bytea\", 0},\n    {{\"longblob\", false}, \"bytea\", 0},\n    {{\"tinyblob\", false}, \"bytea\", 0},\n    {{\"long varchar\", false}, \"text\", -1},\n    {{\"longtext\", false}, \"text\", -1},\n    {{\"mediumtext\", false}, \"text\", -1},\n    {{\"tinytext\", false}, \"text\", -1},\n    {{\"json\", false}, \"jsonb\", -1},\n    {{\"geometry\", false}, \"text\", -1},\n    {{\"geometrycollection\", false}, \"text\", -1},\n    {{\"geomcollection\", false}, \"text\", -1},\n    {{\"linestring\", false}, \"text\", -1},\n    {{\"multilinestring\", false}, \"text\", -1},\n    {{\"multipoint\", false}, \"text\", -1},\n    {{\"multipolygon\", false}, \"text\", -1},\n    {{\"point\", false}, \"text\", -1},\n    {{\"polygon\", false}, \"text\", -1}\n};\n</code></pre>"},{"location":"zh/user-guide/default_datatype_mapping/#sql-server","title":"SQL Server \u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u6620\u5c04","text":"<pre><code>DatatypeHashEntry sqlserver_defaultTypeMappings[] =\n{\n    {{\"int identity\", true}, \"serial\", 0},\n    {{\"bigint identity\", true}, \"bigserial\", 0},\n    {{\"smallint identity\", true}, \"smallserial\", 0},\n    {{\"enum\", false}, \"text\", 0},\n    {{\"int\", false}, \"int\", 0},\n    {{\"bigint\", false}, \"bigint\", 0},\n    {{\"smallint\", false}, \"smallint\", 0},\n    {{\"tinyint\", false}, \"smallint\", 0},\n    {{\"numeric\", false}, \"numeric\", -1},\n    {{\"decimal\", false}, \"numeric\", -1},\n    {{\"bit(1)\", false}, \"bool\", 0},\n    {{\"bit\", false}, \"bit\", 0},\n    {{\"money\", false}, \"money\", 0},\n    {{\"smallmoney\", false}, \"money\", 0},\n    {{\"real\", false}, \"real\", 0},\n    {{\"float\", false}, \"real\", 0},\n    {{\"date\", false}, \"date\", 0},\n    {{\"time\", false}, \"time\", 0},\n    {{\"datetime\", false}, \"timestamp\", 0},\n    {{\"datetime2\", false}, \"timestamp\", 0},\n    {{\"datetimeoffset\", false}, \"timestamptz\", 0},\n    {{\"smalldatetime\", false}, \"timestamp\", 0},\n    {{\"char\", false}, \"char\", -1},\n    {{\"varchar\", false}, \"varchar\", -1},\n    {{\"text\", false}, \"text\", 0},\n    {{\"nchar\", false}, \"char\", 0},\n    {{\"nvarchar\", false}, \"varchar\", -1},\n    {{\"ntext\", false}, \"text\", 0},\n    {{\"binary\", false}, \"bytea\", 0},\n    {{\"varbinary\", false}, \"bytea\", 0},\n    {{\"image\", false}, \"bytea\", 0},\n    {{\"uniqueidentifier\", false}, \"uuid\", 0},\n    {{\"xml\", false}, \"xml\", 0},\n    {{\"json\", false}, \"jsonb\", -1},\n    {{\"hierarchyid\", false}, \"text\", 0},\n    {{\"vector\", false}, \"text\", 0},\n    {{\"geometry\", false}, \"text\", 0},\n    {{\"geography\", false}, \"text\", 0},\n};\n</code></pre>"},{"location":"zh/user-guide/default_datatype_mapping/#oracle","title":"Oracle \u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u6620\u5c04","text":"<pre><code>DatatypeHashEntry oracle_defaultTypeMappings[] =\n{\n    {{\"binary_double\", false}, \"double precision\", 0},\n    {{\"binary_float\", false}, \"real\", 0},\n    {{\"float\", false}, \"real\", 0},\n    {{\"number(0,0)\", false}, \"numeric\", -1},\n    {{\"number(1,0)\", false}, \"smallint\", 0},\n    {{\"number(2,0)\", false}, \"smallint\", 0},\n    {{\"number(3,0)\", false}, \"smallint\", 0},\n    {{\"number(4,0)\", false}, \"smallint\", 0},\n    {{\"number(5,0)\", false}, \"int\", 0},\n    {{\"number(6,0)\", false}, \"int\", 0},\n    {{\"number(7,0)\", false}, \"int\", 0},\n    {{\"number(8,0)\", false}, \"int\", 0},\n    {{\"number(9,0)\", false}, \"int\", 0},\n    {{\"number(10,0)\", false}, \"bigint\", 0},\n    {{\"number(11,0)\", false}, \"bigint\", 0},\n    {{\"number(12,0)\", false}, \"bigint\", 0},\n    {{\"number(13,0)\", false}, \"bigint\", 0},\n    {{\"number(14,0)\", false}, \"bigint\", 0},\n    {{\"number(15,0)\", false}, \"bigint\", 0},\n    {{\"number(16,0)\", false}, \"bigint\", 0},\n    {{\"number(17,0)\", false}, \"bigint\", 0},\n    {{\"number(18,0)\", false}, \"bigint\", 0},\n    {{\"number(19,0)\", false}, \"numeric\", -1},\n    {{\"number(20,0)\", false}, \"numeric\", -1},\n    {{\"number(21,0)\", false}, \"numeric\", -1},\n    {{\"number(22,0)\", false}, \"numeric\", -1},\n    {{\"number(23,0)\", false}, \"numeric\", -1},\n    {{\"number(24,0)\", false}, \"numeric\", -1},\n    {{\"number(25,0)\", false}, \"numeric\", -1},\n    {{\"number(26,0)\", false}, \"numeric\", -1},\n    {{\"number(27,0)\", false}, \"numeric\", -1},\n    {{\"number(28,0)\", false}, \"numeric\", -1},\n    {{\"number(29,0)\", false}, \"numeric\", -1},\n    {{\"number(30,0)\", false}, \"numeric\", -1},\n    {{\"number(31,0)\", false}, \"numeric\", -1},\n    {{\"number(32,0)\", false}, \"numeric\", -1},\n    {{\"number(33,0)\", false}, \"numeric\", -1},\n    {{\"number(34,0)\", false}, \"numeric\", -1},\n    {{\"number(35,0)\", false}, \"numeric\", -1},\n    {{\"number(36,0)\", false}, \"numeric\", -1},\n    {{\"number(37,0)\", false}, \"numeric\", -1},\n    {{\"number(38,0)\", false}, \"numeric\", -1},\n    {{\"number\", false}, \"numeric\", -1},\n    {{\"numeric\", false}, \"numeric\", -1},\n    {{\"date\", false}, \"timestamp\", -1},\n    {{\"long\", false}, \"text\", -1},\n    {{\"interval day to second\", false}, \"interval day to second\", -1},\n    {{\"interval year to month\", false}, \"interval year to month\", 0},\n    {{\"timestamp\", false}, \"timestamp\", -1},\n    {{\"timestamp with local time zone\", false}, \"timestamptz\", -1},\n    {{\"timestamp with time zone\", false}, \"timestamptz\", -1},\n    {{\"date\", false}, \"date\", -1},\n    {{\"char\", false}, \"char\", -1},\n    {{\"nchar\", false}, \"char\", -1},\n    {{\"nvarchar2\", false}, \"varchar\", -1},\n    {{\"varchar\", false}, \"varchar\", -1},\n    {{\"varchar2\", false}, \"varchar\", -1},\n    {{\"long raw\", false}, \"bytea\", 0},\n    {{\"raw\", false}, \"bytea\", 0},\n    {{\"decimal\", false}, \"decimal\", -1},\n    {{\"rowid\", false}, \"text\", 0},\n    {{\"urowid\", false}, \"text\", 0},\n    {{\"xmltype\", false}, \"text\", 0},\n    {{\"bfile\", false}, \"text\", 0},\n    {{\"blob\", false}, \"bytea\", 0},\n    {{\"clob\", false}, \"text\", 0},\n    {{\"nclob\", false}, \"text\", 0},\n    {{\"sdo_geometry\", false}, \"text\", 0},\n    {{\"sdo_topo_geometry\", false}, \"text\", 0},\n    {{\"sdo_georaster\", false}, \"text\", 0},\n    {{\"uritype\", false}, \"text\", 0},\n    {{\"anytype\", false}, \"text\", 0},\n    {{\"anydata\", false}, \"text\", 0},\n    {{\"anydataset\", false}, \"text\", 0},\n};\n</code></pre>"},{"location":"zh/user-guide/object_mapping_rules/","title":"\u914d\u7f6e\u5bf9\u8c61\u6620\u5c04\u548c\u8f6c\u6362\u89c4\u5219","text":"<p>SynchDB \u5177\u6709\u9ed8\u8ba4\u7684\u540d\u79f0\u548c\u6570\u636e\u7c7b\u578b\u6620\u5c04\u89c4\u5219\u6765\u5904\u7406\u4f20\u5165\u7684\u66f4\u6539\u4e8b\u4ef6\u3002\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u9ed8\u8ba4\u89c4\u5219\u5373\u53ef\u6b63\u5e38\u5de5\u4f5c\u3002\u4f46\u662f\uff0c\u5982\u679c\u60a8\u6709\u7279\u5b9a\u7684\u8f6c\u6362\u8981\u6c42\uff0c\u6216\u8005\u9ed8\u8ba4\u89c4\u5219\u4e0d\u9002\u5408\u60a8\uff0c\u5219\u53ef\u4ee5\u4e3a\u7279\u5b9a\u8fde\u63a5\u5668\u914d\u7f6e\u81ea\u5df1\u7684\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\u3002</p>"},{"location":"zh/user-guide/object_mapping_rules/#synchdb_add_objmap","title":"synchdb_add_objmap","text":"<p>\u6b64\u5b9e\u7528\u51fd\u6570\u53ef\u7528\u4e8e\u914d\u7f6e\u8868\u540d\u3001\u5217\u540d\u3001\u6570\u636e\u7c7b\u578b\u4ee5\u53ca\u8f6c\u6362\u89c4\u5219\u3002\u5b83\u9700\u8981 4 \u4e2a\u53c2\u6570\uff1a</p> \u53c2\u6570 \u63cf\u8ff0 \u5fc5\u9700 \u793a\u4f8b \u5907\u6ce8 <code>name</code> \u6b64\u8fde\u63a5\u5668\u7684\u552f\u4e00\u6807\u8bc6\u7b26 \u2713 <code>'mysqlconn'</code> \u5fc5\u987b\u5728\u6240\u6709\u8fde\u63a5\u5668\u4e2d\u552f\u4e00 <code>object type</code> \u5bf9\u8c61\u6620\u5c04\u7684\u7c7b\u578b \u2713 <code>'table'</code> \u53ef\u4ee5\u662f <code>table</code> \u6765\u6620\u5c04\u8868\u540d\uff0c<code>column</code> \u6765\u6620\u5c04\u5217\u540d\uff0c<code>datatype</code> \u6765\u6620\u5c04\u6570\u636e\u7c7b\u578b\uff0c\u6216 <code>transform</code> \u6765\u8fd0\u884c\u6570\u636e\u8f6c\u6362\u8868\u8fbe\u5f0f <code>source object</code> \u4ee5\u5b8c\u5168\u9650\u5b9a\u540d\u79f0\u8868\u793a\u7684\u6e90\u5bf9\u8c61 \u2713 <code>inventory.customers</code> \u8fdc\u7a0b\u6570\u636e\u5e93\u4e2d\u7684\u5bf9\u8c61\u540d\u79f0 <code>destination object</code> \u76ee\u6807\u5bf9\u8c61\u540d\u79f0 \u2713 <code>'schema1.people'</code> PostgreSQL \u7aef\u7684\u76ee\u6807\u5bf9\u8c61\u540d\u79f0\u3002\u53ef\u4ee5\u662f\u5b8c\u5168\u9650\u5b9a\u8868\u540d\u3001\u5217\u540d\u3001\u6570\u636e\u7c7b\u578b\u6216\u8f6c\u6362\u8868\u8fbe\u5f0f"},{"location":"zh/user-guide/object_mapping_rules/#_2","title":"\u914d\u7f6e\u8868\u540d\u6620\u5c04","text":"<ul> <li><code>source object</code> \u8868\u793a\u8fdc\u7a0b\u6570\u636e\u5e93\u4e2d\u4ee5\u5b8c\u5168\u9650\u5b9a\u540d\u79f0\u8868\u793a\u7684\u8868</li> <li><code>destination object</code> \u8868\u793a PostgreSQL \u4e2d\u7684\u8868\u540d\u3002\u5b83\u53ef\u4ee5\u53ea\u662f\u4e00\u4e2a\u540d\u79f0\uff08\u9ed8\u8ba4\u4e3a\u516c\u5171\u67b6\u6784\uff09\u6216 schema.name \u683c\u5f0f\u3002</li> </ul> <p>\u6b64\u793a\u4f8b\u5c06\u6e90\u6570\u636e\u5e93\u4e2d\u7684 <code>inventory.customers</code> \u8868\u6620\u5c04\u5230 PostgreSQL \u4e2d\u7684 <code>schema1.people</code>\u3002 <pre><code>SELECT synchdb_add_objmap('mysqlconn','table','inventory.customers','schema1.people');\n</code></pre></p>"},{"location":"zh/user-guide/object_mapping_rules/#_3","title":"\u914d\u7f6e\u5217\u540d\u6620\u5c04","text":"<ul> <li><code>\u6e90\u5bf9\u8c61</code> \u8868\u793a\u8fdc\u7a0b\u6570\u636e\u5e93\u4e2d\u5b8c\u5168\u9650\u5b9a\u540d\u79f0\u7684\u5217</li> <li><code>\u76ee\u6807\u5bf9\u8c61</code> \u8868\u793a PostgreSQL \u4e2d\u7684\u5217\u540d\u3002\u65e0\u9700\u5c06\u5176\u683c\u5f0f\u5316\u4e3a\u5b8c\u5168\u9650\u5b9a\u5217\u540d\u3002</li> </ul> <p>\u6b64\u793a\u4f8b\u5c06\u6e90\u8868\u4e2d\u7684 <code>inventory.customers.email</code> \u5217\u6620\u5c04\u5230 PostgreSQL \u4e2d\u7684 <code>contact</code>\u3002 <pre><code>SELECT synchdb_add_objmap('mysqlconn','column','inventory.customers.email','contact');\n</code></pre></p>"},{"location":"zh/user-guide/object_mapping_rules/#_4","title":"\u914d\u7f6e\u6570\u636e\u7c7b\u578b\u6620\u5c04","text":"<ul> <li><code>\u6e90\u5bf9\u8c61</code> \u53ef\u4ee5\u8868\u793a\u4e3a\u4ee5\u4e0b\u4e4b\u4e00\uff1a</li> <li>\u5b8c\u5168\u9650\u5b9a\u5217 (inventory.geom.g)\u3002\u8fd9\u610f\u5473\u7740\u6570\u636e\u7c7b\u578b\u6620\u5c04\u4ec5\u9002\u7528\u4e8e\u6b64\u7279\u5b9a\u5217\u3002</li> <li> <p>\u901a\u7528\u6570\u636e\u7c7b\u578b\u5b57\u7b26\u4e32 (int)\u3002\u5982\u679c\u662f\u81ea\u589e\u6570\u636e\u7c7b\u578b\uff0c\u8bf7\u4f7f\u7528\u7ad6\u7ebf (|) \u6dfb\u52a0\uff08int|true \u8868\u793a\u81ea\u589e int\uff09\uff0c\u5426\u5219\u4f7f\u7528\u7ad6\u7ebf (|) \u6dfb\u52a0\uff08int|false \u8868\u793a\u975e\u81ea\u589e int\uff09\u3002\u8fd9\u610f\u5473\u7740\u6570\u636e\u7c7b\u578b\u6620\u5c04\u9002\u7528\u4e8e\u6240\u6709\u7b26\u5408\u6761\u4ef6\u7684\u6570\u636e\u7c7b\u578b\u3002</p> </li> <li> <p><code>destination object</code> \u5e94\u8868\u793a\u4e3a PostgreSQL \u4e2d\u5b58\u5728\u7684\u901a\u7528\u6570\u636e\u7c7b\u578b\u5b57\u7b26\u4e32\u3002\u4f7f\u7528\u7ad6\u7ebf (|) \u8986\u76d6\u5927\u5c0f\uff08text|0 \u5c06\u5927\u5c0f\u8986\u76d6\u4e3a 0\uff0c\u56e0\u4e3a text \u662f\u53ef\u53d8\u5927\u5c0f\uff09\u6216\uff08varchar|-1 \u4f7f\u7528 change \u4e8b\u4ef6\u9644\u5e26\u7684\u4efb\u4f55\u5927\u5c0f\uff09\u3002</p> </li> </ul> <p>\u6b64\u793a\u4f8b\u5c06\u6240\u6709\u975e\u81ea\u589e <code>point</code> \u6570\u636e\u7c7b\u578b\u6620\u5c04\u5230 PostgreSQL \u4e2d\u7684 <code>text</code> \u6570\u636e\u7c7b\u578b\u3002 <pre><code>SELECT synchdb_add_objmap('mysqlconn','datatype','point|false','text|0');\n</code></pre></p> <p>\u6b64\u793a\u4f8b\u5c06\u8868 <code>inventory.geom</code> \u7684\u5217 <code>g</code> \u7684\u6570\u636e\u7c7b\u578b\u6620\u5c04\u5230 PostgreSQL \u4e2d\u7684 <code>geometry</code>\u3002 <pre><code>SELECT synchdb_add_objmap('mysqlconn','datatype','inventory.geom.g','geometry|0');\n</code></pre></p>"},{"location":"zh/user-guide/object_mapping_rules/#_5","title":"\u914d\u7f6e\u8f6c\u6362\u89c4\u5219","text":"<ul> <li><code>\u6e90\u5bf9\u8c61</code> \u8868\u793a\u8981\u8f6c\u6362\u7684\u5217</li> <li><code>\u76ee\u6807\u5bf9\u8c61</code> \u8868\u793a\u5728\u5c06\u5217\u6570\u636e\u5e94\u7528\u4e8e PostgreSQL \u4e4b\u524d\u8981\u5bf9\u5176\u8fd0\u884c\u7684\u8868\u8fbe\u5f0f\u3002\u4f7f\u7528 %d \u4f5c\u4e3a\u8f93\u5165\u5217\u6570\u636e\u7684\u5360\u4f4d\u7b26\u3002\u5982\u679c\u662f\u51e0\u4f55\u7c7b\u578b\uff0c\u5219\u4f7f\u7528 %w \u8868\u793a WKB\uff0c%s \u8868\u793a SRID\u3002</li> </ul> <p>\u6b64\u793a\u4f8b\u5c06\u5728 SynchDB \u6536\u5230\u7684\u201cinventory.products.name\u201d\u5217\u7684\u503c\u524d\u6dfb\u52a0\u201c&gt;&gt;&gt;&gt;&gt;\u201d\u5e76\u5728\u5176\u540e\u6dfb\u52a0\u201c&lt;&lt;&lt;&lt;&lt;\u201d\u3002 <pre><code>SELECT synchdb_add_objmap('mysqlconn','transform','inventory.products.name','''&gt;&gt;&gt;&gt;'' || ''%d'' || ''&lt;&lt;&lt;&lt;&lt;''');\n</code></pre></p> <p>\u6b64\u793a\u4f8b\u5c06\u59cb\u7ec8\u5728 SynchDB \u6536\u5230\u7684\u201cinventory.orders.quantity\u201d\u5217\u7684\u503c\u540e\u6dfb\u52a0 500\uff1a <pre><code>SELECT synchdb_add_objmap('mysqlconn','transform','inventory.orders.quantity','%d + 500');\n</code></pre></p>"},{"location":"zh/user-guide/object_mapping_rules/#_6","title":"** \u4f7f\u7528\u89c4\u5219**","text":"<p>\u5982\u679c\u8fde\u63a5\u5668\u672a\u8fd0\u884c\uff0c\u89c4\u5219\u4f1a\u5728\u4e0b\u6b21\u542f\u52a8\u65f6\u901a\u8fc7 <code>synchdb_start_engine_bgw</code> \u81ea\u52a8\u5e94\u7528\u3002</p> <p>\u5982\u679c\u8fde\u63a5\u5668\u5df2\u5728\u8fd0\u884c\uff0c\u89c4\u5219\u4e0d\u4f1a\u81ea\u52a8\u5e94\u7528\uff0c\u6211\u4eec\u5fc5\u987b\u544a\u8bc9\u8fde\u63a5\u5668\u91cd\u65b0\u52a0\u8f7d\u5bf9\u8c61\u6620\u5c04\u89c4\u5219\uff0c\u5e76\u4f7f\u7528\u5b9e\u7528\u51fd\u6570 <code>synchdb_reload_objmap</code> \u6765\u5e94\u7528\u89c4\u5219\u3002</p> <pre><code>SELECT synchdb_reload_objmap('mysqlconn');\n</code></pre>"},{"location":"zh/user-guide/secured_connection/","title":"\u5b89\u5168\u8fde\u63a5","text":""},{"location":"zh/user-guide/secured_connection/#_2","title":"\u914d\u7f6e\u5b89\u5168\u8fde\u63a5","text":"<p>\u4e3a\u4e86\u786e\u4fdd\u4e0e\u8fdc\u7a0b\u6570\u636e\u5e93\u7684\u8fde\u63a5\u5b89\u5168\uff0c\u6211\u4eec\u9700\u8981\u4e3a <code>synchdb_add_conninfo</code> \u521b\u5efa\u7684\u8fde\u63a5\u5668\u914d\u7f6e\u989d\u5916\u7684 SSL \u76f8\u5173\u53c2\u6570\u3002SSL \u8bc1\u4e66\u548c\u79c1\u94a5\u5fc5\u987b\u6253\u5305\u4e3a Java \u5bc6\u94a5\u5e93\u6587\u4ef6\uff0c\u5e76\u9644\u5e26\u5bc6\u7801\u3002\u8fd9\u4e9b\u4fe1\u606f\u968f\u540e\u4f1a\u901a\u8fc7 synchdb_add_extra_conninfo() \u4f20\u9012\u7ed9 SynchDB\u3002</p> <p>&lt;&lt;\u91cd\u8981\u63d0\u793a&gt;&gt; Openlog Replicator \u9023\u63a5\u5668\u4e0d\u652f\u63f4\u5b89\u5168\u9023\u63a5</p>"},{"location":"zh/user-guide/secured_connection/#synchdb_add_extra_conninfo","title":"synchdb_add_extra_conninfo","text":"<p>\u7528\u9014\uff1a\u4e3a <code>synchdb_add_conninfo</code> \u521b\u5efa\u7684\u73b0\u6709\u8fde\u63a5\u5668\u914d\u7f6e\u989d\u5916\u7684\u8fde\u63a5\u5668\u53c2\u6570</p> \u53c2\u6570 \u63cf\u8ff0 \u5fc5\u9700 \u793a\u4f8b \u5907\u6ce8 <code>name</code> \u6b64\u8fde\u63a5\u5668\u7684\u552f\u4e00\u6807\u8bc6\u7b26 \u2713 <code>'mysqlconn'</code> \u5fc5\u987b\u5728\u6240\u6709\u8fde\u63a5\u5668\u4e2d\u552f\u4e00 <code>ssl_mode</code> SSL \u6a21\u5f0f \u2610 <code>'verify_ca'</code> \u53ef\u4ee5\u662f\u4ee5\u4e0b\u4e4b\u4e00\uff1a<ul><li>\u201cdisabled\u201d- \u4e0d\u4f7f\u7528 SSL\u3002</li><li>\u201cpreferred\u201d- \u5982\u679c\u670d\u52a1\u5668\u652f\u6301\uff0c\u5219\u4f7f\u7528 SSL\u3002</li><li>\u201crequired\u201d- \u5fc5\u987b\u4f7f\u7528 SSL \u5efa\u7acb\u8fde\u63a5\u3002</li><li>\u201cverify_ca\u201d- \u8fde\u63a5\u5668\u4e0e\u670d\u52a1\u5668\u5efa\u7acb TLS\uff0c\u5e76\u5c06\u6839\u636e\u914d\u7f6e\u7684\u4fe1\u4efb\u5e93\u9a8c\u8bc1\u670d\u52a1\u5668\u7684 TLS \u8bc1\u4e66\u3002</li><li>\u201cverify_identity\u201d- \u4e0e verify_ca \u884c\u4e3a\u76f8\u540c\uff0c\u4f46\u5b83\u8fd8\u4f1a\u68c0\u67e5\u670d\u52a1\u5668\u8bc1\u4e66\u7684\u901a\u7528\u540d\u79f0\u4ee5\u5339\u914d\u7cfb\u7edf\u7684\u4e3b\u673a\u540d\u3002 <code>ssl_keystore</code> \u5bc6\u94a5\u5e93\u8def\u5f84 \u2610 <code>/path/to/keystore</code> \u5bc6\u94a5\u5e93\u6587\u4ef6\u7684\u8def\u5f84 <code>ssl_keystore_pass</code> \u5bc6\u94a5\u5e93\u5bc6\u7801 \u2610 <code>'mykeystorepass'</code> \u8bbf\u95ee\u5bc6\u94a5\u5e93\u6587\u4ef6\u7684\u5bc6\u7801 <code>ssl_truststore</code> \u4fe1\u4efb\u5e93\u8def\u5f84 \u2610 <code>'/path/to/truststore'</code> \u4fe1\u4efb\u5e93\u6587\u4ef6\u8def\u5f84 <code>ssl_truststore_pass</code> \u4fe1\u4efb\u5e93\u5bc6\u7801 \u2610 <code>'mytruststorepass'</code> \u8bbf\u95ee\u4fe1\u4efb\u5e93\u6587\u4ef6\u7684\u5bc6\u7801 <pre><code>SELECT synchdb_add_extra_conninfo('mysqlconn', 'verify_ca', '/path/to/keystore', 'mykeystorepass', '/path/to/truststore', 'mytruststorepass');\n</code></pre>"},{"location":"zh/user-guide/secured_connection/#synchdb_del_extra_conninfo","title":"synchdb_del_extra_conninfo","text":"<p>\u7528\u9014\uff1a\u5220\u9664\u7531 <code>synchdb_add_extra_conninfo</code> \u521b\u5efa\u7684\u989d\u5916\u8fde\u63a5\u5668\u53c2\u6570 <pre><code>SELECT synchdb_del_extra_conninfo('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/set_offset/","title":"\u81ea\u5b9a\u4e49\u8d77\u59cb\u504f\u79fb\u91cf\u503c","text":"<p>\u8d77\u59cb\u504f\u79fb\u91cf\u503c\u4ee3\u8868\u5f00\u59cb\u590d\u5236\u7684\u70b9\uff0c\u7c7b\u4f3c\u4e8e PostgreSQL \u7684\u6062\u590d LSN\u3002\u5f53 Debezium \u8fd0\u884c\u5f15\u64ce\u542f\u52a8\u65f6\uff0c\u5b83\u5c06\u4ece\u8fd9\u4e2a\u504f\u79fb\u91cf\u503c\u5f00\u59cb\u590d\u5236\u3002\u5c06\u6b64\u504f\u79fb\u91cf\u503c\u8bbe\u7f6e\u4e3a\u8f83\u65e9\u7684\u503c\u5c06\u5bfc\u81f4 Debezium \u8fd0\u884c\u5f15\u64ce\u4ece\u8f83\u65e9\u7684\u8bb0\u5f55\u5f00\u59cb\u590d\u5236\uff0c\u53ef\u80fd\u4f1a\u590d\u5236\u91cd\u590d\u7684\u6570\u636e\u8bb0\u5f55\u3002\u5728\u8bbe\u7f6e Debezium \u7684\u8d77\u59cb\u504f\u79fb\u91cf\u503c\u65f6\uff0c\u6211\u4eec\u5e94\u8be5\u683c\u5916\u8c28\u614e\u3002</p>"},{"location":"zh/user-guide/set_offset/#_2","title":"\u8bb0\u5f55\u53ef\u8bbe\u7f6e\u7684\u504f\u79fb\u91cf\u503c","text":"<p>\u5728\u64cd\u4f5c\u8fc7\u7a0b\u4e2d\uff0cDebezium \u8fd0\u884c\u5f15\u64ce\u5c06\u751f\u6210\u65b0\u7684\u504f\u79fb\u91cf\u5e76\u5c06\u5176\u5237\u65b0\u5230\u78c1\u76d8\u3002\u6700\u540e\u5237\u65b0\u7684\u504f\u79fb\u91cf\u53ef\u4ee5\u901a\u8fc7 <code>synchdb_state_view()</code> \u5b9e\u7528\u547d\u4ee4\u68c0\u7d22\uff1a <pre><code>postgres=# select name, last_dbz_offset from synchdb_state_view;\n     name      |                                           last_dbz_offset\n---------------+------------------------------------------------------------------------------------------------------\n sqlserverconn | {\"commit_lsn\":\"0000006a:00006608:0003\",\"snapshot\":true,\"snapshot_completed\":false}\n mysqlconn     | {\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}\n oracleconn    | {\"commit_scn\":\"2311579\",\"snapshot_scn\":\"2311578\",\"scn\":\"2311578\"}\n(3 rows)\n</code></pre></p> <p>\u6839\u636e\u8fde\u63a5\u5668\u7c7b\u578b\u7684\u4e0d\u540c\uff0c\u8fd9\u4e2a\u504f\u79fb\u91cf\u503c\u4e5f\u4e0d\u540c\u3002\u4ece\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c<code>mysql</code> \u8fde\u63a5\u5668\u7684\u6700\u540e\u5237\u65b0\u504f\u79fb\u91cf\u662f <code>{\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}</code>\uff0c\u800c <code>sqlserver</code> \u7684\u6700\u540e\u5237\u65b0\u504f\u79fb\u91cf\u662f <code>{\"commit_lsn\":\"0000006a:00006608:0003\",\"snapshot\":true,\"snapshot_completed\":false}</code>\u3002</p> <p>\u6211\u4eec\u5e94\u8be5\u5b9a\u671f\u4fdd\u5b58\u8fd9\u4e9b\u503c\uff0c\u8fd9\u6837\u5982\u679c\u9047\u5230\u95ee\u9898\uff0c\u6211\u4eec\u5c31\u77e5\u9053\u8fc7\u53bb\u53ef\u4ee5\u8bbe\u7f6e\u7684\u504f\u79fb\u91cf\u4f4d\u7f6e\uff0c\u4ee5\u6062\u590d\u590d\u5236\u64cd\u4f5c\u3002</p>"},{"location":"zh/user-guide/set_offset/#_3","title":"\u6682\u505c\u8fde\u63a5\u5668","text":"<p>\u5728\u8bbe\u7f6e\u65b0\u7684\u504f\u79fb\u91cf\u503c\u4e4b\u524d\uff0c\u8fde\u63a5\u5668\u5fc5\u987b\u5904\u4e8e <code>paused</code>\uff08\u6682\u505c\uff09\u72b6\u6001\u3002</p> <p>\u4f7f\u7528 <code>synchdb_pause_engine()</code> SQL \u51fd\u6570\u6682\u505c\u6b63\u5728\u8fd0\u884c\u7684\u8fde\u63a5\u5668\u3002\u8fd9\u5c06\u505c\u6b62 Debezium \u8fd0\u884c\u5f15\u64ce\u4ece\u5f02\u6784\u6570\u636e\u5e93\u590d\u5236\u3002\u5f53\u6682\u505c\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>synchdb_set_offset()</code> SQL \u4f8b\u7a0b\u66f4\u6539 Debezium \u8fde\u63a5\u5668\u7684\u504f\u79fb\u91cf\u503c\uff0c\u4ee5\u4ece\u8fc7\u53bb\u7684\u7279\u5b9a\u70b9\u5f00\u59cb\u590d\u5236\u3002\u5b83\u4ee5 <code>conninfo_name</code> \u4f5c\u4e3a\u53c2\u6570\uff0c\u53ef\u4ee5\u4ece <code>synchdb_get_state()</code> \u89c6\u56fe\u7684\u8f93\u51fa\u4e2d\u627e\u5230\u3002</p> <p>\u4f8b\u5982\uff1a <pre><code>SELECT synchdb_pause_engine('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/set_offset/#_4","title":"\u8bbe\u7f6e\u65b0\u7684\u504f\u79fb\u91cf","text":"<p>\u4f7f\u7528 <code>synchdb_set_offset()</code> SQL \u51fd\u6570\u66f4\u6539\u8fde\u63a5\u5668\u5de5\u4f5c\u8fdb\u7a0b\u7684\u8d77\u59cb\u504f\u79fb\u91cf\u3002\u53ea\u6709\u5f53\u8fde\u63a5\u5668\u5904\u4e8e <code>paused</code> \u72b6\u6001\u65f6\u624d\u80fd\u6267\u884c\u6b64\u64cd\u4f5c\u3002\u8be5\u51fd\u6570\u63a5\u53d7\u4e24\u4e2a\u53c2\u6570\uff0c<code>conninfo_name</code> \u548c <code>\u6709\u6548\u7684\u504f\u79fb\u91cf\u5b57\u7b26\u4e32</code>\uff0c\u8fd9\u4e24\u4e2a\u53c2\u6570\u90fd\u53ef\u4ee5\u4ece <code>synchdb_get_state()</code> \u89c6\u56fe\u7684\u8f93\u51fa\u4e2d\u627e\u5230\u3002</p> <p>\u4f8b\u5982\uff1a <pre><code>SELECT synchdb_set_offset('mysqlconn', '{\"ts_sec\":1741301103,\"file\":\"mysql-bin.000009\",\"pos\":574318212,\"row\":1,\"server_id\":223344,\"event\":2}');\n</code></pre></p>"},{"location":"zh/user-guide/set_offset/#_5","title":"\u6062\u590d\u8fde\u63a5\u5668","text":"<p>\u4f7f\u7528 <code>synchdb_resume_engine()</code> SQL \u51fd\u6570\u4ece\u6682\u505c\u72b6\u6001\u6062\u590d Debezium \u64cd\u4f5c\u3002\u6b64\u51fd\u6570\u4ee5 <code>\u8fde\u63a5\u5668\u540d\u79f0</code> \u4f5c\u4e3a\u5176\u552f\u4e00\u53c2\u6570\uff0c\u53ef\u4ee5\u4ece <code>synchdb_get_state()</code> \u89c6\u56fe\u7684\u8f93\u51fa\u4e2d\u627e\u5230\u3002\u6062\u590d\u7684 Debezium \u8fd0\u884c\u5f15\u64ce\u5c06\u4ece\u65b0\u8bbe\u7f6e\u7684\u504f\u79fb\u91cf\u503c\u5f00\u59cb\u590d\u5236\u3002</p> <p>\u4f8b\u5982\uff1a <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/start_stop_connector/","title":"\u542f\u52a8/\u505c\u6b62\u8fde\u63a5\u5668","text":""},{"location":"zh/user-guide/start_stop_connector/#_2","title":"\u63a7\u5236\u8fde\u63a5\u5668","text":"<p>SynchDB \u63d0\u4f9b\u4e86\u51e0\u4e2a\u5b9e\u7528\u51fd\u6570\u6765\u63a7\u5236\u5df2\u521b\u5efa\u8fde\u63a5\u5668\u7684\u884c\u4e3a\u548c\u751f\u547d\u5468\u671f\u3002</p>"},{"location":"zh/user-guide/start_stop_connector/#_3","title":"\u4ee5\u9ed8\u8ba4\u5feb\u7167\u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668","text":"<p>synchdb_start_engine_bgw() \u53ef\u7528\u4e8e\u4ee5\u540d\u4e3a\u201cinitial\u201d\u7684\u9ed8\u8ba4\u5feb\u7167\u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668\u3002</p> <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre>"},{"location":"zh/user-guide/start_stop_connector/#_4","title":"\u4ee5\u81ea\u5b9a\u4e49\u5feb\u7167\u6a21\u5f0f\u542f\u52a8\u8fde\u63a5\u5668","text":"<p>\u4f7f\u7528\u76f8\u540c\u7684\u51fd\u6570 synchdb_start_engine_bgw()\uff0c\u53ef\u4ee5\u5305\u542b\u5feb\u7167\u6a21\u5f0f\u6765\u542f\u52a8\u8fde\u63a5\u5668\uff0c\u5426\u5219\u5c06\u9ed8\u8ba4\u4f7f\u7528\u201cinitial\u201d\u6a21\u5f0f\u3002</p> <pre><code>-- \u6355\u83b7\u8868\u7ed3\u6784\u5e76\u7ee7\u7eed\u6d41\u5f0f\u4f20\u8f93\u65b0\u7684\u66f4\u6539\nSELECT synchdb_start_engine_bgw('mysqlconn', 'no_data');\n\n-- \u59cb\u7ec8\u91cd\u5efa\u8868\u7ed3\u6784\u548c\u73b0\u6709\u6570\u636e\uff0c\u5e76\u7ee7\u7eed\u6d41\u5f0f\u4f20\u8f93\u65b0\u7684\u66f4\u6539\nSELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre>"},{"location":"zh/user-guide/start_stop_connector/#_5","title":"\u652f\u6301\u7684\u5feb\u7167\u6a21\u5f0f","text":"\u6a21\u5f0f \u63cf\u8ff0 \u7528\u4f8b <code>always</code> \u6bcf\u6b21\u542f\u52a8\u65f6\u90fd\u8fdb\u884c\u5b8c\u6574\u5feb\u7167 \u5b8c\u6210\u6570\u636e\u9a8c\u8bc1 <code>initial</code> \u4ec5\u9650\u9996\u6b21\u5feb\u7167 \u6b63\u5e38\u64cd\u4f5c <code>initial_only</code> \u4e00\u6b21\u6027\u5feb\u7167\uff0c\u7136\u540e\u505c\u6b62 \u6570\u636e\u8fc1\u79fb <code>no_data</code> \u4ec5\u7ed3\u6784\uff0c\u65e0\u6570\u636e \u7ed3\u6784\u540c\u6b65 <code>never</code> \u8df3\u8fc7\u5feb\u7167\uff0c\u4ec5\u6d41\u5f0f\u4f20\u8f93 \u5b9e\u65f6\u66f4\u65b0 <code>recovery</code> \u4ece\u6e90\u91cd\u5efa \u707e\u96be\u6062\u590d <code>when_needed</code> \u6761\u4ef6\u5feb\u7167 \u81ea\u52a8\u6062\u590d <code>schemasync</code> \u4ec5\u7ed3\u6784\uff0c\u65e0\u6570\u636e\uff0c\u65e0 CDC \u6b63\u5e38\u64cd\u4f5c <p>\u8bf7\u53c2\u9605\u6559\u7a0b\uff0c\u4e86\u89e3\u4f55\u65f6\u4f7f\u7528\u4f55\u79cd\u6a21\u5f0f</p>"},{"location":"zh/user-guide/start_stop_connector/#_6","title":"\u6682\u505c\u548c\u6062\u590d\u8fde\u63a5\u5668","text":"<p>\u4f7f\u7528 <code>synchdb_pause_engine</code> \u6682\u505c\u8fde\u63a5\u5668\uff0c\u8fd9\u4f1a\u6682\u65f6\u505c\u6b62\u6b63\u5728\u8fd0\u884c\u7684\u8fde\u63a5\u5668\u3002 <pre><code>SELECT synchdb_pause_engine('mysqlconn');\n</code></pre></p> <p>\u4f7f\u7528 <code>synchdb_resume_engine</code> \u6062\u590d\u5df2\u6682\u505c\u7684\u8fde\u63a5\u5668\u3002 <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/start_stop_connector/#_7","title":"\u505c\u6b62\u6216\u91cd\u542f\u6b63\u5728\u8fd0\u884c\u7684\u8fde\u63a5\u5668","text":"<p>\u4f7f\u7528 <code>synchdb_stop_engine_bgw</code> \u505c\u6b62\u6b63\u5728\u8fd0\u884c\u7684\u8fde\u63a5\u5668\u3002 <pre><code>SELECT synchdb_stop_engine_bgw('mysqlconn');\n</code></pre></p> <p>\u4f7f\u7528 <code>synchdb_restart_connector</code> \u4ee5\u4e0d\u540c\u7684\u5feb\u7167\u6a21\u5f0f\u91cd\u542f\u6b63\u5728\u8fd0\u884c\u7684\u8fde\u63a5\u5668\u3002 <pre><code>-- \u4f7f\u7528\u7279\u5b9a\u5feb\u7167\u6a21\u5f0f\u91cd\u542f\nSELECT synchdb_restart_connector('mysqlconn', 'initial');\n\n-- \u4f7f\u7528\u7279\u5b9a\u5feb\u7167\u6a21\u5f0f\u542f\u52a8\nSELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/","title":"\u51fd\u6570\u53c2\u8003","text":"<p>\u6b64\u9875\u9762\u8bb0\u5f55\u4e86 SynchDB \u6dfb\u52a0\u7684\u6240\u6709 SQL \u51fd\u6570/\u89c6\u56fe\u3002</p>"},{"location":"zh/user-guide/utility_functions/#_2","title":"\u8fde\u63a5\u5668\u7ba1\u7406","text":""},{"location":"zh/user-guide/utility_functions/#synchdb_add_conninfo","title":"synchdb_add_conninfo","text":"<p>\u7528\u9014: \u521b\u5efa\u65b0\u7684\u8fde\u63a5\u5668\u914d\u7f6e</p> <p>\u53c2\u6570:</p> \u53c2\u6570 \u8bf4\u660e \u5fc5\u586b \u793a\u4f8b \u6ce8\u610f\u4e8b\u9879 <code>name</code> \u6b64\u8fde\u63a5\u5668\u7684\u552f\u4e00\u6807\u8bc6\u7b26 \u2713 <code>'mysqlconn'</code> \u5fc5\u987b\u5728\u6240\u6709\u8fde\u63a5\u5668\u4e2d\u552f\u4e00 <code>hostname</code> \u5f02\u6784\u6570\u636e\u5e93\u7684IP\u5730\u5740\u6216\u4e3b\u673a\u540d \u2713 <code>'127.0.0.1'</code> \u652f\u6301IPv4\u3001IPv6\u548c\u4e3b\u673a\u540d <code>port</code> \u6570\u636e\u5e93\u8fde\u63a5\u7aef\u53e3\u53f7 \u2713 <code>3306</code> \u9ed8\u8ba4\u503c: MySQL(3306), SQLServer(1433) <code>username</code> \u8eab\u4efd\u9a8c\u8bc1\u7528\u6237\u540d \u2713 <code>'mysqluser'</code> \u9700\u8981\u9002\u5f53\u7684\u6743\u9650 <code>password</code> \u8eab\u4efd\u9a8c\u8bc1\u5bc6\u7801 \u2713 <code>'mysqlpwd'</code> \u5b89\u5168\u5b58\u50a8 <code>source database</code> \u6e90\u6570\u636e\u5e93\u540d\u79f0 \u2713 <code>'inventory'</code> \u5fc5\u987b\u5b58\u5728\u4e8e\u6e90\u7cfb\u7edf\u4e2d <code>destination database</code> \u76ee\u6807PostgreSQL\u6570\u636e\u5e93 \u2713 <code>'postgres'</code> \uff08\u5df2\u5f03\u7528\uff09\u5c06\u59cb\u7ec8\u8c03\u6574\u4e3a SynchDB \u5b89\u88c5\u7684\u540c\u4e00\u6570\u636e\u5e93 <code>table</code> \u8868\u89c4\u8303\u6a21\u5f0f \u2610 <code>'[db].[table]'</code> \u7a7a=\u590d\u5236\u6240\u6709\u8868\uff0c\u652f\u6301\u6b63\u5219\u8868\u8fbe\u5f0f\uff08\u4f8b\u5982\uff0cmydb.testtable*\uff09\uff0c\u4f7f\u7528 <code>file:</code> \u524d\u7f00\u4f7f\u8fde\u63a5\u5668\u4ece JSON \u6587\u4ef6\u8bfb\u53d6\u8868\u5217\u8868\uff08\u4f8b\u5982\uff0cfile:/path/to/filelist.json\uff09\u3002\u6587\u4ef6\u683c\u5f0f\u89c1\u4e0b\u6587 <code>connector</code> \u8fde\u63a5\u5668\u7c7b\u578b(<code>mysql</code>/<code>sqlserver</code>) \u2713 <code>'mysql'</code> \u53c2\u89c1\u4e0a\u8ff0\u652f\u6301\u7684\u8fde\u63a5\u5668 <p>Table\u5217\u8868\u6587\u4ef6\u793a\u4f8b: <pre><code>{\n    \"table_list\":\n    [\n        \"mydb.table1\",\n        \"mydb.table2\",\n        \"mydb.table3\",\n        \"mydb.table4\"\n    ]\n}\n</code></pre></p> <p>\u4f7f\u7528\u793a\u4f8b: <pre><code>-- MySQL \u793a\u4f8b\nSELECT synchdb_add_conninfo(\n    'mysqlconn',    -- \u8fde\u63a5\u5668\u540d\u79f0\n    '127.0.0.1',    -- \u4e3b\u673a\n    3306,           -- \u7aef\u53e3\n    'mysqluser',    -- \u7528\u6237\u540d\n    'mysqlpwd',     -- \u5bc6\u7801\n    'inventory',    -- \u6e90\u6570\u636e\u5e93\n    'postgres',     -- \u76ee\u6807\u6570\u636e\u5e93\n    '',             -- \u8868\uff08\u7a7a\u8868\u793a\u5168\u90e8\uff09\n    'mysql',        -- \u8fde\u63a5\u5668\u7c7b\u578b\n    'myrule.json'   -- \u89c4\u5219\u6587\u4ef6\n);\n\n-- SQL Server \u793a\u4f8b\nSELECT synchdb_add_conninfo(\n    'sqlserverconn',\n    '127.0.0.1',\n    1433,\n    'sa',\n    'MyPassword123',\n    'testDB',\n    'postgres',\n    'dbo.orders',   -- \u6307\u5b9a\u8868\n    'sqlserver',\n    'mssql_rules.json'\n);\n\n-- Oracle \u793a\u4f8b\nSELECT synchdb_add_conninfo(\n    'oracleconn',\n    '127.0.0.1',\n    1521,\n    'c##dbzuser',\n    'dbz',\n    'mydb',\n    'postgres',\n    '',   -- all tables\n    'oracle'\n);\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_add_objmap","title":"synchdb_add_objmap","text":"<p>\u76ee\u7684\uff1a\u4e3a\u6bcf\u4e2a\u8fde\u63a5\u5668\u6dfb\u52a0\u4e00\u4e2a\u5bf9\u8c61\u6620\u5c04\u89c4\u5219</p> \u53c2\u6570 \u8bf4\u660e \u5fc5\u9700 \u793a\u4f8b \u6ce8\u91ca <code>name</code> \u6b64\u8fde\u63a5\u5668\u7684\u552f\u4e00\u6807\u8bc6\u7b26 \u2713 <code>'mysqlconn'</code> \u5fc5\u987b\u5728\u6240\u6709\u8fde\u63a5\u5668\u4e2d\u552f\u4e00 <code>object type</code> \u5bf9\u8c61\u6620\u5c04\u7684\u7c7b\u578b \u2713 <code>'table'</code> \u53ef\u4ee5\u662f <code>table</code> \u4ee5\u6620\u5c04\u8868\u540d\u3001<code>column</code> \u4ee5\u6620\u5c04\u5217\u540d\u3001<code>datatype</code> \u4ee5\u6620\u5c04\u6570\u636e\u7c7b\u578b\u6216 <code>transform</code> \u4ee5\u8fd0\u884c\u6570\u636e\u8f6c\u6362\u8868\u8fbe\u5f0f <code>source object</code> \u4ee5\u5b8c\u5168\u9650\u5b9a\u540d\u79f0\u8868\u793a\u7684\u6e90\u5bf9\u8c61 \u2713 <code>inventory.customers</code> \u8fdc\u7a0b\u6570\u636e\u5e93\u4e2d\u8868\u793a\u7684\u5bf9\u8c61\u540d\u79f0 <code>destination object</code> \u76ee\u6807\u5bf9\u8c61\u540d\u79f0 \u2713 <code>'schema1.people'</code> PostgreSQL \u7aef\u7684\u76ee\u6807\u5bf9\u8c61\u540d\u79f0\u3002\u53ef\u4ee5\u662f\u5b8c\u5168\u9650\u5b9a\u7684\u8868\u540d\u3001\u5217\u540d\u3001\u6570\u636e\u7c7b\u578b\u6216\u8f6c\u6362\u8868\u8fbe\u5f0f <p><pre><code>SELECT synchdb_add_objmap('mysqlconn','table','inventory.customers','schema1.people');\nSELECT synchdb_add_objmap('mysqlconn','column','inventory.customers.email','contact');\nSELECT synchdb_add_objmap('mysqlconn','datatype','point|false','text|0');\nSELECT synchdb_add_objmap('mysqlconn','datatype','inventory.geom.g','geometry|0');\nSELECT synchdb_add_objmap('mysqlconn','transform','inventory.products.name','''&gt;&gt;&gt;&gt;'' || ''%d'' || ''&lt;&lt;&lt;&lt;&lt;''');\n</code></pre> \u8868\u793a <code>table</code> \u6620\u5c04\u7684\u65b9\u5f0f\uff1a * <code>source object</code> \u8868\u793a\u8fdc\u7a0b\u6570\u636e\u5e93\u4e2d\u7684\u5b8c\u5168\u9650\u5b9a\u540d\u79f0\u7684\u8868 * <code>destination object</code> \u8868\u793a PostgreSQL \u4e2d\u7684\u8868\u540d\u3002\u5b83\u53ef\u4ee5\u53ea\u662f\u4e00\u4e2a\u540d\u79f0\uff08\u9ed8\u8ba4\u4e3a\u516c\u5171\u67b6\u6784\uff09\u6216 schema.name \u683c\u5f0f\u3002</p> <p>\u8868\u793a <code>column</code> \u6620\u5c04\u7684\u65b9\u5f0f\uff1a * <code>source object</code> \u8868\u793a\u8fdc\u7a0b\u6570\u636e\u5e93\u4e2d\u7684\u5b8c\u5168\u9650\u5b9a\u540d\u79f0\u7684\u5217 * <code>destination object</code> \u8868\u793a PostgreSQL \u4e2d\u7684\u5217\u540d\u3002\u65e0\u9700\u5c06\u5176\u683c\u5f0f\u5316\u4e3a\u5b8c\u5168\u9650\u5b9a\u7684\u5217\u540d\u3002</p> <p>\u8868\u793a <code>\u6570\u636e\u7c7b\u578b</code> \u6620\u5c04\u7684\u65b9\u5f0f\uff1a * <code>\u6e90\u5bf9\u8c61</code> \u53ef\u4ee5\u8868\u793a\u4e3a\u4ee5\u4e0b\u4e4b\u4e00\uff1a * \u5b8c\u5168\u9650\u5b9a\u7684\u5217 (inventory.geom.g)\u3002\u8fd9\u610f\u5473\u7740\u6570\u636e\u7c7b\u578b\u6620\u5c04\u4ec5\u9002\u7528\u4e8e\u6b64\u7279\u5b9a\u5217\u3002 * \u901a\u7528\u6570\u636e\u7c7b\u578b\u5b57\u7b26\u4e32 (int)\u3002\u5982\u679c\u5b83\u662f\u81ea\u52a8\u589e\u91cf\u6570\u636e\u7c7b\u578b (int|true \u8868\u793a\u81ea\u52a8\u589e\u91cf int) \u6216 (int|false \u8868\u793a\u975e\u81ea\u52a8\u589e\u91cf int)\uff0c\u8bf7\u4f7f\u7528\u7ba1\u9053 (|) \u6dfb\u52a0\u3002\u8fd9\u610f\u5473\u7740\u6570\u636e\u7c7b\u578b\u6620\u5c04\u9002\u7528\u4e8e\u5177\u6709\u5339\u914d\u6761\u4ef6\u7684\u6240\u6709\u6570\u636e\u7c7b\u578b\u3002</p> <ul> <li><code>\u76ee\u6807\u5bf9\u8c61</code> \u5e94\u8868\u793a\u4e3a PostgreSQL \u4e2d\u5b58\u5728\u7684\u901a\u7528\u6570\u636e\u7c7b\u578b\u5b57\u7b26\u4e32\u3002\u4f7f\u7528\u7ba1\u9053 (|) \u8986\u76d6\u5927\u5c0f\uff08text|0 \u5c06\u5927\u5c0f\u8986\u76d6\u4e3a 0\uff0c\u56e0\u4e3a\u6587\u672c\u662f\u53ef\u53d8\u5927\u5c0f\uff09\u6216\uff08varchar|-1 \u4f7f\u7528\u66f4\u6539\u4e8b\u4ef6\u9644\u5e26\u7684\u4efb\u4f55\u5927\u5c0f\uff09</li> </ul> <p>\u8868\u793a <code>transform</code> \u6620\u5c04\u7684\u65b9\u5f0f\uff1a * <code>source object</code> \u8868\u793a\u8981\u8f6c\u6362\u7684\u5217 * <code>destination object</code> \u8868\u793a\u5728\u5c06\u5217\u6570\u636e\u5e94\u7528\u4e8e PostgreSQL \u4e4b\u524d\u8981\u5728\u5217\u6570\u636e\u4e0a\u8fd0\u884c\u7684\u8868\u8fbe\u5f0f\u3002\u4f7f\u7528 %d \u4f5c\u4e3a\u8f93\u5165\u5217\u6570\u636e\u7684\u5360\u4f4d\u7b26\u3002\u5982\u679c\u662f\u51e0\u4f55\u7c7b\u578b\uff0c\u5219\u4f7f\u7528 %w \u8868\u793a WKB\uff0c\u4f7f\u7528 %s \u8868\u793a SRID\u3002</p>"},{"location":"zh/user-guide/utility_functions/#synchdb_add_extra_conninfo","title":"synchdb_add_extra_conninfo","text":"<p>\u7528\u9014\uff1a\u4e3a\u7531 <code>synchdb_add_conninfo</code> \u521b\u5efa\u7684\u73b0\u6709\u8fde\u63a5\u5668\u914d\u7f6e\u989d\u5916\u7684\u8fde\u63a5\u5668\u53c2\u6570</p> \u53c2\u6570 \u8bf4\u660e \u5fc5\u9700 \u793a\u4f8b \u6ce8\u91ca <code>name</code> \u6b64\u8fde\u63a5\u5668\u7684\u552f\u4e00\u6807\u8bc6\u7b26 \u2713 <code>'mysqlconn'</code> \u5fc5\u987b\u5728\u6240\u6709\u8fde\u63a5\u5668\u4e2d\u552f\u4e00 <code>ssl_mode</code> SSL \u6a21\u5f0f \u2610 <code>'verify_ca'</code> \u53ef\u4ee5\u662f\u4ee5\u4e0b\u4e4b\u4e00\uff1a<ul><li> \u201cdisabled\u201d - \u4e0d\u4f7f\u7528 SSL\u3002</li><li> \u201cpreferred\u201d - \u5982\u679c\u670d\u52a1\u5668\u652f\u6301\uff0c\u5219\u4f7f\u7528 SSL\u3002</li><li> \u201crequired\u201d - \u5fc5\u987b\u4f7f\u7528 SSL \u6765\u5efa\u7acb\u8fde\u63a5\u3002</li><li> \u201cverify_ca\u201d - \u8fde\u63a5\u5668\u4e0e\u670d\u52a1\u5668\u5efa\u7acb TLS\uff0c\u5e76\u5c06\u6839\u636e\u914d\u7f6e\u7684\u4fe1\u4efb\u5e93\u9a8c\u8bc1\u670d\u52a1\u5668\u7684 TLS \u8bc1\u4e66\u3002 </li><li> \u201cverify_identity\u201d - \u4e0e verify_ca \u884c\u4e3a\u76f8\u540c\uff0c\u4f46\u5b83\u8fd8\u4f1a\u68c0\u67e5\u670d\u52a1\u5668\u8bc1\u4e66\u7684\u901a\u7528\u540d\u79f0\u662f\u5426\u4e0e\u7cfb\u7edf\u7684\u4e3b\u673a\u540d\u5339\u914d\u3002 <code>ssl_keystore</code> \u5bc6\u94a5\u5e93\u8def\u5f84 \u2610 <code>/path/to/keystore</code> \u5bc6\u94a5\u5e93\u6587\u4ef6\u7684\u8def\u5f84 <code>ssl_keystore_pass</code> \u5bc6\u94a5\u5e93\u5bc6\u7801 \u2610 <code>'mykeystorepass'</code> \u8bbf\u95ee\u5bc6\u94a5\u5e93\u6587\u4ef6\u7684\u5bc6\u7801 <code>ssl_truststore</code> \u4fe1\u4efb\u5e93\u8def\u5f84 \u2610 <code>'/path/to/truststore'</code> \u4fe1\u4efb\u5e93\u6587\u4ef6\u7684\u8def\u5f84 <code>ssl_truststore_pass</code> \u4fe1\u4efb\u5e93\u5bc6\u7801 \u2610 <code>'mytruststorepass'</code> \u8bbf\u95ee\u4fe1\u4efb\u5e93\u6587\u4ef6\u7684\u5bc6\u7801 <pre><code>SELECT synchdb_add_extra_conninfo('mysqlconn', 'verify_ca', '/path/to/keystore', 'mykeystorepass', '/path/to/truststore', 'mytruststorepass');\n</code></pre>"},{"location":"zh/user-guide/utility_functions/#synchdb_del_extra_conninfo","title":"synchdb_del_extra_conninfo","text":"<p>\u7528\u9014\uff1a\u5220\u9664\u7531 <code>synchdb_add_extra_conninfo</code> \u521b\u5efa\u7684\u989d\u5916\u8fde\u63a5\u5668\u53c2\u6570 <pre><code>SELECT synchdb_del_extra_conninfo('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_del_conninfo","title":"synchdb_del_conninfo","text":"<p>\u7528\u9014\uff1a\u5220\u9664\u7531 <code>synchdb_add_conninfo</code> \u521b\u5efa\u7684\u8fde\u63a5\u5668\u4fe1\u606f <pre><code>SELECT synchdb_del_extra_conninfo('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_del_objmap","title":"synchdb_del_objmap","text":"<p>\u7528\u9014\uff1a\u7981\u7528\u7531 <code>synchdb_add_objmap</code> \u521b\u5efa\u7684\u5bf9\u8c61\u6620\u5c04\u8bb0\u5f55</p> <p>| \u53c2\u6570 | \u8bf4\u660e | \u5fc5\u9700 | \u793a\u4f8b | \u6ce8\u91ca | |:-:|:-|:-:|:-|:-|:-| | <code>name</code> | \u6b64\u8fde\u63a5\u5668\u7684\u552f\u4e00\u6807\u8bc6\u7b26 | \u2713 | <code>'mysqlconn'</code> |\u5fc5\u987b\u5728\u6240\u6709\u8fde\u63a5\u5668\u4e2d\u4fdd\u6301\u552f\u4e00 | | <code>object type</code> | \u5bf9\u8c61\u6620\u5c04\u7684\u7c7b\u578b | \u2713 | <code>'table'</code> | \u53ef\u4ee5\u662f <code>table</code> \u6765\u6620\u5c04\u8868\u540d\u3001<code>column</code> \u6765\u6620\u5c04\u5217\u540d\u3001<code>datatype</code> \u6765\u6620\u5c04\u6570\u636e\u7c7b\u578b\u6216 <code>transform</code> \u6765\u8fd0\u884c\u6570\u636e\u8f6c\u6362\u8868\u8fbe\u5f0f | | <code>source object</code> | \u4ee5\u5b8c\u5168\u9650\u5b9a\u540d\u79f0\u8868\u793a\u7684\u6e90\u5bf9\u8c61 | \u2713 | <code>inventory.customers</code> | \u8fdc\u7a0b\u6570\u636e\u5e93\u4e2d\u8868\u793a\u7684\u5bf9\u8c61\u540d\u79f0 |</p> <pre><code>SELECT synchdb_del_extra_conninfo('mysqlconn', 'transform', 'inventory.products.name');\n</code></pre>"},{"location":"zh/user-guide/utility_functions/#_3","title":"\u57fa\u672c\u63a7\u5236\u51fd\u6570","text":""},{"location":"zh/user-guide/utility_functions/#synchdb_start_engine_bgw","title":"synchdb_start_engine_bgw","text":"<p>\u7528\u9014: \u542f\u52a8\u8fde\u63a5\u5668 <pre><code>SELECT synchdb_start_engine_bgw('mysqlconn');\n</code></pre></p> <p>\u60a8\u8fd8\u53ef\u4ee5\u5305\u542b\u5feb\u7167\u6a21\u5f0f\u6765\u542f\u52a8\u8fde\u63a5\u5668\uff0c\u5426\u5219\u5c06\u9ed8\u8ba4\u4f7f\u7528\u201cinitial\u201d\u6a21\u5f0f\u3002\u8bf7\u53c2\u9605\u4e0b\u9762\u7684\u4e0d\u540c\u5feb\u7167\u6a21\u5f0f\u5217\u8868\u3002 <pre><code>-- \u6355\u83b7\u8868\u67b6\u6784\u5e76\u7ee7\u7eed\u4f20\u8f93\u65b0\u7684\u66f4\u6539\nSELECT synchdb_start_engine_bgw('mysqlconn', 'no_data');\n\n-- \u59cb\u7ec8\u91cd\u65b0\u6355\u83b7\u8868\u67b6\u6784\u3001\u73b0\u6709\u6570\u636e\u5e76\u7ee7\u7eed\u4f20\u8f93\u65b0\u7684\u66f4\u6539\nSELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_pause_engine","title":"synchdb_pause_engine","text":"<p>\u7528\u9014: \u6682\u505c\u8fd0\u884c\u4e2d\u7684\u8fde\u63a5\u5668 <pre><code>SELECT synchdb_pause_engine_bgw('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_resume_engine","title":"synchdb_resume_engine","text":"<p>\u7528\u9014: \u6062\u590d\u5df2\u6682\u505c\u7684\u8fde\u63a5\u5668 <pre><code>SELECT synchdb_resume_engine('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_stop_engine_bgw","title":"synchdb_stop_engine_bgw","text":"<p>\u7528\u9014: \u7ec8\u6b62\u8fde\u63a5\u5668 <pre><code>SELECT synchdb_stop_engine('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_reload_objmap","title":"synchdb_reload_objmap","text":"<p>\u76ee\u7684\uff1a\u4f7f\u8fde\u63a5\u5668\u518d\u6b21\u52a0\u8f7d\u5bf9\u8c61\u6620\u5c04\u89c4\u5219 <pre><code>SELECT synchdb_reload_objmap('mysqlconn');\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#_4","title":"\u72b6\u6001\u7ba1\u7406","text":""},{"location":"zh/user-guide/utility_functions/#synchdb_state_view","title":"synchdb_state_view","text":"<p>\u7528\u9014: \u76d1\u63a7\u8fde\u63a5\u5668\u72b6\u6001</p> <pre><code>SELECT * FROM synchdb_state_view();\n</code></pre> <p>\u8fd4\u56de\u5b57\u6bb5:</p> \u5b57\u6bb5 \u8bf4\u660e \u7c7b\u578b <code>name</code> \u5173\u8054\u7684\u8fde\u63a5\u5668\u540d\u79f0 Text <code>connector_type</code> \u8fde\u63a5\u5668\u7c7b\u578b(<code>mysql</code>\u6216<code>sqlserver</code>) Text <code>pid</code> \u5de5\u4f5c\u8fdb\u7a0bID Integer <code>stage</code> \u5f53\u524d\u8fde\u63a5\u5668\u9636\u6bb5 Text <code>state</code> \u5f53\u524d\u8fde\u63a5\u5668\u72b6\u6001 Text <code>err</code> \u6700\u65b0\u9519\u8bef\u6d88\u606f Text <code>last_dbz_offset</code> \u6700\u540e\u8bb0\u5f55\u7684Debezium\u504f\u79fb\u91cf JSON <p>\u53ef\u80fd\u7684\u72b6\u6001:</p> <ul> <li>\ud83d\udd34 <code>stopped</code> - \u5df2\u505c\u6b62</li> <li>\ud83d\udfe1 <code>initializing</code> - \u521d\u59cb\u5316\u4e2d</li> <li>\ud83d\udfe0 <code>paused</code> - \u5df2\u6682\u505c</li> <li>\ud83d\udfe2 <code>syncing</code> - \u4e3b\u52a8\u8f6e\u8be2\u4e2d</li> <li>\ud83d\udd35 <code>parsing</code> - \u89e3\u6790\u4e8b\u4ef6\u4e2d</li> <li>\ud83d\udfe3 <code>converting</code> - \u8f6c\u6362\u6570\u636e\u4e2d</li> <li>\u26aa <code>executing</code> - \u5e94\u7528\u66f4\u6539\u4e2d</li> <li>\ud83d\udfe4 <code>updating offset</code> - \u66f4\u65b0\u68c0\u67e5\u70b9\u4e2d</li> <li>\ud83d\udfe8 <code>restarting</code> - \u91cd\u542f\u4e2d</li> <li>\u26aa <code>dumping memory</code> - \u6b63\u5728\u8f93\u51fa JVM \u5185\u5b58\u4fe1\u606f\u5230 log \u6587\u4ef6</li> <li>\u26ab <code>unknown</code> - \u672a\u77e5\u72b6\u6001</li> </ul> <p>\u53ef\u80fd\u7684\u9636\u6bb5:</p> <ul> <li><code>initial snapshot</code> - \u8fde\u63a5\u5668\u6b63\u5728\u6267\u884c\u521d\u59cb\u5feb\u7167\uff08\u6784\u5efa\u8868\u67b6\u6784\u548c\u53ef\u9009\u7684\u521d\u59cb\u6570\u636e\uff09</li> <li><code>change data capture</code> - \u8fde\u63a5\u5668\u6b63\u5728\u6d41\u5f0f\u4f20\u8f93\u540e\u7eed\u8868\u53d8\u66f4\uff08CDC\uff09</li> <li><code>schema sync</code> - \u8fde\u63a5\u5668\u4ec5\u590d\u5236\u8868\u67b6\u6784</li> </ul>"},{"location":"zh/user-guide/utility_functions/#synchdb_stats_view","title":"synchdb_stats_view","text":"<p>\u7528\u9014\uff1a\u7d2f\u8ba1\u6536\u96c6\u8fde\u63a5\u5668\u5904\u7406\u7edf\u8ba1\u4fe1\u606f</p> <pre><code>SELECT * FROM synchdb_stats_view();\n</code></pre> \u5b57\u6bb5 \u8bf4\u660e \u7c7b\u578b name \u5173\u8054\u7684\u8fde\u63a5\u5668\u540d\u79f0 Text ddls \u5df2\u5b8c\u6210\u7684 DDL \u64cd\u4f5c\u6570 Bigint dmls \u5df2\u5b8c\u6210\u7684 DML \u64cd\u4f5c\u6570 Bigint reads \u521d\u59cb\u5feb\u7167\u9636\u6bb5\u5b8c\u6210\u7684 READ \u4e8b\u4ef6\u6570 Bigint creating CDC \u9636\u6bb5\u5b8c\u6210\u7684 CREATES \u4e8b\u4ef6\u6570 Bigint updates CDC \u9636\u6bb5\u5b8c\u6210\u7684 UPDATES \u4e8b\u4ef6\u6570 Bigint deletes CDC \u9636\u6bb5\u5b8c\u6210\u7684 DELETES \u4e8b\u4ef6\u6570 Bigint bad_events \u5ffd\u7565\u7684\u574f\u4e8b\u4ef6\u6570\uff08\u4f8b\u5982\u7a7a\u4e8b\u4ef6\u3001\u4e0d\u652f\u6301\u7684 DDL \u4e8b\u4ef6\u7b49\uff09 Bigint total_events \u5904\u7406\u7684\u4e8b\u4ef6\u603b\u6570\uff08\u5305\u62ec bad_events\uff09 Bigint batches_done \u5b8c\u6210\u7684\u6279\u6b21\u6570 Bigint avg_batch_size \u5e73\u5747\u6279\u6b21\u5927\u5c0f\uff08total_events / batches_done\uff09 Bigint"},{"location":"zh/user-guide/utility_functions/#synchdb_reset_stats","title":"synchdb_reset_stats","text":"<p>\u7528\u9014\uff1a\u91cd\u7f6e\u6307\u5b9a\u8fde\u63a5\u5668\u7684\u6240\u6709\u7edf\u8ba1\u4fe1\u606f</p> <pre><code>SELECT synchdb_reset_stats('mysqlconn');\n</code></pre>"},{"location":"zh/user-guide/utility_functions/#synchdb_set_offset","title":"synchdb_set_offset","text":"<p>\u7528\u9014: \u914d\u7f6e\u81ea\u5b9a\u4e49\u8d77\u59cb\u4f4d\u7f6e</p> <p>MySQL\u793a\u4f8b: <pre><code>SELECT synchdb_set_offset(\n    'mysqlconn', \n    '{\"ts_sec\":1725644339,\"file\":\"mysql-bin.000004\",\"pos\":138466,\"row\":1,\"server_id\":223344,\"event\":2}'\n);\n</code></pre></p> <p>SQL Server\u793a\u4f8b: <pre><code>SELECT synchdb_set_offset(\n    'sqlserverconn',\n    '{\"event_serial_no\":1,\"commit_lsn\":\"00000100:00000c00:0003\",\"change_lsn\":\"00000100:00000c00:0002\"}'\n);\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_log_jvm_meminfo","title":"synchdb_log_jvm_meminfo","text":"<p>\u7528\u9014: \u4f7f Java \u865a\u62df\u673a (JVM) \u8f93\u51fa\u5f53\u524dheap\u548cnon-heap\u4f7f\u7528\u60c5\u51b5\u7edf\u8ba1\u4fe1\u606f\u5230 PostgreSQL log \u6587\u4ef6\u3002 <pre><code>SELECT synchdb_log_jvm_meminfo('mysqlconn');\n</code></pre></p> <p>\u68c0\u67e5 PostgreSQL \u65e5\u5fd7\u6587\u4ef6\uff1a <pre><code>2024-12-09 14:34:21.910 PST [25491] LOG:  Requesting memdump for mysqlconn connector\n2024-12-09 14:34:21 WARN  DebeziumRunner:297 - Heap Memory:\n2024-12-09 14:34:21 WARN  DebeziumRunner:298 -   Used: 19272600 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:299 -   Committed: 67108864 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:300 -   Max: 2147483648 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:302 - Non-Heap Memory:\n2024-12-09 14:34:21 WARN  DebeziumRunner:303 -   Used: 42198864 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:304 -   Committed: 45023232 bytes\n2024-12-09 14:34:21 WARN  DebeziumRunner:305 -   Max: -1 bytes\n</code></pre></p>"},{"location":"zh/user-guide/utility_functions/#synchdb_att_view","title":"synchdb_att_view","text":"<p>\u7528\u9014\uff1a\u5e76\u6392\u663e\u793a\u8fde\u63a5\u5668\u7684\u6570\u636e\u7c7b\u578b\u3001\u540d\u79f0\u6620\u5c04\u548c\u5916\u90e8\u8868\u4e0e\u672c\u5730\u8868\u4e4b\u95f4\u7684\u8f6c\u6362\u89c4\u5219\u5173\u7cfb\u3002</p> <pre><code>SELECT * FROM synchdb_att_view();\n</code></pre> <p>\u8fd4\u56de\u5b57\u6bb5\uff1a</p> \u5b57\u6bb5 \u63cf\u8ff0 \u7c7b\u578b <code>name</code> \u8fde\u63a5\u5668\u6807\u8bc6\u7b26 \u6587\u672c <code>attnum</code> \u5c5e\u6027\u7f16\u53f7 \u6574\u6570 <code>ext_tbname</code> \u8fdc\u7a0b\u663e\u793a\u7684\u8868\u540d \u6587\u672c <code>pg_tbname</code> PostgreSQL \u4e2d\u7684\u6620\u5c04\u8868\u540d \u6587\u672c <code>ext_attname</code> \u8fdc\u7a0b\u663e\u793a\u7684\u5217\u540d \u6587\u672c <code>pg_attname</code> PostgreSQL \u4e2d\u7684\u6620\u5c04\u5217\u540d \u6587\u672c <code>ext_atttypename</code> \u8fdc\u7a0b\u663e\u793a\u7684\u6570\u636e\u7c7b\u578b \u6587\u672c <code>pg_atttypename</code> PostgreSQL \u4e2d\u7684\u6620\u5c04\u6570\u636e\u7c7b\u578b \u6587\u672c <code>transform</code> \u8f6c\u6362\u8868\u8fbe\u5f0f \u6587\u672c"},{"location":"zh/user-guide/utility_functions/#_5","title":"\u5feb\u7167\u7ba1\u7406","text":""},{"location":"zh/user-guide/utility_functions/#synchdb_restart_connector","title":"synchdb_restart_connector","text":"<p>\u7528\u9014: \u4f7f\u7528\u6307\u5b9a\u7684\u5feb\u7167\u6a21\u5f0f\u91cd\u65b0\u521d\u59cb\u5316\u8fde\u63a5\u5668</p> <p>\u5feb\u7167\u6a21\u5f0f:</p> \u6a21\u5f0f \u8bf4\u660e \u4f7f\u7528\u573a\u666f <code>always</code> \u6bcf\u6b21\u542f\u52a8\u65f6\u6267\u884c\u5b8c\u6574\u5feb\u7167 \u5b8c\u6574\u6570\u636e\u9a8c\u8bc1 <code>initial</code> \u4ec5\u9996\u6b21\u5feb\u7167 \u6b63\u5e38\u64cd\u4f5c <code>initial_only</code> \u6267\u884c\u4e00\u6b21\u5feb\u7167\u540e\u505c\u6b62 \u6570\u636e\u8fc1\u79fb <code>no_data</code> \u4ec5\u6355\u83b7\u8868\u7ed3\u6784\uff0c\u4e0d\u542b\u6570\u636e \u67b6\u6784\u540c\u6b65 <code>never</code> \u8df3\u8fc7\u5feb\u7167\uff0c\u76f4\u63a5\u5f00\u59cb\u6d41\u5f0f\u4f20\u8f93 \u5b9e\u65f6\u66f4\u65b0 <code>recovery</code> \u4ece\u6e90\u8868\u91cd\u5efa\u4e3b\u9898 \u707e\u96be\u6062\u590d <code>when_needed</code> \u6309\u9700\u6267\u884c\u5feb\u7167 \u81ea\u52a8\u6062\u590d <code>schemasync</code> \u4ec5\u7ed3\u6784\uff0c\u65e0\u6570\u636e\uff0c\u65e0 CDC \u6b63\u5e38\u64cd\u4f5c <p>\u793a\u4f8b: <pre><code>-- \u4f7f\u7528\u7279\u5b9a\u5feb\u7167\u6a21\u5f0f\u91cd\u542f\nSELECT synchdb_restart_connector('mysqlconn', 'initial');\n\n-- \u4f7f\u7528\u7279\u5b9a\u5feb\u7167\u6a21\u5f0f\u542f\u52a8\nSELECT synchdb_start_engine_bgw('mysqlconn', 'always');\n</code></pre></p> <p>\ud83d\udcdd \u9644\u52a0\u8bf4\u660e:</p> <ul> <li>\u542f\u52a8\u524d\u59cb\u7ec8\u9a8c\u8bc1\u8fde\u63a5\u5668\u914d\u7f6e</li> <li>\u5728\u5feb\u7167\u64cd\u4f5c\u671f\u95f4\u76d1\u63a7\u7cfb\u7edf\u8d44\u6e90</li> <li>\u5728\u8fdb\u884c\u91cd\u8981\u64cd\u4f5c\u524d\u5907\u4efdPostgreSQL\u76ee\u6807\u6570\u636e\u5e93</li> <li>\u6d4b\u8bd5\u4ecePostgreSQL\u670d\u52a1\u5668\u5230\u6e90\u6570\u636e\u5e93\u7684\u8fde\u63a5\u6027</li> <li>\u786e\u4fdd\u6e90\u6570\u636e\u5e93\u5df2\u914d\u7f6e\u6240\u9700\u6743\u9650</li> <li>\u5efa\u8bae\u5b9a\u671f\u76d1\u63a7\u9519\u8bef\u65e5\u5fd7</li> </ul>"},{"location":"zh/architecture/nom_native_datatype_handling/","title":"\u5904\u7406\u975e\u539f\u751f\u6570\u636e\u7c7b\u578b","text":""},{"location":"zh/architecture/nom_native_datatype_handling/#_2","title":"\u5904\u7406\u975e\u539f\u751f\u6570\u636e\u7c7b\u578b","text":"<p>\u8868\u53ef\u80fd\u5305\u542b\u7531\u7528\u6237\u81ea\u5b9a\u4e49\u521b\u5efa\u6216\u7531\u53e6\u4e00\u4e2a\u5df2\u5b89\u88c5\u7684\u6269\u5c55\u521b\u5efa\u7684\u5217\u6570\u636e\u7c7b\u578b\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e4b\u524d\u63d0\u5230\u7684\u539f\u751f\u6570\u636e\u7c7b\u578b\u5904\u7406\u5c06\u4e0d\u8d77\u4f5c\u7528\uff0c\u56e0\u4e3a\u8be5\u7c7b\u578b\u672a\u5217\u5728\u53d7\u652f\u6301\u7684\u539f\u751f\u6570\u636e\u7c7b\u578b\u5217\u8868\u4e2d\u3002\u76f8\u53cd\uff0cDML \u8f6c\u6362\u5668\u4f1a\u8bbf\u95eePG Catalog \u76ee\u5f55\uff0c\u83b7\u53d6\u975e\u539f\u751f\u6570\u636e\u7c7b\u578b\u7684 OID\uff0c\u5e76\u67e5\u627e\u5176\u5728 PostgreSQL \u4e2d\u5b9a\u4e49\u7684\u201c\u7c7b\u522b\u201d\u3002\u4ee5\u4e0b\u662f\u622a\u81f3\u7248\u672c 17 \u7684 PostgreSQL \u652f\u6301\u7684\u7c7b\u522b\u5217\u8868\uff1a</p> <pre><code>#define  TYPCATEGORY_INVALID  '\\0'\n#define  TYPCATEGORY_ARRAY    'A'\n#define  TYPCATEGORY_BOOLEAN  'B'\n#define  TYPCATEGORY_COMPOSITE  'C'\n#define  TYPCATEGORY_DATETIME 'D'\n#define  TYPCATEGORY_ENUM   'E'\n#define  TYPCATEGORY_GEOMETRIC  'G'\n#define  TYPCATEGORY_NETWORK  'I'\n#define  TYPCATEGORY_NUMERIC  'N'\n#define  TYPCATEGORY_PSEUDOTYPE 'P'\n#define  TYPCATEGORY_RANGE    'R'\n#define  TYPCATEGORY_STRING   'S'\n#define  TYPCATEGORY_TIMESPAN 'T'\n#define  TYPCATEGORY_USER   'U'\n#define  TYPCATEGORY_BITSTRING  'V'\n#define  TYPCATEGORY_UNKNOWN  'X'\n</code></pre> <p>\u7c7b\u522b\u4f1a\u544a\u8bc9 DML \u8f6c\u6362\u5668\u6570\u636e\u7c7b\u578b\u7684\u6027\u8d28\uff08\u6570\u5b57\uff1f\u5b57\u7b26\u4e32\uff1f\u65e5\u671f\u65f6\u95f4\uff1f...\u7b49\u7b49\uff09\uff0c\u4ee5\u5e2e\u52a9\u8f6c\u6362\u5668\u9009\u62e9\u6b63\u786e\u7684\u4f8b\u7a0b\u8fdb\u884c\u5904\u7406\u3002\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u7c7b\u522b\u4e0e\u63cf\u8ff0\u8f93\u5165\u6570\u636e\u683c\u5f0f\u7684 DBZ \u5143\u6570\u636e\u914d\u5bf9\u5c31\u8db3\u4ee5\u9009\u62e9\u6b63\u786e\u7684\u4f8b\u7a0b\u6765\u5904\u7406\u6570\u636e\u3002\u4f46\u662f\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u8fd9\u53ef\u80fd\u8fd8\u4e0d\u591f\u3002\u4f8b\u5982\uff0c\u81ea\u5b9a\u4e49 DATE\u3001TIME\u3001TIMESTAMP \u65e5\u671f\u7c7b\u578b\u90fd\u53ef\u4ee5\u5f52\u7c7b\u5728 <code>TYPCATEGORY_DATETIME</code> \u4e0b\uff0c\u56e0\u6b64\u8f6c\u6362\u5668\u4e0d\u77e5\u9053\u5b83\u662f\u5426\u6b63\u5728\u4f7f\u7528 DATE\u3001TIME \u6216 TIMESTAMP\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u7c7b\u578b\u90fd\u4f1a\u4ea7\u751f\u4e0d\u540c\u7684\u65f6\u95f4\u683c\u5f0f\u3002\u76ee\u524d\uff0c\u8f6c\u6362\u5668\u4f1a\u4ece\u6570\u636e\u7c7b\u578b\u540d\u79f0\u4e2d\u67e5\u627e\u67d0\u4e9b\u5173\u952e\u5b57\u6765\u8bc6\u522b\u3002\u5c06\u6765\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u516c\u5f00\u8fd9\u90e8\u5206\uff0c\u8ba9\u7528\u6237\u544a\u8bc9\u8f6c\u6362\u5668\u5728\u51fa\u73b0\u6b67\u4e49\u65f6\u5e94\u8be5\u4f7f\u7528\u54ea\u4e2a\u4f8b\u7a0b\u3002\u53e6\u4e00\u4e2a\u793a\u4f8b\u662f <code>TYPCATEGORY_USER</code> \u548c <code>TYPCATEGORY_GEOMETRIC</code>\uff0c\u5b83\u4eec\u6ca1\u6709\u6e05\u695a\u5730\u8868\u660e\u6570\u636e\u683c\u5f0f\u3002\u5bf9\u4e8e\u8fd9\u4e9b\u7c7b\u522b\uff0c\u8f6c\u6362\u5668\u76ee\u524d\u4e0d\u6267\u884c\u4efb\u4f55\u8fdb\u4e00\u6b65\u5904\u7406\uff0c\u56e0\u4e3a\u5b83\u53ea\u662f\u5c06\u6570\u636e\u8d1f\u8f7d\u4fdd\u6301\u539f\u6837\u3002PostgreSQL \u53ef\u80fd\u4f1a\u4e5f\u53ef\u80fd\u4e0d\u4f1a\u62d2\u7edd\u6b64\u7c7b\u672a\u5904\u7406\u7684\u6570\u636e\u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u63a5\u4e0b\u6765\u7684\u8f6c\u6362\u529f\u80fd\u5f88\u91cd\u8981\uff0c\u5b83\u4e3a DML \u8f6c\u6362\u5668\u63d0\u4f9b\u4e86\u6700\u540e\u4e00\u6b21\u7ea0\u6b63\u5176\u6570\u636e\u8d1f\u8f7d\u7684\u673a\u4f1a\u3002</p>"}]}